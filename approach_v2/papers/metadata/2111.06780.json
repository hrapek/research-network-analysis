{
    "abstract": "Value-based deep Reinforcement Learning (RL) algorithms suffer from the estimation bias primarily caused by function approximation and temporal difference (TD) learning. This problem induces faulty state-action value estimates and therefore harms the performance and robustness of the learning algorithms. Although several techniques were proposed to tackle, learning algorithms still suffer from this bias. Here, we introduce a technique that eliminates the estimation bias in off-policy continuous control algorithms using the experience replay mechanism. We adaptively learn the weighting hyper-parameter beta in the Weighted Twin Delayed Deep Deterministic Policy Gradient algorithm. Our method is named Adaptive-WD3 (AWD3). We show through continuous control environments of OpenAI gym that our algorithm matches or outperforms the state-of-the-art off-policy policy gradient learning algorithms.",
    "arxivId": "2111.06780",
    "authors": [
        {
            "authorId": "2127730684",
            "name": "Dogan C. Cicek",
            "url": "https://www.semanticscholar.org/author/2127730684"
        },
        {
            "authorId": "2127743985",
            "name": "Enes Duran",
            "url": "https://www.semanticscholar.org/author/2127743985"
        },
        {
            "authorId": "2127728640",
            "name": "Baturay Sa\u011flam",
            "url": "https://www.semanticscholar.org/author/2127728640"
        },
        {
            "authorId": "2140401362",
            "name": "Kagan Kaya",
            "url": "https://www.semanticscholar.org/author/2140401362"
        },
        {
            "authorId": "2127736071",
            "name": "Furkan B. Mutlu",
            "url": "https://www.semanticscholar.org/author/2127736071"
        },
        {
            "authorId": "1685178",
            "name": "S. Kozat",
            "url": "https://www.semanticscholar.org/author/1685178"
        }
    ],
    "citationVelocity": 0,
    "citations": [
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "153316233",
                    "name": "Xuesong Wang"
                },
                {
                    "authorId": "2142719112",
                    "name": "Jiazhi Zhang"
                },
                {
                    "authorId": "2112565542",
                    "name": "Yangyang Gu"
                },
                {
                    "authorId": "2111142270",
                    "name": "Longyang Huang"
                },
                {
                    "authorId": "2165326549",
                    "name": "Kun Yu"
                },
                {
                    "authorId": "33718755",
                    "name": "Yuhu Cheng"
                }
            ],
            "doi": "10.1109/TCDS.2023.3242274",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "aac10374a3c42c3b1337ee1950f4f144a8dc6c14",
            "title": "Alternated Greedy-Step Deterministic Policy Gradient",
            "url": "https://www.semanticscholar.org/paper/aac10374a3c42c3b1337ee1950f4f144a8dc6c14",
            "venue": "IEEE Transactions on Cognitive and Developmental Systems",
            "year": 2023
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2096673438",
                    "name": "Tamal Sarkar"
                },
                {
                    "authorId": "49558136",
                    "name": "Shobhanjana Kalita"
                }
            ],
            "doi": "10.1007/s42979-023-02326-7",
            "intent": [],
            "isInfluential": false,
            "paperId": "14376b861c15b11f310384cedbaf91a90fc45282",
            "title": "Bias Estimation Correction in Multi-Agent Reinforcement Learning for Mixed Cooperative-Competitive Environments",
            "url": "https://www.semanticscholar.org/paper/14376b861c15b11f310384cedbaf91a90fc45282",
            "venue": "SN Computer Science",
            "year": 2023
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2204218584",
                    "name": "Benjamin Smith"
                },
                {
                    "authorId": "2138773",
                    "name": "Anahita Khojandi"
                },
                {
                    "authorId": "2066228940",
                    "name": "Rama K. Vasudevan"
                }
            ],
            "doi": "10.1145/3609502",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "b28210a0a591fe104e32fbcb8a1617ebdf27ca95",
            "title": "Bias in Reinforcement Learning: A Review in Healthcare Applications",
            "url": "https://www.semanticscholar.org/paper/b28210a0a591fe104e32fbcb8a1617ebdf27ca95",
            "venue": "ACM Comput. Surv.",
            "year": 2023
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "1423724513",
                    "name": "M. Hebaish"
                },
                {
                    "authorId": "2061099244",
                    "name": "A. Hussein"
                },
                {
                    "authorId": "2145704",
                    "name": "Amr El Mougy"
                }
            ],
            "doi": "10.1109/VTC2022-Spring54318.2022.9860536",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "24155c63bbfa526f44d51ccc4ad321508354a0f1",
            "title": "Towards Safe and Efficient Modular Path Planning using Twin Delayed DDPG",
            "url": "https://www.semanticscholar.org/paper/24155c63bbfa526f44d51ccc4ad321508354a0f1",
            "venue": "2022 IEEE 95th Vehicular Technology Conference: (VTC2022-Spring)",
            "year": 2022
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2127728640",
                    "name": "Baturay Sa\u011flam"
                },
                {
                    "authorId": "2127736071",
                    "name": "Furkan B. Mutlu"
                },
                {
                    "authorId": "2177336931",
                    "name": "Kaan Gonc"
                },
                {
                    "authorId": "2161050823",
                    "name": "Onat Dalmaz"
                },
                {
                    "authorId": "1685178",
                    "name": "S. Kozat"
                }
            ],
            "doi": "10.1109/SIU55565.2022.9864957",
            "intent": [],
            "isInfluential": false,
            "paperId": "79a07b341a558424bdccf13dec632f03d06cf7a7",
            "title": "An Intrinsic Motivation Based Artificial Goal Generation in On-Policy Continuous Control",
            "url": "https://www.semanticscholar.org/paper/79a07b341a558424bdccf13dec632f03d06cf7a7",
            "venue": "2022 30th Signal Processing and Communications Applications Conference (SIU)",
            "year": 2022
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2127728640",
                    "name": "Baturay Sa\u011flam"
                },
                {
                    "authorId": "2127736071",
                    "name": "Furkan B. Mutlu"
                },
                {
                    "authorId": "2161050823",
                    "name": "Onat Dalmaz"
                },
                {
                    "authorId": "1685178",
                    "name": "S. Kozat"
                }
            ],
            "doi": "10.1109/SIU55565.2022.9864795",
            "intent": [],
            "isInfluential": false,
            "paperId": "b909ccbf7bef7b8918b342eda2d03dd0bd9a1a17",
            "title": "Unified Intrinsically Motivated Exploration for Off-Policy Learning in Continuous Action Spaces",
            "url": "https://www.semanticscholar.org/paper/b909ccbf7bef7b8918b342eda2d03dd0bd9a1a17",
            "venue": "2022 30th Signal Processing and Communications Applications Conference (SIU)",
            "year": 2022
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2127728640",
                    "name": "Baturay Sa\u011flam"
                },
                {
                    "authorId": "2161050823",
                    "name": "Onat Dalmaz"
                },
                {
                    "authorId": "2177336931",
                    "name": "Kaan Gonc"
                },
                {
                    "authorId": "1685178",
                    "name": "S. Kozat"
                }
            ],
            "doi": "10.1109/SIU55565.2022.9864786",
            "intent": [],
            "isInfluential": false,
            "paperId": "9aa3f532b656ba463089af0c4650342ba4992838",
            "title": "Improving the Performance of Batch-Constrained Reinforcement Learning in Continuous Action Domains via Generative Adversarial Networks",
            "url": "https://www.semanticscholar.org/paper/9aa3f532b656ba463089af0c4650342ba4992838",
            "venue": "2022 30th Signal Processing and Communications Applications Conference (SIU)",
            "year": 2022
        }
    ],
    "corpusId": 244102999,
    "doi": "10.1109/ICTAI52525.2021.00123",
    "fieldsOfStudy": [
        "Computer Science"
    ],
    "influentialCitationCount": 0,
    "isOpenAccess": true,
    "isPublisherLicensed": true,
    "is_open_access": true,
    "is_publisher_licensed": true,
    "numCitedBy": 7,
    "numCiting": 18,
    "paperId": "8e23f6faac92456683df9d6d70832cb385c80cab",
    "references": [
        {
            "arxivId": "2006.12622",
            "authors": [
                {
                    "authorId": "2152879770",
                    "name": "Qiang He"
                },
                {
                    "authorId": "1761961",
                    "name": "Xinwen Hou"
                }
            ],
            "doi": "10.1109/ICTAI50040.2020.00068",
            "intent": [
                "background",
                "methodology"
            ],
            "isInfluential": true,
            "paperId": "9198eb3a335aa6ba8758e908707df4b911d08753",
            "title": "WD3: Taming the Estimation Bias in Deep Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/9198eb3a335aa6ba8758e908707df4b911d08753",
            "venue": "2020 IEEE 32nd International Conference on Tools with Artificial Intelligence (ICTAI)",
            "year": 2020
        },
        {
            "arxivId": "2002.06487",
            "authors": [
                {
                    "authorId": "51305487",
                    "name": "Qingfeng Lan"
                },
                {
                    "authorId": "7303313",
                    "name": "Yangchen Pan"
                },
                {
                    "authorId": "2655967",
                    "name": "Alona Fyshe"
                },
                {
                    "authorId": "144542337",
                    "name": "Martha White"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "b9c529a242ffc453386befc6e95db204e7e9c603",
            "title": "Maxmin Q-learning: Controlling the Estimation Bias of Q-learning",
            "url": "https://www.semanticscholar.org/paper/b9c529a242ffc453386befc6e95db204e7e9c603",
            "venue": "ICLR",
            "year": 2020
        },
        {
            "arxivId": "1812.02900",
            "authors": [
                {
                    "authorId": "14637819",
                    "name": "Scott Fujimoto"
                },
                {
                    "authorId": "2462512",
                    "name": "D. Meger"
                },
                {
                    "authorId": "144368601",
                    "name": "Doina Precup"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "5285cb8faada5de8a92a47622950f6cfd476ac1d",
            "title": "Off-Policy Deep Reinforcement Learning without Exploration",
            "url": "https://www.semanticscholar.org/paper/5285cb8faada5de8a92a47622950f6cfd476ac1d",
            "venue": "ICML",
            "year": 2018
        },
        {
            "arxivId": "1812.02648",
            "authors": [
                {
                    "authorId": "7634925",
                    "name": "H. V. Hasselt"
                },
                {
                    "authorId": "2895238",
                    "name": "Yotam Doron"
                },
                {
                    "authorId": "3367628",
                    "name": "Florian Strub"
                },
                {
                    "authorId": "39357484",
                    "name": "Matteo Hessel"
                },
                {
                    "authorId": "2873921",
                    "name": "Nicolas Sonnerat"
                },
                {
                    "authorId": "3321484",
                    "name": "Joseph Modayil"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "6bc692616db7b1a7ef2ea7c270c893adfb57ed0e",
            "title": "Deep Reinforcement Learning and the Deadly Triad",
            "url": "https://www.semanticscholar.org/paper/6bc692616db7b1a7ef2ea7c270c893adfb57ed0e",
            "venue": "ArXiv",
            "year": 2018
        },
        {
            "arxivId": "1802.09477",
            "authors": [
                {
                    "authorId": "14637819",
                    "name": "Scott Fujimoto"
                },
                {
                    "authorId": "47662867",
                    "name": "H. V. Hoof"
                },
                {
                    "authorId": "2462512",
                    "name": "D. Meger"
                }
            ],
            "doi": null,
            "intent": [
                "background",
                "methodology"
            ],
            "isInfluential": true,
            "paperId": "4debb99c0c63bfaa97dd433bc2828e4dac81c48b",
            "title": "Addressing Function Approximation Error in Actor-Critic Methods",
            "url": "https://www.semanticscholar.org/paper/4debb99c0c63bfaa97dd433bc2828e4dac81c48b",
            "venue": "ICML",
            "year": 2018
        },
        {
            "arxivId": "1712.00378",
            "authors": [
                {
                    "authorId": "34758368",
                    "name": "Fabio Pardo"
                },
                {
                    "authorId": "80675449",
                    "name": "Arash Tavakoli"
                },
                {
                    "authorId": "6495683",
                    "name": "Vitaly Levdik"
                },
                {
                    "authorId": "1686032",
                    "name": "Petar Kormushev"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "b542d5f3973970902eab247154f74cc5abb5cbb4",
            "title": "Time Limits in Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/b542d5f3973970902eab247154f74cc5abb5cbb4",
            "venue": "ICML",
            "year": 2017
        },
        {
            "arxivId": "1709.06560",
            "authors": [
                {
                    "authorId": "40068904",
                    "name": "Peter Henderson"
                },
                {
                    "authorId": "18014232",
                    "name": "Riashat Islam"
                },
                {
                    "authorId": "143902541",
                    "name": "Philip Bachman"
                },
                {
                    "authorId": "145134886",
                    "name": "Joelle Pineau"
                },
                {
                    "authorId": "144368601",
                    "name": "Doina Precup"
                },
                {
                    "authorId": "2462512",
                    "name": "D. Meger"
                }
            ],
            "doi": "10.1609/aaai.v32i1.11694",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "33690ff21ef1efb576410e656f2e60c89d0307d6",
            "title": "Deep Reinforcement Learning that Matters",
            "url": "https://www.semanticscholar.org/paper/33690ff21ef1efb576410e656f2e60c89d0307d6",
            "venue": "AAAI",
            "year": 2017
        },
        {
            "arxivId": "1611.01929",
            "authors": [
                {
                    "authorId": "8412923",
                    "name": "Oron Anschel"
                },
                {
                    "authorId": "35712547",
                    "name": "Nir Baram"
                },
                {
                    "authorId": "1742179",
                    "name": "N. Shimkin"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "6ecb8a743f92db6c6b8691ab8e8aebbb06fb1b48",
            "title": "Averaged-DQN: Variance Reduction and Stabilization for Deep Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/6ecb8a743f92db6c6b8691ab8e8aebbb06fb1b48",
            "venue": "ICML",
            "year": 2016
        },
        {
            "arxivId": "1606.01540",
            "authors": [
                {
                    "authorId": "2065151121",
                    "name": "Greg Brockman"
                },
                {
                    "authorId": "34415167",
                    "name": "Vicki Cheung"
                },
                {
                    "authorId": "152877508",
                    "name": "Ludwig Pettersson"
                },
                {
                    "authorId": "2113526509",
                    "name": "Jonas Schneider"
                },
                {
                    "authorId": "47971768",
                    "name": "John Schulman"
                },
                {
                    "authorId": "2109541439",
                    "name": "Jie Tang"
                },
                {
                    "authorId": "2563432",
                    "name": "Wojciech Zaremba"
                }
            ],
            "doi": null,
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "2b10281297ee001a9f3f4ea1aa9bea6b638c27df",
            "title": "OpenAI Gym",
            "url": "https://www.semanticscholar.org/paper/2b10281297ee001a9f3f4ea1aa9bea6b638c27df",
            "venue": "ArXiv",
            "year": 2016
        },
        {
            "arxivId": "1509.06461",
            "authors": [
                {
                    "authorId": "7634925",
                    "name": "H. V. Hasselt"
                },
                {
                    "authorId": "35099444",
                    "name": "A. Guez"
                },
                {
                    "authorId": "145824029",
                    "name": "David Silver"
                }
            ],
            "doi": "10.1609/aaai.v30i1.10295",
            "intent": [
                "background",
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "3b9732bb07dc99bde5e1f9f75251c6ea5039373e",
            "title": "Deep Reinforcement Learning with Double Q-Learning",
            "url": "https://www.semanticscholar.org/paper/3b9732bb07dc99bde5e1f9f75251c6ea5039373e",
            "venue": "AAAI",
            "year": 2015
        },
        {
            "arxivId": "1509.02971",
            "authors": [
                {
                    "authorId": "2542999",
                    "name": "T. Lillicrap"
                },
                {
                    "authorId": "2323922",
                    "name": "Jonathan J. Hunt"
                },
                {
                    "authorId": "1863250",
                    "name": "A. Pritzel"
                },
                {
                    "authorId": "2801204",
                    "name": "N. Heess"
                },
                {
                    "authorId": "1968210",
                    "name": "Tom Erez"
                },
                {
                    "authorId": "2109481",
                    "name": "Yuval Tassa"
                },
                {
                    "authorId": "145824029",
                    "name": "David Silver"
                },
                {
                    "authorId": "1688276",
                    "name": "Daan Wierstra"
                }
            ],
            "doi": null,
            "intent": [
                "background",
                "methodology"
            ],
            "isInfluential": true,
            "paperId": "024006d4c2a89f7acacc6e4438d156525b60a98f",
            "title": "Continuous control with deep reinforcement learning",
            "url": "https://www.semanticscholar.org/paper/024006d4c2a89f7acacc6e4438d156525b60a98f",
            "venue": "ICLR",
            "year": 2015
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "3255983",
                    "name": "Volodymyr Mnih"
                },
                {
                    "authorId": "2645384",
                    "name": "K. Kavukcuoglu"
                },
                {
                    "authorId": "145824029",
                    "name": "David Silver"
                },
                {
                    "authorId": "2228824",
                    "name": "Andrei A. Rusu"
                },
                {
                    "authorId": "144056327",
                    "name": "J. Veness"
                },
                {
                    "authorId": "1792298",
                    "name": "Marc G. Bellemare"
                },
                {
                    "authorId": "1753223",
                    "name": "Alex Graves"
                },
                {
                    "authorId": "3137672",
                    "name": "Martin A. Riedmiller"
                },
                {
                    "authorId": "145600108",
                    "name": "A. Fidjeland"
                },
                {
                    "authorId": "2273072",
                    "name": "Georg Ostrovski"
                },
                {
                    "authorId": "48348688",
                    "name": "Stig Petersen"
                },
                {
                    "authorId": "50388928",
                    "name": "Charlie Beattie"
                },
                {
                    "authorId": "49813280",
                    "name": "Amir Sadik"
                },
                {
                    "authorId": "2460849",
                    "name": "Ioannis Antonoglou"
                },
                {
                    "authorId": "143776287",
                    "name": "Helen King"
                },
                {
                    "authorId": "2106164",
                    "name": "D. Kumaran"
                },
                {
                    "authorId": "1688276",
                    "name": "Daan Wierstra"
                },
                {
                    "authorId": "34313265",
                    "name": "S. Legg"
                },
                {
                    "authorId": "48987704",
                    "name": "D. Hassabis"
                }
            ],
            "doi": "10.1038/nature14236",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "340f48901f72278f6bf78a04ee5b01df208cc508",
            "title": "Human-level control through deep reinforcement learning",
            "url": "https://www.semanticscholar.org/paper/340f48901f72278f6bf78a04ee5b01df208cc508",
            "venue": "Nature",
            "year": 2015
        },
        {
            "arxivId": "1412.6980",
            "authors": [
                {
                    "authorId": "1726807",
                    "name": "Diederik P. Kingma"
                },
                {
                    "authorId": "2503659",
                    "name": "Jimmy Ba"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "a6cb366736791bcccc5c8639de5a8f9636bf87e8",
            "title": "Adam: A Method for Stochastic Optimization",
            "url": "https://www.semanticscholar.org/paper/a6cb366736791bcccc5c8639de5a8f9636bf87e8",
            "venue": "ICLR",
            "year": 2014
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "144832491",
                    "name": "E. Todorov"
                },
                {
                    "authorId": "1968210",
                    "name": "Tom Erez"
                },
                {
                    "authorId": "2109481",
                    "name": "Yuval Tassa"
                }
            ],
            "doi": "10.1109/IROS.2012.6386109",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "b354ee518bfc1ac0d8ac447eece9edb69e92eae1",
            "title": "MuJoCo: A physics engine for model-based control",
            "url": "https://www.semanticscholar.org/paper/b354ee518bfc1ac0d8ac447eece9edb69e92eae1",
            "venue": "2012 IEEE/RSJ International Conference on Intelligent Robots and Systems",
            "year": 2012
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "1710970",
                    "name": "S. Nadarajah"
                },
                {
                    "authorId": "32741853",
                    "name": "S. Kotz"
                }
            ],
            "doi": "10.1109/TVLSI.2007.912191",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "956f307c3b63528c88f5858aef1716cd402348fd",
            "title": "Exact Distribution of the Max/Min of Two Gaussian Random Variables",
            "url": "https://www.semanticscholar.org/paper/956f307c3b63528c88f5858aef1716cd402348fd",
            "venue": "IEEE Transactions on Very Large Scale Integration (VLSI) Systems",
            "year": 2008
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "1699645",
                    "name": "R. Sutton"
                }
            ],
            "doi": "10.1023/A:1022633531479",
            "intent": [],
            "isInfluential": false,
            "paperId": "a91635f8d0e7fb804efd1c38d9c24ee952ba7076",
            "title": "Learning to predict by the methods of temporal differences",
            "url": "https://www.semanticscholar.org/paper/a91635f8d0e7fb804efd1c38d9c24ee952ba7076",
            "venue": "Machine Learning",
            "year": 1988
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "144867807",
                    "name": "S. Thrun"
                },
                {
                    "authorId": "2149607686",
                    "name": "Anton Schwartz"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": true,
            "paperId": "26b8747eb4d7fb4d4fc45707606d5e969b9afb0c",
            "title": "Issues in Using Function Approximation for Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/26b8747eb4d7fb4d4fc45707606d5e969b9afb0c",
            "venue": "",
            "year": 1999
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2238176724",
                    "name": "R. S. Sutton"
                },
                {
                    "authorId": "1730590",
                    "name": "A. Barto"
                }
            ],
            "doi": "10.1109/TNN.1998.712192",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "97efafdb4a3942ab3efba53ded7413199f79c054",
            "title": "Reinforcement Learning: An Introduction",
            "url": "https://www.semanticscholar.org/paper/97efafdb4a3942ab3efba53ded7413199f79c054",
            "venue": "IEEE Trans. Neural Networks",
            "year": 1998
        }
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "title": "AWD3: Dynamic Reduction of the Estimation Bias",
    "topics": [],
    "url": "https://www.semanticscholar.org/paper/8e23f6faac92456683df9d6d70832cb385c80cab",
    "venue": "IEEE International Conference on Tools with Artificial Intelligence",
    "year": 2021
}
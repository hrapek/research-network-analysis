{
    "abstract": "Human beings are particularly good at reasoning and inference from just a few examples. When facing new tasks, humans will leverage knowledge and skills learned before, and quickly integrate them with the new task. In addition to learning by experimentation, human also learn socio-culturally through instructions and learning by example. In this way humans can learn much faster compared with most current artificial intelligence algorithms in many tasks. In this paper, we test the idea of speeding up machine learning through social learning. We argue that in solving real-world problems, especially when the task is designed by humans, and/or for humans, there are typically instructions from user manuals and/or human experts which give guidelines on how to better accomplish the tasks. We argue that these instructions have tremendous value in designing a reinforcement learning system which can learn in human fashion, and we test the idea by playing the Atari games Tennis and Pong. We experimentally demonstrate that the instructions provide key information about the task, which can be used to decompose the learning task into sub-systems and construct options for the temporally extended planning, and dramatically accelerate the learning process.",
    "arxivId": "1909.12465",
    "authors": [
        {
            "authorId": "2146052628",
            "name": "Hua Huang",
            "url": "https://www.semanticscholar.org/author/2146052628"
        },
        {
            "authorId": "144719476",
            "name": "Adrian Barbu",
            "url": "https://www.semanticscholar.org/author/144719476"
        }
    ],
    "citationVelocity": 0,
    "citations": [],
    "corpusId": 203591727,
    "doi": null,
    "fieldsOfStudy": [
        "Computer Science"
    ],
    "influentialCitationCount": 0,
    "isOpenAccess": false,
    "isPublisherLicensed": true,
    "is_open_access": false,
    "is_publisher_licensed": true,
    "numCitedBy": 0,
    "numCiting": 22,
    "paperId": "df3ac75ec8ad937b7e1d43d6e4f40aa0cfa6bc01",
    "references": [
        {
            "arxivId": "1811.12927",
            "authors": [
                {
                    "authorId": "2071658",
                    "name": "R. Mahjourian"
                },
                {
                    "authorId": "3111912",
                    "name": "N. Jaitly"
                },
                {
                    "authorId": "2849560",
                    "name": "N. Lazic"
                },
                {
                    "authorId": "1736651",
                    "name": "S. Levine"
                },
                {
                    "authorId": "1686788",
                    "name": "R. Miikkulainen"
                }
            ],
            "doi": "10.15781/T24J0BJ23",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "072fda4494b0d522c8e97f7f1ead38001a37c0d7",
            "title": "Hierarchical Policy Design for Sample-Efficient Learning of Robot Table Tennis Through Self-Play",
            "url": "https://www.semanticscholar.org/paper/072fda4494b0d522c8e97f7f1ead38001a37c0d7",
            "venue": "ArXiv",
            "year": 2018
        },
        {
            "arxivId": "1810.11583",
            "authors": [
                {
                    "authorId": "40497459",
                    "name": "M. Riemer"
                },
                {
                    "authorId": "46331912",
                    "name": "Miao Liu"
                },
                {
                    "authorId": "1699108",
                    "name": "G. Tesauro"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "51e7b68ca6f78e4a212af7c1d0c44382b38b9a85",
            "title": "Learning Abstract Options",
            "url": "https://www.semanticscholar.org/paper/51e7b68ca6f78e4a212af7c1d0c44382b38b9a85",
            "venue": "NeurIPS",
            "year": 2018
        },
        {
            "arxivId": "1805.08296",
            "authors": [
                {
                    "authorId": "7624658",
                    "name": "Ofir Nachum"
                },
                {
                    "authorId": "2046135",
                    "name": "S. Gu"
                },
                {
                    "authorId": "1697141",
                    "name": "Honglak Lee"
                },
                {
                    "authorId": "1736651",
                    "name": "S. Levine"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "39b7007e6f3dd0744833f292f07ed77973503bfd",
            "title": "Data-Efficient Hierarchical Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/39b7007e6f3dd0744833f292f07ed77973503bfd",
            "venue": "NeurIPS",
            "year": 2018
        },
        {
            "arxivId": "1803.00590",
            "authors": [
                {
                    "authorId": "145000658",
                    "name": "Hoang Minh Le"
                },
                {
                    "authorId": "48272707",
                    "name": "Nan Jiang"
                },
                {
                    "authorId": "40333747",
                    "name": "Alekh Agarwal"
                },
                {
                    "authorId": "144652072",
                    "name": "Miroslav Dud\u00edk"
                },
                {
                    "authorId": "1740159",
                    "name": "Yisong Yue"
                },
                {
                    "authorId": "1722360",
                    "name": "Hal Daum\u00e9"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "fb9693183bc74568c72188431c18cb2b07c87213",
            "title": "Hierarchical Imitation and Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/fb9693183bc74568c72188431c18cb2b07c87213",
            "venue": "ICML",
            "year": 2018
        },
        {
            "arxivId": "1802.10567",
            "authors": [
                {
                    "authorId": "3137672",
                    "name": "Martin A. Riedmiller"
                },
                {
                    "authorId": "49512734",
                    "name": "Roland Hafner"
                },
                {
                    "authorId": "2066153554",
                    "name": "Thomas Lampe"
                },
                {
                    "authorId": "2366050",
                    "name": "Michael Neunert"
                },
                {
                    "authorId": "3110620",
                    "name": "Jonas Degrave"
                },
                {
                    "authorId": "8023592",
                    "name": "T. Wiele"
                },
                {
                    "authorId": "3255983",
                    "name": "Volodymyr Mnih"
                },
                {
                    "authorId": "2801204",
                    "name": "N. Heess"
                },
                {
                    "authorId": "2060551",
                    "name": "Jost Tobias Springenberg"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "cab81775baae7ba2d056ebbc60437f2e03358ca3",
            "title": "Learning by Playing - Solving Sparse Reward Tasks from Scratch",
            "url": "https://www.semanticscholar.org/paper/cab81775baae7ba2d056ebbc60437f2e03358ca3",
            "venue": "ICML",
            "year": 2018
        },
        {
            "arxivId": "1710.02298",
            "authors": [
                {
                    "authorId": "39357484",
                    "name": "Matteo Hessel"
                },
                {
                    "authorId": "3321484",
                    "name": "Joseph Modayil"
                },
                {
                    "authorId": "7634925",
                    "name": "H. V. Hasselt"
                },
                {
                    "authorId": "1725157",
                    "name": "T. Schaul"
                },
                {
                    "authorId": "2273072",
                    "name": "Georg Ostrovski"
                },
                {
                    "authorId": "2605877",
                    "name": "Will Dabney"
                },
                {
                    "authorId": "48257711",
                    "name": "Dan Horgan"
                },
                {
                    "authorId": "1808897",
                    "name": "Bilal Piot"
                },
                {
                    "authorId": "37666967",
                    "name": "M. G. Azar"
                },
                {
                    "authorId": "145824029",
                    "name": "David Silver"
                }
            ],
            "doi": "10.1609/aaai.v32i1.11796",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "0ab3f7ecbdc5a33565a234215604a6ca9d155a33",
            "title": "Rainbow: Combining Improvements in Deep Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/0ab3f7ecbdc5a33565a234215604a6ca9d155a33",
            "venue": "AAAI",
            "year": 2017
        },
        {
            "arxivId": "1710.00459",
            "authors": [
                {
                    "authorId": "32019380",
                    "name": "Melrose Roderick"
                },
                {
                    "authorId": "21471370",
                    "name": "Christopher Grimm"
                },
                {
                    "authorId": "2913681",
                    "name": "Stefanie Tellex"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "55f730385016802dd6452a34d0271b5c47ded332",
            "title": "Deep Abstract Q-Networks",
            "url": "https://www.semanticscholar.org/paper/55f730385016802dd6452a34d0271b5c47ded332",
            "venue": "AAMAS",
            "year": 2017
        },
        {
            "arxivId": "1709.04571",
            "authors": [
                {
                    "authorId": "40638357",
                    "name": "J. Harb"
                },
                {
                    "authorId": "145180695",
                    "name": "Pierre-Luc Bacon"
                },
                {
                    "authorId": "26389489",
                    "name": "Martin Klissarov"
                },
                {
                    "authorId": "144368601",
                    "name": "Doina Precup"
                }
            ],
            "doi": "10.1609/aaai.v32i1.11831",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "96e81cabed55630f2ad3e1346300bd7a7a17f060",
            "title": "When Waiting is not an Option : Learning Options with a Deliberation Cost",
            "url": "https://www.semanticscholar.org/paper/96e81cabed55630f2ad3e1346300bd7a7a17f060",
            "venue": "AAAI",
            "year": 2017
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "48987704",
                    "name": "D. Hassabis"
                },
                {
                    "authorId": "2106164",
                    "name": "D. Kumaran"
                },
                {
                    "authorId": "2372244",
                    "name": "C. Summerfield"
                },
                {
                    "authorId": "46378362",
                    "name": "M. Botvinick"
                }
            ],
            "doi": "10.1016/j.neuron.2017.06.011",
            "intent": [],
            "isInfluential": false,
            "paperId": "5870d0edaaa0f28bbe657238febaaf1181e81378",
            "title": "Neuroscience-Inspired Artificial Intelligence",
            "url": "https://www.semanticscholar.org/paper/5870d0edaaa0f28bbe657238febaaf1181e81378",
            "venue": "Neuron",
            "year": 2017
        },
        {
            "arxivId": "1703.01161",
            "authors": [
                {
                    "authorId": "9948791",
                    "name": "A. Vezhnevets"
                },
                {
                    "authorId": "2217144",
                    "name": "Simon Osindero"
                },
                {
                    "authorId": "1725157",
                    "name": "T. Schaul"
                },
                {
                    "authorId": "2801204",
                    "name": "N. Heess"
                },
                {
                    "authorId": "3093886",
                    "name": "Max Jaderberg"
                },
                {
                    "authorId": "145824029",
                    "name": "David Silver"
                },
                {
                    "authorId": "2645384",
                    "name": "K. Kavukcuoglu"
                }
            ],
            "doi": null,
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "049c6e5736313374c6e594c34b9be89a3a09dced",
            "title": "FeUdal Networks for Hierarchical Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/049c6e5736313374c6e594c34b9be89a3a09dced",
            "venue": "ICML",
            "year": 2017
        },
        {
            "arxivId": "1703.00956",
            "authors": [
                {
                    "authorId": "40066857",
                    "name": "Marlos C. Machado"
                },
                {
                    "authorId": "1792298",
                    "name": "Marc G. Bellemare"
                },
                {
                    "authorId": "1687780",
                    "name": "Michael Bowling"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "8423cc50c18d68f797adaa4f571f5e4efbe325a5",
            "title": "A Laplacian Framework for Option Discovery in Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/8423cc50c18d68f797adaa4f571f5e4efbe325a5",
            "venue": "ICML",
            "year": 2017
        },
        {
            "arxivId": "1704.03012",
            "authors": [
                {
                    "authorId": "10104623",
                    "name": "Carlos Florensa"
                },
                {
                    "authorId": "144581158",
                    "name": "Yan Duan"
                },
                {
                    "authorId": "1689992",
                    "name": "P. Abbeel"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "3deecaee4ec1a37de3cb10420eaabff067669e17",
            "title": "Stochastic Neural Networks for Hierarchical Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/3deecaee4ec1a37de3cb10420eaabff067669e17",
            "venue": "ICLR",
            "year": 2016
        },
        {
            "arxivId": "1611.05397",
            "authors": [
                {
                    "authorId": "3093886",
                    "name": "Max Jaderberg"
                },
                {
                    "authorId": "3255983",
                    "name": "Volodymyr Mnih"
                },
                {
                    "authorId": "144792148",
                    "name": "Wojciech M. Czarnecki"
                },
                {
                    "authorId": "1725157",
                    "name": "T. Schaul"
                },
                {
                    "authorId": "1700356",
                    "name": "Joel Z. Leibo"
                },
                {
                    "authorId": "145824029",
                    "name": "David Silver"
                },
                {
                    "authorId": "2645384",
                    "name": "K. Kavukcuoglu"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "d7bd6e3addd8bc8e2e154048300eea15f030ed33",
            "title": "Reinforcement Learning with Unsupervised Auxiliary Tasks",
            "url": "https://www.semanticscholar.org/paper/d7bd6e3addd8bc8e2e154048300eea15f030ed33",
            "venue": "ICLR",
            "year": 2016
        },
        {
            "arxivId": "1609.05140",
            "authors": [
                {
                    "authorId": "145180695",
                    "name": "Pierre-Luc Bacon"
                },
                {
                    "authorId": "40638357",
                    "name": "J. Harb"
                },
                {
                    "authorId": "144368601",
                    "name": "Doina Precup"
                }
            ],
            "doi": "10.1609/aaai.v31i1.10916",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "15b26d8cb35d7e795c8832fe08794224ee1e9f84",
            "title": "The Option-Critic Architecture",
            "url": "https://www.semanticscholar.org/paper/15b26d8cb35d7e795c8832fe08794224ee1e9f84",
            "venue": "AAAI",
            "year": 2016
        },
        {
            "arxivId": "1606.01540",
            "authors": [
                {
                    "authorId": "2065151121",
                    "name": "Greg Brockman"
                },
                {
                    "authorId": "34415167",
                    "name": "Vicki Cheung"
                },
                {
                    "authorId": "152877508",
                    "name": "Ludwig Pettersson"
                },
                {
                    "authorId": "2113526509",
                    "name": "Jonas Schneider"
                },
                {
                    "authorId": "47971768",
                    "name": "John Schulman"
                },
                {
                    "authorId": "2109541439",
                    "name": "Jie Tang"
                },
                {
                    "authorId": "2563432",
                    "name": "Wojciech Zaremba"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "2b10281297ee001a9f3f4ea1aa9bea6b638c27df",
            "title": "OpenAI Gym",
            "url": "https://www.semanticscholar.org/paper/2b10281297ee001a9f3f4ea1aa9bea6b638c27df",
            "venue": "ArXiv",
            "year": 2016
        },
        {
            "arxivId": "1604.06057",
            "authors": [
                {
                    "authorId": "1954876",
                    "name": "Tejas D. Kulkarni"
                },
                {
                    "authorId": "144958935",
                    "name": "Karthik Narasimhan"
                },
                {
                    "authorId": "3231182",
                    "name": "A. Saeedi"
                },
                {
                    "authorId": "1763295",
                    "name": "J. Tenenbaum"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "d37620e6f8fe678a43e12930743281cd8cca6a66",
            "title": "Hierarchical Deep Reinforcement Learning: Integrating Temporal Abstraction and Intrinsic Motivation",
            "url": "https://www.semanticscholar.org/paper/d37620e6f8fe678a43e12930743281cd8cca6a66",
            "venue": "NIPS",
            "year": 2016
        },
        {
            "arxivId": "1909.01561",
            "authors": [
                {
                    "authorId": "2373318",
                    "name": "B. Lake"
                },
                {
                    "authorId": "37774552",
                    "name": "T. Ullman"
                },
                {
                    "authorId": "1763295",
                    "name": "J. Tenenbaum"
                },
                {
                    "authorId": "1831199",
                    "name": "S. Gershman"
                }
            ],
            "doi": "10.1017/S0140525X17000140",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "5f0625c30014c12f333eb518268647673d18f9f1",
            "title": "What can the brain teach us about building artificial intelligence?",
            "url": "https://www.semanticscholar.org/paper/5f0625c30014c12f333eb518268647673d18f9f1",
            "venue": "Behavioral and Brain Sciences",
            "year": 2016
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "3255983",
                    "name": "Volodymyr Mnih"
                },
                {
                    "authorId": "2645384",
                    "name": "K. Kavukcuoglu"
                },
                {
                    "authorId": "145824029",
                    "name": "David Silver"
                },
                {
                    "authorId": "2228824",
                    "name": "Andrei A. Rusu"
                },
                {
                    "authorId": "144056327",
                    "name": "J. Veness"
                },
                {
                    "authorId": "1792298",
                    "name": "Marc G. Bellemare"
                },
                {
                    "authorId": "1753223",
                    "name": "Alex Graves"
                },
                {
                    "authorId": "3137672",
                    "name": "Martin A. Riedmiller"
                },
                {
                    "authorId": "145600108",
                    "name": "A. Fidjeland"
                },
                {
                    "authorId": "2273072",
                    "name": "Georg Ostrovski"
                },
                {
                    "authorId": "48348688",
                    "name": "Stig Petersen"
                },
                {
                    "authorId": "50388928",
                    "name": "Charlie Beattie"
                },
                {
                    "authorId": "49813280",
                    "name": "Amir Sadik"
                },
                {
                    "authorId": "2460849",
                    "name": "Ioannis Antonoglou"
                },
                {
                    "authorId": "143776287",
                    "name": "Helen King"
                },
                {
                    "authorId": "2106164",
                    "name": "D. Kumaran"
                },
                {
                    "authorId": "1688276",
                    "name": "Daan Wierstra"
                },
                {
                    "authorId": "34313265",
                    "name": "S. Legg"
                },
                {
                    "authorId": "48987704",
                    "name": "D. Hassabis"
                }
            ],
            "doi": "10.1038/nature14236",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "340f48901f72278f6bf78a04ee5b01df208cc508",
            "title": "Human-level control through deep reinforcement learning",
            "url": "https://www.semanticscholar.org/paper/340f48901f72278f6bf78a04ee5b01df208cc508",
            "venue": "Nature",
            "year": 2015
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "1765407",
                    "name": "G. Konidaris"
                },
                {
                    "authorId": "1795401",
                    "name": "Sarah Osentoski"
                },
                {
                    "authorId": "143640165",
                    "name": "P. Thomas"
                }
            ],
            "doi": "10.1609/aaai.v25i1.7903",
            "intent": [],
            "isInfluential": false,
            "paperId": "c29b7798b6839b84b87b4910f6263ee5a89f9279",
            "title": "Value Function Approximation in Reinforcement Learning Using the Fourier Basis",
            "url": "https://www.semanticscholar.org/paper/c29b7798b6839b84b87b4910f6263ee5a89f9279",
            "venue": "AAAI",
            "year": 2011
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "1699645",
                    "name": "R. Sutton"
                },
                {
                    "authorId": "144368601",
                    "name": "Doina Precup"
                },
                {
                    "authorId": "1699868",
                    "name": "Satinder Singh"
                }
            ],
            "doi": "10.1016/S0004-3702(99)00052-1",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "0e7638dc16a5e5e9e46c91272bfb9c3dd242ef6d",
            "title": "Between MDPs and Semi-MDPs: A Framework for Temporal Abstraction in Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/0e7638dc16a5e5e9e46c91272bfb9c3dd242ef6d",
            "venue": "Artif. Intell.",
            "year": 1999
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "1790646",
                    "name": "P. Dayan"
                },
                {
                    "authorId": "1695689",
                    "name": "Geoffrey E. Hinton"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "1678bd32846b1aded5b1e80a617170812e80f562",
            "title": "Feudal Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/1678bd32846b1aded5b1e80a617170812e80f562",
            "venue": "NIPS",
            "year": 1992
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2440249",
                    "name": "Pedro Tsividis"
                },
                {
                    "authorId": "51907782",
                    "name": "Thomas Pouncy"
                },
                {
                    "authorId": "39689742",
                    "name": "J. L. Xu"
                },
                {
                    "authorId": "1763295",
                    "name": "J. Tenenbaum"
                },
                {
                    "authorId": "1831199",
                    "name": "S. Gershman"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "6d7a36eeb9b5dd4276de9753c997fc6f5ba99259",
            "title": "Human Learning in Atari",
            "url": "https://www.semanticscholar.org/paper/6d7a36eeb9b5dd4276de9753c997fc6f5ba99259",
            "venue": "AAAI Spring Symposia",
            "year": 2017
        }
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        },
        {
            "category": "Psychology",
            "source": "s2-fos-model"
        }
    ],
    "title": "Playing Atari Ball Games with Hierarchical Reinforcement Learning",
    "topics": [
        {
            "topic": "Reinforcement learning",
            "topicId": "2557",
            "url": "https://www.semanticscholar.org/topic/2557"
        },
        {
            "topic": "Atari",
            "topicId": "20108",
            "url": "https://www.semanticscholar.org/topic/20108"
        },
        {
            "topic": "Artificial intelligence",
            "topicId": "8286",
            "url": "https://www.semanticscholar.org/topic/8286"
        },
        {
            "topic": "Machine learning",
            "topicId": "168",
            "url": "https://www.semanticscholar.org/topic/168"
        },
        {
            "topic": "Experiment",
            "topicId": "378",
            "url": "https://www.semanticscholar.org/topic/378"
        },
        {
            "topic": "Humans",
            "topicId": "732",
            "url": "https://www.semanticscholar.org/topic/732"
        },
        {
            "topic": "Algorithm",
            "topicId": "305",
            "url": "https://www.semanticscholar.org/topic/305"
        }
    ],
    "url": "https://www.semanticscholar.org/paper/df3ac75ec8ad937b7e1d43d6e4f40aa0cfa6bc01",
    "venue": "arXiv.org",
    "year": 2019
}
{
    "abstract": "We consider the finite horizon continuous reinforcement learning problem. Our contribution is three-fold. First,we give a tractable algorithm based on optimistic value iteration for the problem. Next,we give a lower bound on regret of order \u03a9(T^2/3) for any algorithm discretizes the state space, improving the previous regret bound of \u03a9(T^1/2) of Ortner and Ryabko [1] for the same problem. Next,under the assumption that the rewards and transitions are H\u00f6lder Continuous we show that the upper bound on the discretization error is const.Ln^-\u03b1 T. Finally,we give some simple experiments to validate our propositions.",
    "arxivId": "1906.11245",
    "authors": [
        {
            "authorId": "150259692",
            "name": "Phanideep Gampa",
            "url": "https://www.semanticscholar.org/author/150259692"
        },
        {
            "authorId": "150300036",
            "name": "Sairam Satwik Kondamudi",
            "url": "https://www.semanticscholar.org/author/150300036"
        },
        {
            "authorId": "103463506",
            "name": "L. Kailasam",
            "url": "https://www.semanticscholar.org/author/103463506"
        }
    ],
    "citationVelocity": 0,
    "citations": [
        {
            "arxivId": "2107.03635",
            "authors": [
                {
                    "authorId": "2112720838",
                    "name": "Yi Xiong"
                },
                {
                    "authorId": "2959816",
                    "name": "Ningyuan Chen"
                },
                {
                    "authorId": "49779805",
                    "name": "Xuefeng Gao"
                },
                {
                    "authorId": "50177340",
                    "name": "Xiang Zhou"
                }
            ],
            "doi": "10.1111/poms.13778",
            "intent": [],
            "isInfluential": false,
            "paperId": "c092ff39c65a12bfc426f6a5ad20a4b656539609",
            "title": "Sublinear regret for learning POMDPs",
            "url": "https://www.semanticscholar.org/paper/c092ff39c65a12bfc426f6a5ad20a4b656539609",
            "venue": "Production and Operations Management",
            "year": 2021
        }
    ],
    "corpusId": 195699758,
    "doi": "10.1109/ICoIAS.2019.00018",
    "fieldsOfStudy": [
        "Computer Science"
    ],
    "influentialCitationCount": 0,
    "isOpenAccess": true,
    "isPublisherLicensed": true,
    "is_open_access": true,
    "is_publisher_licensed": true,
    "numCitedBy": 1,
    "numCiting": 13,
    "paperId": "51a2127ebe0ac0e7d658e92bbf7dc453e26101bc",
    "references": [
        {
            "arxivId": "1703.05449",
            "authors": [
                {
                    "authorId": "37666967",
                    "name": "M. G. Azar"
                },
                {
                    "authorId": "2561924",
                    "name": "Ian Osband"
                },
                {
                    "authorId": "1708654",
                    "name": "R. Munos"
                }
            ],
            "doi": null,
            "intent": [
                "background",
                "methodology"
            ],
            "isInfluential": true,
            "paperId": "67d10cea808937089d6492acff14ad9ef156e3c5",
            "title": "Minimax Regret Bounds for Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/67d10cea808937089d6492acff14ad9ef156e3c5",
            "venue": "ICML",
            "year": 2017
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "33578174",
                    "name": "K. Lakshmanan"
                },
                {
                    "authorId": "1786887",
                    "name": "R. Ortner"
                },
                {
                    "authorId": "1757258",
                    "name": "D. Ryabko"
                }
            ],
            "doi": null,
            "intent": [
                "background",
                "methodology"
            ],
            "isInfluential": true,
            "paperId": "d3aaa9dd1c1a3b07c613a69466c86e6443babac4",
            "title": "Improved Regret Bounds for Undiscounted Continuous Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/d3aaa9dd1c1a3b07c613a69466c86e6443babac4",
            "venue": "ICML",
            "year": 2015
        },
        {
            "arxivId": "1406.1853",
            "authors": [
                {
                    "authorId": "2561924",
                    "name": "Ian Osband"
                },
                {
                    "authorId": "1731282",
                    "name": "Benjamin Van Roy"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "8783688bfe249bd1cab13146a76ba50fe88128c7",
            "title": "Model-based Reinforcement Learning and the Eluder Dimension",
            "url": "https://www.semanticscholar.org/paper/8783688bfe249bd1cab13146a76ba50fe88128c7",
            "venue": "NIPS",
            "year": 2014
        },
        {
            "arxivId": "1302.2550",
            "authors": [
                {
                    "authorId": "1786887",
                    "name": "R. Ortner"
                },
                {
                    "authorId": "1757258",
                    "name": "D. Ryabko"
                }
            ],
            "doi": null,
            "intent": [
                "background",
                "methodology"
            ],
            "isInfluential": true,
            "paperId": "91bd5deb13e9487a69b347c71788c3d60acd73cf",
            "title": "Online Regret Bounds for Undiscounted Continuous Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/91bd5deb13e9487a69b347c71788c3d60acd73cf",
            "venue": "NIPS",
            "year": 2012
        },
        {
            "arxivId": "1303.5984",
            "authors": [
                {
                    "authorId": "145424823",
                    "name": "M. Ibrahimi"
                },
                {
                    "authorId": "2548570",
                    "name": "Adel Javanmard"
                },
                {
                    "authorId": "1731282",
                    "name": "Benjamin Van Roy"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "58f4aeb87f2e52ab5a88cf207edcf1b7e56d500b",
            "title": "Efficient Reinforcement Learning for High Dimensional Linear Quadratic Systems",
            "url": "https://www.semanticscholar.org/paper/58f4aeb87f2e52ab5a88cf207edcf1b7e56d500b",
            "venue": "NIPS",
            "year": 2012
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "40396948",
                    "name": "A. Bernstein"
                },
                {
                    "authorId": "1742179",
                    "name": "N. Shimkin"
                }
            ],
            "doi": "10.1007/s10994-010-5186-7",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "07e3a5831bbd73cf3e40e16bc727451337d8a1f6",
            "title": "Adaptive-resolution reinforcement learning with\u00a0polynomial exploration in deterministic domains",
            "url": "https://www.semanticscholar.org/paper/07e3a5831bbd73cf3e40e16bc727451337d8a1f6",
            "venue": "Machine Learning",
            "year": 2010
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2563117",
                    "name": "E. Brunskill"
                },
                {
                    "authorId": "1700606",
                    "name": "Bethany R. Leffler"
                },
                {
                    "authorId": "47681372",
                    "name": "Lihong Li"
                },
                {
                    "authorId": "144885169",
                    "name": "M. Littman"
                },
                {
                    "authorId": "143724999",
                    "name": "N. Roy"
                }
            ],
            "doi": "10.5555/1577069.1755851",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "9e6f4510e865c10d2d7a0a2c36ee671fe156e729",
            "title": "Provably Efficient Learning with Typed Parametric Models",
            "url": "https://www.semanticscholar.org/paper/9e6f4510e865c10d2d7a0a2c36ee671fe156e729",
            "venue": "J. Mach. Learn. Res.",
            "year": 2009
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2137760143",
                    "name": "Thomas Jaksch"
                },
                {
                    "authorId": "1786887",
                    "name": "R. Ortner"
                },
                {
                    "authorId": "144543541",
                    "name": "P. Auer"
                }
            ],
            "doi": "10.5555/1756006.1859902",
            "intent": [
                "background",
                "methodology"
            ],
            "isInfluential": true,
            "paperId": "0cafe2903b097fc042782c359cb231ea34ef7ed3",
            "title": "Near-optimal Regret Bounds for Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/0cafe2903b097fc042782c359cb231ea34ef7ed3",
            "venue": "J. Mach. Learn. Res.",
            "year": 2008
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "1990806",
                    "name": "Alexander L. Strehl"
                },
                {
                    "authorId": "144885169",
                    "name": "M. Littman"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "913de703dda29eafd014201387a761ee8604f8d7",
            "title": "Online Linear Regression and Its Application to Model-Based Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/913de703dda29eafd014201387a761ee8604f8d7",
            "venue": "NIPS",
            "year": 2007
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "1388837087",
                    "name": "Yasin Abbasi-Yadkori"
                },
                {
                    "authorId": "40868287",
                    "name": "Csaba Szepesvari"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "3f99769ca3f0e3f41a239a1b58adf26bb930b9b2",
            "title": "Off-policy Learning with Options and Recognizers",
            "url": "https://www.semanticscholar.org/paper/3f99769ca3f0e3f41a239a1b58adf26bb930b9b2",
            "venue": "NIPS",
            "year": 2005
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "144695232",
                    "name": "S. Kakade"
                },
                {
                    "authorId": "81338045",
                    "name": "Michael Kearns"
                },
                {
                    "authorId": "144162125",
                    "name": "J. Langford"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "6bddcc4ff63e80fe576d379776284ede0be0a80c",
            "title": "Exploration in Metric State Spaces",
            "url": "https://www.semanticscholar.org/paper/6bddcc4ff63e80fe576d379776284ede0be0a80c",
            "venue": "ICML",
            "year": 2003
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "1399121447",
                    "name": "O. Hern\u00e1ndez-Lerma"
                },
                {
                    "authorId": "4141450",
                    "name": "J. Lasserre"
                }
            ],
            "doi": "10.1007/978-1-4612-0729-0",
            "intent": [],
            "isInfluential": false,
            "paperId": "313b17d9c66ad760e8152e3c915ccf455d0385de",
            "title": "Discrete-time Markov control processes",
            "url": "https://www.semanticscholar.org/paper/313b17d9c66ad760e8152e3c915ccf455d0385de",
            "venue": "",
            "year": 1999
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "34793579",
                    "name": "W. Fleming"
                }
            ],
            "doi": "10.1090/s0273-0979-97-00708-8",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "ee1cf4e0fb20a51541c63000ffe190987708c28a",
            "title": "Book Review: Discrete-time Markov control processes: Basic optimality criteria",
            "url": "https://www.semanticscholar.org/paper/ee1cf4e0fb20a51541c63000ffe190987708c28a",
            "venue": "",
            "year": 1997
        }
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        },
        {
            "category": "Mathematics",
            "source": "s2-fos-model"
        }
    ],
    "title": "A Tractable Algorithm for Finite-Horizon Continuous Reinforcement Learning",
    "topics": [
        {
            "topic": "Algorithm",
            "topicId": "305",
            "url": "https://www.semanticscholar.org/topic/305"
        },
        {
            "topic": "Reinforcement learning",
            "topicId": "2557",
            "url": "https://www.semanticscholar.org/topic/2557"
        },
        {
            "topic": "Regret (decision theory)",
            "topicId": "528786",
            "url": "https://www.semanticscholar.org/topic/528786"
        },
        {
            "topic": "Discretization error",
            "topicId": "318976",
            "url": "https://www.semanticscholar.org/topic/318976"
        },
        {
            "topic": "Cobham's thesis",
            "topicId": "266433",
            "url": "https://www.semanticscholar.org/topic/266433"
        },
        {
            "topic": "Markov decision process",
            "topicId": "2556",
            "url": "https://www.semanticscholar.org/topic/2556"
        },
        {
            "topic": "State space",
            "topicId": "6115",
            "url": "https://www.semanticscholar.org/topic/6115"
        },
        {
            "topic": "Markov chain",
            "topicId": "5418",
            "url": "https://www.semanticscholar.org/topic/5418"
        },
        {
            "topic": "Experiment",
            "topicId": "378",
            "url": "https://www.semanticscholar.org/topic/378"
        },
        {
            "topic": "Iteration",
            "topicId": "11823",
            "url": "https://www.semanticscholar.org/topic/11823"
        },
        {
            "topic": "Sampling (signal processing)",
            "topicId": "7839",
            "url": "https://www.semanticscholar.org/topic/7839"
        },
        {
            "topic": "Const (computer programming)",
            "topicId": "128399",
            "url": "https://www.semanticscholar.org/topic/128399"
        },
        {
            "topic": "Singular value decomposition",
            "topicId": "7730",
            "url": "https://www.semanticscholar.org/topic/7730"
        }
    ],
    "url": "https://www.semanticscholar.org/paper/51a2127ebe0ac0e7d658e92bbf7dc453e26101bc",
    "venue": "Annual Meeting of the IEEE Industry Applications Society",
    "year": 2019
}
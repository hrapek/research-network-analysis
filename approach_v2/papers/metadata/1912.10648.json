{
    "abstract": "Gradient-based methods are often used for policy optimization in deep reinforcement learning, despite being vulnerable to local optima and saddle points. Although gradient-free methods (e.g., genetic algorithms or evolution strategies) help mitigate these issues, poor initialization and local optima are still concerns in highly nonconvex spaces. This paper presents a method for policy optimization based on Monte-Carlo tree search and gradient-free optimization. Our method, called Monte-Carlo tree search for policy optimization (MCTSPO), provides a better exploration-exploitation trade-off through the use of the upper confidence bound heuristic. We demonstrate improved performance on reinforcement learning tasks with deceptive or sparse reward functions compared to popular gradient-based and deep genetic algorithm baselines.",
    "arxivId": "1912.10648",
    "authors": [
        {
            "authorId": "2109076657",
            "name": "Xiaobai Ma",
            "url": "https://www.semanticscholar.org/author/2109076657"
        },
        {
            "authorId": "1404112858",
            "name": "K. Driggs-Campbell",
            "url": "https://www.semanticscholar.org/author/1404112858"
        },
        {
            "authorId": "2079174",
            "name": "Zongzhang Zhang",
            "url": "https://www.semanticscholar.org/author/2079174"
        },
        {
            "authorId": "2275756",
            "name": "Mykel J. Kochenderfer",
            "url": "https://www.semanticscholar.org/author/2275756"
        }
    ],
    "citationVelocity": 0,
    "citations": [
        {
            "arxivId": "2301.09709",
            "authors": [
                {
                    "authorId": "1388622049",
                    "name": "Anna Winnicki"
                },
                {
                    "authorId": "143808204",
                    "name": "R. Srikant"
                }
            ],
            "doi": "10.48550/arXiv.2301.09709",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "752ede352b0e92714d315217752bb56e38974095",
            "title": "On The Convergence Of Policy Iteration-Based Reinforcement Learning With Monte Carlo Policy Evaluation",
            "url": "https://www.semanticscholar.org/paper/752ede352b0e92714d315217752bb56e38974095",
            "venue": "AISTATS",
            "year": 2023
        },
        {
            "arxivId": "2010.05545",
            "authors": [
                {
                    "authorId": "2060551",
                    "name": "Jost Tobias Springenberg"
                },
                {
                    "authorId": "2801204",
                    "name": "N. Heess"
                },
                {
                    "authorId": "3187297",
                    "name": "D. Mankowitz"
                },
                {
                    "authorId": "1879232",
                    "name": "J. Merel"
                },
                {
                    "authorId": "2631257",
                    "name": "Arunkumar Byravan"
                },
                {
                    "authorId": "2799799",
                    "name": "A. Abdolmaleki"
                },
                {
                    "authorId": "2059147422",
                    "name": "Jackie Kay"
                },
                {
                    "authorId": "3110620",
                    "name": "Jonas Degrave"
                },
                {
                    "authorId": "4337102",
                    "name": "Julian Schrittwieser"
                },
                {
                    "authorId": "2109481",
                    "name": "Yuval Tassa"
                },
                {
                    "authorId": "1741293",
                    "name": "J. Buchli"
                },
                {
                    "authorId": "143813532",
                    "name": "Dan Belov"
                },
                {
                    "authorId": "3137672",
                    "name": "Martin A. Riedmiller"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "6cf28553e91f14422941b9289b3281a4d09a072f",
            "title": "Local Search for Policy Iteration in Continuous Control",
            "url": "https://www.semanticscholar.org/paper/6cf28553e91f14422941b9289b3281a4d09a072f",
            "venue": "ArXiv",
            "year": 2020
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "145769793",
                    "name": "L. Cox"
                }
            ],
            "doi": "10.1111/risa.13553",
            "intent": [],
            "isInfluential": false,
            "paperId": "77e92ff9f81952a3e8ec49c84b63c141100285a4",
            "title": "Answerable and Unanswerable Questions in Risk Analysis with Open\u2010World Novelty",
            "url": "https://www.semanticscholar.org/paper/77e92ff9f81952a3e8ec49c84b63c141100285a4",
            "venue": "Risk analysis : an official publication of the Society for Risk Analysis",
            "year": 2020
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2273298",
                    "name": "Tetsuro Morimura"
                },
                {
                    "authorId": "2056746714",
                    "name": "K. Ota"
                },
                {
                    "authorId": "1419592188",
                    "name": "Kenshi Abe"
                },
                {
                    "authorId": "2115513885",
                    "name": "Peinan Zhang"
                }
            ],
            "doi": "10.48550/arXiv.2206.01011",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "5cf03766541e5389702d6733018e3ff92f4f44b8",
            "title": "Policy Gradient Algorithms with Monte-Carlo Tree Search for Non-Markov Decision Processes",
            "url": "https://www.semanticscholar.org/paper/5cf03766541e5389702d6733018e3ff92f4f44b8",
            "venue": "ArXiv",
            "year": 2022
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2115672028",
                    "name": "Jia-Jia Cai"
                }
            ],
            "doi": "10.1007/978-3-030-63833-7_60",
            "intent": [],
            "isInfluential": false,
            "paperId": "4b58de6291b8e5352c98566cd6300e53f244007d",
            "title": "WD3-MPER: A Method to Alleviate Approximation Bias in Actor-Critic",
            "url": "https://www.semanticscholar.org/paper/4b58de6291b8e5352c98566cd6300e53f244007d",
            "venue": "ICONIP",
            "year": 2020
        }
    ],
    "corpusId": 199465937,
    "doi": "10.24963/ijcai.2019/432",
    "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
    ],
    "influentialCitationCount": 0,
    "isOpenAccess": true,
    "isPublisherLicensed": true,
    "is_open_access": true,
    "is_publisher_licensed": true,
    "numCitedBy": 5,
    "numCiting": 34,
    "paperId": "b1948d623c2dae0aa9427a909f452d52cc31b1cc",
    "references": [
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2271599030",
                    "name": "PhD Thesis"
                },
                {
                    "authorId": "2271596583",
                    "name": "Cyber R\u0430nge"
                },
                {
                    "authorId": "2271592999",
                    "name": "L\u0430b M\u0430n\u0430ger"
                }
            ],
            "doi": "10.5194/se-2020-89-sc4",
            "intent": [
                "background"
            ],
            "isInfluential": true,
            "paperId": "41456401db746b9f8f579a3120b80b9791de9b18",
            "title": "PhD thesis",
            "url": "https://www.semanticscholar.org/paper/41456401db746b9f8f579a3120b80b9791de9b18",
            "venue": "",
            "year": 2020
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2502026",
                    "name": "Hendrik Baier"
                },
                {
                    "authorId": "1714467",
                    "name": "P. Cowling"
                }
            ],
            "doi": "10.1109/CIG.2018.8490403",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "ff036887bb872c65fb41130044125493e7856f5e",
            "title": "Evolutionary MCTS for Multi-Action Adversarial Games",
            "url": "https://www.semanticscholar.org/paper/ff036887bb872c65fb41130044125493e7856f5e",
            "venue": "2018 IEEE Conference on Computational Intelligence and Games (CIG)",
            "year": 2018
        },
        {
            "arxivId": "1805.07917",
            "authors": [
                {
                    "authorId": "3440874",
                    "name": "Shauharda Khadka"
                },
                {
                    "authorId": "1711099",
                    "name": "Kagan Tumer"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "d5805a80b63ed0a605e5469e321a7e3c42eaf324",
            "title": "Evolution-Guided Policy Gradient in Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/d5805a80b63ed0a605e5469e321a7e3c42eaf324",
            "venue": "NeurIPS",
            "year": 2018
        },
        {
            "arxivId": "1802.08842",
            "authors": [
                {
                    "authorId": "22259392",
                    "name": "P. Chrabaszcz"
                },
                {
                    "authorId": "1678656",
                    "name": "I. Loshchilov"
                },
                {
                    "authorId": "144661829",
                    "name": "F. Hutter"
                }
            ],
            "doi": "10.24963/ijcai.2018/197",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "19af387c0ee32929b54ff45656129a721a84c192",
            "title": "Back to Basics: Benchmarking Canonical Evolution Strategies for Playing Atari",
            "url": "https://www.semanticscholar.org/paper/19af387c0ee32929b54ff45656129a721a84c192",
            "venue": "IJCAI",
            "year": 2018
        },
        {
            "arxivId": "1712.06563",
            "authors": [
                {
                    "authorId": "39799304",
                    "name": "J. Lehman"
                },
                {
                    "authorId": "2108203529",
                    "name": "Jay Chen"
                },
                {
                    "authorId": "2552141",
                    "name": "J. Clune"
                },
                {
                    "authorId": "1846883",
                    "name": "Kenneth O. Stanley"
                }
            ],
            "doi": "10.1145/3205455.3205473",
            "intent": [
                "methodology"
            ],
            "isInfluential": true,
            "paperId": "0a830e847f46425f21e34239ba75f026280c0706",
            "title": "Safe mutations for deep and recurrent neural networks through output gradients",
            "url": "https://www.semanticscholar.org/paper/0a830e847f46425f21e34239ba75f026280c0706",
            "venue": "GECCO",
            "year": 2017
        },
        {
            "arxivId": "1712.06567",
            "authors": [
                {
                    "authorId": "9927844",
                    "name": "F. Such"
                },
                {
                    "authorId": "8309711",
                    "name": "Vashisht Madhavan"
                },
                {
                    "authorId": "32577240",
                    "name": "Edoardo Conti"
                },
                {
                    "authorId": "39799304",
                    "name": "J. Lehman"
                },
                {
                    "authorId": "1846883",
                    "name": "Kenneth O. Stanley"
                },
                {
                    "authorId": "2552141",
                    "name": "J. Clune"
                }
            ],
            "doi": null,
            "intent": [
                "background",
                "methodology"
            ],
            "isInfluential": true,
            "paperId": "819bcae49054e00cef3c0972d48b4e40a525f4d9",
            "title": "Deep Neuroevolution: Genetic Algorithms Are a Competitive Alternative for Training Deep Neural Networks for Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/819bcae49054e00cef3c0972d48b4e40a525f4d9",
            "venue": "ArXiv",
            "year": 2017
        },
        {
            "arxivId": "1710.02298",
            "authors": [
                {
                    "authorId": "39357484",
                    "name": "Matteo Hessel"
                },
                {
                    "authorId": "3321484",
                    "name": "Joseph Modayil"
                },
                {
                    "authorId": "7634925",
                    "name": "H. V. Hasselt"
                },
                {
                    "authorId": "1725157",
                    "name": "T. Schaul"
                },
                {
                    "authorId": "2273072",
                    "name": "Georg Ostrovski"
                },
                {
                    "authorId": "2605877",
                    "name": "Will Dabney"
                },
                {
                    "authorId": "48257711",
                    "name": "Dan Horgan"
                },
                {
                    "authorId": "1808897",
                    "name": "Bilal Piot"
                },
                {
                    "authorId": "37666967",
                    "name": "M. G. Azar"
                },
                {
                    "authorId": "145824029",
                    "name": "David Silver"
                }
            ],
            "doi": "10.1609/aaai.v32i1.11796",
            "intent": [],
            "isInfluential": false,
            "paperId": "0ab3f7ecbdc5a33565a234215604a6ca9d155a33",
            "title": "Rainbow: Combining Improvements in Deep Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/0ab3f7ecbdc5a33565a234215604a6ca9d155a33",
            "venue": "AAAI",
            "year": 2017
        },
        {
            "arxivId": "1708.05144",
            "authors": [
                {
                    "authorId": "3374063",
                    "name": "Yuhuai Wu"
                },
                {
                    "authorId": "2711409",
                    "name": "Elman Mansimov"
                },
                {
                    "authorId": "1785346",
                    "name": "R. Grosse"
                },
                {
                    "authorId": "145657522",
                    "name": "Shun Liao"
                },
                {
                    "authorId": "2503659",
                    "name": "Jimmy Ba"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "2b6f2b163372e3417b687cc43313f2a630e7bca7",
            "title": "Scalable trust-region method for deep reinforcement learning using Kronecker-factored approximation",
            "url": "https://www.semanticscholar.org/paper/2b6f2b163372e3417b687cc43313f2a630e7bca7",
            "venue": "NIPS",
            "year": 2017
        },
        {
            "arxivId": "1707.06347",
            "authors": [
                {
                    "authorId": "47971768",
                    "name": "John Schulman"
                },
                {
                    "authorId": "143909660",
                    "name": "Filip Wolski"
                },
                {
                    "authorId": "6515819",
                    "name": "Prafulla Dhariwal"
                },
                {
                    "authorId": "38909097",
                    "name": "Alec Radford"
                },
                {
                    "authorId": "2067138712",
                    "name": "Oleg Klimov"
                }
            ],
            "doi": null,
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "dce6f9d4017b1785979e7520fd0834ef8cf02f4b",
            "title": "Proximal Policy Optimization Algorithms",
            "url": "https://www.semanticscholar.org/paper/dce6f9d4017b1785979e7520fd0834ef8cf02f4b",
            "venue": "ArXiv",
            "year": 2017
        },
        {
            "arxivId": "1703.03864",
            "authors": [
                {
                    "authorId": "2887364",
                    "name": "Tim Salimans"
                },
                {
                    "authorId": "2126278",
                    "name": "Jonathan Ho"
                },
                {
                    "authorId": "41192764",
                    "name": "Xi Chen"
                },
                {
                    "authorId": "1701686",
                    "name": "I. Sutskever"
                }
            ],
            "doi": null,
            "intent": [
                "methodology"
            ],
            "isInfluential": true,
            "paperId": "4ee802a58d32aa049d549d06be440ac947b53987",
            "title": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/4ee802a58d32aa049d549d06be440ac947b53987",
            "venue": "ArXiv",
            "year": 2017
        },
        {
            "arxivId": "1606.01540",
            "authors": [
                {
                    "authorId": "2065151121",
                    "name": "Greg Brockman"
                },
                {
                    "authorId": "34415167",
                    "name": "Vicki Cheung"
                },
                {
                    "authorId": "152877508",
                    "name": "Ludwig Pettersson"
                },
                {
                    "authorId": "2113526509",
                    "name": "Jonas Schneider"
                },
                {
                    "authorId": "47971768",
                    "name": "John Schulman"
                },
                {
                    "authorId": "2109541439",
                    "name": "Jie Tang"
                },
                {
                    "authorId": "2563432",
                    "name": "Wojciech Zaremba"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "2b10281297ee001a9f3f4ea1aa9bea6b638c27df",
            "title": "OpenAI Gym",
            "url": "https://www.semanticscholar.org/paper/2b10281297ee001a9f3f4ea1aa9bea6b638c27df",
            "venue": "ArXiv",
            "year": 2016
        },
        {
            "arxivId": "1604.06778",
            "authors": [
                {
                    "authorId": "144581158",
                    "name": "Yan Duan"
                },
                {
                    "authorId": "41192764",
                    "name": "Xi Chen"
                },
                {
                    "authorId": "3127100",
                    "name": "Rein Houthooft"
                },
                {
                    "authorId": "47971768",
                    "name": "John Schulman"
                },
                {
                    "authorId": "1689992",
                    "name": "P. Abbeel"
                }
            ],
            "doi": null,
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "1464776f20e2bccb6182f183b5ff2e15b0ae5e56",
            "title": "Benchmarking Deep Reinforcement Learning for Continuous Control",
            "url": "https://www.semanticscholar.org/paper/1464776f20e2bccb6182f183b5ff2e15b0ae5e56",
            "venue": "ICML",
            "year": 2016
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "1979505",
                    "name": "A. Geramifard"
                },
                {
                    "authorId": "2160071",
                    "name": "Christoph Dann"
                },
                {
                    "authorId": "2071122375",
                    "name": "Robert H. Klein"
                },
                {
                    "authorId": "2605877",
                    "name": "Will Dabney"
                },
                {
                    "authorId": "1713935",
                    "name": "J. How"
                }
            ],
            "doi": "10.5555/2789272.2886799",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "f8f03a2b287aaa712b8dbd14024b452da6b04956",
            "title": "RLPy: a value-function-based reinforcement learning framework for education and research",
            "url": "https://www.semanticscholar.org/paper/f8f03a2b287aaa712b8dbd14024b452da6b04956",
            "venue": "J. Mach. Learn. Res.",
            "year": 2015
        },
        {
            "arxivId": "1506.02438",
            "authors": [
                {
                    "authorId": "47971768",
                    "name": "John Schulman"
                },
                {
                    "authorId": "29912342",
                    "name": "Philipp Moritz"
                },
                {
                    "authorId": "1736651",
                    "name": "S. Levine"
                },
                {
                    "authorId": "1694621",
                    "name": "Michael I. Jordan"
                },
                {
                    "authorId": "1689992",
                    "name": "P. Abbeel"
                }
            ],
            "doi": null,
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "d316c82c12cf4c45f9e85211ef3d1fa62497bff8",
            "title": "High-Dimensional Continuous Control Using Generalized Advantage Estimation",
            "url": "https://www.semanticscholar.org/paper/d316c82c12cf4c45f9e85211ef3d1fa62497bff8",
            "venue": "ICLR",
            "year": 2015
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "3255983",
                    "name": "Volodymyr Mnih"
                },
                {
                    "authorId": "2645384",
                    "name": "K. Kavukcuoglu"
                },
                {
                    "authorId": "145824029",
                    "name": "David Silver"
                },
                {
                    "authorId": "2228824",
                    "name": "Andrei A. Rusu"
                },
                {
                    "authorId": "144056327",
                    "name": "J. Veness"
                },
                {
                    "authorId": "1792298",
                    "name": "Marc G. Bellemare"
                },
                {
                    "authorId": "1753223",
                    "name": "Alex Graves"
                },
                {
                    "authorId": "3137672",
                    "name": "Martin A. Riedmiller"
                },
                {
                    "authorId": "145600108",
                    "name": "A. Fidjeland"
                },
                {
                    "authorId": "2273072",
                    "name": "Georg Ostrovski"
                },
                {
                    "authorId": "48348688",
                    "name": "Stig Petersen"
                },
                {
                    "authorId": "50388928",
                    "name": "Charlie Beattie"
                },
                {
                    "authorId": "49813280",
                    "name": "Amir Sadik"
                },
                {
                    "authorId": "2460849",
                    "name": "Ioannis Antonoglou"
                },
                {
                    "authorId": "143776287",
                    "name": "Helen King"
                },
                {
                    "authorId": "2106164",
                    "name": "D. Kumaran"
                },
                {
                    "authorId": "1688276",
                    "name": "Daan Wierstra"
                },
                {
                    "authorId": "34313265",
                    "name": "S. Legg"
                },
                {
                    "authorId": "48987704",
                    "name": "D. Hassabis"
                }
            ],
            "doi": "10.1038/nature14236",
            "intent": [],
            "isInfluential": false,
            "paperId": "340f48901f72278f6bf78a04ee5b01df208cc508",
            "title": "Human-level control through deep reinforcement learning",
            "url": "https://www.semanticscholar.org/paper/340f48901f72278f6bf78a04ee5b01df208cc508",
            "venue": "Nature",
            "year": 2015
        },
        {
            "arxivId": "1502.05477",
            "authors": [
                {
                    "authorId": "47971768",
                    "name": "John Schulman"
                },
                {
                    "authorId": "1736651",
                    "name": "S. Levine"
                },
                {
                    "authorId": "1689992",
                    "name": "P. Abbeel"
                },
                {
                    "authorId": "1694621",
                    "name": "Michael I. Jordan"
                },
                {
                    "authorId": "29912342",
                    "name": "Philipp Moritz"
                }
            ],
            "doi": null,
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "449532187c94af3dd3aa55e16d2c50f7854d2199",
            "title": "Trust Region Policy Optimization",
            "url": "https://www.semanticscholar.org/paper/449532187c94af3dd3aa55e16d2c50f7854d2199",
            "venue": "ICML",
            "year": 2015
        },
        {
            "arxivId": "1412.6980",
            "authors": [
                {
                    "authorId": "1726807",
                    "name": "Diederik P. Kingma"
                },
                {
                    "authorId": "2503659",
                    "name": "Jimmy Ba"
                }
            ],
            "doi": null,
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "a6cb366736791bcccc5c8639de5a8f9636bf87e8",
            "title": "Adam: A Method for Stochastic Optimization",
            "url": "https://www.semanticscholar.org/paper/a6cb366736791bcccc5c8639de5a8f9636bf87e8",
            "venue": "ICLR",
            "year": 2014
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "144763731",
                    "name": "Thomas Keller"
                },
                {
                    "authorId": "3208076",
                    "name": "M. Helmert"
                }
            ],
            "doi": "10.1609/icaps.v23i1.13557",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "2bd4d15b2a318ea80120c7c6d5f8545f65528c97",
            "title": "Trial-Based Heuristic Tree Search for Finite Horizon MDPs",
            "url": "https://www.semanticscholar.org/paper/2bd4d15b2a318ea80120c7c6d5f8545f65528c97",
            "venue": "ICAPS",
            "year": 2013
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2186376",
                    "name": "M. Grzes"
                },
                {
                    "authorId": "2380005",
                    "name": "D. Kudenko"
                }
            ],
            "doi": "10.1109/ICMLA.2009.33",
            "intent": [],
            "isInfluential": false,
            "paperId": "fc305a94648ce083799ff1e5e1e9e339b2ae316b",
            "title": "Theoretical and Empirical Analysis of Reward Shaping in Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/fc305a94648ce083799ff1e5e1e9e339b2ae316b",
            "venue": "2009 International Conference on Machine Learning and Applications",
            "year": 2009
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2059549547",
                    "name": "Guillaume M"
                },
                {
                    "authorId": "2229020235",
                    "name": "J-B Chaslot"
                },
                {
                    "authorId": "1997644",
                    "name": "M. Winands"
                },
                {
                    "authorId": "150123238",
                    "name": "H. Jaap Van Den Herik"
                },
                {
                    "authorId": "145495343",
                    "name": "J. Uiterwijk"
                },
                {
                    "authorId": "1759257",
                    "name": "B. Bouzy"
                }
            ],
            "doi": "10.1142/S1793005708001094",
            "intent": [],
            "isInfluential": false,
            "paperId": "966b8c5b01f1eb4b7bb8f4a83ba3f1f1879f5250",
            "title": "Progressive Strategies for Monte-Carlo Tree Search",
            "url": "https://www.semanticscholar.org/paper/966b8c5b01f1eb4b7bb8f4a83ba3f1f1879f5250",
            "venue": "",
            "year": 2008
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2059549547",
                    "name": "Guillaume M"
                },
                {
                    "authorId": "2229020235",
                    "name": "J-B Chaslot"
                },
                {
                    "authorId": "1997644",
                    "name": "M. Winands"
                },
                {
                    "authorId": "150123238",
                    "name": "H. Jaap Van Den Herik"
                }
            ],
            "doi": "10.1007/978-3-540-87608-3_6",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "3b41773cf65c4d7cde97e3b8c82295433b9a8f39",
            "title": "Parallel Monte-Carlo Tree Search",
            "url": "https://www.semanticscholar.org/paper/3b41773cf65c4d7cde97e3b8c82295433b9a8f39",
            "venue": "Computers and Games",
            "year": 2008
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2668005",
                    "name": "Pawel Wawrzynski"
                }
            ],
            "doi": "10.1109/EURCON.2007.4400335",
            "intent": [
                "background",
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "77f3cd7165ecf2c60c1b3e29eba1b0623a91d00a",
            "title": "Learning to Control a 6-Degree-of-Freedom Walking Robot",
            "url": "https://www.semanticscholar.org/paper/77f3cd7165ecf2c60c1b3e29eba1b0623a91d00a",
            "venue": "EUROCON 2007 - The International Conference on \"Computer as a Tool\"",
            "year": 2007
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "143865718",
                    "name": "V. Ferrari"
                },
                {
                    "authorId": "1688869",
                    "name": "Andrew Zisserman"
                }
            ],
            "doi": null,
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "7142185fd2e86e922f609562f30820cd7c5af7f4",
            "title": "Advances in Neural Information Processing Systems (NIPS)",
            "url": "https://www.semanticscholar.org/paper/7142185fd2e86e922f609562f30820cd7c5af7f4",
            "venue": "",
            "year": 2007
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "34908205",
                    "name": "Levente Kocsis"
                },
                {
                    "authorId": "40868287",
                    "name": "Csaba Szepesvari"
                }
            ],
            "doi": "10.1007/11871842_29",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "e635d81a617d1239232a9c9a11a196c53dab8240",
            "title": "Bandit Based Monte-Carlo Planning",
            "url": "https://www.semanticscholar.org/paper/e635d81a617d1239232a9c9a11a196c53dab8240",
            "venue": "ECML",
            "year": 2006
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "1760402",
                    "name": "A. Moore"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "874b3a63422eeaf24c14435ee6091ed48247bff3",
            "title": "Efficient memory-based learning for robot control",
            "url": "https://www.semanticscholar.org/paper/874b3a63422eeaf24c14435ee6091ed48247bff3",
            "venue": "",
            "year": 1990
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "49481579",
                    "name": "Seshashayee S. Murthy"
                },
                {
                    "authorId": "2083404",
                    "name": "M. Raibert"
                }
            ],
            "doi": "10.5555/22112.22143",
            "intent": [
                "background",
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "f7334fac8662ccdfc76438d23e10b76f3ca2726f",
            "title": "3-D balance in legged locomotion: modeling and simulation for the one-legged case",
            "url": "https://www.semanticscholar.org/paper/f7334fac8662ccdfc76438d23e10b76f3ca2726f",
            "venue": "Workshop on Motion",
            "year": 1986
        }
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Mathematics",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "title": "Monte Carlo Tree Search for Policy Optimization",
    "topics": [],
    "url": "https://www.semanticscholar.org/paper/b1948d623c2dae0aa9427a909f452d52cc31b1cc",
    "venue": "International Joint Conference on Artificial Intelligence",
    "year": 2019
}
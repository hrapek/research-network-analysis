{
    "abstract": "In this project we demonstrate the effectiveness of the transformer encoder as a viable architecture for policies in variable action environments. Using it, we train an agent using Proximal Policy Optimisation (PPO) on multiple maps against scripted opponents in the Gym-$\\mu$RTS environment. The final agent is able to achieve a higher return using half the computational resources of the next-best RL agent, which used the GridNet architecture. The source code and pre-trained models are available here: https://github.com/NiklasZ/transformers-for-variable-action-envs",
    "arxivId": "2301.03679",
    "authors": [
        {
            "authorId": "2199840041",
            "name": "Niklas Zwingenberger",
            "url": "https://www.semanticscholar.org/author/2199840041"
        }
    ],
    "citationVelocity": 0,
    "citations": [
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2276604978",
                    "name": "Shaobo Hu"
                },
                {
                    "authorId": "2302788220",
                    "name": "Wei Liu"
                }
            ],
            "doi": "10.1109/CSIS-IAC60628.2023.10363820",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "3562641055308ce7da379ee41e8918adc63eab13",
            "title": "Enhancing Real-Time Strategy Games via Transformer Encoder with Patch Embedding",
            "url": "https://www.semanticscholar.org/paper/3562641055308ce7da379ee41e8918adc63eab13",
            "venue": "2023 International Annual Conference on Complex Systems and Intelligent Science (CSIS-IAC)",
            "year": 2023
        }
    ],
    "corpusId": 255570136,
    "doi": "10.48550/arXiv.2301.03679",
    "fieldsOfStudy": [
        "Computer Science"
    ],
    "influentialCitationCount": 0,
    "isOpenAccess": true,
    "isPublisherLicensed": true,
    "is_open_access": true,
    "is_publisher_licensed": true,
    "numCitedBy": 1,
    "numCiting": 16,
    "paperId": "396fc4d4f363c13520c58727254418e975e98bd0",
    "references": [
        {
            "arxivId": "2106.01345",
            "authors": [
                {
                    "authorId": "2108435457",
                    "name": "Lili Chen"
                },
                {
                    "authorId": "2070275468",
                    "name": "Kevin Lu"
                },
                {
                    "authorId": "19275599",
                    "name": "A. Rajeswaran"
                },
                {
                    "authorId": "3436470",
                    "name": "Kimin Lee"
                },
                {
                    "authorId": "1954250",
                    "name": "Aditya Grover"
                },
                {
                    "authorId": "51093256",
                    "name": "M. Laskin"
                },
                {
                    "authorId": "1689992",
                    "name": "P. Abbeel"
                },
                {
                    "authorId": "41207614",
                    "name": "A. Srinivas"
                },
                {
                    "authorId": "2080746",
                    "name": "Igor Mordatch"
                }
            ],
            "doi": null,
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "c1ad5f9b32d80f1c65d67894e5b8c2fdf0ae4500",
            "title": "Decision Transformer: Reinforcement Learning via Sequence Modeling",
            "url": "https://www.semanticscholar.org/paper/c1ad5f9b32d80f1c65d67894e5b8c2fdf0ae4500",
            "venue": "NeurIPS",
            "year": 2021
        },
        {
            "arxivId": "2105.13807",
            "authors": [
                {
                    "authorId": "7649626",
                    "name": "Sheng-Jun Huang"
                },
                {
                    "authorId": "1722671",
                    "name": "Santiago Onta\u00f1\u00f3n"
                },
                {
                    "authorId": "35636840",
                    "name": "Chris Bamford"
                },
                {
                    "authorId": "2106385506",
                    "name": "Lukasz Grela"
                }
            ],
            "doi": "10.1109/CoG52621.2021.9619076",
            "intent": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "paperId": "cd867413da9d30731beaf8c5498d1217c9c734c3",
            "title": "Gym-\u00b5RTS: Toward Affordable Full Game Real-time Strategy Games Research with Deep Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/cd867413da9d30731beaf8c5498d1217c9c734c3",
            "venue": "2021 IEEE Conference on Games (CoG)",
            "year": 2021
        },
        {
            "arxivId": "2006.14171",
            "authors": [
                {
                    "authorId": "50178929",
                    "name": "Shengyi Huang"
                },
                {
                    "authorId": "2066060119",
                    "name": "Santiago Ontan'on"
                }
            ],
            "doi": "10.32473/flairs.v35i.130584",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "83b7d091fa44906d4cc873fdfaa4ba3d1858e7bb",
            "title": "A Closer Look at Invalid Action Masking in Policy Gradient Algorithms",
            "url": "https://www.semanticscholar.org/paper/83b7d091fa44906d4cc873fdfaa4ba3d1858e7bb",
            "venue": "FLAIRS",
            "year": 2020
        },
        {
            "arxivId": "2006.05990",
            "authors": [
                {
                    "authorId": "2206490",
                    "name": "Marcin Andrychowicz"
                },
                {
                    "authorId": "150918315",
                    "name": "Anton Raichuk"
                },
                {
                    "authorId": "2067024592",
                    "name": "Piotr Sta'nczyk"
                },
                {
                    "authorId": "1741487247",
                    "name": "Manu Orsini"
                },
                {
                    "authorId": "35022714",
                    "name": "Sertan Girgin"
                },
                {
                    "authorId": "52153018",
                    "name": "Rapha\u00ebl Marinier"
                },
                {
                    "authorId": "122562941",
                    "name": "L'eonard Hussenot"
                },
                {
                    "authorId": "1737555",
                    "name": "M. Geist"
                },
                {
                    "authorId": "1721354",
                    "name": "O. Pietquin"
                },
                {
                    "authorId": "145605490",
                    "name": "Marcin Michalski"
                },
                {
                    "authorId": "1802148",
                    "name": "S. Gelly"
                },
                {
                    "authorId": "1936951",
                    "name": "Olivier Bachem"
                }
            ],
            "doi": null,
            "intent": [
                "result"
            ],
            "isInfluential": false,
            "paperId": "cbe9be3a9731c13dd18fc7bdfaf8dcedfe7a5544",
            "title": "What Matters In On-Policy Reinforcement Learning? A Large-Scale Empirical Study",
            "url": "https://www.semanticscholar.org/paper/cbe9be3a9731c13dd18fc7bdfaf8dcedfe7a5544",
            "venue": "ArXiv",
            "year": 2020
        },
        {
            "arxivId": "2005.12729",
            "authors": [
                {
                    "authorId": "39468283",
                    "name": "Logan Engstrom"
                },
                {
                    "authorId": "34562927",
                    "name": "Andrew Ilyas"
                },
                {
                    "authorId": "2852106",
                    "name": "Shibani Santurkar"
                },
                {
                    "authorId": "2754804",
                    "name": "Dimitris Tsipras"
                },
                {
                    "authorId": "2342697",
                    "name": "F. Janoos"
                },
                {
                    "authorId": "143806546",
                    "name": "L. Rudolph"
                },
                {
                    "authorId": "143826246",
                    "name": "A. Madry"
                }
            ],
            "doi": null,
            "intent": [
                "result"
            ],
            "isInfluential": false,
            "paperId": "d415b724fbc35afcc8dd91738123edfa6a5db634",
            "title": "Implementation Matters in Deep Policy Gradients: A Case Study on PPO and TRPO",
            "url": "https://www.semanticscholar.org/paper/d415b724fbc35afcc8dd91738123edfa6a5db634",
            "venue": "ArXiv",
            "year": 2020
        },
        {
            "arxivId": "1911.08265",
            "authors": [
                {
                    "authorId": "4337102",
                    "name": "Julian Schrittwieser"
                },
                {
                    "authorId": "2460849",
                    "name": "Ioannis Antonoglou"
                },
                {
                    "authorId": "2067208983",
                    "name": "T. Hubert"
                },
                {
                    "authorId": "34838386",
                    "name": "K. Simonyan"
                },
                {
                    "authorId": "2175946",
                    "name": "L. Sifre"
                },
                {
                    "authorId": "152380508",
                    "name": "Simon Schmitt"
                },
                {
                    "authorId": "35099444",
                    "name": "A. Guez"
                },
                {
                    "authorId": "49860549",
                    "name": "Edward Lockhart"
                },
                {
                    "authorId": "48987704",
                    "name": "D. Hassabis"
                },
                {
                    "authorId": "1686971",
                    "name": "T. Graepel"
                },
                {
                    "authorId": "2542999",
                    "name": "T. Lillicrap"
                },
                {
                    "authorId": "145824029",
                    "name": "David Silver"
                }
            ],
            "doi": "10.1038/s41586-020-03051-4",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "3507bd62a14bd0e8ead28cdedb1c33ba83c39c6b",
            "title": "Mastering Atari, Go, chess and shogi by planning with a learned model",
            "url": "https://www.semanticscholar.org/paper/3507bd62a14bd0e8ead28cdedb1c33ba83c39c6b",
            "venue": "Nature",
            "year": 2019
        },
        {
            "arxivId": "1908.02265",
            "authors": [
                {
                    "authorId": "8553015",
                    "name": "Jiasen Lu"
                },
                {
                    "authorId": "1746610",
                    "name": "Dhruv Batra"
                },
                {
                    "authorId": "153432684",
                    "name": "Devi Parikh"
                },
                {
                    "authorId": "2297229",
                    "name": "Stefan Lee"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "65a9c7b0800c86a196bc14e7621ff895cc6ab287",
            "title": "ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks",
            "url": "https://www.semanticscholar.org/paper/65a9c7b0800c86a196bc14e7621ff895cc6ab287",
            "venue": "NeurIPS",
            "year": 2019
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "1390738614",
                    "name": "Lei Han"
                },
                {
                    "authorId": "2075416111",
                    "name": "Peng Sun"
                },
                {
                    "authorId": "1390662136",
                    "name": "Yali Du"
                },
                {
                    "authorId": "3081531",
                    "name": "Jiechao Xiong"
                },
                {
                    "authorId": "2117944720",
                    "name": "Qing Wang"
                },
                {
                    "authorId": "1910318",
                    "name": "Xinghai Sun"
                },
                {
                    "authorId": "2118959751",
                    "name": "Han Liu"
                },
                {
                    "authorId": "38144094",
                    "name": "T. Zhang"
                }
            ],
            "doi": null,
            "intent": [
                "methodology"
            ],
            "isInfluential": true,
            "paperId": "e9ba37d9993205b5025560dc9ee38b971c44a521",
            "title": "Grid-Wise Control for Multi-Agent Reinforcement Learning in Video Game AI",
            "url": "https://www.semanticscholar.org/paper/e9ba37d9993205b5025560dc9ee38b971c44a521",
            "venue": "ICML",
            "year": 2019
        },
        {
            "arxivId": "1707.06347",
            "authors": [
                {
                    "authorId": "47971768",
                    "name": "John Schulman"
                },
                {
                    "authorId": "143909660",
                    "name": "Filip Wolski"
                },
                {
                    "authorId": "6515819",
                    "name": "Prafulla Dhariwal"
                },
                {
                    "authorId": "38909097",
                    "name": "Alec Radford"
                },
                {
                    "authorId": "2067138712",
                    "name": "Oleg Klimov"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": true,
            "paperId": "dce6f9d4017b1785979e7520fd0834ef8cf02f4b",
            "title": "Proximal Policy Optimization Algorithms",
            "url": "https://www.semanticscholar.org/paper/dce6f9d4017b1785979e7520fd0834ef8cf02f4b",
            "venue": "ArXiv",
            "year": 2017
        },
        {
            "arxivId": "1706.03762",
            "authors": [
                {
                    "authorId": "40348417",
                    "name": "Ashish Vaswani"
                },
                {
                    "authorId": "1846258",
                    "name": "Noam M. Shazeer"
                },
                {
                    "authorId": "3877127",
                    "name": "Niki Parmar"
                },
                {
                    "authorId": "39328010",
                    "name": "Jakob Uszkoreit"
                },
                {
                    "authorId": "145024664",
                    "name": "Llion Jones"
                },
                {
                    "authorId": "19177000",
                    "name": "Aidan N. Gomez"
                },
                {
                    "authorId": "40527594",
                    "name": "Lukasz Kaiser"
                },
                {
                    "authorId": "3443442",
                    "name": "Illia Polosukhin"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": true,
            "paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776",
            "title": "Attention is All you Need",
            "url": "https://www.semanticscholar.org/paper/204e3073870fae3d05bcbc2f6a8e263d9b72e776",
            "venue": "NIPS",
            "year": 2017
        },
        {
            "arxivId": "1506.02438",
            "authors": [
                {
                    "authorId": "47971768",
                    "name": "John Schulman"
                },
                {
                    "authorId": "29912342",
                    "name": "Philipp Moritz"
                },
                {
                    "authorId": "1736651",
                    "name": "S. Levine"
                },
                {
                    "authorId": "1694621",
                    "name": "Michael I. Jordan"
                },
                {
                    "authorId": "1689992",
                    "name": "P. Abbeel"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "d316c82c12cf4c45f9e85211ef3d1fa62497bff8",
            "title": "High-Dimensional Continuous Control Using Generalized Advantage Estimation",
            "url": "https://www.semanticscholar.org/paper/d316c82c12cf4c45f9e85211ef3d1fa62497bff8",
            "venue": "ICLR",
            "year": 2015
        },
        {
            "arxivId": "1502.05477",
            "authors": [
                {
                    "authorId": "47971768",
                    "name": "John Schulman"
                },
                {
                    "authorId": "1736651",
                    "name": "S. Levine"
                },
                {
                    "authorId": "1689992",
                    "name": "P. Abbeel"
                },
                {
                    "authorId": "1694621",
                    "name": "Michael I. Jordan"
                },
                {
                    "authorId": "29912342",
                    "name": "Philipp Moritz"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "449532187c94af3dd3aa55e16d2c50f7854d2199",
            "title": "Trust Region Policy Optimization",
            "url": "https://www.semanticscholar.org/paper/449532187c94af3dd3aa55e16d2c50f7854d2199",
            "venue": "ICML",
            "year": 2015
        },
        {
            "arxivId": "1810.04805",
            "authors": [
                {
                    "authorId": "39172707",
                    "name": "Jacob Devlin"
                },
                {
                    "authorId": "1744179",
                    "name": "Ming-Wei Chang"
                },
                {
                    "authorId": "2544107",
                    "name": "Kenton Lee"
                },
                {
                    "authorId": "3259253",
                    "name": "Kristina Toutanova"
                }
            ],
            "doi": "10.18653/v1/N19-1423",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992",
            "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
            "url": "https://www.semanticscholar.org/paper/df2b0e26d0599ce3e70df8a9da02e51594e0e992",
            "venue": "NAACL",
            "year": 2019
        }
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "title": "Transformers as Policies for Variable Action Environments",
    "topics": [],
    "url": "https://www.semanticscholar.org/paper/396fc4d4f363c13520c58727254418e975e98bd0",
    "venue": "arXiv.org",
    "year": 2023
}
{
    "abstract": "\n \n Unifying seemingly disparate algorithmic ideas to produce better performing algorithms has been a longstanding goal in reinforcement learning. As a primary example, TD(\u03bb) elegantly unifies one-step TD prediction with Monte Carlo methods through the use of eligibility traces and the trace-decay parameter. Currently, there are a multitude of algorithms that can be used to perform TD control, including Sarsa, Q-learning, and Expected Sarsa. These methods are often studied in the one-step case, but they can be extended across multiple time steps to achieve better performance. Each of these algorithms is seemingly distinct, and no one dominates the others for all problems. In this paper, we study a new multi-step action-value algorithm called Q(\u03c3) that unifies and generalizes these existing algorithms, while subsuming them as special cases. A new parameter, \u03c3, is introduced to allow the degree of sampling performed by the algorithm at each step during its backup to be continuously varied, with Sarsa existing at one extreme (full sampling), and Expected Sarsa existing at the other (pure expectation). Q(\u03c3) is generally applicable to both on- and off-policy learning, but in this work we focus on experiments in the on-policy case. Our results show that an intermediate value of \u03c3, which results in a mixture of the existing algorithms, performs better than either extreme. The mixture can also be varied dynamically which can result in even greater performance.\n \n",
    "arxivId": "1703.01327",
    "authors": [
        {
            "authorId": "8119874",
            "name": "Kristopher De Asis",
            "url": "https://www.semanticscholar.org/author/8119874"
        },
        {
            "authorId": "2229073527",
            "name": "Fernando Hernandez-Garcia",
            "url": "https://www.semanticscholar.org/author/2229073527"
        },
        {
            "authorId": "2143192399",
            "name": "Zach Holland",
            "url": "https://www.semanticscholar.org/author/2143192399"
        },
        {
            "authorId": "1699645",
            "name": "R. Sutton",
            "url": "https://www.semanticscholar.org/author/1699645"
        }
    ],
    "citationVelocity": 16,
    "citations": [
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2331570894",
                    "name": "Zhenglin Wei"
                },
                {
                    "authorId": "2302161799",
                    "name": "Tiejiang Sun"
                },
                {
                    "authorId": "2320719502",
                    "name": "Mengjie Zhou"
                }
            ],
            "doi": "10.3390/sym16111537",
            "intent": [],
            "isInfluential": false,
            "paperId": "2491b190d2b3489b59f7e5ba629111fba44b084c",
            "title": "LIRL: Latent Imagination-Based Reinforcement Learning for Efficient Coverage Path Planning",
            "url": "https://www.semanticscholar.org/paper/2491b190d2b3489b59f7e5ba629111fba44b084c",
            "venue": "Symmetry",
            "year": 2024
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2292350584",
                    "name": "Yiwen Zhang"
                },
                {
                    "authorId": "2292327010",
                    "name": "Zhen Mei"
                },
                {
                    "authorId": "2292305033",
                    "name": "Xiaoqian Wu"
                },
                {
                    "authorId": "2292489623",
                    "name": "Huaiguang Jiang"
                },
                {
                    "authorId": "2301808104",
                    "name": "Jun Zhang"
                },
                {
                    "authorId": "2153578520",
                    "name": "Wenzhong Gao"
                }
            ],
            "doi": "10.1109/TSG.2024.3399705",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "64c2b721ae48c119517334247e180bbe1241d386",
            "title": "Two-Step Diffusion Policy Deep Reinforcement Learning Method for Low-Carbon Multi-Energy Microgrid Energy Management",
            "url": "https://www.semanticscholar.org/paper/64c2b721ae48c119517334247e180bbe1241d386",
            "venue": "IEEE Transactions on Smart Grid",
            "year": 2024
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2257996577",
                    "name": "Hongshuo Zhang"
                },
                {
                    "authorId": "2291093212",
                    "name": "Yanyun Yu"
                },
                {
                    "authorId": "2312186202",
                    "name": "Zelin Song"
                },
                {
                    "authorId": "2312032908",
                    "name": "Yanzhao Han"
                },
                {
                    "authorId": "2312128759",
                    "name": "Zhiyao Yang"
                },
                {
                    "authorId": "2311604604",
                    "name": "Lang Ti"
                }
            ],
            "doi": "10.3390/jmse12071187",
            "intent": [],
            "isInfluential": false,
            "paperId": "1442a4fd5e38589b963965afa144d625a4f6ec33",
            "title": "Method for Collaborative Layout Optimization of Ship Equipment and Pipe Based on Improved Multi-Agent Reinforcement Learning and Artificial Fish Swarm Algorithm",
            "url": "https://www.semanticscholar.org/paper/1442a4fd5e38589b963965afa144d625a4f6ec33",
            "venue": "Journal of Marine Science and Engineering",
            "year": 2024
        },
        {
            "arxivId": "2407.02748",
            "authors": [
                {
                    "authorId": "2149635378",
                    "name": "H. T. Nguyen"
                },
                {
                    "authorId": "2288024478",
                    "name": "Muhammad Usman"
                },
                {
                    "authorId": "1709598",
                    "name": "R. Buyya"
                }
            ],
            "doi": "10.1109/CLOUD62652.2024.00060",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "57a9d48de1db8c7b6240f358a76767dd8747c139",
            "title": "DRLQ: A Deep Reinforcement Learning-based Task Placement for Quantum Cloud Computing",
            "url": "https://www.semanticscholar.org/paper/57a9d48de1db8c7b6240f358a76767dd8747c139",
            "venue": "2024 IEEE 17th International Conference on Cloud Computing (CLOUD)",
            "year": 2024
        },
        {
            "arxivId": "2407.02369",
            "authors": [
                {
                    "authorId": "2270577121",
                    "name": "Villavarayan Antony Vijesh"
                },
                {
                    "authorId": "2270571638",
                    "name": "Shreyas Sumithra Rudresha"
                }
            ],
            "doi": "10.48550/arXiv.2407.02369",
            "intent": [
                "background",
                "methodology"
            ],
            "isInfluential": true,
            "paperId": "f5efcf0b130ae0e0b215eba6d60ffa62d2771293",
            "title": "Two-Step Q-Learning",
            "url": "https://www.semanticscholar.org/paper/f5efcf0b130ae0e0b215eba6d60ffa62d2771293",
            "venue": "ArXiv",
            "year": 2024
        },
        {
            "arxivId": "2406.08878",
            "authors": [
                {
                    "authorId": "51455502",
                    "name": "Jonathan Booher"
                },
                {
                    "authorId": "2274348",
                    "name": "Khashayar Rohanimanesh"
                },
                {
                    "authorId": "2306112100",
                    "name": "Junhong Xu"
                },
                {
                    "authorId": "2151685634",
                    "name": "Vladislav Isenbaev"
                },
                {
                    "authorId": "3117588",
                    "name": "A. Balakrishna"
                },
                {
                    "authorId": "2308273664",
                    "name": "Ishan Gupta"
                },
                {
                    "authorId": "2287268692",
                    "name": "Wei Liu"
                },
                {
                    "authorId": "1380315305",
                    "name": "Aleksandr Petiushko"
                }
            ],
            "doi": "10.48550/arXiv.2406.08878",
            "intent": [
                "background",
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "ef0cd988e78c8f84bef6225a59aeee973d4ebc82",
            "title": "CIMRL: Combining IMitation and Reinforcement Learning for Safe Autonomous Driving",
            "url": "https://www.semanticscholar.org/paper/ef0cd988e78c8f84bef6225a59aeee973d4ebc82",
            "venue": "ArXiv",
            "year": 2024
        },
        {
            "arxivId": "2406.03678",
            "authors": [
                {
                    "authorId": "15042674",
                    "name": "Yaozhong Gan"
                },
                {
                    "authorId": "2147420753",
                    "name": "Renye Yan"
                },
                {
                    "authorId": "2291996748",
                    "name": "Zhe Wu"
                },
                {
                    "authorId": "2305010358",
                    "name": "Junliang Xing"
                }
            ],
            "doi": "10.48550/arXiv.2406.03678",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "b5e91a4d8d05148ee50ae346ac156e92882ebd63",
            "title": "Reflective Policy Optimization",
            "url": "https://www.semanticscholar.org/paper/b5e91a4d8d05148ee50ae346ac156e92882ebd63",
            "venue": "ICML",
            "year": 2024
        },
        {
            "arxivId": "2405.18289",
            "authors": [
                {
                    "authorId": "2302888962",
                    "name": "Yuhui Wang"
                },
                {
                    "authorId": "97423891",
                    "name": "M. Strupl"
                },
                {
                    "authorId": "79787170",
                    "name": "Francesco Faccio"
                },
                {
                    "authorId": "2108761828",
                    "name": "Qingyuan Wu"
                },
                {
                    "authorId": "2303474590",
                    "name": "Haozhe Liu"
                },
                {
                    "authorId": "2303462817",
                    "name": "Michal Grudzie'n"
                },
                {
                    "authorId": "2109869742",
                    "name": "Xiaoyang Tan"
                },
                {
                    "authorId": "2252220989",
                    "name": "J\u00fcrgen Schmidhuber"
                }
            ],
            "doi": "10.48550/arXiv.2405.18289",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "018380f2038eb83f44dab2bb204518f33d793bcc",
            "title": "Highway Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/018380f2038eb83f44dab2bb204518f33d793bcc",
            "venue": "ArXiv",
            "year": 2024
        },
        {
            "arxivId": "2405.16522",
            "authors": [
                {
                    "authorId": "2303415273",
                    "name": "Wuhao Wang"
                },
                {
                    "authorId": "2303419236",
                    "name": "Zhiyong Chen"
                },
                {
                    "authorId": "2303408893",
                    "name": "Lepeng Zhang"
                }
            ],
            "doi": "10.48550/arXiv.2405.16522",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "5f1bd5267b411e9b839f4ce3bf1f49572a779265",
            "title": "Multi-State TD Target for Model-Free Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/5f1bd5267b411e9b839f4ce3bf1f49572a779265",
            "venue": "ArXiv",
            "year": 2024
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2192840963",
                    "name": "Li Xiong"
                },
                {
                    "authorId": "2193108656",
                    "name": "Ling Li"
                },
                {
                    "authorId": "2297488561",
                    "name": "Wei Liu"
                },
                {
                    "authorId": "2312010698",
                    "name": "Zhencheng Liang"
                },
                {
                    "authorId": "2238443785",
                    "name": "Wuneng Ling"
                },
                {
                    "authorId": "2313289020",
                    "name": "Ye Zhang"
                }
            ],
            "doi": "10.1109/ICPST61417.2024.10602197",
            "intent": [],
            "isInfluential": false,
            "paperId": "45f0314de84b27619990e8d3b4c93ff4ad542d31",
            "title": "A Multi-Step Joint Q-learning Cooperative Algorithm for Regional Interconnected Power Systems",
            "url": "https://www.semanticscholar.org/paper/45f0314de84b27619990e8d3b4c93ff4ad542d31",
            "venue": "2024 IEEE 2nd International Conference on Power Science and Technology (ICPST)",
            "year": 2024
        },
        {
            "arxivId": "2404.11834",
            "authors": [
                {
                    "authorId": "153088943",
                    "name": "Ruofan Wu"
                },
                {
                    "authorId": "13048995",
                    "name": "Junmin Zhong"
                },
                {
                    "authorId": "2265578584",
                    "name": "Jennie Si"
                }
            ],
            "doi": "10.48550/arXiv.2404.11834",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "0c9cd009e31582c7356d8c32003e34f25b6a2c5c",
            "title": "Actor-Critic Reinforcement Learning with Phased Actor",
            "url": "https://www.semanticscholar.org/paper/0c9cd009e31582c7356d8c32003e34f25b6a2c5c",
            "venue": "ArXiv",
            "year": 2024
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2054332918",
                    "name": "Tie Qiu"
                },
                {
                    "authorId": "2220661163",
                    "name": "Xinwei Yang"
                },
                {
                    "authorId": "144354001",
                    "name": "Ning Chen"
                },
                {
                    "authorId": "1443784440",
                    "name": "Songwei Zhang"
                },
                {
                    "authorId": "2165744386",
                    "name": "Geyong Min"
                },
                {
                    "authorId": "144953170",
                    "name": "Dapeng Oliver Wu"
                }
            ],
            "doi": "10.1109/TNET.2023.3319499",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "45818304e3c689702cf9ef35454804403a2e3b70",
            "title": "A Self-Adaptive Robustness Optimization Method With Evolutionary Multi-Agent for IoT Topology",
            "url": "https://www.semanticscholar.org/paper/45818304e3c689702cf9ef35454804403a2e3b70",
            "venue": "IEEE/ACM Transactions on Networking",
            "year": 2024
        },
        {
            "arxivId": "2403.00564",
            "authors": [
                {
                    "authorId": "2255485492",
                    "name": "Shengjie Wang"
                },
                {
                    "authorId": "2290359314",
                    "name": "Shaohuai Liu"
                },
                {
                    "authorId": "83546634",
                    "name": "Weirui Ye"
                },
                {
                    "authorId": "2289844086",
                    "name": "Jiacheng You"
                },
                {
                    "authorId": "2220893390",
                    "name": "Yang Gao"
                }
            ],
            "doi": "10.48550/arXiv.2403.00564",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "9d7b0bd13d5d7efd31123691c5960993fe610239",
            "title": "EfficientZero V2: Mastering Discrete and Continuous Control with Limited Data",
            "url": "https://www.semanticscholar.org/paper/9d7b0bd13d5d7efd31123691c5960993fe610239",
            "venue": "ICML",
            "year": 2024
        },
        {
            "arxivId": "2402.15781",
            "authors": [
                {
                    "authorId": "2280902784",
                    "name": "Donghwan Lee"
                }
            ],
            "doi": "10.48550/arXiv.2402.15781",
            "intent": [],
            "isInfluential": false,
            "paperId": "a63c81db9804faa6fd7d86049a3d73dc92f0ad8e",
            "title": "Analysis of Off-Policy Multi-Step TD-Learning with Linear Function Approximation",
            "url": "https://www.semanticscholar.org/paper/a63c81db9804faa6fd7d86049a3d73dc92f0ad8e",
            "venue": "ArXiv",
            "year": 2024
        },
        {
            "arxivId": "2402.12874",
            "authors": [
                {
                    "authorId": "1703123567",
                    "name": "Hsiao-Ru Pan"
                },
                {
                    "authorId": "2261392474",
                    "name": "Bernhard Scholkopf"
                }
            ],
            "doi": "10.48550/arXiv.2402.12874",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "6c5404b8d176e5adf9ecfb19d663e47c3902feaa",
            "title": "Skill or Luck? Return Decomposition via Advantage Functions",
            "url": "https://www.semanticscholar.org/paper/6c5404b8d176e5adf9ecfb19d663e47c3902feaa",
            "venue": "ICLR",
            "year": 2024
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2264704457",
                    "name": "Han Zhang"
                },
                {
                    "authorId": "2263564656",
                    "name": "Xiaohui Zhang"
                },
                {
                    "authorId": "2149060657",
                    "name": "Zhao Feng"
                },
                {
                    "authorId": "2172007228",
                    "name": "Xiaohui Xiao"
                }
            ],
            "doi": "10.1109/LRA.2023.3328448",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "c3a755d6a4d8b8a4c4f7ea7ddf0735f37a2d8587",
            "title": "Heterogeneous Multi-Robot Cooperation With Asynchronous Multi-Agent Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/c3a755d6a4d8b8a4c4f7ea7ddf0735f37a2d8587",
            "venue": "IEEE Robotics and Automation Letters",
            "year": 2024
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2274713342",
                    "name": "Yang-Gon Kim"
                },
                {
                    "authorId": "2152494980",
                    "name": "Yunki Han"
                },
                {
                    "authorId": "121510047",
                    "name": "Jaekang Shin"
                },
                {
                    "authorId": "2274460745",
                    "name": "Jun-Kyum Kim"
                },
                {
                    "authorId": "2274483217",
                    "name": "Lee-Sup Kim"
                }
            ],
            "doi": "10.1109/LCA.2023.3341152",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "8983e0500c873421a74a44abd86879d84dd25d1c",
            "title": "Accelerating Deep Reinforcement Learning via Phase-Level Parallelism for Robotics Applications",
            "url": "https://www.semanticscholar.org/paper/8983e0500c873421a74a44abd86879d84dd25d1c",
            "venue": "IEEE Computer Architecture Letters",
            "year": 2024
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2193559109",
                    "name": "Zhenghongyuan Ni"
                },
                {
                    "authorId": "2110438935",
                    "name": "Ye Jin"
                },
                {
                    "authorId": "144160387",
                    "name": "Peng Liu"
                },
                {
                    "authorId": "144122124",
                    "name": "Wei Zhao"
                }
            ],
            "doi": "10.1007/s12559-023-10226-4",
            "intent": [],
            "isInfluential": false,
            "paperId": "eed9387a1fd1224ea534de1c603c043ff03f76f8",
            "title": "A Novel Heuristic Exploration Method Based on Action Effectiveness Constraints to Relieve Loop Enhancement Effect in Reinforcement Learning with Sparse Rewards",
            "url": "https://www.semanticscholar.org/paper/eed9387a1fd1224ea534de1c603c043ff03f76f8",
            "venue": "Cognitive Computation",
            "year": 2023
        },
        {
            "arxivId": "2311.17565",
            "authors": [
                {
                    "authorId": "2268716364",
                    "name": "Lisheng Wu"
                },
                {
                    "authorId": "2268689498",
                    "name": "Ke Chen"
                }
            ],
            "doi": "10.48550/arXiv.2311.17565",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "ecdcd0160080d33bd62b895a48ec80e0771b3824",
            "title": "Bias Resilient Multi-Step Off-Policy Goal-Conditioned Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/ecdcd0160080d33bd62b895a48ec80e0771b3824",
            "venue": "ArXiv",
            "year": 2023
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "97693361",
                    "name": "Yinlong Yuan"
                },
                {
                    "authorId": "2258967993",
                    "name": "Jian Yang"
                },
                {
                    "authorId": "2259613133",
                    "name": "Zhu Liang Yu"
                },
                {
                    "authorId": "2153513423",
                    "name": "Yun Cheng"
                },
                {
                    "authorId": "2258966170",
                    "name": "Pengpeng Jiao"
                },
                {
                    "authorId": "2258968901",
                    "name": "Liang Hua"
                }
            ],
            "doi": "10.1007/s10846-023-01953-9",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "17dcd5a1003240b85d183a7ce85318eee6e48755",
            "title": "Hierarchical Goal-Guided Learning for the Evasive Maneuver of Fixed-Wing UAVs based on Deep Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/17dcd5a1003240b85d183a7ce85318eee6e48755",
            "venue": "Journal of Intelligent & Robotic Systems",
            "year": 2023
        },
        {
            "arxivId": "2309.16819",
            "authors": [
                {
                    "authorId": "2065572258",
                    "name": "Diogo S. Carvalho"
                },
                {
                    "authorId": "2254945291",
                    "name": "Pedro A. Santos"
                },
                {
                    "authorId": "145125979",
                    "name": "Francisco S. Melo"
                }
            ],
            "doi": "10.48550/arXiv.2309.16819",
            "intent": [
                "background"
            ],
            "isInfluential": true,
            "paperId": "ee959afb069392c5a36831b88f9b3ddcd333647b",
            "title": "Multi-Bellman operator for convergence of Q-learning with linear function approximation",
            "url": "https://www.semanticscholar.org/paper/ee959afb069392c5a36831b88f9b3ddcd333647b",
            "venue": "ArXiv",
            "year": 2023
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2140386806",
                    "name": "Ruchen Huang"
                },
                {
                    "authorId": "47860825",
                    "name": "Hongwen He"
                },
                {
                    "authorId": "2184599245",
                    "name": "Miaojue Gao"
                }
            ],
            "doi": "10.1016/j.apenergy.2023.121358",
            "intent": [],
            "isInfluential": false,
            "paperId": "e8aeb4c68f995c76d8355cb81af474e28b49705a",
            "title": "Training-efficient and cost-optimal energy management for fuel cell hybrid electric bus based on a novel distributed deep reinforcement learning framework",
            "url": "https://www.semanticscholar.org/paper/e8aeb4c68f995c76d8355cb81af474e28b49705a",
            "venue": "Applied Energy",
            "year": 2023
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "153730914",
                    "name": "M. Varshosaz"
                },
                {
                    "authorId": "2236699191",
                    "name": "Mohsen Ghaffari"
                },
                {
                    "authorId": "1752361",
                    "name": "E. Johnsen"
                },
                {
                    "authorId": "1723400",
                    "name": "A. W\u0105sowski"
                }
            ],
            "doi": "10.1145/3607835",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "a6596fc2ec7b9c2367b9272b341fb779a6c3ba6f",
            "title": "Formal Specification and Testing for Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/a6596fc2ec7b9c2367b9272b341fb779a6c3ba6f",
            "venue": "Proc. ACM Program. Lang.",
            "year": 2023
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2109053023",
                    "name": "Ran Wang"
                },
                {
                    "authorId": "50773290",
                    "name": "K. Kashima"
                }
            ],
            "doi": "10.1080/01691864.2023.2229886",
            "intent": [
                "methodology"
            ],
            "isInfluential": true,
            "paperId": "7d00ade4ed837b87f3fa843d5fddd6b41ee576ff",
            "title": "Deep reinforcement learning for continuous-time self-triggered control with experimental evaluation",
            "url": "https://www.semanticscholar.org/paper/7d00ade4ed837b87f3fa843d5fddd6b41ee576ff",
            "venue": "Adv. Robotics",
            "year": 2023
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2088036837",
                    "name": "Z. Ye"
                },
                {
                    "authorId": "2090950337",
                    "name": "B. Schuller"
                }
            ],
            "doi": "10.2139/ssrn.4352099",
            "intent": [],
            "isInfluential": false,
            "paperId": "0316c7822731fc1fc9b1554252e0c51e433c7c55",
            "title": "Human-aligned trading by imitative multi-loss reinforcement learning",
            "url": "https://www.semanticscholar.org/paper/0316c7822731fc1fc9b1554252e0c51e433c7c55",
            "venue": "Expert Syst. Appl.",
            "year": 2023
        },
        {
            "arxivId": "2306.17833",
            "authors": [
                {
                    "authorId": "7981071",
                    "name": "Kavosh Asadi"
                },
                {
                    "authorId": "2915023",
                    "name": "Rasool Fakoor"
                },
                {
                    "authorId": "3218963",
                    "name": "Shoham Sabach"
                }
            ],
            "doi": "10.48550/arXiv.2306.17833",
            "intent": [
                "background",
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "d0eac1da5d54638fd3dc41cd1e477d804dc4d806",
            "title": "Resetting the Optimizer in Deep RL: An Empirical Study",
            "url": "https://www.semanticscholar.org/paper/d0eac1da5d54638fd3dc41cd1e477d804dc4d806",
            "venue": "NeurIPS",
            "year": 2023
        },
        {
            "arxivId": "2306.14133",
            "authors": [
                {
                    "authorId": "2220572426",
                    "name": "Jun Song"
                },
                {
                    "authorId": "2903347",
                    "name": "Niao He"
                },
                {
                    "authorId": "46573184",
                    "name": "Lijun Ding"
                },
                {
                    "authorId": "2220594878",
                    "name": "Chaoyue Zhao"
                }
            ],
            "doi": "10.48550/arXiv.2306.14133",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "2732028656ffa7c240932d38a7e134747c2aefeb",
            "title": "Provably Convergent Policy Optimization via Metric-aware Trust Region Methods",
            "url": "https://www.semanticscholar.org/paper/2732028656ffa7c240932d38a7e134747c2aefeb",
            "venue": "Trans. Mach. Learn. Res.",
            "year": 2023
        },
        {
            "arxivId": "2306.14047",
            "authors": [
                {
                    "authorId": "2115752260",
                    "name": "Jun Song"
                },
                {
                    "authorId": "2212069428",
                    "name": "Chaoyue Zhao"
                }
            ],
            "doi": "10.1109/PESGM52003.2023.10252418",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "0c4be80ec42f9a201a2111bceac68e5a90169312",
            "title": "Towards Optimal Pricing of Demand Response - A Nonparametric Constrained Policy Optimization Approach",
            "url": "https://www.semanticscholar.org/paper/0c4be80ec42f9a201a2111bceac68e5a90169312",
            "venue": "2023 IEEE Power & Energy Society General Meeting (PESGM)",
            "year": 2023
        },
        {
            "arxivId": "2306.04846",
            "authors": [
                {
                    "authorId": "32718688",
                    "name": "Keizo Hori"
                },
                {
                    "authorId": "2081851",
                    "name": "Yuya Sasaki"
                },
                {
                    "authorId": "2594996",
                    "name": "Daichi Amagata"
                },
                {
                    "authorId": "93978544",
                    "name": "Y. Murosaki"
                },
                {
                    "authorId": "48075831",
                    "name": "Makoto Onizuka"
                }
            ],
            "doi": "10.1145/3593078.3593932",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "4f30781a4c0acaab7bfdef39b549bc91ecda523e",
            "title": "Learned Spatial Data Partitioning",
            "url": "https://www.semanticscholar.org/paper/4f30781a4c0acaab7bfdef39b549bc91ecda523e",
            "venue": "aiDM@SIGMOD",
            "year": 2023
        },
        {
            "arxivId": "2303.08856",
            "authors": [
                {
                    "authorId": "98084420",
                    "name": "Jiajun Shen"
                },
                {
                    "authorId": "41018676",
                    "name": "K. Kuwaranancharoen"
                },
                {
                    "authorId": "2459274",
                    "name": "R. Ayoub"
                },
                {
                    "authorId": "2528093",
                    "name": "Pietro Mercati"
                },
                {
                    "authorId": "144882686",
                    "name": "S. Sundaram"
                }
            ],
            "doi": "10.23919/ACC55779.2023.10155973",
            "intent": [],
            "isInfluential": false,
            "paperId": "48cc4c3c8b3d038be0eff5d71a8489c9274226be",
            "title": "On the Benefits of Leveraging Structural Information in Planning Over the Learned Model",
            "url": "https://www.semanticscholar.org/paper/48cc4c3c8b3d038be0eff5d71a8489c9274226be",
            "venue": "2023 American Control Conference (ACC)",
            "year": 2023
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2140386806",
                    "name": "Ruchen Huang"
                },
                {
                    "authorId": "47860825",
                    "name": "Hongwen He"
                },
                {
                    "authorId": "98212954",
                    "name": "Xuyang Zhao"
                },
                {
                    "authorId": "2184599245",
                    "name": "Miaojue Gao"
                }
            ],
            "doi": "10.1016/j.jpowsour.2023.232717",
            "intent": [],
            "isInfluential": false,
            "paperId": "3027315346acfe10d9c774b510363a4b582981db",
            "title": "Longevity-aware energy management for fuel cell hybrid electric bus based on a novel proximal policy optimization deep reinforcement learning framework",
            "url": "https://www.semanticscholar.org/paper/3027315346acfe10d9c774b510363a4b582981db",
            "venue": "Journal of Power Sources",
            "year": 2023
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2110577904",
                    "name": "Chia-Hao Tsai"
                },
                {
                    "authorId": "2144488753",
                    "name": "Jung-Ji Lin"
                },
                {
                    "authorId": "2188633967",
                    "name": "Teng-Feng Hsieh"
                },
                {
                    "authorId": "3105683",
                    "name": "J. Yen"
                }
            ],
            "doi": "10.3390/robotics11050116",
            "intent": [],
            "isInfluential": false,
            "paperId": "51ff6172e3d7d36582ad189e6a0caf203a5afa51",
            "title": "Trajectory Control of An Articulated Robot Based on Direct Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/51ff6172e3d7d36582ad189e6a0caf203a5afa51",
            "venue": "Robotics",
            "year": 2022
        },
        {
            "arxivId": "2210.04820",
            "authors": [
                {
                    "authorId": "13048995",
                    "name": "Junmin Zhong"
                },
                {
                    "authorId": "153088943",
                    "name": "Ruofan Wu"
                },
                {
                    "authorId": "46333892",
                    "name": "J. Si"
                }
            ],
            "doi": "10.48550/arXiv.2210.04820",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "ad55e3eca451705dfe8bb200b9f0f0e199fb1d75",
            "title": "Long N-step Surrogate Stage Reward to Reduce Variances of Deep Reinforcement Learning in Complex Problems",
            "url": "https://www.semanticscholar.org/paper/ad55e3eca451705dfe8bb200b9f0f0e199fb1d75",
            "venue": "ArXiv",
            "year": 2022
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "148431434",
                    "name": "Zhengwei Lv"
                },
                {
                    "authorId": "2197404619",
                    "name": "Chao Peng"
                },
                {
                    "authorId": "2156122710",
                    "name": "Zhao Zhang"
                },
                {
                    "authorId": "144121517",
                    "name": "Ting Su"
                },
                {
                    "authorId": "49599759",
                    "name": "Kai Liu"
                },
                {
                    "authorId": "2197406061",
                    "name": "Ping Yang"
                }
            ],
            "doi": "10.1145/3551349.3559505",
            "intent": [],
            "isInfluential": false,
            "paperId": "b320c20782d764ea85b8aa97e05cf4b5fee11f9d",
            "title": "Fastbot2: Reusable Automated Model-based GUI Testing for Android Enhanced by Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/b320c20782d764ea85b8aa97e05cf4b5fee11f9d",
            "venue": "ASE",
            "year": 2022
        },
        {
            "arxivId": "2209.05530",
            "authors": [
                {
                    "authorId": "2175115642",
                    "name": "Hao-Chu Lin"
                },
                {
                    "authorId": "120738487",
                    "name": "Yihao Sun"
                },
                {
                    "authorId": "2000940184",
                    "name": "Jiajin Zhang"
                },
                {
                    "authorId": "144705629",
                    "name": "Yang Yu"
                }
            ],
            "doi": "10.48550/arXiv.2209.05530",
            "intent": [
                "background",
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "c56bc32f12c991f0e1b7d2999a1ec4a842c25709",
            "title": "Model-based Reinforcement Learning with Multi-step Plan Value Estimation",
            "url": "https://www.semanticscholar.org/paper/c56bc32f12c991f0e1b7d2999a1ec4a842c25709",
            "venue": "ECAI",
            "year": 2022
        },
        {
            "arxivId": "2209.04999",
            "authors": [
                {
                    "authorId": "2113609651",
                    "name": "Lingheng Meng"
                },
                {
                    "authorId": "39267789",
                    "name": "R. Gorbet"
                },
                {
                    "authorId": "2153472363",
                    "name": "Dana Kuli'c"
                }
            ],
            "doi": "10.48550/arXiv.2209.04999",
            "intent": [],
            "isInfluential": false,
            "paperId": "b885461aa0e29c57344fb6c0c894e83fce2f7c70",
            "title": "Partial Observability during DRL for Robot Control",
            "url": "https://www.semanticscholar.org/paper/b885461aa0e29c57344fb6c0c894e83fce2f7c70",
            "venue": "ArXiv",
            "year": 2022
        },
        {
            "arxivId": "2209.03993",
            "authors": [
                {
                    "authorId": "2067637897",
                    "name": "Taku Yamagata"
                },
                {
                    "authorId": "2100092361",
                    "name": "Ahmed Khalil"
                },
                {
                    "authorId": "2126710957",
                    "name": "Ra\u00fal Santos-Rodr\u00edguez"
                }
            ],
            "doi": "10.48550/arXiv.2209.03993",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "fbb15aa7303586d25dc73f84c23f9b5447b0c06b",
            "title": "Q-learning Decision Transformer: Leveraging Dynamic Programming for Conditional Sequence Modelling in Offline RL",
            "url": "https://www.semanticscholar.org/paper/fbb15aa7303586d25dc73f84c23f9b5447b0c06b",
            "venue": "ICML",
            "year": 2022
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2180685824",
                    "name": "Marc Espin\u00f3s Longa"
                },
                {
                    "authorId": "1809291",
                    "name": "A. Tsourdos"
                },
                {
                    "authorId": "2985826",
                    "name": "G. Inalhan"
                }
            ],
            "doi": "10.23919/ACC53348.2022.9867171",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "5f00795d77b0eae57b278cf34a93d05dcf1a95aa",
            "title": "Swarm Intelligence in Cooperative Environments: N-Step Dynamic Tree Search Algorithm Extended Analysis",
            "url": "https://www.semanticscholar.org/paper/5f00795d77b0eae57b278cf34a93d05dcf1a95aa",
            "venue": "2022 American Control Conference (ACC)",
            "year": 2022
        },
        {
            "arxivId": "2206.01896",
            "authors": [
                {
                    "authorId": "35217291",
                    "name": "Brett Daley"
                },
                {
                    "authorId": "121466678",
                    "name": "I. Chan"
                }
            ],
            "doi": "10.48550/arXiv.2206.01896",
            "intent": [],
            "isInfluential": false,
            "paperId": "a0132491355da6a3376e9a21d306dd702dead68d",
            "title": "Adaptive Tree Backup Algorithms for Temporal-Difference Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/a0132491355da6a3376e9a21d306dd702dead68d",
            "venue": "ArXiv",
            "year": 2022
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2145954657",
                    "name": "Yang Zhang"
                },
                {
                    "authorId": "2436287",
                    "name": "Qingyu Yang"
                },
                {
                    "authorId": "38065539",
                    "name": "Dou An"
                },
                {
                    "authorId": "46598765",
                    "name": "Donghe Li"
                },
                {
                    "authorId": "34815981",
                    "name": "Zongze Wu"
                }
            ],
            "doi": "10.1109/TCYB.2022.3165074",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "af2063e95cb9b473073885d54fc0afef144e1ea8",
            "title": "Multistep Multiagent Reinforcement Learning for Optimal Energy Schedule Strategy of Charging Stations in Smart Grid",
            "url": "https://www.semanticscholar.org/paper/af2063e95cb9b473073885d54fc0afef144e1ea8",
            "venue": "IEEE Transactions on Cybernetics",
            "year": 2022
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2148723420",
                    "name": "Marc Espin\u00f3s Longa"
                },
                {
                    "authorId": "2985826",
                    "name": "G. Inalhan"
                },
                {
                    "authorId": "1809291",
                    "name": "A. Tsourdos"
                }
            ],
            "doi": "10.2514/6.2022-1839",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "68007b475f83cf1d16234cc17e6367917b7de10d",
            "title": "Swarm Intelligence in Cooperative Environments: Introducing the N-Step Dynamic Tree Search Algorithm",
            "url": "https://www.semanticscholar.org/paper/68007b475f83cf1d16234cc17e6367917b7de10d",
            "venue": "AIAA SCITECH 2022 Forum",
            "year": 2022
        },
        {
            "arxivId": "2111.02997",
            "authors": [
                {
                    "authorId": "2503523",
                    "name": "Shangtong Zhang"
                },
                {
                    "authorId": "15032777",
                    "name": "R\u00e9mi Tachet des Combes"
                },
                {
                    "authorId": "144100820",
                    "name": "R. Laroche"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": true,
            "paperId": "7d01b6db1a74d2d7712307a992d6772095d75649",
            "title": "Global Optimality and Finite Sample Analysis of Softmax Off-Policy Actor Critic under State Distribution Mismatch",
            "url": "https://www.semanticscholar.org/paper/7d01b6db1a74d2d7712307a992d6772095d75649",
            "venue": "J. Mach. Learn. Res.",
            "year": 2021
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "50300258",
                    "name": "Tianjun Sun"
                },
                {
                    "authorId": "46517217",
                    "name": "Zhenhai Gao"
                },
                {
                    "authorId": "115784937",
                    "name": "Zhi-Kai Chang"
                },
                {
                    "authorId": "2074109733",
                    "name": "Kehan Zhao"
                }
            ],
            "doi": "10.1007/s42235-021-00113-9",
            "intent": [],
            "isInfluential": false,
            "paperId": "5a6c04d90b9c7d8a9b4047a5d00edea944831294",
            "title": "Brain-like Intelligent Decision-making Based on Basal Ganglia and Its Application in Automatic Car-following",
            "url": "https://www.semanticscholar.org/paper/5a6c04d90b9c7d8a9b4047a5d00edea944831294",
            "venue": "Journal of Bionic Engineering",
            "year": 2021
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2145386769",
                    "name": "Di Wang"
                },
                {
                    "authorId": "8367715",
                    "name": "Mengqi Hu"
                }
            ],
            "doi": "10.1109/TNNLS.2021.3117790",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "898d7114242d6d02a79534f502a72a49263625dd",
            "title": "Deep Deterministic Policy Gradient With Compatible Critic Network",
            "url": "https://www.semanticscholar.org/paper/898d7114242d6d02a79534f502a72a49263625dd",
            "venue": "IEEE Transactions on Neural Networks and Learning Systems",
            "year": 2021
        },
        {
            "arxivId": "2107.14171",
            "authors": [
                {
                    "authorId": "2070303222",
                    "name": "Jiayi Weng"
                },
                {
                    "authorId": "1477962932",
                    "name": "Huayu Chen"
                },
                {
                    "authorId": "143848636",
                    "name": "Dong Yan"
                },
                {
                    "authorId": "89470893",
                    "name": "Kaichao You"
                },
                {
                    "authorId": "49720341",
                    "name": "Alexis Duburcq"
                },
                {
                    "authorId": "2112152893",
                    "name": "Minghao Zhang"
                },
                {
                    "authorId": "2118006538",
                    "name": "Yi Su"
                },
                {
                    "authorId": "2093561216",
                    "name": "Hang Su"
                },
                {
                    "authorId": "145254043",
                    "name": "Jun Zhu"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "80438f2ef228776b22118915f1a27e2cf4a0f4e0",
            "title": "Tianshou: a Highly Modularized Deep Reinforcement Learning Library",
            "url": "https://www.semanticscholar.org/paper/80438f2ef228776b22118915f1a27e2cf4a0f4e0",
            "venue": "J. Mach. Learn. Res.",
            "year": 2021
        },
        {
            "arxivId": "2106.10075",
            "authors": [
                {
                    "authorId": "1710725",
                    "name": "Stefan Wagner"
                },
                {
                    "authorId": "2113839973",
                    "name": "Michael Janschek"
                },
                {
                    "authorId": "148250214",
                    "name": "Tobias Uelwer"
                },
                {
                    "authorId": "1734990",
                    "name": "S. Harmeling"
                }
            ],
            "doi": "10.1007/978-3-030-86380-7_39",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "e8d186d1b98b6ce62c441c48c3dbbd5b00c030a2",
            "title": "Learning to Plan via a Multi-Step Policy Regression Method",
            "url": "https://www.semanticscholar.org/paper/e8d186d1b98b6ce62c441c48c3dbbd5b00c030a2",
            "venue": "ICANN",
            "year": 2021
        },
        {
            "arxivId": "2105.15119",
            "authors": [
                {
                    "authorId": "145420906",
                    "name": "P. Costa"
                },
                {
                    "authorId": "104052936",
                    "name": "Peter Verleijsdonk"
                },
                {
                    "authorId": "134769013",
                    "name": "Simon Voorberg"
                },
                {
                    "authorId": "33719277",
                    "name": "A. Ak\u00e7ay"
                },
                {
                    "authorId": "2701192",
                    "name": "S. Kapodistria"
                },
                {
                    "authorId": "2152091",
                    "name": "W. Jaarsveld"
                },
                {
                    "authorId": "2108466121",
                    "name": "Yingqian Zhang"
                }
            ],
            "doi": "10.1016/j.ejor.2022.06.044",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "838f39fbf576494ca6f9a68e575a63293b6b028a",
            "title": "Policies for the Dynamic Traveling Maintainer Problem with Alerts",
            "url": "https://www.semanticscholar.org/paper/838f39fbf576494ca6f9a68e575a63293b6b028a",
            "venue": "Eur. J. Oper. Res.",
            "year": 2021
        },
        {
            "arxivId": "2105.08877",
            "authors": [
                {
                    "authorId": "2097711464",
                    "name": "A. Fathan"
                },
                {
                    "authorId": "3203751",
                    "name": "E. Delage"
                }
            ],
            "doi": null,
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "7cc48a91db783fb8a66b2bb6c0b92f87c2254317",
            "title": "Deep Reinforcement Learning for Optimal Stopping with Application in Financial Engineering",
            "url": "https://www.semanticscholar.org/paper/7cc48a91db783fb8a66b2bb6c0b92f87c2254317",
            "venue": "ArXiv",
            "year": 2021
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2089576047",
                    "name": "Zahra Movahedi"
                },
                {
                    "authorId": "1977068",
                    "name": "A. Bastanfard"
                }
            ],
            "doi": "10.1007/s11042-021-10968-z",
            "intent": [],
            "isInfluential": false,
            "paperId": "ce07398ed5995904e919fdcbe1e2a32e278f4688",
            "title": "Toward competitive multi-agents in Polo game based on reinforcement learning",
            "url": "https://www.semanticscholar.org/paper/ce07398ed5995904e919fdcbe1e2a32e278f4688",
            "venue": "Multimedia Tools and Applications",
            "year": 2021
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "34719248",
                    "name": "Josiah P. Hanna"
                },
                {
                    "authorId": "2791038",
                    "name": "S. Niekum"
                },
                {
                    "authorId": "144848112",
                    "name": "P. Stone"
                }
            ],
            "doi": "10.1007/s10994-020-05938-9",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "28146afb4e983349aab0f03955f145e59ec72093",
            "title": "Importance sampling in reinforcement learning with an estimated behavior policy",
            "url": "https://www.semanticscholar.org/paper/28146afb4e983349aab0f03955f145e59ec72093",
            "venue": "Machine Learning",
            "year": 2021
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "1734851748",
                    "name": "Lei Xi"
                },
                {
                    "authorId": "2145294281",
                    "name": "Lipeng Zhou"
                },
                {
                    "authorId": "48615168",
                    "name": "Yanchun Xu"
                },
                {
                    "authorId": "2145308410",
                    "name": "Xi Chen"
                }
            ],
            "doi": "10.1109/TSTE.2020.3047137",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "04b9cfb6c69e002cb6e8cd0234a3704cf28f3fe9",
            "title": "A Multi-Step Unified Reinforcement Learning Method for Automatic Generation Control in Multi-Area Interconnected Power Grid",
            "url": "https://www.semanticscholar.org/paper/04b9cfb6c69e002cb6e8cd0234a3704cf28f3fe9",
            "venue": "IEEE Transactions on Sustainable Energy",
            "year": 2021
        },
        {
            "arxivId": "2103.05115",
            "authors": [
                {
                    "authorId": "2107323185",
                    "name": "S. K. Zhou"
                },
                {
                    "authorId": "2242292542",
                    "name": "Hoang Ngan Le"
                },
                {
                    "authorId": "1769788",
                    "name": "Khoa Luu"
                },
                {
                    "authorId": "2242289774",
                    "name": "Hien V Nguyen"
                },
                {
                    "authorId": "144827643",
                    "name": "N. Ayache"
                }
            ],
            "doi": "10.1016/j.media.2021.102193",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "29f05531de4426cf0b88bace56b47bf0ac9ce0a2",
            "title": "Deep reinforcement learning in medical imaging: A literature review",
            "url": "https://www.semanticscholar.org/paper/29f05531de4426cf0b88bace56b47bf0ac9ce0a2",
            "venue": "Medical Image Anal.",
            "year": 2021
        },
        {
            "arxivId": "2102.11717",
            "authors": [
                {
                    "authorId": "2115768892",
                    "name": "Yuhui Wang"
                },
                {
                    "authorId": "2108761828",
                    "name": "Qingyuan Wu"
                },
                {
                    "authorId": "2107782398",
                    "name": "Pengcheng He"
                },
                {
                    "authorId": "2109869742",
                    "name": "Xiaoyang Tan"
                }
            ],
            "doi": null,
            "intent": [
                "background",
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "644777a1183274384e5c7ca5e4bcadd282233570",
            "title": "Greedy-Step Off-Policy Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/644777a1183274384e5c7ca5e4bcadd282233570",
            "venue": "",
            "year": 2021
        },
        {
            "arxivId": "2012.04461",
            "authors": [
                {
                    "authorId": "89839369",
                    "name": "Jiongzhi Zheng"
                },
                {
                    "authorId": "145905328",
                    "name": "Kun He"
                },
                {
                    "authorId": "48129197",
                    "name": "Jianrong Zhou"
                },
                {
                    "authorId": "101487852",
                    "name": "Yan Jin"
                },
                {
                    "authorId": "107891952",
                    "name": "Chumin Li"
                }
            ],
            "doi": "10.1609/aaai.v35i14.17476",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "87fa4e906465fc2d8f8331a3165a9fe3ba05ed91",
            "title": "Combining Reinforcement Learning with Lin-Kernighan-Helsgaun Algorithm for the Traveling Salesman Problem",
            "url": "https://www.semanticscholar.org/paper/87fa4e906465fc2d8f8331a3165a9fe3ba05ed91",
            "venue": "AAAI",
            "year": 2020
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "46959622",
                    "name": "Haibo Deng"
                },
                {
                    "authorId": "1851380",
                    "name": "Shiqun Yin"
                },
                {
                    "authorId": "2026161185",
                    "name": "Xiaohong Deng"
                },
                {
                    "authorId": "2145338875",
                    "name": "Shiwei Li"
                }
            ],
            "doi": "10.1109/HPCC-SmartCity-DSS50907.2020.00131",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "d466b3a1fc09c564c8a29a734e848e4e0c1b4ead",
            "title": "Value-based Algorithms Optimization with Discounted Multiple-step Learning Method in Deep Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/d466b3a1fc09c564c8a29a734e848e4e0c1b4ead",
            "venue": "2020 IEEE 22nd International Conference on High Performance Computing and Communications; IEEE 18th International Conference on Smart City; IEEE 6th International Conference on Data Science and Systems (HPCC/SmartCity/DSS)",
            "year": 2020
        },
        {
            "arxivId": "2007.08229",
            "authors": [
                {
                    "authorId": "1492127964",
                    "name": "Po-Han Chiang"
                },
                {
                    "authorId": "35973593",
                    "name": "Hsuan-Kung Yang"
                },
                {
                    "authorId": "33317877",
                    "name": "Zhang-Wei Hong"
                },
                {
                    "authorId": "1492122970",
                    "name": "Chun-Yi Lee"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "bfc17bc0d9d8a75ea11f4c6c86d92c2bcd4f98e9",
            "title": "Mixture of Step Returns in Bootstrapped DQN",
            "url": "https://www.semanticscholar.org/paper/bfc17bc0d9d8a75ea11f4c6c86d92c2bcd4f98e9",
            "venue": "ArXiv",
            "year": 2020
        },
        {
            "arxivId": "2008.06738",
            "authors": [
                {
                    "authorId": "137071348",
                    "name": "Brahma S. Pavse"
                },
                {
                    "authorId": "9571638",
                    "name": "Ishan Durugkar"
                },
                {
                    "authorId": "34719248",
                    "name": "Josiah P. Hanna"
                },
                {
                    "authorId": "144848112",
                    "name": "P. Stone"
                }
            ],
            "doi": "10.26153/TSW/14853",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "0f9d996c06ea67d9cf1ca09bb714261f18445579",
            "title": "Reducing Sampling Error in Batch Temporal Difference Learning",
            "url": "https://www.semanticscholar.org/paper/0f9d996c06ea67d9cf1ca09bb714261f18445579",
            "venue": "ICML",
            "year": 2020
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "21780262",
                    "name": "Rajkumar Ramamurthy"
                },
                {
                    "authorId": "2018549",
                    "name": "R. Sifa"
                },
                {
                    "authorId": "1396407321",
                    "name": "Max L\u00fcbbering"
                },
                {
                    "authorId": "1692283",
                    "name": "C. Bauckhage"
                }
            ],
            "doi": "10.1109/IJCNN48605.2020.9206982",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "8307a2915f56f48d07158fa335cb49b3959aa738",
            "title": "Novelty-Guided Reinforcement Learning via Encoded Behaviors",
            "url": "https://www.semanticscholar.org/paper/8307a2915f56f48d07158fa335cb49b3959aa738",
            "venue": "2020 International Joint Conference on Neural Networks (IJCNN)",
            "year": 2020
        },
        {
            "arxivId": "2006.07815",
            "authors": [
                {
                    "authorId": "2115753847",
                    "name": "Jun Song"
                },
                {
                    "authorId": "1949005",
                    "name": "Chaoyue Zhao"
                }
            ],
            "doi": null,
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "e641dcbb7522b9f22086eb1c26e10ef29b7e0cb4",
            "title": "Optimistic Distributionally Robust Policy Optimization",
            "url": "https://www.semanticscholar.org/paper/e641dcbb7522b9f22086eb1c26e10ef29b7e0cb4",
            "venue": "ArXiv",
            "year": 2020
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "1828817",
                    "name": "M. Greguri\u0107"
                },
                {
                    "authorId": "24359418",
                    "name": "M. Vuji\u0107"
                },
                {
                    "authorId": "48489908",
                    "name": "C. Alexopoulos"
                },
                {
                    "authorId": "31176581",
                    "name": "Mladen Mileti\u0107"
                }
            ],
            "doi": "10.3390/app10114011",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "0d3e4c23d55b1567dbeb24f7fdfca47d6bcfe216",
            "title": "Application of Deep Reinforcement Learning in Traffic Signal Control: An Overview and Impact of Open Traffic Data",
            "url": "https://www.semanticscholar.org/paper/0d3e4c23d55b1567dbeb24f7fdfca47d6bcfe216",
            "venue": "Applied Sciences",
            "year": 2020
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "3420880",
                    "name": "T. P. D. Homem"
                },
                {
                    "authorId": "145275454",
                    "name": "P. Santos"
                },
                {
                    "authorId": "2209202",
                    "name": "Anna Helena Reali Costa"
                },
                {
                    "authorId": "32999467",
                    "name": "Reinaldo A. C. Bianchi"
                },
                {
                    "authorId": "41070350",
                    "name": "R. L. D. M\u00e1ntaras"
                }
            ],
            "doi": "10.1016/j.artint.2020.103258",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "f087d3ff8da57e553349449c3a141227c34fd713",
            "title": "Qualitative case-based reasoning and learning",
            "url": "https://www.semanticscholar.org/paper/f087d3ff8da57e553349449c3a141227c34fd713",
            "venue": "Artif. Intell.",
            "year": 2020
        },
        {
            "arxivId": "2005.12890",
            "authors": [
                {
                    "authorId": "39735569",
                    "name": "Dominic C. Rose"
                },
                {
                    "authorId": "1720732860",
                    "name": "Jamie F. Mair"
                },
                {
                    "authorId": "4424096",
                    "name": "J. P. Garrahan"
                }
            ],
            "doi": "10.1088/1367-2630/abd7bd",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "42777109289db3b4bfedc05b9b976e18758a1156",
            "title": "A reinforcement learning approach to rare trajectory sampling",
            "url": "https://www.semanticscholar.org/paper/42777109289db3b4bfedc05b9b976e18758a1156",
            "venue": "New Journal of Physics",
            "year": 2020
        },
        {
            "arxivId": "2004.10888",
            "authors": [
                {
                    "authorId": "2503523",
                    "name": "Shangtong Zhang"
                },
                {
                    "authorId": "2156641089",
                    "name": "Bo Liu"
                },
                {
                    "authorId": "1766767",
                    "name": "Shimon Whiteson"
                }
            ],
            "doi": "10.1609/aaai.v35i12.17302",
            "intent": [],
            "isInfluential": false,
            "paperId": "11d558cf04914a19068338705526593fe7fb6cd3",
            "title": "Mean-Variance Policy Iteration for Risk-Averse Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/11d558cf04914a19068338705526593fe7fb6cd3",
            "venue": "AAAI",
            "year": 2020
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2503523",
                    "name": "Shangtong Zhang"
                },
                {
                    "authorId": "40107085",
                    "name": "Bo Liu"
                },
                {
                    "authorId": "1766767",
                    "name": "Shimon Whiteson"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": true,
            "paperId": "26a5ea837ccefbf12ab7289b5cc31fa77957bf8c",
            "title": "Per-Step Reward: A New Perspective for Risk-Averse Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/26a5ea837ccefbf12ab7289b5cc31fa77957bf8c",
            "venue": "ArXiv",
            "year": 2020
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2088468768",
                    "name": "Raj Shah"
                },
                {
                    "authorId": "2088485835",
                    "name": "Ashutosh Tambe"
                },
                {
                    "authorId": "2088485871",
                    "name": "Tej Bhatt"
                },
                {
                    "authorId": "72183982",
                    "name": "Uday Rote"
                }
            ],
            "doi": "10.2139/ssrn.3586788",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "634a24305d3a7d9de0f0d6f8ac8204ac18abb23f",
            "title": "Real-Time Stock Market Forecasting using Ensemble Deep Learning and Rainbow DQN",
            "url": "https://www.semanticscholar.org/paper/634a24305d3a7d9de0f0d6f8ac8204ac18abb23f",
            "venue": "SSRN Electronic Journal",
            "year": 2020
        },
        {
            "arxivId": "1912.10316",
            "authors": [
                {
                    "authorId": "1470544636",
                    "name": "Abhishek Nan"
                }
            ],
            "doi": null,
            "intent": [
                "background",
                "result",
                "methodology"
            ],
            "isInfluential": true,
            "paperId": "b08279b44d781b728ef386f8facf4833dbf1a1c1",
            "title": "Exploring TD error as a heuristic for \u03c3 selection in Q(\u03c3, \u03bb)",
            "url": "https://www.semanticscholar.org/paper/b08279b44d781b728ef386f8facf4833dbf1a1c1",
            "venue": "ArXiv",
            "year": 2019
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "1491241661",
                    "name": "Tongyu Guo"
                },
                {
                    "authorId": "2116009595",
                    "name": "Haitao Zhang"
                },
                {
                    "authorId": "2143496502",
                    "name": "Han Huang"
                },
                {
                    "authorId": "1956549",
                    "name": "Jianli Guo"
                },
                {
                    "authorId": "1491233456",
                    "name": "Chenze He"
                }
            ],
            "doi": "10.1109/ISPA-BDCloud-SustainCom-SocialCom48970.2019.00065",
            "intent": [
                "methodology"
            ],
            "isInfluential": true,
            "paperId": "b6520fc146f7997b4964aef5620013ab873c80ad",
            "title": "Multi-Resource Fair Allocation for Composited Services in Edge Micro-Clouds",
            "url": "https://www.semanticscholar.org/paper/b6520fc146f7997b4964aef5620013ab873c80ad",
            "venue": "2019 IEEE Intl Conf on Parallel & Distributed Processing with Applications, Big Data & Cloud Computing, Sustainable Computing & Communications, Social Computing & Networking (ISPA/BDCloud/SocialCom/SustainCom)",
            "year": 2019
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2116289339",
                    "name": "Quan Zhou"
                },
                {
                    "authorId": "2117986015",
                    "name": "Ji Li"
                },
                {
                    "authorId": "47869993",
                    "name": "B. Shuai"
                },
                {
                    "authorId": "2087668608",
                    "name": "Huw Williams"
                },
                {
                    "authorId": "2169615",
                    "name": "Yinglong He"
                },
                {
                    "authorId": "48458706",
                    "name": "Ziyang Li"
                },
                {
                    "authorId": "47995280",
                    "name": "Hongming Xu"
                },
                {
                    "authorId": "2150928700",
                    "name": "Fuwu Yan"
                }
            ],
            "doi": "10.1016/j.apenergy.2019.113755",
            "intent": [],
            "isInfluential": false,
            "paperId": "6dffc5d0093a63f54836329522b41aab46cafd16",
            "title": "Multi-step reinforcement learning for model-free predictive energy management of an electrified off-highway vehicle",
            "url": "https://www.semanticscholar.org/paper/6dffc5d0093a63f54836329522b41aab46cafd16",
            "venue": "",
            "year": 2019
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "152577264",
                    "name": "J. Hanna"
                }
            ],
            "doi": "10.26153/TSW/7716",
            "intent": [],
            "isInfluential": false,
            "paperId": "4f1d5b1473bf6e46c989dadbe1cf3d3a66a01e71",
            "title": "Data efficient reinforcement learning with off-policy and simulated data",
            "url": "https://www.semanticscholar.org/paper/4f1d5b1473bf6e46c989dadbe1cf3d3a66a01e71",
            "venue": "",
            "year": 2019
        },
        {
            "arxivId": "1911.04094",
            "authors": [
                {
                    "authorId": "1410010512",
                    "name": "Xinghu Yao"
                },
                {
                    "authorId": "2068033738",
                    "name": "Chao Wen"
                },
                {
                    "authorId": "2115768892",
                    "name": "Yuhui Wang"
                },
                {
                    "authorId": "2248421",
                    "name": "Xiaoyang Tan"
                }
            ],
            "doi": "10.1109/TNNLS.2021.3089493",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "060571527cdf3036adb78911c5b1c065b92c4714",
            "title": "SMIX(\u03bb): Enhancing Centralized Value Functions for Cooperative Multiagent Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/060571527cdf3036adb78911c5b1c065b92c4714",
            "venue": "IEEE Transactions on Neural Networks and Learning Systems",
            "year": 2019
        },
        {
            "arxivId": "1911.04107",
            "authors": [
                {
                    "authorId": "2146661698",
                    "name": "Gang Chen"
                },
                {
                    "authorId": "34377382",
                    "name": "Dingcheng Li"
                },
                {
                    "authorId": "2115800155",
                    "name": "Ran Xu"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "f4f16fe875e57098ce6cf7fb2e79f682efc6e0ea",
            "title": "Context-aware Active Multi-Step Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/f4f16fe875e57098ce6cf7fb2e79f682efc6e0ea",
            "venue": "ArXiv",
            "year": 2019
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "147637011",
                    "name": "Mengwen Yuan"
                },
                {
                    "authorId": "2108783749",
                    "name": "Xi Wu"
                },
                {
                    "authorId": "144539164",
                    "name": "Rui Yan"
                },
                {
                    "authorId": "3134548",
                    "name": "Huajin Tang"
                }
            ],
            "doi": "10.1162/neco_a_01238",
            "intent": [],
            "isInfluential": false,
            "paperId": "5acd85d789ab0a747968f8fa36b2a8f1614af71c",
            "title": "Reinforcement Learning in Spiking Neural Networks with Stochastic and Deterministic Synapses",
            "url": "https://www.semanticscholar.org/paper/5acd85d789ab0a747968f8fa36b2a8f1614af71c",
            "venue": "Neural Computation",
            "year": 2019
        },
        {
            "arxivId": "1910.07478",
            "authors": [
                {
                    "authorId": "144845456",
                    "name": "Mark Rowland"
                },
                {
                    "authorId": "2605877",
                    "name": "Will Dabney"
                },
                {
                    "authorId": "1708654",
                    "name": "R. Munos"
                }
            ],
            "doi": null,
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "22ef540fdf0550a0079b6b3217785339413a4b82",
            "title": "Adaptive Trade-Offs in Off-Policy Learning",
            "url": "https://www.semanticscholar.org/paper/22ef540fdf0550a0079b6b3217785339413a4b82",
            "venue": "AISTATS",
            "year": 2019
        },
        {
            "arxivId": "1909.13518",
            "authors": [
                {
                    "authorId": "49480778",
                    "name": "Gabriel Kalweit"
                },
                {
                    "authorId": "39392865",
                    "name": "M. Huegle"
                },
                {
                    "authorId": "145581493",
                    "name": "J. Boedecker"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "cf1a7deb963416202c3ef417ad7ed7586fd0e4e8",
            "title": "Off-policy Multi-step Q-learning",
            "url": "https://www.semanticscholar.org/paper/cf1a7deb963416202c3ef417ad7ed7586fd0e4e8",
            "venue": "ArXiv",
            "year": 2019
        },
        {
            "arxivId": "1909.02877",
            "authors": [
                {
                    "authorId": "150196660",
                    "name": "Long Yang"
                },
                {
                    "authorId": "2153636406",
                    "name": "Yu Zhang"
                },
                {
                    "authorId": "48809559",
                    "name": "Qian Zheng"
                },
                {
                    "authorId": "143714920",
                    "name": "Pengfei Li"
                },
                {
                    "authorId": "2055725787",
                    "name": "Gang Pan"
                }
            ],
            "doi": null,
            "intent": [
                "background",
                "methodology"
            ],
            "isInfluential": true,
            "paperId": "f3fb22b547ec3234fc5c04bcfcc25f487b6cc797",
            "title": "Gradient Q(\u03c3, \u03bb): A Unified Algorithm with Function Approximation for Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/f3fb22b547ec3234fc5c04bcfcc25f487b6cc797",
            "venue": "ArXiv",
            "year": 2019
        },
        {
            "arxivId": "1908.10479",
            "authors": [
                {
                    "authorId": "1388837087",
                    "name": "Yasin Abbasi-Yadkori"
                },
                {
                    "authorId": "2849560",
                    "name": "N. Lazic"
                },
                {
                    "authorId": "40868287",
                    "name": "Csaba Szepesvari"
                },
                {
                    "authorId": "39752522",
                    "name": "G. Weisz"
                }
            ],
            "doi": null,
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "1355142b30c0960dac5d8a99e18bd4980fc77221",
            "title": "Exploration-Enhanced POLITEX",
            "url": "https://www.semanticscholar.org/paper/1355142b30c0960dac5d8a99e18bd4980fc77221",
            "venue": "ArXiv",
            "year": 2019
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2107704725",
                    "name": "Z. Xu"
                },
                {
                    "authorId": "1854066561",
                    "name": "Lei Cao"
                },
                {
                    "authorId": "2435866",
                    "name": "Xi-liang Chen"
                },
                {
                    "authorId": "2779190",
                    "name": "Jin-Hee Cho"
                }
            ],
            "doi": "10.1093/COMJNL/BXZ066",
            "intent": [],
            "isInfluential": false,
            "paperId": "4cd909c37ee27a97b57f36bd0cad1a2fcb23c441",
            "title": "Deep Reinforcement Learning with Adaptive Update Target Combination",
            "url": "https://www.semanticscholar.org/paper/4cd909c37ee27a97b57f36bd0cad1a2fcb23c441",
            "venue": "Comput. J.",
            "year": 2019
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "40628127",
                    "name": "R. Kl\u00edma"
                }
            ],
            "doi": null,
            "intent": [
                "background",
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "23f2c868e5fe90c9fb3d074987c87a5d2926b073",
            "title": "Multi-agent learning for security and sustainability",
            "url": "https://www.semanticscholar.org/paper/23f2c868e5fe90c9fb3d074987c87a5d2926b073",
            "venue": "",
            "year": 2019
        },
        {
            "arxivId": "1905.13320",
            "authors": [
                {
                    "authorId": "7981071",
                    "name": "Kavosh Asadi"
                },
                {
                    "authorId": "31498163",
                    "name": "Dipendra Kumar Misra"
                },
                {
                    "authorId": "2144254660",
                    "name": "Seungchan Kim"
                },
                {
                    "authorId": "144885169",
                    "name": "M. Littman"
                }
            ],
            "doi": null,
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "069d18aefd5cc0eef1b3f0403ebcec188b1d2c1f",
            "title": "Combating the Compounding-Error Problem with a Multi-step Model",
            "url": "https://www.semanticscholar.org/paper/069d18aefd5cc0eef1b3f0403ebcec188b1d2c1f",
            "venue": "ArXiv",
            "year": 2019
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2849560",
                    "name": "N. Lazic"
                },
                {
                    "authorId": "1388837087",
                    "name": "Yasin Abbasi-Yadkori"
                },
                {
                    "authorId": "144383716",
                    "name": "K. Bhatia"
                },
                {
                    "authorId": "39752522",
                    "name": "G. Weisz"
                },
                {
                    "authorId": "1745169",
                    "name": "P. Bartlett"
                },
                {
                    "authorId": "40868287",
                    "name": "Csaba Szepesvari"
                }
            ],
            "doi": null,
            "intent": [
                "background",
                "methodology"
            ],
            "isInfluential": true,
            "paperId": "757b7295a43a53218dae38da41c0394b96ad4bfa",
            "title": "POLITEX: Regret Bounds for Policy Iteration using Expert Prediction",
            "url": "https://www.semanticscholar.org/paper/757b7295a43a53218dae38da41c0394b96ad4bfa",
            "venue": "ICML",
            "year": 2019
        },
        {
            "arxivId": "1905.07237",
            "authors": [
                {
                    "authorId": "9645178",
                    "name": "Longxiang Shi"
                },
                {
                    "authorId": "66841497",
                    "name": "Shijian Li"
                },
                {
                    "authorId": "2148761004",
                    "name": "Longbing Cao"
                },
                {
                    "authorId": "150196660",
                    "name": "Long Yang"
                },
                {
                    "authorId": "2055725787",
                    "name": "Gang Pan"
                }
            ],
            "doi": null,
            "intent": [
                "background",
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "8cb0eeca66b5ea086731b0a26af4ef48a90a4d45",
            "title": "TBQ($\\sigma$): Improving Efficiency of Trace Utilization for Off-Policy Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/8cb0eeca66b5ea086731b0a26af4ef48a90a4d45",
            "venue": "",
            "year": 2019
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "9645178",
                    "name": "Longxiang Shi"
                },
                {
                    "authorId": "66841497",
                    "name": "Shijian Li"
                },
                {
                    "authorId": "2148761004",
                    "name": "Longbing Cao"
                },
                {
                    "authorId": "150196660",
                    "name": "Long Yang"
                },
                {
                    "authorId": "2055725787",
                    "name": "Gang Pan"
                }
            ],
            "doi": null,
            "intent": [
                "background",
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "40ef079611709ce282119e18a0abcc6bfccbb023",
            "title": "TBQ(\u03c3): Improving Efficiency of Trace Utilization for Off-Policy Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/40ef079611709ce282119e18a0abcc6bfccbb023",
            "venue": "AAMAS",
            "year": 2019
        },
        {
            "arxivId": "1902.10646",
            "authors": [
                {
                    "authorId": "23524897",
                    "name": "R. Chourasia"
                },
                {
                    "authorId": "1703727",
                    "name": "A. Singla"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "e458dfe74294b228cfe45b377f10707ea86396fd",
            "title": "Unifying Ensemble Methods for Q-learning via Social Choice Theory",
            "url": "https://www.semanticscholar.org/paper/e458dfe74294b228cfe45b377f10707ea86396fd",
            "venue": "ArXiv",
            "year": 2019
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "97693361",
                    "name": "Yinlong Yuan"
                },
                {
                    "authorId": "153009573",
                    "name": "Z. Yu"
                },
                {
                    "authorId": "9238882",
                    "name": "Z. Gu"
                },
                {
                    "authorId": "2116834048",
                    "name": "Xiaoyan Deng"
                },
                {
                    "authorId": "48514757",
                    "name": "Yuanqing Li"
                }
            ],
            "doi": "10.1007/s10489-019-01417-4",
            "intent": [
                "background",
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "fd0e3da7d5dbc60c282545be4c0b37363ea2b6c8",
            "title": "A novel multi-step reinforcement learning method for solving reward hacking",
            "url": "https://www.semanticscholar.org/paper/fd0e3da7d5dbc60c282545be4c0b37363ea2b6c8",
            "venue": "Applied Intelligence",
            "year": 2019
        },
        {
            "arxivId": "1901.08021",
            "authors": [
                {
                    "authorId": "40628127",
                    "name": "R. Kl\u00edma"
                },
                {
                    "authorId": "2539968",
                    "name": "D. Bloembergen"
                },
                {
                    "authorId": "1689073",
                    "name": "M. Kaisers"
                },
                {
                    "authorId": "2274623",
                    "name": "K. Tuyls"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "3844948a988be0f260e0618cfb6b47017f3adbd6",
            "title": "Robust temporal difference learning for critical domains",
            "url": "https://www.semanticscholar.org/paper/3844948a988be0f260e0618cfb6b47017f3adbd6",
            "venue": "AAMAS",
            "year": 2019
        },
        {
            "arxivId": "1901.07510",
            "authors": [
                {
                    "authorId": "1398240048",
                    "name": "J. F. Hernandez-Garcia"
                },
                {
                    "authorId": "1699645",
                    "name": "R. Sutton"
                }
            ],
            "doi": null,
            "intent": [
                "methodology"
            ],
            "isInfluential": true,
            "paperId": "09cd2dc227efdfb4885ac282ac481278ad60d8ac",
            "title": "Understanding Multi-Step Deep Reinforcement Learning: A Systematic Study of the DQN Target",
            "url": "https://www.semanticscholar.org/paper/09cd2dc227efdfb4885ac282ac481278ad60d8ac",
            "venue": "ArXiv",
            "year": 2019
        },
        {
            "arxivId": "1901.02069",
            "authors": [
                {
                    "authorId": "2146653509",
                    "name": "Jie Liu"
                },
                {
                    "authorId": "2157163806",
                    "name": "Zhi\u2010Xi Chen"
                },
                {
                    "authorId": "90875085",
                    "name": "Wenhui Dong"
                },
                {
                    "authorId": "2118448378",
                    "name": "Xiao Wang"
                },
                {
                    "authorId": "2117868522",
                    "name": "Jia Shi"
                },
                {
                    "authorId": "145638479",
                    "name": "Hong-Liang Teng"
                },
                {
                    "authorId": "32452445",
                    "name": "Xi-Wang Dai"
                },
                {
                    "authorId": "145032830",
                    "name": "S. Yau"
                },
                {
                    "authorId": "50568007",
                    "name": "C. Liang"
                },
                {
                    "authorId": "2056811760",
                    "name": "Ping-Fa Feng"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "3d7b7aa77e04691cb955e6ae6907a3099e68cbf8",
            "title": "Microwave Integrated Circuits Design with Relational Induction Neural Network",
            "url": "https://www.semanticscholar.org/paper/3d7b7aa77e04691cb955e6ae6907a3099e68cbf8",
            "venue": "",
            "year": 2019
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "8119874",
                    "name": "Kristopher De Asis"
                }
            ],
            "doi": "10.7939/R3GH9BR75",
            "intent": [
                "background",
                "result"
            ],
            "isInfluential": false,
            "paperId": "f5571171cd2a71f432f360fde5d08e12e8b42afc",
            "title": "A Unified View of Multi-step Temporal Difference Learning",
            "url": "https://www.semanticscholar.org/paper/f5571171cd2a71f432f360fde5d08e12e8b42afc",
            "venue": "",
            "year": 2018
        },
        {
            "arxivId": "1810.07254",
            "authors": [
                {
                    "authorId": "80775608",
                    "name": "Yitzhak Spielberg"
                },
                {
                    "authorId": "1746466",
                    "name": "A. Azaria"
                }
            ],
            "doi": "10.1109/ICTAI.2019.00043",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "2bbb5aab8009aa86caa0eec063ea9b2baf209dad",
            "title": "The Concept of Criticality in Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/2bbb5aab8009aa86caa0eec063ea9b2baf209dad",
            "venue": "2019 IEEE 31st International Conference on Tools with Artificial Intelligence (ICTAI)",
            "year": 2018
        },
        {
            "arxivId": "1810.06339",
            "authors": [
                {
                    "authorId": "2276894",
                    "name": "Yuxi Li"
                }
            ],
            "doi": "10.1007/978-3-319-94463-0_9",
            "intent": [],
            "isInfluential": false,
            "paperId": "f2ac2a3fd7b341f2b1be752b4dd46ed9abcf0751",
            "title": "Deep Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/f2ac2a3fd7b341f2b1be752b4dd46ed9abcf0751",
            "venue": "Reinforcement Learning for Cyber-Physical Systems",
            "year": 2018
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "3440874",
                    "name": "Shauharda Khadka"
                },
                {
                    "authorId": "1711099",
                    "name": "Kagan Tumer"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "9dd606ce1442f8c0ae6764a0e52d049c2779e4c4",
            "title": "Evolutionary Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/9dd606ce1442f8c0ae6764a0e52d049c2779e4c4",
            "venue": "NIPS 2018",
            "year": 2018
        },
        {
            "arxivId": "1805.07917",
            "authors": [
                {
                    "authorId": "3440874",
                    "name": "Shauharda Khadka"
                },
                {
                    "authorId": "1711099",
                    "name": "Kagan Tumer"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "d5805a80b63ed0a605e5469e321a7e3c42eaf324",
            "title": "Evolution-Guided Policy Gradient in Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/d5805a80b63ed0a605e5469e321a7e3c42eaf324",
            "venue": "NeurIPS",
            "year": 2018
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "40963426",
                    "name": "Sriram Ganapathi Subramanian"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "12cd422b0e5377d05a48103797d7bbe63b3867a0",
            "title": "Reinforcement Learning for Determining Spread Dynamics of Spatially Spreading Processes with Emphasis on Forest Fires",
            "url": "https://www.semanticscholar.org/paper/12cd422b0e5377d05a48103797d7bbe63b3867a0",
            "venue": "",
            "year": 2018
        },
        {
            "arxivId": "1804.04216",
            "authors": [
                {
                    "authorId": "49306150",
                    "name": "Thomas Spooner"
                },
                {
                    "authorId": "1918884",
                    "name": "John Fearnley"
                },
                {
                    "authorId": "2377870",
                    "name": "Rahul Savani"
                },
                {
                    "authorId": "41018986",
                    "name": "Andreas Koukorinis"
                }
            ],
            "doi": null,
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "5304fa70d844da391cd12e45e38b57ab37195024",
            "title": "Market Making via Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/5304fa70d844da391cd12e45e38b57ab37195024",
            "venue": "AAMAS",
            "year": 2018
        },
        {
            "arxivId": "1802.08294",
            "authors": [
                {
                    "authorId": "3187297",
                    "name": "D. Mankowitz"
                },
                {
                    "authorId": "40501144",
                    "name": "Augustin \u017d\u00eddek"
                },
                {
                    "authorId": "143999673",
                    "name": "Andr\u00e9 Barreto"
                },
                {
                    "authorId": "48257711",
                    "name": "Dan Horgan"
                },
                {
                    "authorId": "39357484",
                    "name": "Matteo Hessel"
                },
                {
                    "authorId": "34660073",
                    "name": "John Quan"
                },
                {
                    "authorId": "2894414",
                    "name": "Junhyuk Oh"
                },
                {
                    "authorId": "7634925",
                    "name": "H. V. Hasselt"
                },
                {
                    "authorId": "145824029",
                    "name": "David Silver"
                },
                {
                    "authorId": "1725157",
                    "name": "T. Schaul"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "d72e69eacd4afeac33f71d07c484686084e55b9a",
            "title": "Unicorn: Continual Learning with a Universal, Off-policy Agent",
            "url": "https://www.semanticscholar.org/paper/d72e69eacd4afeac33f71d07c484686084e55b9a",
            "venue": "ArXiv",
            "year": 2018
        },
        {
            "arxivId": "1802.03171",
            "authors": [
                {
                    "authorId": "150196660",
                    "name": "Long Yang"
                },
                {
                    "authorId": "35747042",
                    "name": "Minhao Shi"
                },
                {
                    "authorId": "48809559",
                    "name": "Qian Zheng"
                },
                {
                    "authorId": "49320509",
                    "name": "Wenjia Meng"
                },
                {
                    "authorId": "2055725787",
                    "name": "Gang Pan"
                }
            ],
            "doi": "10.24963/ijcai.2018/414",
            "intent": [],
            "isInfluential": false,
            "paperId": "d0b4a50a792f0741d4a925c9f76f4070a18b5450",
            "title": "A Unified Approach for Multi-step Temporal-Difference Learning with Eligibility Traces in Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/d0b4a50a792f0741d4a925c9f76f4070a18b5450",
            "venue": "IJCAI",
            "year": 2018
        },
        {
            "arxivId": "1711.10907",
            "authors": [
                {
                    "authorId": "2325148791",
                    "name": "Mariya Popova"
                },
                {
                    "authorId": "2385206",
                    "name": "O. Isayev"
                },
                {
                    "authorId": "2239082164",
                    "name": "Alexander Tropsha"
                }
            ],
            "doi": "10.1126/sciadv.aap7885",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "4edd98e3947d8406ec95518c294721757afffb5d",
            "title": "Deep reinforcement learning for de novo drug design",
            "url": "https://www.semanticscholar.org/paper/4edd98e3947d8406ec95518c294721757afffb5d",
            "venue": "Science Advances",
            "year": 2017
        },
        {
            "arxivId": "1711.01569",
            "authors": [
                {
                    "authorId": "30022423",
                    "name": "M. Dumke"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "c120f47f2cb8f7acbe69810b765e37d63cea89d6",
            "title": "Double Q($\\sigma$) and Q($\\sigma, \\lambda$): Unifying Reinforcement Learning Control Algorithms",
            "url": "https://www.semanticscholar.org/paper/c120f47f2cb8f7acbe69810b765e37d63cea89d6",
            "venue": "",
            "year": 2017
        },
        {
            "arxivId": "1711.03817",
            "authors": [
                {
                    "authorId": "3134710",
                    "name": "A. Harutyunyan"
                },
                {
                    "authorId": "2528631",
                    "name": "Peter Vrancx"
                },
                {
                    "authorId": "145180695",
                    "name": "Pierre-Luc Bacon"
                },
                {
                    "authorId": "144368601",
                    "name": "Doina Precup"
                },
                {
                    "authorId": "144336828",
                    "name": "A. Now\u00e9"
                }
            ],
            "doi": "10.1609/aaai.v32i1.11740",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "8cb0d366c7dc7f87b2c178532cc7762440721c97",
            "title": "Learning with Options that Terminate Off-Policy",
            "url": "https://www.semanticscholar.org/paper/8cb0d366c7dc7f87b2c178532cc7762440721c97",
            "venue": "AAAI",
            "year": 2017
        },
        {
            "arxivId": "1701.07274",
            "authors": [
                {
                    "authorId": "2276894",
                    "name": "Yuxi Li"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "9f1e9e56d80146766bc2316efbc54d8b770a23df",
            "title": "Deep Reinforcement Learning: An Overview",
            "url": "https://www.semanticscholar.org/paper/9f1e9e56d80146766bc2316efbc54d8b770a23df",
            "venue": "ArXiv",
            "year": 2017
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "13048995",
                    "name": "Junmin Zhong"
                },
                {
                    "authorId": "153088943",
                    "name": "Ruofan Wu"
                },
                {
                    "authorId": "2265578584",
                    "name": "Jennie Si"
                }
            ],
            "doi": null,
            "intent": [
                "background",
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "61702a94b5aa6588e4f77cce1afa5d6377f34874",
            "title": "A Long N-step Surrogate Stage Reward for Deep Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/61702a94b5aa6588e4f77cce1afa5d6377f34874",
            "venue": "NeurIPS",
            "year": 2023
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "1678696",
                    "name": "Laizhong Cui"
                },
                {
                    "authorId": "2065440916",
                    "name": "Dongyuan Su"
                },
                {
                    "authorId": "123362946",
                    "name": "Shu Yang"
                },
                {
                    "authorId": "2108388268",
                    "name": "Zhi Wang"
                },
                {
                    "authorId": "2055356098",
                    "name": "Zhongxing Ming"
                }
            ],
            "doi": "10.1109/TMM.2020.2985631",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "d8b92a954c18265738d243b50ba6c36a91469d40",
            "title": "TCLiVi: Transmission Control in Live Video Streaming Based on Deep Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/d8b92a954c18265738d243b50ba6c36a91469d40",
            "venue": "IEEE Transactions on Multimedia",
            "year": 2021
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2115768892",
                    "name": "Yuhui Wang"
                },
                {
                    "authorId": "2107782398",
                    "name": "Pengcheng He"
                },
                {
                    "authorId": "2248421",
                    "name": "Xiaoyang Tan"
                }
            ],
            "doi": null,
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "872767fe724f52b38141059cbf9a8e25679665cd",
            "title": "Greedy Multi-step Off-Policy Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/872767fe724f52b38141059cbf9a8e25679665cd",
            "venue": "ArXiv",
            "year": 2021
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "31375908",
                    "name": "Jonas J\u00e4ger"
                },
                {
                    "authorId": "2090479313",
                    "name": "Felix Helfenstein"
                },
                {
                    "authorId": "48413184",
                    "name": "F. Scharf"
                }
            ],
            "doi": "10.1007/978-3-030-41188-6_12",
            "intent": [],
            "isInfluential": false,
            "paperId": "1bbf5eae353cf1d1c6dc7dafd06991bfc33e5f64",
            "title": "Bring Color to Deep Q-Networks: Limitations and Improvements of DQN Leading to Rainbow DQN",
            "url": "https://www.semanticscholar.org/paper/1bbf5eae353cf1d1c6dc7dafd06991bfc33e5f64",
            "venue": "",
            "year": 2021
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2115768892",
                    "name": "Yuhui Wang"
                },
                {
                    "authorId": "2108761828",
                    "name": "Qingyuan Wu"
                },
                {
                    "authorId": "2107782398",
                    "name": "Pengcheng He"
                },
                {
                    "authorId": "2109869742",
                    "name": "Xiaoyang Tan"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "692758859e5a7717b8acfe1e0f527e7e8cebe269",
            "title": "A Novel Greedy-Step Bellman Optimality Equation for Ef\ufb01cient Value Propagation",
            "url": "https://www.semanticscholar.org/paper/692758859e5a7717b8acfe1e0f527e7e8cebe269",
            "venue": "",
            "year": 2021
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2098284730",
                    "name": "Li-peng"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "dc026ceb7975a0e98c2d580857001a2b7c5afc25",
            "title": "Coordinated AGC Algorithm for Distributed Multi-region Multi-energy Micro-network Group",
            "url": "https://www.semanticscholar.org/paper/dc026ceb7975a0e98c2d580857001a2b7c5afc25",
            "venue": "",
            "year": 2020
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "137071348",
                    "name": "Brahma S. Pavse"
                },
                {
                    "authorId": "34719248",
                    "name": "Josiah P. Hanna"
                },
                {
                    "authorId": "9571638",
                    "name": "Ishan Durugkar"
                },
                {
                    "authorId": "144848112",
                    "name": "P. Stone"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "cb2f9420dfb371ec866637c5b9a92a076fd746bd",
            "title": "O N S AMPLING E RROR IN B ATCH A CTION -V ALUE P REDICTION A LGORITHMS",
            "url": "https://www.semanticscholar.org/paper/cb2f9420dfb371ec866637c5b9a92a076fd746bd",
            "venue": "",
            "year": 2020
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "13461630",
                    "name": "Niko Yasui"
                }
            ],
            "doi": "10.7939/R3-8FVC-9G30",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "4e50d52f0b59561e3902b997ce8a48633351491e",
            "title": "An Empirical Study of Exploration Strategies for Model-Free Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/4e50d52f0b59561e3902b997ce8a48633351491e",
            "venue": "",
            "year": 2020
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "72628397",
                    "name": "Xinlian Yu"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "c51cc45524fae92614a2727a5ca3ae6f903f86c9",
            "title": "Modeling and Optimizing Routing Decisions for Travelers and On-demand Service Providers",
            "url": "https://www.semanticscholar.org/paper/c51cc45524fae92614a2727a5ca3ae6f903f86c9",
            "venue": "",
            "year": 2019
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "30085378",
                    "name": "V. Ionescu"
                },
                {
                    "authorId": "1397308210",
                    "name": "Zsuzsanna Onet-Marian"
                },
                {
                    "authorId": "1397308193",
                    "name": "Marin-Georgian Badita"
                },
                {
                    "authorId": "1695873",
                    "name": "G. Czibula"
                },
                {
                    "authorId": "31058148",
                    "name": "Mihai-Ioan Popescu"
                },
                {
                    "authorId": "1682133",
                    "name": "J. Dibangoye"
                },
                {
                    "authorId": "1807441",
                    "name": "Olivier Simonin"
                }
            ],
            "doi": "10.1016/j.procs.2019.09.164",
            "intent": [],
            "isInfluential": false,
            "paperId": "981a32cbacb55a8ef08f7eb1832cb9e0fc0ab465",
            "title": "DynFloR: A Flow Approach for Data Delivery Optimization in Multi-Robot Network Patrolling",
            "url": "https://www.semanticscholar.org/paper/981a32cbacb55a8ef08f7eb1832cb9e0fc0ab465",
            "venue": "KES",
            "year": 2019
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "40628127",
                    "name": "R. Kl\u00edma"
                },
                {
                    "authorId": "2539968",
                    "name": "D. Bloembergen"
                },
                {
                    "authorId": "1689073",
                    "name": "M. Kaisers"
                },
                {
                    "authorId": "2274623",
                    "name": "K. Tuyls"
                }
            ],
            "doi": null,
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "ebe84994fc3f617e41ae856b8df1e0a00a84142a",
            "title": "Towards learning to best respond when losing control",
            "url": "https://www.semanticscholar.org/paper/ebe84994fc3f617e41ae856b8df1e0a00a84142a",
            "venue": "",
            "year": 2018
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2452961",
                    "name": "How-Wei Huang"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "08034c5de31c35f937d9b0338560530b3748d6fc",
            "title": "An Empirical Study of Least-Squares Algorithms in Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/08034c5de31c35f937d9b0338560530b3748d6fc",
            "venue": "",
            "year": 2018
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "40628127",
                    "name": "R. Kl\u00edma"
                },
                {
                    "authorId": "2539968",
                    "name": "D. Bloembergen"
                },
                {
                    "authorId": "1689073",
                    "name": "M. Kaisers"
                },
                {
                    "authorId": "2274623",
                    "name": "K. Tuyls"
                }
            ],
            "doi": null,
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "6ffb8d5b3b39f7c372c3909a34498b7d4afae9bc",
            "title": "Learning robust policies when losing control",
            "url": "https://www.semanticscholar.org/paper/6ffb8d5b3b39f7c372c3909a34498b7d4afae9bc",
            "venue": "",
            "year": 2018
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "1686924",
                    "name": "B. Bischl"
                },
                {
                    "authorId": "48305274",
                    "name": "Xudong Sun"
                }
            ],
            "doi": "10.5282/ubm/epub.59093",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "d720325c2ffb803db07f75ad9047af803b70f83b",
            "title": "Reinforcement Learning in R",
            "url": "https://www.semanticscholar.org/paper/d720325c2ffb803db07f75ad9047af803b70f83b",
            "venue": "",
            "year": 2017
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "1505834515",
                    "name": "Sreehari Rammohan"
                },
                {
                    "authorId": "2082463338",
                    "name": "Bowen He"
                },
                {
                    "authorId": "2148459804",
                    "name": "Shangqun Yu"
                },
                {
                    "authorId": "2121321400",
                    "name": "Eric Hsiung"
                },
                {
                    "authorId": "152156591",
                    "name": "Eric Rosen"
                },
                {
                    "authorId": "1765407",
                    "name": "G. Konidaris"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "2858344b447aeaa362050b59641a022c64a0187b",
            "title": "Exploring Improvements in Value Based Deep Reinforcement Learning for Continuous Control",
            "url": "https://www.semanticscholar.org/paper/2858344b447aeaa362050b59641a022c64a0187b",
            "venue": "",
            "year": null
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2268498382",
                    "name": "Ben van Oostendorp"
                }
            ],
            "doi": null,
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "ca9a0ea4f1cdaa98c7e457257a1dbe1491cdc4f4",
            "title": "Object Detectors as Input for Reinforcement Learning Agents",
            "url": "https://www.semanticscholar.org/paper/ca9a0ea4f1cdaa98c7e457257a1dbe1491cdc4f4",
            "venue": "",
            "year": null
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2321058142",
                    "name": "Namkyoung Lee"
                },
                {
                    "authorId": "2320929495",
                    "name": "Joohyun Woo"
                },
                {
                    "authorId": "2321036226",
                    "name": "Sungryul Kim"
                }
            ],
            "doi": "10.1016/j.apenergy.2024.124431",
            "intent": [],
            "isInfluential": false,
            "paperId": "bb30d1400d6bd3a812aa8d57f19f34497bc437c4",
            "title": "A deep reinforcement learning ensemble for maintenance scheduling in offshore wind farms",
            "url": "https://www.semanticscholar.org/paper/bb30d1400d6bd3a812aa8d57f19f34497bc437c4",
            "venue": "Applied Energy",
            "year": null
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2306430634",
                    "name": "Hongyi Wang"
                },
                {
                    "authorId": "2321328036",
                    "name": "Yang Li"
                },
                {
                    "authorId": "2321123690",
                    "name": "Jing Yang"
                },
                {
                    "authorId": "2181204038",
                    "name": "Daqiang Hu"
                },
                {
                    "authorId": "2181175387",
                    "name": "Zhi Liao"
                }
            ],
            "doi": "10.26599/tst.2024.9010038",
            "intent": [],
            "isInfluential": false,
            "paperId": "823aa1c9dfcefa0e0d12a550bd06f805892ec5ed",
            "title": "CamDroid: Context-Aware Model-Based Automated GUI Testing for Android Apps",
            "url": "https://www.semanticscholar.org/paper/823aa1c9dfcefa0e0d12a550bd06f805892ec5ed",
            "venue": "Tsinghua Science and Technology",
            "year": null
        }
    ],
    "corpusId": 16544526,
    "doi": "10.1609/aaai.v32i1.11631",
    "fieldsOfStudy": [
        "Computer Science"
    ],
    "influentialCitationCount": 9,
    "isOpenAccess": true,
    "isPublisherLicensed": true,
    "is_open_access": true,
    "is_publisher_licensed": true,
    "numCitedBy": 118,
    "numCiting": 12,
    "paperId": "e2e8d2ae77ffaf9b526d28bd7ed4fb555e50ee24",
    "references": [
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "1748153",
                    "name": "H. V. Seijen"
                },
                {
                    "authorId": "7634925",
                    "name": "H. V. Hasselt"
                },
                {
                    "authorId": "1766767",
                    "name": "Shimon Whiteson"
                },
                {
                    "authorId": "32239759",
                    "name": "M. Wiering"
                }
            ],
            "doi": "10.1109/ADPRL.2009.4927542",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "823ed45723c980f753d16fdd29f22e63cdfdcd3f",
            "title": "A theoretical and empirical analysis of Expected Sarsa",
            "url": "https://www.semanticscholar.org/paper/823ed45723c980f753d16fdd29f22e63cdfdcd3f",
            "venue": "2009 IEEE Symposium on Adaptive Dynamic Programming and Reinforcement Learning",
            "year": 2009
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "144368601",
                    "name": "Doina Precup"
                },
                {
                    "authorId": "1699645",
                    "name": "R. Sutton"
                },
                {
                    "authorId": "1699868",
                    "name": "Satinder Singh"
                }
            ],
            "doi": null,
            "intent": [
                "background",
                "methodology"
            ],
            "isInfluential": true,
            "paperId": "78020db7e3d968f6e6cc26d18e31e5b668ca7fee",
            "title": "Eligibility Traces for Off-Policy Policy Evaluation",
            "url": "https://www.semanticscholar.org/paper/78020db7e3d968f6e6cc26d18e31e5b668ca7fee",
            "venue": "ICML",
            "year": 2000
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "1699868",
                    "name": "Satinder Singh"
                },
                {
                    "authorId": "35132120",
                    "name": "T. Jaakkola"
                },
                {
                    "authorId": "144885169",
                    "name": "M. Littman"
                },
                {
                    "authorId": "40868287",
                    "name": "Csaba Szepesvari"
                }
            ],
            "doi": "10.1023/A:1007678930559",
            "intent": [],
            "isInfluential": false,
            "paperId": "712ec1bd9287ac210a7630ce03ca2b0930ebd351",
            "title": "Convergence Results for Single-Step On-Policy Reinforcement-Learning Algorithms",
            "url": "https://www.semanticscholar.org/paper/712ec1bd9287ac210a7630ce03ca2b0930ebd351",
            "venue": "Machine Learning",
            "year": 2000
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "1804676",
                    "name": "B. Kr\u00f6se"
                }
            ],
            "doi": "10.1016/0921-8890(95)00026-C",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "59b50a775542e87f078db35b868ac10ab43d4c75",
            "title": "Learning from delayed rewards",
            "url": "https://www.semanticscholar.org/paper/59b50a775542e87f078db35b868ac10ab43d4c75",
            "venue": "Robotics Auton. Syst.",
            "year": 1995
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "145290695",
                    "name": "C. Watkins"
                },
                {
                    "authorId": "1790646",
                    "name": "P. Dayan"
                }
            ],
            "doi": "10.1007/BF00992698",
            "intent": [],
            "isInfluential": false,
            "paperId": "03b7e51c52084ac1db5118342a00b5fbcfc587aa",
            "title": "Q-learning",
            "url": "https://www.semanticscholar.org/paper/03b7e51c52084ac1db5118342a00b5fbcfc587aa",
            "venue": "Machine Learning",
            "year": 1992
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "1699645",
                    "name": "R. Sutton"
                }
            ],
            "doi": "10.1023/A:1022633531479",
            "intent": [
                "background",
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "a91635f8d0e7fb804efd1c38d9c24ee952ba7076",
            "title": "Learning to predict by the methods of temporal differences",
            "url": "https://www.semanticscholar.org/paper/a91635f8d0e7fb804efd1c38d9c24ee952ba7076",
            "venue": "Machine Learning",
            "year": 1988
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2257178939",
                    "name": "Richard S. Sutton"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "7ca8ac34767d6e6cb389eeebcdabc4225b39edfe",
            "title": "Advances in Neural Information Processing Systems pp MIT Press Generalization in Reinforcement Learning Successful Examples Using Sparse Coarse Coding",
            "url": "https://www.semanticscholar.org/paper/7ca8ac34767d6e6cb389eeebcdabc4225b39edfe",
            "venue": "",
            "year": 2010
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2238176724",
                    "name": "R. S. Sutton"
                },
                {
                    "authorId": "1730590",
                    "name": "A. Barto"
                }
            ],
            "doi": "10.1109/TNN.1998.712192",
            "intent": [
                "background",
                "methodology"
            ],
            "isInfluential": true,
            "paperId": "97efafdb4a3942ab3efba53ded7413199f79c054",
            "title": "Reinforcement Learning: An Introduction",
            "url": "https://www.semanticscholar.org/paper/97efafdb4a3942ab3efba53ded7413199f79c054",
            "venue": "IEEE Trans. Neural Networks",
            "year": 1998
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "3466704",
                    "name": "Gavin Adrian Rummery"
                }
            ],
            "doi": null,
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "ae35e9d47cc2db815ccd4346d4df462fce953960",
            "title": "Problem solving with reinforcement learning",
            "url": "https://www.semanticscholar.org/paper/ae35e9d47cc2db815ccd4346d4df462fce953960",
            "venue": "",
            "year": 1995
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "35132120",
                    "name": "T. Jaakkola"
                },
                {
                    "authorId": "1694621",
                    "name": "Michael I. Jordan"
                },
                {
                    "authorId": "1699868",
                    "name": "Satinder Singh"
                }
            ],
            "doi": "10.1162/neco.1994.6.6.1185",
            "intent": [],
            "isInfluential": false,
            "paperId": "4e9d797427cd56be90932d6092fc3b6282dfb96f",
            "title": "On the Convergence of Stochastic Iterative Dynamic Programming Algorithms",
            "url": "https://www.semanticscholar.org/paper/4e9d797427cd56be90932d6092fc3b6282dfb96f",
            "venue": "Neural Computation",
            "year": 1994
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "3466704",
                    "name": "Gavin Adrian Rummery"
                },
                {
                    "authorId": "145387873",
                    "name": "M. Niranjan"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "7a09464f26e18a25a948baaa736270bfb84b5e12",
            "title": "On-line Q-learning using connectionist systems",
            "url": "https://www.semanticscholar.org/paper/7a09464f26e18a25a948baaa736270bfb84b5e12",
            "venue": "",
            "year": 1994
        }
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "title": "Multi-step Reinforcement Learning: A Unifying Algorithm",
    "topics": [],
    "url": "https://www.semanticscholar.org/paper/e2e8d2ae77ffaf9b526d28bd7ed4fb555e50ee24",
    "venue": "AAAI Conference on Artificial Intelligence",
    "year": 2017
}
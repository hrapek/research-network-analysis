{
    "abstract": "In order for reinforcement learning techniques to be useful in real-world decision making processes, they must be able to produce robust performance from limited data. Deep policy optimization methods have achieved impressive results on complex tasks, but their real-world adoption remains limited because they often require significant amounts of data to succeed. When combined with small sample sizes, these methods can result in unstable learning due to their reliance on high-dimensional sample-based estimates. In this work, we develop techniques to control the uncertainty introduced by these estimates. We leverage these techniques to propose a deep policy optimization approach designed to produce stable performance even when data is scarce. The resulting algorithm, Uncertainty-Aware Trust Region Policy Optimization, generates robust policy updates that adapt to the level of uncertainty present throughout the learning process.",
    "arxivId": "2012.10791",
    "authors": [
        {
            "authorId": "2039906784",
            "name": "James Queeney",
            "url": "https://www.semanticscholar.org/author/2039906784"
        },
        {
            "authorId": "1691402",
            "name": "I. Paschalidis",
            "url": "https://www.semanticscholar.org/author/1691402"
        },
        {
            "authorId": "1721319",
            "name": "C. Cassandras",
            "url": "https://www.semanticscholar.org/author/1721319"
        }
    ],
    "citationVelocity": 0,
    "citations": [
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2320714170",
                    "name": "Qiuhong Wang"
                },
                {
                    "authorId": "2216588362",
                    "name": "Jingjing Gu"
                }
            ],
            "doi": "10.1109/IJCNN60899.2024.10651542",
            "intent": [],
            "isInfluential": false,
            "paperId": "ec75dbd839c663253877af826b4392cda56ee183",
            "title": "Dynamic Environment-driven Autonomous Drone Path Planning via Deep Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/ec75dbd839c663253877af826b4392cda56ee183",
            "venue": "2024 International Joint Conference on Neural Networks (IJCNN)",
            "year": 2024
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2297141833",
                    "name": "Haotian Xu"
                },
                {
                    "authorId": "2207125",
                    "name": "Junyu Xuan"
                },
                {
                    "authorId": "46266495",
                    "name": "Guangquan Zhang"
                },
                {
                    "authorId": "2110186016",
                    "name": "Jie Lu"
                }
            ],
            "doi": "10.1016/j.neucom.2024.127716",
            "intent": [],
            "isInfluential": false,
            "paperId": "e2126f6567a5c847a759de54a22751547c28976c",
            "title": "Trust region policy optimization via entropy regularization for Kullback-Leibler divergence constraint",
            "url": "https://www.semanticscholar.org/paper/e2126f6567a5c847a759de54a22751547c28976c",
            "venue": "Neurocomputing",
            "year": 2024
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "49507478",
                    "name": "Haotian Xu"
                },
                {
                    "authorId": "2152531724",
                    "name": "Zheng Yan"
                },
                {
                    "authorId": "2207125",
                    "name": "Junyu Xuan"
                },
                {
                    "authorId": "46266495",
                    "name": "Guangquan Zhang"
                },
                {
                    "authorId": "144864069",
                    "name": "Jie Lu"
                }
            ],
            "doi": "10.1016/j.neucom.2023.02.008",
            "intent": [],
            "isInfluential": false,
            "paperId": "82ffc0a492a8dd20616d26942a6c01b656f787fc",
            "title": "Improving proximal policy optimization with alpha divergence",
            "url": "https://www.semanticscholar.org/paper/82ffc0a492a8dd20616d26942a6c01b656f787fc",
            "venue": "Neurocomputing",
            "year": 2023
        },
        {
            "arxivId": "2208.09322",
            "authors": [
                {
                    "authorId": "2005408902",
                    "name": "Jianfei Ma"
                }
            ],
            "doi": "10.48550/arXiv.2208.09322",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "07bddd2860981bd406e83525b0eb42d9c73dc95e",
            "title": "Entropy Augmented Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/07bddd2860981bd406e83525b0eb42d9c73dc95e",
            "venue": "ArXiv",
            "year": 2022
        },
        {
            "arxivId": "2206.13714",
            "authors": [
                {
                    "authorId": "2039906784",
                    "name": "James Queeney"
                },
                {
                    "authorId": "1691402",
                    "name": "I. Paschalidis"
                },
                {
                    "authorId": "1721319",
                    "name": "C. Cassandras"
                }
            ],
            "doi": "10.1109/TAC.2024.3454011",
            "intent": [],
            "isInfluential": false,
            "paperId": "d78e611208de3b80982df0ce7b1957d1477374ab",
            "title": "Generalized Policy Improvement Algorithms with Theoretically Supported Sample Reuse",
            "url": "https://www.semanticscholar.org/paper/d78e611208de3b80982df0ce7b1957d1477374ab",
            "venue": "IEEE Transactions on Automatic Control",
            "year": 2022
        },
        {
            "arxivId": "2203.06250",
            "authors": [
                {
                    "authorId": "151245006",
                    "name": "Vittorio Giammarino"
                },
                {
                    "authorId": "1379530056",
                    "name": "Matthew F. Dunne"
                },
                {
                    "authorId": "2158821300",
                    "name": "Kylie N. Moore"
                },
                {
                    "authorId": "4493719",
                    "name": "M. Hasselmo"
                },
                {
                    "authorId": "33330716",
                    "name": "C. Stern"
                },
                {
                    "authorId": "1691402",
                    "name": "I. Paschalidis"
                }
            ],
            "doi": "10.1177/10597123231201655",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "784c1e1b02ac95b31189ac12d12a4fa909634052",
            "title": "Combining imitation and deep reinforcement learning to human-level performance on a virtual foraging task",
            "url": "https://www.semanticscholar.org/paper/784c1e1b02ac95b31189ac12d12a4fa909634052",
            "venue": "Adapt. Behav.",
            "year": 2022
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "151245006",
                    "name": "Vittorio Giammarino"
                },
                {
                    "authorId": "1379530056",
                    "name": "Matthew F. Dunne"
                },
                {
                    "authorId": "2158821300",
                    "name": "Kylie N. Moore"
                },
                {
                    "authorId": "4493719",
                    "name": "M. Hasselmo"
                },
                {
                    "authorId": "2250243815",
                    "name": "Chantal E. Stern"
                },
                {
                    "authorId": "1691402",
                    "name": "I. Paschalidis"
                }
            ],
            "doi": "10.48550/arXiv.2203.06250",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "0837867076e372ea90236acafc10ea542d38c176",
            "title": "Learning from humans: combining imitation and deep reinforcement learning to accomplish human-level performance on a virtual foraging task",
            "url": "https://www.semanticscholar.org/paper/0837867076e372ea90236acafc10ea542d38c176",
            "venue": "ArXiv",
            "year": 2022
        }
    ],
    "corpusId": 229339930,
    "doi": "10.1609/aaai.v35i11.17130",
    "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
    ],
    "influentialCitationCount": 0,
    "isOpenAccess": true,
    "isPublisherLicensed": true,
    "is_open_access": true,
    "is_publisher_licensed": true,
    "numCitedBy": 7,
    "numCiting": 26,
    "paperId": "b29ef3794829d56ce139a8d02aa88c307d045ed3",
    "references": [
        {
            "arxivId": "1806.05618",
            "authors": [
                {
                    "authorId": "145388375",
                    "name": "M. Papini"
                },
                {
                    "authorId": "51035180",
                    "name": "Damiano Binaghi"
                },
                {
                    "authorId": "51032963",
                    "name": "Giuseppe Canonaco"
                },
                {
                    "authorId": "6234609",
                    "name": "Matteo Pirotta"
                },
                {
                    "authorId": "1792167",
                    "name": "Marcello Restelli"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "108b2ea6100d71fd25e3f71743c1e5c4674d6d8c",
            "title": "Stochastic Variance-Reduced Policy Gradient",
            "url": "https://www.semanticscholar.org/paper/108b2ea6100d71fd25e3f71743c1e5c4674d6d8c",
            "venue": "ICML",
            "year": 2018
        },
        {
            "arxivId": "1712.06924",
            "authors": [
                {
                    "authorId": "144100820",
                    "name": "R. Laroche"
                },
                {
                    "authorId": "31480268",
                    "name": "P. Trichelair"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "7eb0db941fbf19857631ec1c907f2888ea308779",
            "title": "Safe Policy Improvement with Baseline Bootstrapping",
            "url": "https://www.semanticscholar.org/paper/7eb0db941fbf19857631ec1c907f2888ea308779",
            "venue": "ICML",
            "year": 2017
        },
        {
            "arxivId": "1709.06560",
            "authors": [
                {
                    "authorId": "40068904",
                    "name": "Peter Henderson"
                },
                {
                    "authorId": "18014232",
                    "name": "Riashat Islam"
                },
                {
                    "authorId": "143902541",
                    "name": "Philip Bachman"
                },
                {
                    "authorId": "145134886",
                    "name": "Joelle Pineau"
                },
                {
                    "authorId": "144368601",
                    "name": "Doina Precup"
                },
                {
                    "authorId": "2462512",
                    "name": "D. Meger"
                }
            ],
            "doi": "10.1609/aaai.v32i1.11694",
            "intent": [
                "background",
                "methodology"
            ],
            "isInfluential": true,
            "paperId": "33690ff21ef1efb576410e656f2e60c89d0307d6",
            "title": "Deep Reinforcement Learning that Matters",
            "url": "https://www.semanticscholar.org/paper/33690ff21ef1efb576410e656f2e60c89d0307d6",
            "venue": "AAAI",
            "year": 2017
        },
        {
            "arxivId": "1708.05144",
            "authors": [
                {
                    "authorId": "3374063",
                    "name": "Yuhuai Wu"
                },
                {
                    "authorId": "2711409",
                    "name": "Elman Mansimov"
                },
                {
                    "authorId": "1785346",
                    "name": "R. Grosse"
                },
                {
                    "authorId": "145657522",
                    "name": "Shun Liao"
                },
                {
                    "authorId": "2503659",
                    "name": "Jimmy Ba"
                }
            ],
            "doi": null,
            "intent": [
                "background",
                "methodology"
            ],
            "isInfluential": true,
            "paperId": "2b6f2b163372e3417b687cc43313f2a630e7bca7",
            "title": "Scalable trust-region method for deep reinforcement learning using Kronecker-factored approximation",
            "url": "https://www.semanticscholar.org/paper/2b6f2b163372e3417b687cc43313f2a630e7bca7",
            "venue": "NIPS",
            "year": 2017
        },
        {
            "arxivId": "1707.06347",
            "authors": [
                {
                    "authorId": "47971768",
                    "name": "John Schulman"
                },
                {
                    "authorId": "143909660",
                    "name": "Filip Wolski"
                },
                {
                    "authorId": "6515819",
                    "name": "Prafulla Dhariwal"
                },
                {
                    "authorId": "38909097",
                    "name": "Alec Radford"
                },
                {
                    "authorId": "2067138712",
                    "name": "Oleg Klimov"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "dce6f9d4017b1785979e7520fd0834ef8cf02f4b",
            "title": "Proximal Policy Optimization Algorithms",
            "url": "https://www.semanticscholar.org/paper/dce6f9d4017b1785979e7520fd0834ef8cf02f4b",
            "venue": "ArXiv",
            "year": 2017
        },
        {
            "arxivId": "1705.10528",
            "authors": [
                {
                    "authorId": "3381809",
                    "name": "Joshua Achiam"
                },
                {
                    "authorId": "145641013",
                    "name": "David Held"
                },
                {
                    "authorId": "3025260",
                    "name": "Aviv Tamar"
                },
                {
                    "authorId": "1689992",
                    "name": "P. Abbeel"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "7a4193d0b042643a8bb9ec262ed7f9d509bdb12e",
            "title": "Constrained Policy Optimization",
            "url": "https://www.semanticscholar.org/paper/7a4193d0b042643a8bb9ec262ed7f9d509bdb12e",
            "venue": "ICML",
            "year": 2017
        },
        {
            "arxivId": "1703.02702",
            "authors": [
                {
                    "authorId": "34026610",
                    "name": "Lerrel Pinto"
                },
                {
                    "authorId": "2068894907",
                    "name": "James Davidson"
                },
                {
                    "authorId": "1694199",
                    "name": "R. Sukthankar"
                },
                {
                    "authorId": "1726095131",
                    "name": "A. Gupta"
                }
            ],
            "doi": null,
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "9c4082bfbd46b781e70657f14895306c57c842e3",
            "title": "Robust Adversarial Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/9c4082bfbd46b781e70657f14895306c57c842e3",
            "venue": "ICML",
            "year": 2017
        },
        {
            "arxivId": "1610.01283",
            "authors": [
                {
                    "authorId": "19275599",
                    "name": "A. Rajeswaran"
                },
                {
                    "authorId": "7686370",
                    "name": "Sarvjeet Ghotra"
                },
                {
                    "authorId": "1736651",
                    "name": "S. Levine"
                },
                {
                    "authorId": "1723632",
                    "name": "Balaraman Ravindran"
                }
            ],
            "doi": null,
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "9228fa3b363229780da4cb1d258942e0c13c2947",
            "title": "EPOpt: Learning Robust Neural Network Policies Using Model Ensembles",
            "url": "https://www.semanticscholar.org/paper/9228fa3b363229780da4cb1d258942e0c13c2947",
            "venue": "ICLR",
            "year": 2016
        },
        {
            "arxivId": "1606.01540",
            "authors": [
                {
                    "authorId": "2065151121",
                    "name": "Greg Brockman"
                },
                {
                    "authorId": "34415167",
                    "name": "Vicki Cheung"
                },
                {
                    "authorId": "152877508",
                    "name": "Ludwig Pettersson"
                },
                {
                    "authorId": "2113526509",
                    "name": "Jonas Schneider"
                },
                {
                    "authorId": "47971768",
                    "name": "John Schulman"
                },
                {
                    "authorId": "2109541439",
                    "name": "Jie Tang"
                },
                {
                    "authorId": "2563432",
                    "name": "Wojciech Zaremba"
                }
            ],
            "doi": null,
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "2b10281297ee001a9f3f4ea1aa9bea6b638c27df",
            "title": "OpenAI Gym",
            "url": "https://www.semanticscholar.org/paper/2b10281297ee001a9f3f4ea1aa9bea6b638c27df",
            "venue": "ArXiv",
            "year": 2016
        },
        {
            "arxivId": "1604.06778",
            "authors": [
                {
                    "authorId": "144581158",
                    "name": "Yan Duan"
                },
                {
                    "authorId": "41192764",
                    "name": "Xi Chen"
                },
                {
                    "authorId": "3127100",
                    "name": "Rein Houthooft"
                },
                {
                    "authorId": "47971768",
                    "name": "John Schulman"
                },
                {
                    "authorId": "1689992",
                    "name": "P. Abbeel"
                }
            ],
            "doi": null,
            "intent": [
                "background",
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "1464776f20e2bccb6182f183b5ff2e15b0ae5e56",
            "title": "Benchmarking Deep Reinforcement Learning for Continuous Control",
            "url": "https://www.semanticscholar.org/paper/1464776f20e2bccb6182f183b5ff2e15b0ae5e56",
            "venue": "ICML",
            "year": 2016
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "143640165",
                    "name": "P. Thomas"
                },
                {
                    "authorId": "1709005",
                    "name": "Georgios Theocharous"
                },
                {
                    "authorId": "1678622",
                    "name": "M. Ghavamzadeh"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "127cf09abf45c9d3cb4d859a72e6cc67acc2b57b",
            "title": "High Confidence Policy Improvement",
            "url": "https://www.semanticscholar.org/paper/127cf09abf45c9d3cb4d859a72e6cc67acc2b57b",
            "venue": "ICML",
            "year": 2015
        },
        {
            "arxivId": "1506.02438",
            "authors": [
                {
                    "authorId": "47971768",
                    "name": "John Schulman"
                },
                {
                    "authorId": "29912342",
                    "name": "Philipp Moritz"
                },
                {
                    "authorId": "1736651",
                    "name": "S. Levine"
                },
                {
                    "authorId": "1694621",
                    "name": "Michael I. Jordan"
                },
                {
                    "authorId": "1689992",
                    "name": "P. Abbeel"
                }
            ],
            "doi": null,
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "d316c82c12cf4c45f9e85211ef3d1fa62497bff8",
            "title": "High-Dimensional Continuous Control Using Generalized Advantage Estimation",
            "url": "https://www.semanticscholar.org/paper/d316c82c12cf4c45f9e85211ef3d1fa62497bff8",
            "venue": "ICLR",
            "year": 2015
        },
        {
            "arxivId": "1502.05477",
            "authors": [
                {
                    "authorId": "47971768",
                    "name": "John Schulman"
                },
                {
                    "authorId": "1736651",
                    "name": "S. Levine"
                },
                {
                    "authorId": "1689992",
                    "name": "P. Abbeel"
                },
                {
                    "authorId": "1694621",
                    "name": "Michael I. Jordan"
                },
                {
                    "authorId": "29912342",
                    "name": "Philipp Moritz"
                }
            ],
            "doi": null,
            "intent": [
                "background",
                "methodology"
            ],
            "isInfluential": true,
            "paperId": "449532187c94af3dd3aa55e16d2c50f7854d2199",
            "title": "Trust Region Policy Optimization",
            "url": "https://www.semanticscholar.org/paper/449532187c94af3dd3aa55e16d2c50f7854d2199",
            "venue": "ICML",
            "year": 2015
        },
        {
            "arxivId": "1412.6980",
            "authors": [
                {
                    "authorId": "1726807",
                    "name": "Diederik P. Kingma"
                },
                {
                    "authorId": "2503659",
                    "name": "Jimmy Ba"
                }
            ],
            "doi": null,
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "a6cb366736791bcccc5c8639de5a8f9636bf87e8",
            "title": "Adam: A Method for Stochastic Optimization",
            "url": "https://www.semanticscholar.org/paper/a6cb366736791bcccc5c8639de5a8f9636bf87e8",
            "venue": "ICLR",
            "year": 2014
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2108925678",
                    "name": "Rie Johnson"
                },
                {
                    "authorId": "50728655",
                    "name": "Tong Zhang"
                }
            ],
            "doi": null,
            "intent": [
                "background",
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "43c05444fbc239321f6676f3cd539cac34fde7b8",
            "title": "Accelerating Stochastic Gradient Descent using Predictive Variance Reduction",
            "url": "https://www.semanticscholar.org/paper/43c05444fbc239321f6676f3cd539cac34fde7b8",
            "venue": "NIPS",
            "year": 2013
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "144832491",
                    "name": "E. Todorov"
                },
                {
                    "authorId": "1968210",
                    "name": "Tom Erez"
                },
                {
                    "authorId": "2109481",
                    "name": "Yuval Tassa"
                }
            ],
            "doi": "10.1109/IROS.2012.6386109",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "b354ee518bfc1ac0d8ac447eece9edb69e92eae1",
            "title": "MuJoCo: A physics engine for model-based control",
            "url": "https://www.semanticscholar.org/paper/b354ee518bfc1ac0d8ac447eece9edb69e92eae1",
            "venue": "2012 IEEE/RSJ International Conference on Intelligent Robots and Systems",
            "year": 2012
        },
        {
            "arxivId": "1110.2842",
            "authors": [
                {
                    "authorId": "143724861",
                    "name": "Daniel J. Hsu"
                },
                {
                    "authorId": "144695232",
                    "name": "S. Kakade"
                },
                {
                    "authorId": "49104973",
                    "name": "Tong Zhang"
                }
            ],
            "doi": "10.1214/ECP.V17-2079",
            "intent": [
                "background"
            ],
            "isInfluential": true,
            "paperId": "5f3038a0bba2ee932a0aaa3460d42c6a43014878",
            "title": "A tail inequality for quadratic forms of subgaussian random vectors",
            "url": "https://www.semanticscholar.org/paper/5f3038a0bba2ee932a0aaa3460d42c6a43014878",
            "venue": "ArXiv",
            "year": 2011
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "47681372",
                    "name": "Lihong Li"
                },
                {
                    "authorId": "144885169",
                    "name": "M. Littman"
                },
                {
                    "authorId": "144926179",
                    "name": "Thomas J. Walsh"
                },
                {
                    "authorId": "1990806",
                    "name": "Alexander L. Strehl"
                }
            ],
            "doi": "10.1007/s10994-010-5225-4",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "03d3fbad90f047d238b35a742e44b6cd5946d591",
            "title": "Knows what it knows: a\u00a0framework for\u00a0self-aware learning",
            "url": "https://www.semanticscholar.org/paper/03d3fbad90f047d238b35a742e44b6cd5946d591",
            "venue": "ICML '08",
            "year": 2008
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "144695232",
                    "name": "S. Kakade"
                },
                {
                    "authorId": "144162125",
                    "name": "J. Langford"
                }
            ],
            "doi": null,
            "intent": [
                "background",
                "methodology"
            ],
            "isInfluential": true,
            "paperId": "523b4ce1c2a1336962444abc1dec215756c2f3e6",
            "title": "Approximately Optimal Approximate Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/523b4ce1c2a1336962444abc1dec215756c2f3e6",
            "venue": "ICML",
            "year": 2002
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "1699645",
                    "name": "R. Sutton"
                },
                {
                    "authorId": "145689002",
                    "name": "David A. McAllester"
                },
                {
                    "authorId": "1699868",
                    "name": "Satinder Singh"
                },
                {
                    "authorId": "144830983",
                    "name": "Y. Mansour"
                }
            ],
            "doi": null,
            "intent": [
                "methodology"
            ],
            "isInfluential": true,
            "paperId": "a20f0ce0616def7cc9a87446c228906cd5da093b",
            "title": "Policy Gradient Methods for Reinforcement Learning with Function Approximation",
            "url": "https://www.semanticscholar.org/paper/a20f0ce0616def7cc9a87446c228906cd5da093b",
            "venue": "NIPS",
            "year": 1999
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2265092802",
                    "name": "Long Chen"
                }
            ],
            "doi": null,
            "intent": [
                "methodology"
            ],
            "isInfluential": true,
            "paperId": "6d73c9947d840cd84a8eee79c224add5fbbb929e",
            "title": "FINDING STRUCTURE WITH RANDOMNESS : PROBABILISTIC ALGORITHMS FOR CONSTRUCTING",
            "url": "https://www.semanticscholar.org/paper/6d73c9947d840cd84a8eee79c224add5fbbb929e",
            "venue": "",
            "year": 2016
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2116648700",
                    "name": "Ronald J. Williams"
                }
            ],
            "doi": "10.1023/A:1022672621406",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "4c915c1eecb217c123a36dc6d3ce52d12c742614",
            "title": "Simple Statistical Gradient-Following Algorithms for Connectionist Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/4c915c1eecb217c123a36dc6d3ce52d12c742614",
            "venue": "Machine Learning",
            "year": 2004
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "50844636",
                    "name": "Vijay R. Konda"
                },
                {
                    "authorId": "144224173",
                    "name": "J. Tsitsiklis"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "ac4af1df88e178386d782705acc159eaa0c3904a",
            "title": "Actor-Critic Algorithms",
            "url": "https://www.semanticscholar.org/paper/ac4af1df88e178386d782705acc159eaa0c3904a",
            "venue": "NIPS",
            "year": 1999
        }
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Mathematics",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "title": "Uncertainty-Aware Policy Optimization: A Robust, Adaptive Trust Region Approach",
    "topics": [],
    "url": "https://www.semanticscholar.org/paper/b29ef3794829d56ce139a8d02aa88c307d045ed3",
    "venue": "AAAI Conference on Artificial Intelligence",
    "year": 2020
}
{
    "abstract": "Reinforcement learning in complex environments may require supervision to prevent the agent from attempting dangerous actions. As a result of supervisor intervention, the executed action may differ from the action specified by the policy. How does this affect learning? We present the Modified-Action Markov Decision Process, an extension of the MDP model that allows actions to differ from the policy. We analyze the asymptotic behaviours of common reinforcement learning algorithms in this setting and show that they adapt in different ways: some completely ignore modifications while others go to various lengths in trying to avoid action modifications that decrease reward. By choosing the right algorithm, developers can prevent their agents from learning to circumvent interruptions or constraints, and better control agent responses to other kinds of action modification, like self-damage.",
    "arxivId": "2102.07716",
    "authors": [
        {
            "authorId": "2074405406",
            "name": "Eric Langlois",
            "url": "https://www.semanticscholar.org/author/2074405406"
        },
        {
            "authorId": "1868196",
            "name": "Tom Everitt",
            "url": "https://www.semanticscholar.org/author/1868196"
        }
    ],
    "citationVelocity": 0,
    "citations": [
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "1658859117",
                    "name": "Mostafa Rezaeimozafar"
                },
                {
                    "authorId": "81397046",
                    "name": "Maeve Duffy"
                },
                {
                    "authorId": "13157339",
                    "name": "R. Monaghan"
                },
                {
                    "authorId": "2266946295",
                    "name": "Enda Barrett"
                }
            ],
            "doi": "10.1016/j.apenergy.2023.122244",
            "intent": [],
            "isInfluential": false,
            "paperId": "65d02499eab425b4dc5a9625290d80c322364d75",
            "title": "A hybrid heuristic-reinforcement learning-based real-time control model for residential behind-the-meter PV-battery systems",
            "url": "https://www.semanticscholar.org/paper/65d02499eab425b4dc5a9625290d80c322364d75",
            "venue": "Applied Energy",
            "year": 2024
        },
        {
            "arxivId": "2401.03529",
            "authors": [
                {
                    "authorId": "2320312621",
                    "name": "Evan Ryan Gunter"
                },
                {
                    "authorId": "103356487",
                    "name": "Yevgeny Liokumovich"
                },
                {
                    "authorId": "2578985",
                    "name": "Victoria Krakovna"
                }
            ],
            "doi": "10.48550/arXiv.2401.03529",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "a62e18921b954ae3a2343fe9a7aa5899847ef5fe",
            "title": "Quantifying stability of non-power-seeking in artificial agents",
            "url": "https://www.semanticscholar.org/paper/a62e18921b954ae3a2343fe9a7aa5899847ef5fe",
            "venue": "ArXiv",
            "year": 2024
        },
        {
            "arxivId": "2301.02324",
            "authors": [
                {
                    "authorId": "84379741",
                    "name": "Lewis Hammond"
                },
                {
                    "authorId": "2105894098",
                    "name": "James Fox"
                },
                {
                    "authorId": "1868196",
                    "name": "Tom Everitt"
                },
                {
                    "authorId": "2057014575",
                    "name": "Ryan Carey"
                },
                {
                    "authorId": "144938187",
                    "name": "A. Abate"
                },
                {
                    "authorId": "2059979020",
                    "name": "M. Wooldridge"
                }
            ],
            "doi": "10.1016/j.artint.2023.103919",
            "intent": [],
            "isInfluential": false,
            "paperId": "4801d7cd39020ff156c4078a4a2c0d655a33ed15",
            "title": "Reasoning about Causality in Games",
            "url": "https://www.semanticscholar.org/paper/4801d7cd39020ff156c4078a4a2c0d655a33ed15",
            "venue": "Artif. Intell.",
            "year": 2023
        },
        {
            "arxivId": "2208.08345",
            "authors": [
                {
                    "authorId": "40947466",
                    "name": "Zachary Kenton"
                },
                {
                    "authorId": "2117776492",
                    "name": "Ramana Kumar"
                },
                {
                    "authorId": "33859827",
                    "name": "Sebastian Farquhar"
                },
                {
                    "authorId": "7762173",
                    "name": "Jonathan G. Richens"
                },
                {
                    "authorId": "2181810768",
                    "name": "Matt MacDermott"
                },
                {
                    "authorId": "1868196",
                    "name": "Tom Everitt"
                }
            ],
            "doi": "10.48550/arXiv.2208.08345",
            "intent": [
                "background",
                "methodology"
            ],
            "isInfluential": true,
            "paperId": "0c1f1fe5497971479b33e31b236c11d44fbf7a98",
            "title": "Discovering Agents",
            "url": "https://www.semanticscholar.org/paper/0c1f1fe5497971479b33e31b236c11d44fbf7a98",
            "venue": "Artif. Intell.",
            "year": 2022
        },
        {
            "arxivId": "2202.11629",
            "authors": [
                {
                    "authorId": "146400709",
                    "name": "Chris van Merwijk"
                },
                {
                    "authorId": "2057014575",
                    "name": "Ryan Carey"
                },
                {
                    "authorId": "1868196",
                    "name": "Tom Everitt"
                }
            ],
            "doi": "10.1609/aaai.v36i9.21242",
            "intent": [
                "background",
                "result"
            ],
            "isInfluential": true,
            "paperId": "a43196ca18c750472479c4d9a4ffe09659e5e3cd",
            "title": "A Complete Criterion for Value of Information in Soluble Influence Diagrams",
            "url": "https://www.semanticscholar.org/paper/a43196ca18c750472479c4d9a4ffe09659e5e3cd",
            "venue": "AAAI",
            "year": 2022
        },
        {
            "arxivId": "2201.12427",
            "authors": [
                {
                    "authorId": "2910174",
                    "name": "Haonan Yu"
                },
                {
                    "authorId": "2155782544",
                    "name": "Wei Xu"
                },
                {
                    "authorId": null,
                    "name": "Haichao Zhang"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "0ba7f2e592dda172bc3d07f88cdcf2a57830deec",
            "title": "Towards Safe Reinforcement Learning with a Safety Editor Policy",
            "url": "https://www.semanticscholar.org/paper/0ba7f2e592dda172bc3d07f88cdcf2a57830deec",
            "venue": "NeurIPS",
            "year": 2022
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2777677",
                    "name": "George K. Sidiropoulos"
                },
                {
                    "authorId": "2745021",
                    "name": "C. Kiourt"
                },
                {
                    "authorId": "3486649",
                    "name": "Vasileios Sevetlidis"
                },
                {
                    "authorId": "1683264",
                    "name": "G. Pavlidis"
                }
            ],
            "doi": "10.1145/3503823.3503905",
            "intent": [
                "background",
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "3636c903cd1165a5aedbbc5e208308393d01158f",
            "title": "Shaping the Behavior of Reinforcement Learning Agents",
            "url": "https://www.semanticscholar.org/paper/3636c903cd1165a5aedbbc5e208308393d01158f",
            "venue": "PCI",
            "year": 2021
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "1868196",
                    "name": "Tom Everitt"
                },
                {
                    "authorId": "2285619625",
                    "name": "Marcus Hutter"
                },
                {
                    "authorId": "2286745466",
                    "name": "Ramana Kumar"
                },
                {
                    "authorId": "2578985",
                    "name": "Victoria Krakovna"
                }
            ],
            "doi": "10.1007/s11229-021-03141-4",
            "intent": [],
            "isInfluential": false,
            "paperId": "d1f4a948538923687b3d475a20acf35d2e596d91",
            "title": "Reward tampering problems and solutions in reinforcement learning: a causal influence diagram perspective",
            "url": "https://www.semanticscholar.org/paper/d1f4a948538923687b3d475a20acf35d2e596d91",
            "venue": "Synthese",
            "year": 2021
        },
        {
            "arxivId": "2103.14659",
            "authors": [
                {
                    "authorId": "40947466",
                    "name": "Zachary Kenton"
                },
                {
                    "authorId": "1868196",
                    "name": "Tom Everitt"
                },
                {
                    "authorId": "51932191",
                    "name": "Laura Weidinger"
                },
                {
                    "authorId": "116589025",
                    "name": "Iason Gabriel"
                },
                {
                    "authorId": "148305440",
                    "name": "Vladimir Mikulik"
                },
                {
                    "authorId": "2060655766",
                    "name": "G. Irving"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "49f905eb03958c7cfae52ac759ea8978b8b2a6ea",
            "title": "Alignment of Language Agents",
            "url": "https://www.semanticscholar.org/paper/49f905eb03958c7cfae52ac759ea8978b8b2a6ea",
            "venue": "ArXiv",
            "year": 2021
        },
        {
            "arxivId": "2102.05008",
            "authors": [
                {
                    "authorId": "84379741",
                    "name": "Lewis Hammond"
                },
                {
                    "authorId": "2105894098",
                    "name": "James Fox"
                },
                {
                    "authorId": "1868196",
                    "name": "Tom Everitt"
                },
                {
                    "authorId": "144938187",
                    "name": "A. Abate"
                },
                {
                    "authorId": "48106342",
                    "name": "M. Wooldridge"
                }
            ],
            "doi": "10.5555/3463952.3464023",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "2cb982ae08873860727b46250cd63e0cb8e1a661",
            "title": "Equilibrium Refinements for Multi-Agent Influence Diagrams: Theory and Practice",
            "url": "https://www.semanticscholar.org/paper/2cb982ae08873860727b46250cd63e0cb8e1a661",
            "venue": "AAMAS",
            "year": 2021
        },
        {
            "arxivId": "2102.01685",
            "authors": [
                {
                    "authorId": "1868196",
                    "name": "Tom Everitt"
                },
                {
                    "authorId": "2057014575",
                    "name": "Ryan Carey"
                },
                {
                    "authorId": "2074405406",
                    "name": "Eric Langlois"
                },
                {
                    "authorId": "145981974",
                    "name": "Pedro A. Ortega"
                },
                {
                    "authorId": "34313265",
                    "name": "S. Legg"
                }
            ],
            "doi": "10.1609/aaai.v35i13.17368",
            "intent": [
                "background"
            ],
            "isInfluential": true,
            "paperId": "67a5303464a764453a2435bec453bed1c5ac9c43",
            "title": "Agent Incentives: A Causal Perspective",
            "url": "https://www.semanticscholar.org/paper/67a5303464a764453a2435bec453bed1c5ac9c43",
            "venue": "AAAI",
            "year": 2021
        },
        {
            "arxivId": "2012.13490",
            "authors": [
                {
                    "authorId": "38562041",
                    "name": "Khimya Khetarpal"
                },
                {
                    "authorId": "40497459",
                    "name": "M. Riemer"
                },
                {
                    "authorId": "2109771",
                    "name": "I. Rish"
                },
                {
                    "authorId": "144368601",
                    "name": "Doina Precup"
                }
            ],
            "doi": "10.1613/jair.1.13673",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "9faecf3e18a833f2d49b030d591cc2ded0b54336",
            "title": "Towards Continual Reinforcement Learning: A Review and Perspectives",
            "url": "https://www.semanticscholar.org/paper/9faecf3e18a833f2d49b030d591cc2ded0b54336",
            "venue": "J. Artif. Intell. Res.",
            "year": 2020
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2105894098",
                    "name": "James Fox"
                },
                {
                    "authorId": "1868196",
                    "name": "Tom Everitt"
                },
                {
                    "authorId": "2057014575",
                    "name": "Ryan Carey"
                },
                {
                    "authorId": "2074405406",
                    "name": "Eric Langlois"
                },
                {
                    "authorId": "144938187",
                    "name": "A. Abate"
                },
                {
                    "authorId": "2059979020",
                    "name": "M. Wooldridge"
                }
            ],
            "doi": "10.25080/majora-1b6fd038-008",
            "intent": [],
            "isInfluential": false,
            "paperId": "7ebaa98ffb099d2e6f1552eb549e8f59b344d534",
            "title": "PyCID: A Python Library for Causal Influence Diagrams",
            "url": "https://www.semanticscholar.org/paper/7ebaa98ffb099d2e6f1552eb549e8f59b344d534",
            "venue": "SciPy",
            "year": 2021
        }
    ],
    "corpusId": 231925111,
    "doi": "10.1609/aaai.v35i13.17378",
    "fieldsOfStudy": [
        "Computer Science"
    ],
    "influentialCitationCount": 0,
    "isOpenAccess": true,
    "isPublisherLicensed": true,
    "is_open_access": true,
    "is_publisher_licensed": true,
    "numCitedBy": 13,
    "numCiting": 33,
    "paperId": "81d612d385aec3839ab53babfa83081221de22b4",
    "references": [
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2808839",
                    "name": "Srivatsan Krishnan"
                },
                {
                    "authorId": "1389561411",
                    "name": "Sharad Chitlangia"
                },
                {
                    "authorId": "2347284",
                    "name": "Maximilian Lam"
                },
                {
                    "authorId": "148439143",
                    "name": "Zishen Wan"
                },
                {
                    "authorId": "145520045",
                    "name": "Aleksandra Faust"
                },
                {
                    "authorId": "1805668",
                    "name": "V. Reddi"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "1e73f2194e387d779b9fbcbb95b95a18a76facd7",
            "title": "Quantized Reinforcement Learning (QUARL)",
            "url": "https://www.semanticscholar.org/paper/1e73f2194e387d779b9fbcbb95b95a18a76facd7",
            "venue": "ArXiv",
            "year": 2019
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "1868196",
                    "name": "Tom Everitt"
                },
                {
                    "authorId": "145981974",
                    "name": "Pedro A. Ortega"
                },
                {
                    "authorId": "2057742794",
                    "name": "Elizabeth Barnes"
                },
                {
                    "authorId": "34313265",
                    "name": "S. Legg"
                }
            ],
            "doi": null,
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "c63ffb172fdacdddf5c8f84d4a1db00fb014bfbb",
            "title": "Understanding Agent Incentives using Causal Influence Diagrams. Part I: Single Action Settings",
            "url": "https://www.semanticscholar.org/paper/c63ffb172fdacdddf5c8f84d4a1db00fb014bfbb",
            "venue": "ArXiv",
            "year": 2019
        },
        {
            "arxivId": "1801.08757",
            "authors": [
                {
                    "authorId": "2801905",
                    "name": "Gal Dalal"
                },
                {
                    "authorId": "1729912",
                    "name": "Krishnamurthy Dvijotham"
                },
                {
                    "authorId": "7515048",
                    "name": "Matej Vecer\u00edk"
                },
                {
                    "authorId": "143772943",
                    "name": "Todd Hester"
                },
                {
                    "authorId": "3316271",
                    "name": "Cosmin Paduraru"
                },
                {
                    "authorId": "2109481",
                    "name": "Yuval Tassa"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "7f567df97dc7e099d96e6c590ddf5aef8c5b11c4",
            "title": "Safe Exploration in Continuous Action Spaces",
            "url": "https://www.semanticscholar.org/paper/7f567df97dc7e099d96e6c590ddf5aef8c5b11c4",
            "venue": "ArXiv",
            "year": 2018
        },
        {
            "arxivId": "1711.09883",
            "authors": [
                {
                    "authorId": "2990741",
                    "name": "J. Leike"
                },
                {
                    "authorId": "26890260",
                    "name": "Miljan Martic"
                },
                {
                    "authorId": "2578985",
                    "name": "Victoria Krakovna"
                },
                {
                    "authorId": "145981974",
                    "name": "Pedro A. Ortega"
                },
                {
                    "authorId": "1868196",
                    "name": "Tom Everitt"
                },
                {
                    "authorId": "8455031",
                    "name": "Andrew Lefrancq"
                },
                {
                    "authorId": "1749270",
                    "name": "Laurent Orseau"
                },
                {
                    "authorId": "34313265",
                    "name": "S. Legg"
                }
            ],
            "doi": null,
            "intent": [
                "background",
                "result",
                "methodology"
            ],
            "isInfluential": true,
            "paperId": "d09bec5af4eef5038e48b26b6c14098f95997114",
            "title": "AI Safety Gridworlds",
            "url": "https://www.semanticscholar.org/paper/d09bec5af4eef5038e48b26b6c14098f95997114",
            "venue": "ArXiv",
            "year": 2017
        },
        {
            "arxivId": "1707.05173",
            "authors": [
                {
                    "authorId": "2058848938",
                    "name": "W. Saunders"
                },
                {
                    "authorId": "144864359",
                    "name": "Girish Sastry"
                },
                {
                    "authorId": "2214496",
                    "name": "Andreas Stuhlm\u00fcller"
                },
                {
                    "authorId": "47107786",
                    "name": "Owain Evans"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "30ff82cebce6fdc2957043c4085a426414474d78",
            "title": "Trial without Error: Towards Safe Reinforcement Learning via Human Intervention",
            "url": "https://www.semanticscholar.org/paper/30ff82cebce6fdc2957043c4085a426414474d78",
            "venue": "AAMAS",
            "year": 2017
        },
        {
            "arxivId": "1705.08551",
            "authors": [
                {
                    "authorId": "2064772",
                    "name": "Felix Berkenkamp"
                },
                {
                    "authorId": "3422558",
                    "name": "M. Turchetta"
                },
                {
                    "authorId": "143633801",
                    "name": "Angela P. Schoellig"
                },
                {
                    "authorId": "145343838",
                    "name": "Andreas Krause"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "88880d88073a99107bbc009c9f4a4197562e1e44",
            "title": "Safe Model-based Reinforcement Learning with Stability Guarantees",
            "url": "https://www.semanticscholar.org/paper/88880d88073a99107bbc009c9f4a4197562e1e44",
            "venue": "NIPS",
            "year": 2017
        },
        {
            "arxivId": "1703.03864",
            "authors": [
                {
                    "authorId": "2887364",
                    "name": "Tim Salimans"
                },
                {
                    "authorId": "2126278",
                    "name": "Jonathan Ho"
                },
                {
                    "authorId": "41192764",
                    "name": "Xi Chen"
                },
                {
                    "authorId": "1701686",
                    "name": "I. Sutskever"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "4ee802a58d32aa049d549d06be440ac947b53987",
            "title": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/4ee802a58d32aa049d549d06be440ac947b53987",
            "venue": "ArXiv",
            "year": 2017
        },
        {
            "arxivId": "1701.04079",
            "authors": [
                {
                    "authorId": "152422014",
                    "name": "David Abel"
                },
                {
                    "authorId": "3373139",
                    "name": "J. Salvatier"
                },
                {
                    "authorId": "2214496",
                    "name": "Andreas Stuhlm\u00fcller"
                },
                {
                    "authorId": "47107786",
                    "name": "Owain Evans"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "e245ef09fe9e4f56d0fa7f75257298588f4d0392",
            "title": "Agent-Agnostic Human-in-the-Loop Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/e245ef09fe9e4f56d0fa7f75257298588f4d0392",
            "venue": "ArXiv",
            "year": 2017
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "145155783",
                    "name": "C. Robert"
                }
            ],
            "doi": "10.1080/09332480.2017.1302723",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "e0fe9b2f77288bc5e6f778611a49e62e98231f8c",
            "title": "Superintelligence: Paths, Dangers, Strategies",
            "url": "https://www.semanticscholar.org/paper/e0fe9b2f77288bc5e6f778611a49e62e98231f8c",
            "venue": "",
            "year": 2017
        },
        {
            "arxivId": "1610.00633",
            "authors": [
                {
                    "authorId": "2046135",
                    "name": "S. Gu"
                },
                {
                    "authorId": "29891985",
                    "name": "E. Holly"
                },
                {
                    "authorId": "2542999",
                    "name": "T. Lillicrap"
                },
                {
                    "authorId": "1736651",
                    "name": "S. Levine"
                }
            ],
            "doi": "10.1109/ICRA.2017.7989385",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "e37b999f0c96d7136db07b0185b837d5decd599a",
            "title": "Deep reinforcement learning for robotic manipulation with asynchronous off-policy updates",
            "url": "https://www.semanticscholar.org/paper/e37b999f0c96d7136db07b0185b837d5decd599a",
            "venue": "2017 IEEE International Conference on Robotics and Automation (ICRA)",
            "year": 2016
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "1749270",
                    "name": "Laurent Orseau"
                },
                {
                    "authorId": "2054678912",
                    "name": "S. Armstrong"
                }
            ],
            "doi": null,
            "intent": [
                "background",
                "methodology"
            ],
            "isInfluential": true,
            "paperId": "ac70bb2458f01a9e47fc1afe0dd478fb2feb8f50",
            "title": "Safely Interruptible Agents",
            "url": "https://www.semanticscholar.org/paper/ac70bb2458f01a9e47fc1afe0dd478fb2feb8f50",
            "venue": "UAI",
            "year": 2016
        },
        {
            "arxivId": "1511.06393",
            "authors": [
                {
                    "authorId": "1933900",
                    "name": "D. Lin"
                },
                {
                    "authorId": "2390504",
                    "name": "S. Talathi"
                },
                {
                    "authorId": "145712235",
                    "name": "V. Annapureddy"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "33da17e0070dfceed05aec1602a7d1e3284cf715",
            "title": "Fixed Point Quantization of Deep Convolutional Networks",
            "url": "https://www.semanticscholar.org/paper/33da17e0070dfceed05aec1602a7d1e3284cf715",
            "venue": "ICML",
            "year": 2015
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "1401526941",
                    "name": "V. Heidrich-Meisner"
                },
                {
                    "authorId": "1748824",
                    "name": "C. Igel"
                }
            ],
            "doi": "10.1145/1569901.1570064",
            "intent": [],
            "isInfluential": false,
            "paperId": "028e3653560b056017749446d8f654560dcc0947",
            "title": "Uncertainty handling CMA-ES for reinforcement learning",
            "url": "https://www.semanticscholar.org/paper/028e3653560b056017749446d8f654560dcc0947",
            "venue": "GECCO",
            "year": 2009
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "1808760",
                    "name": "S. Omohundro"
                }
            ],
            "doi": "10.1201/9781351251389-3",
            "intent": [],
            "isInfluential": false,
            "paperId": "a6582abc47397d96888108ea308c0168d94a230d",
            "title": "The Basic AI Drives",
            "url": "https://www.semanticscholar.org/paper/a6582abc47397d96888108ea308c0168d94a230d",
            "venue": "AGI",
            "year": 2008
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "27581584",
                    "name": "R. Howard"
                },
                {
                    "authorId": "1843259",
                    "name": "J. Matheson"
                }
            ],
            "doi": "10.1287/deca.1050.0020",
            "intent": [],
            "isInfluential": false,
            "paperId": "cbefa1a15f53a0ee9196eeff113feeea8bfbcee6",
            "title": "Influence Diagrams",
            "url": "https://www.semanticscholar.org/paper/cbefa1a15f53a0ee9196eeff113feeea8bfbcee6",
            "venue": "Decis. Anal.",
            "year": 2005
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "1699868",
                    "name": "Satinder Singh"
                },
                {
                    "authorId": "35132120",
                    "name": "T. Jaakkola"
                },
                {
                    "authorId": "144885169",
                    "name": "M. Littman"
                },
                {
                    "authorId": "40868287",
                    "name": "Csaba Szepesvari"
                }
            ],
            "doi": "10.1023/A:1007678930559",
            "intent": [],
            "isInfluential": false,
            "paperId": "712ec1bd9287ac210a7630ce03ca2b0930ebd351",
            "title": "Convergence Results for Single-Step On-Policy Reinforcement-Learning Algorithms",
            "url": "https://www.semanticscholar.org/paper/712ec1bd9287ac210a7630ce03ca2b0930ebd351",
            "venue": "Machine Learning",
            "year": 2000
        },
        {
            "arxivId": "1106.0221",
            "authors": [
                {
                    "authorId": "1859405",
                    "name": "David E. Moriarty"
                },
                {
                    "authorId": "1803820",
                    "name": "A. Schultz"
                },
                {
                    "authorId": "1869443",
                    "name": "J. Grefenstette"
                }
            ],
            "doi": "10.1613/jair.613",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "856695874f6c482f9609db902326f15d8f6d7c83",
            "title": "Evolutionary Algorithms for Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/856695874f6c482f9609db902326f15d8f6d7c83",
            "venue": "J. Artif. Intell. Res.",
            "year": 1999
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "37814588",
                    "name": "M. Puterman"
                },
                {
                    "authorId": "24313010",
                    "name": "M. C. Shin"
                }
            ],
            "doi": "10.1287/MNSC.24.11.1127",
            "intent": [],
            "isInfluential": false,
            "paperId": "a7b608eff19a85f85b34cda3ecb66d0a3e572583",
            "title": "Modified Policy Iteration Algorithms for Discounted Markov Decision Problems",
            "url": "https://www.semanticscholar.org/paper/a7b608eff19a85f85b34cda3ecb66d0a3e572583",
            "venue": "",
            "year": 1978
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "27581584",
                    "name": "R. Howard"
                }
            ],
            "doi": "10.2307/3611804",
            "intent": [],
            "isInfluential": false,
            "paperId": "c7d3e9a1dd86f9c96f709d0ddb76972862784231",
            "title": "Dynamic Programming and Markov Processes",
            "url": "https://www.semanticscholar.org/paper/c7d3e9a1dd86f9c96f709d0ddb76972862784231",
            "venue": "",
            "year": 1960
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2257178939",
                    "name": "Richard S. Sutton"
                }
            ],
            "doi": null,
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "7ca8ac34767d6e6cb389eeebcdabc4225b39edfe",
            "title": "Advances in Neural Information Processing Systems pp MIT Press Generalization in Reinforcement Learning Successful Examples Using Sparse Coarse Coding",
            "url": "https://www.semanticscholar.org/paper/7ca8ac34767d6e6cb389eeebcdabc4225b39edfe",
            "venue": "",
            "year": 2010
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2116648700",
                    "name": "Ronald J. Williams"
                }
            ],
            "doi": "10.1023/A:1022672621406",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "4c915c1eecb217c123a36dc6d3ce52d12c742614",
            "title": "Simple Statistical Gradient-Following Algorithms for Connectionist Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/4c915c1eecb217c123a36dc6d3ce52d12c742614",
            "venue": "Machine Learning",
            "year": 2004
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "145290695",
                    "name": "C. Watkins"
                },
                {
                    "authorId": "1790646",
                    "name": "P. Dayan"
                }
            ],
            "doi": "10.1023/A:1022676722315",
            "intent": [],
            "isInfluential": false,
            "paperId": "805256745b33eeab46fdd0344d647e55ffecc436",
            "title": "Technical Note: Q-Learning",
            "url": "https://www.semanticscholar.org/paper/805256745b33eeab46fdd0344d647e55ffecc436",
            "venue": "Machine Learning",
            "year": 2004
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2238176724",
                    "name": "R. S. Sutton"
                },
                {
                    "authorId": "1730590",
                    "name": "A. Barto"
                }
            ],
            "doi": "10.1109/TNN.1998.712192",
            "intent": [],
            "isInfluential": false,
            "paperId": "97efafdb4a3942ab3efba53ded7413199f79c054",
            "title": "Reinforcement Learning: An Introduction",
            "url": "https://www.semanticscholar.org/paper/97efafdb4a3942ab3efba53ded7413199f79c054",
            "venue": "IEEE Trans. Neural Networks",
            "year": 1998
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "3466704",
                    "name": "Gavin Adrian Rummery"
                },
                {
                    "authorId": "145387873",
                    "name": "M. Niranjan"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "7a09464f26e18a25a948baaa736270bfb84b5e12",
            "title": "On-line Q-learning using connectionist systems",
            "url": "https://www.semanticscholar.org/paper/7a09464f26e18a25a948baaa736270bfb84b5e12",
            "venue": "",
            "year": 1994
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "35132120",
                    "name": "T. Jaakkola"
                },
                {
                    "authorId": "1694621",
                    "name": "Michael I. Jordan"
                },
                {
                    "authorId": "1699868",
                    "name": "Satinder Singh"
                }
            ],
            "doi": "10.1162/neco.1994.6.6.1185",
            "intent": [
                "background",
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "4e9d797427cd56be90932d6092fc3b6282dfb96f",
            "title": "On the Convergence of Stochastic Iterative Dynamic Programming Algorithms",
            "url": "https://www.semanticscholar.org/paper/4e9d797427cd56be90932d6092fc3b6282dfb96f",
            "venue": "Neural Computation",
            "year": 1994
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "13739357",
                    "name": "Julie Clacy"
                },
                {
                    "authorId": "2280867032",
                    "name": "Ruth Thomas"
                }
            ],
            "doi": "10.7748/ns.2.13.36.s81",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "84d3a7cc59092a33f2a55cbdb35cf07eef86065d",
            "title": "In line.",
            "url": "https://www.semanticscholar.org/paper/84d3a7cc59092a33f2a55cbdb35cf07eef86065d",
            "venue": "Nursing standard (Royal College of Nursing (Great Britain) : 1987)",
            "year": 1988
        },
        {
            "arxivId": null,
            "authors": [],
            "doi": "10.5860/choice.47-3771",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "404d1df16b673659f52a8017bde4ba00f901e8bd",
            "title": "Causality : Models , Reasoning , and Inference",
            "url": "https://www.semanticscholar.org/paper/404d1df16b673659f52a8017bde4ba00f901e8bd",
            "venue": "",
            "year": null
        }
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "title": "How RL Agents Behave When Their Actions Are Modified",
    "topics": [],
    "url": "https://www.semanticscholar.org/paper/81d612d385aec3839ab53babfa83081221de22b4",
    "venue": "AAAI Conference on Artificial Intelligence",
    "year": 2021
}
{
    "abstract": "Reinforcement learning is one of the core components in designing an artificial intelligent system emphasizing real-time response. Reinforcement learning influences the system to take actions within an arbitrary environment either having previous knowledge about the environment model or not. In this paper, we present a comprehensive study on Reinforcement Learning focusing on various dimensions including challenges, the recent development of different state-of-the-art techniques, and future directions. The fundamental objective of this paper is to provide a framework for the presentation of available methods of reinforcement learning that is informative enough and simple to follow for the new researchers and academics in this domain considering the latest concerns. First, we illustrated the core techniques of reinforcement learning in an easily understandable and comparable way. Finally, we analyzed and depicted the recent developments in reinforcement learning approaches. My analysis pointed out that most of the models focused on tuning policy values rather than tuning other things in a particular state of reasoning.",
    "arxivId": "2001.06921",
    "authors": [
        {
            "authorId": "2785515",
            "name": "A. Mondal",
            "url": "https://www.semanticscholar.org/author/2785515"
        }
    ],
    "citationVelocity": 0,
    "citations": [
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2255774551",
                    "name": "Reza Heibati"
                },
                {
                    "authorId": "2255771251",
                    "name": "Ramin Alipour-Sarabi"
                },
                {
                    "authorId": "30876074",
                    "name": "S. Bathaee"
                }
            ],
            "doi": "10.24200/sci.2023.62911.8101",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "0b7e1944b851c6e1158533e776c7fe6aa051bc47",
            "title": "A survey on the most practical signal processing methods in conditional monitoring in wind turbines",
            "url": "https://www.semanticscholar.org/paper/0b7e1944b851c6e1158533e776c7fe6aa051bc47",
            "venue": "Scientia Iranica",
            "year": 2023
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2128266128",
                    "name": "H. Moussaoui"
                },
                {
                    "authorId": "9112723",
                    "name": "Nabil El Akkad"
                },
                {
                    "authorId": "71543756",
                    "name": "M. Benslimane"
                }
            ],
            "doi": "10.12785/ijcds/1301118",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "f5f4ce3cc2ee6bf93b90ca975808c71906cce8dd",
            "title": "Reinforcement Learning: A review",
            "url": "https://www.semanticscholar.org/paper/f5f4ce3cc2ee6bf93b90ca975808c71906cce8dd",
            "venue": "International Journal of Computing and Digital Systems",
            "year": 2023
        },
        {
            "arxivId": "2203.13959",
            "authors": [
                {
                    "authorId": "35311608",
                    "name": "V. Tran"
                },
                {
                    "authorId": "1682421",
                    "name": "M. A. Mabrok"
                },
                {
                    "authorId": "143997049",
                    "name": "S. Anavatti"
                },
                {
                    "authorId": "144034308",
                    "name": "M. Garratt"
                },
                {
                    "authorId": "1739741",
                    "name": "I. Petersen"
                }
            ],
            "doi": "10.1109/TCYB.2022.3175366",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "b54add4bf3bfd80b75691859ba30a20e73673951",
            "title": "Robust Fuzzy Q-Learning-Based Strictly Negative Imaginary Tracking Controllers for the Uncertain Quadrotor Systems",
            "url": "https://www.semanticscholar.org/paper/b54add4bf3bfd80b75691859ba30a20e73673951",
            "venue": "IEEE Transactions on Cybernetics",
            "year": 2022
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2156206537",
                    "name": "\u00c1lvaro Ojeda Rold\u00e1n"
                },
                {
                    "authorId": "2158944714",
                    "name": "Gert Gassner"
                },
                {
                    "authorId": "2099151001",
                    "name": "M. Schlautmann"
                },
                {
                    "authorId": "2156208116",
                    "name": "Luis Enrique Acevedo Galicia"
                },
                {
                    "authorId": "2156210189",
                    "name": "Doru Stefan Andreiana"
                },
                {
                    "authorId": "3013933",
                    "name": "M. Heiskanen"
                },
                {
                    "authorId": "2156210372",
                    "name": "Carlos Leyva Guerrero"
                },
                {
                    "authorId": "2156208555",
                    "name": "Fernando Dorado Navas"
                },
                {
                    "authorId": "2123901187",
                    "name": "Alejandro del Real Torres"
                }
            ],
            "doi": "10.3390/jmmp6020034",
            "intent": [],
            "isInfluential": false,
            "paperId": "20f3ce0979ee3715518ad90e23b60e1746a6ea21",
            "title": "Optimisation of Operator Support Systems through Artificial Intelligence for the Cast Steel Industry: A Case for Optimisation of the Oxygen Blowing Process Based on Machine Learning Algorithms",
            "url": "https://www.semanticscholar.org/paper/20f3ce0979ee3715518ad90e23b60e1746a6ea21",
            "venue": "Journal of Manufacturing and Materials Processing",
            "year": 2022
        },
        {
            "arxivId": "2201.04866",
            "authors": [
                {
                    "authorId": "2051453551",
                    "name": "Emanuel Metzenthin"
                },
                {
                    "authorId": "28918194",
                    "name": "Christian Bartz"
                },
                {
                    "authorId": "1708312",
                    "name": "C. Meinel"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "ea551054f061de61bc9b4aaf7352b3b77b994b62",
            "title": "Weakly Supervised Scene Text Detection using Deep Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/ea551054f061de61bc9b4aaf7352b3b77b994b62",
            "venue": "ArXiv",
            "year": 2022
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2034276221",
                    "name": "Taki Hasan Rafi"
                }
            ],
            "doi": "10.20944/PREPRINTS202104.0202.V1",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "e0d677afaf7a5669f9cce993b3ca678bd0d67cfc",
            "title": "A Brief Review on Spiking Neural Network - A Biological Inspiration",
            "url": "https://www.semanticscholar.org/paper/e0d677afaf7a5669f9cce993b3ca678bd0d67cfc",
            "venue": "",
            "year": 2021
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "1788797",
                    "name": "Y. Nakamoto"
                },
                {
                    "authorId": "108742689",
                    "name": "E. Kumalija"
                },
                {
                    "authorId": "1794685",
                    "name": "Menglei Zhang"
                }
            ],
            "doi": "10.1109/CANDARW51189.2020.00063",
            "intent": [],
            "isInfluential": false,
            "paperId": "e2fbc99bfc7ae1d7375909832d17def4b20142e3",
            "title": "Toward autonomous adaptive embedded systems for sustainable services using reinforcement learning (WiP report)",
            "url": "https://www.semanticscholar.org/paper/e2fbc99bfc7ae1d7375909832d17def4b20142e3",
            "venue": "2020 Eighth International Symposium on Computing and Networking Workshops (CANDARW)",
            "year": 2020
        },
        {
            "arxivId": "2009.08328",
            "authors": [
                {
                    "authorId": "51149606",
                    "name": "Jeffrey M. Ede"
                }
            ],
            "doi": "10.1088/2632-2153/abd614",
            "intent": [],
            "isInfluential": false,
            "paperId": "b00e89b4ede90904704dff6b64eed34384dfc083",
            "title": "Deep learning in electron microscopy",
            "url": "https://www.semanticscholar.org/paper/b00e89b4ede90904704dff6b64eed34384dfc083",
            "venue": "Mach. Learn. Sci. Technol.",
            "year": 2020
        }
    ],
    "corpusId": 210838947,
    "doi": null,
    "fieldsOfStudy": [
        "Computer Science"
    ],
    "influentialCitationCount": 0,
    "isOpenAccess": false,
    "isPublisherLicensed": true,
    "is_open_access": false,
    "is_publisher_licensed": true,
    "numCitedBy": 8,
    "numCiting": 35,
    "paperId": "58d55473fafcaa1f8106052dbe6987863ebc8388",
    "references": [
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "152420788",
                    "name": "Mohit Sewak"
                }
            ],
            "doi": "10.1007/978-981-13-8285-7_1",
            "intent": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "paperId": "3a5ac09e759f3223ee78b995ae2b519efc0f9292",
            "title": "Introduction to Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/3a5ac09e759f3223ee78b995ae2b519efc0f9292",
            "venue": "Deep Reinforcement Learning",
            "year": 2019
        },
        {
            "arxivId": "2405.10369",
            "authors": [
                {
                    "authorId": "1714016",
                    "name": "F. W\u00f6rg\u00f6tter"
                },
                {
                    "authorId": "2728662",
                    "name": "B. Porr"
                }
            ],
            "doi": "10.4249/scholarpedia.1448",
            "intent": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "paperId": "4ffb0130c2e19033a1696c32dac2239f702c8dc4",
            "title": "Reinforcement learning",
            "url": "https://www.semanticscholar.org/paper/4ffb0130c2e19033a1696c32dac2239f702c8dc4",
            "venue": "Scholarpedia",
            "year": 2020
        },
        {
            "arxivId": "1805.07917",
            "authors": [
                {
                    "authorId": "3440874",
                    "name": "Shauharda Khadka"
                },
                {
                    "authorId": "1711099",
                    "name": "Kagan Tumer"
                }
            ],
            "doi": null,
            "intent": [
                "methodology",
                "background"
            ],
            "isInfluential": false,
            "paperId": "d5805a80b63ed0a605e5469e321a7e3c42eaf324",
            "title": "Evolution-Guided Policy Gradient in Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/d5805a80b63ed0a605e5469e321a7e3c42eaf324",
            "venue": "NeurIPS",
            "year": 2018
        },
        {
            "arxivId": "1801.01290",
            "authors": [
                {
                    "authorId": "2587648",
                    "name": "Tuomas Haarnoja"
                },
                {
                    "authorId": "35499972",
                    "name": "Aurick Zhou"
                },
                {
                    "authorId": "1689992",
                    "name": "P. Abbeel"
                },
                {
                    "authorId": "1736651",
                    "name": "S. Levine"
                }
            ],
            "doi": null,
            "intent": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "paperId": "811df72e210e20de99719539505da54762a11c6d",
            "title": "Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor",
            "url": "https://www.semanticscholar.org/paper/811df72e210e20de99719539505da54762a11c6d",
            "venue": "ICML",
            "year": 2018
        },
        {
            "arxivId": "1709.10089",
            "authors": [
                {
                    "authorId": "3422774",
                    "name": "Ashvin Nair"
                },
                {
                    "authorId": "39593364",
                    "name": "Bob McGrew"
                },
                {
                    "authorId": "2206490",
                    "name": "Marcin Andrychowicz"
                },
                {
                    "authorId": "2563432",
                    "name": "Wojciech Zaremba"
                },
                {
                    "authorId": "1689992",
                    "name": "P. Abbeel"
                }
            ],
            "doi": "10.1109/ICRA.2018.8463162",
            "intent": [
                "methodology"
            ],
            "isInfluential": true,
            "paperId": "c28ec2a40a2c77e20d64cf1c85dc931106df8e83",
            "title": "Overcoming Exploration in Reinforcement Learning with Demonstrations",
            "url": "https://www.semanticscholar.org/paper/c28ec2a40a2c77e20d64cf1c85dc931106df8e83",
            "venue": "2018 IEEE International Conference on Robotics and Automation (ICRA)",
            "year": 2017
        },
        {
            "arxivId": "1707.06347",
            "authors": [
                {
                    "authorId": "47971768",
                    "name": "John Schulman"
                },
                {
                    "authorId": "143909660",
                    "name": "Filip Wolski"
                },
                {
                    "authorId": "6515819",
                    "name": "Prafulla Dhariwal"
                },
                {
                    "authorId": "38909097",
                    "name": "Alec Radford"
                },
                {
                    "authorId": "2067138712",
                    "name": "Oleg Klimov"
                }
            ],
            "doi": null,
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "dce6f9d4017b1785979e7520fd0834ef8cf02f4b",
            "title": "Proximal Policy Optimization Algorithms",
            "url": "https://www.semanticscholar.org/paper/dce6f9d4017b1785979e7520fd0834ef8cf02f4b",
            "venue": "ArXiv",
            "year": 2017
        },
        {
            "arxivId": "1707.01495",
            "authors": [
                {
                    "authorId": "2206490",
                    "name": "Marcin Andrychowicz"
                },
                {
                    "authorId": "150074096",
                    "name": "Dwight Crow"
                },
                {
                    "authorId": "2064770039",
                    "name": "Alex Ray"
                },
                {
                    "authorId": "2113526509",
                    "name": "Jonas Schneider"
                },
                {
                    "authorId": "2062025076",
                    "name": "Rachel Fong"
                },
                {
                    "authorId": "2930640",
                    "name": "P. Welinder"
                },
                {
                    "authorId": "39593364",
                    "name": "Bob McGrew"
                },
                {
                    "authorId": "2052880384",
                    "name": "Joshua Tobin"
                },
                {
                    "authorId": "1689992",
                    "name": "P. Abbeel"
                },
                {
                    "authorId": "2563432",
                    "name": "Wojciech Zaremba"
                }
            ],
            "doi": null,
            "intent": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "paperId": "429ed4c9845d0abd1f8204e1d7705919559bc2a2",
            "title": "Hindsight Experience Replay",
            "url": "https://www.semanticscholar.org/paper/429ed4c9845d0abd1f8204e1d7705919559bc2a2",
            "venue": "NIPS",
            "year": 2017
        },
        {
            "arxivId": "1611.05397",
            "authors": [
                {
                    "authorId": "3093886",
                    "name": "Max Jaderberg"
                },
                {
                    "authorId": "3255983",
                    "name": "Volodymyr Mnih"
                },
                {
                    "authorId": "144792148",
                    "name": "Wojciech M. Czarnecki"
                },
                {
                    "authorId": "1725157",
                    "name": "T. Schaul"
                },
                {
                    "authorId": "1700356",
                    "name": "Joel Z. Leibo"
                },
                {
                    "authorId": "145824029",
                    "name": "David Silver"
                },
                {
                    "authorId": "2645384",
                    "name": "K. Kavukcuoglu"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "d7bd6e3addd8bc8e2e154048300eea15f030ed33",
            "title": "Reinforcement Learning with Unsupervised Auxiliary Tasks",
            "url": "https://www.semanticscholar.org/paper/d7bd6e3addd8bc8e2e154048300eea15f030ed33",
            "venue": "ICLR",
            "year": 2016
        },
        {
            "arxivId": "1602.01783",
            "authors": [
                {
                    "authorId": "3255983",
                    "name": "Volodymyr Mnih"
                },
                {
                    "authorId": "36045539",
                    "name": "Adri\u00e0 Puigdom\u00e8nech Badia"
                },
                {
                    "authorId": "153583218",
                    "name": "Mehdi Mirza"
                },
                {
                    "authorId": "1753223",
                    "name": "Alex Graves"
                },
                {
                    "authorId": "2542999",
                    "name": "T. Lillicrap"
                },
                {
                    "authorId": "3367786",
                    "name": "Tim Harley"
                },
                {
                    "authorId": "145824029",
                    "name": "David Silver"
                },
                {
                    "authorId": "2645384",
                    "name": "K. Kavukcuoglu"
                }
            ],
            "doi": null,
            "intent": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "paperId": "69e76e16740ed69f4dc55361a3d319ac2f1293dd",
            "title": "Asynchronous Methods for Deep Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/69e76e16740ed69f4dc55361a3d319ac2f1293dd",
            "venue": "ICML",
            "year": 2016
        },
        {
            "arxivId": "1509.02971",
            "authors": [
                {
                    "authorId": "2542999",
                    "name": "T. Lillicrap"
                },
                {
                    "authorId": "2323922",
                    "name": "Jonathan J. Hunt"
                },
                {
                    "authorId": "1863250",
                    "name": "A. Pritzel"
                },
                {
                    "authorId": "2801204",
                    "name": "N. Heess"
                },
                {
                    "authorId": "1968210",
                    "name": "Tom Erez"
                },
                {
                    "authorId": "2109481",
                    "name": "Yuval Tassa"
                },
                {
                    "authorId": "145824029",
                    "name": "David Silver"
                },
                {
                    "authorId": "1688276",
                    "name": "Daan Wierstra"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "024006d4c2a89f7acacc6e4438d156525b60a98f",
            "title": "Continuous control with deep reinforcement learning",
            "url": "https://www.semanticscholar.org/paper/024006d4c2a89f7acacc6e4438d156525b60a98f",
            "venue": "ICLR",
            "year": 2015
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "3255983",
                    "name": "Volodymyr Mnih"
                },
                {
                    "authorId": "2645384",
                    "name": "K. Kavukcuoglu"
                },
                {
                    "authorId": "145824029",
                    "name": "David Silver"
                },
                {
                    "authorId": "2228824",
                    "name": "Andrei A. Rusu"
                },
                {
                    "authorId": "144056327",
                    "name": "J. Veness"
                },
                {
                    "authorId": "1792298",
                    "name": "Marc G. Bellemare"
                },
                {
                    "authorId": "1753223",
                    "name": "Alex Graves"
                },
                {
                    "authorId": "3137672",
                    "name": "Martin A. Riedmiller"
                },
                {
                    "authorId": "145600108",
                    "name": "A. Fidjeland"
                },
                {
                    "authorId": "2273072",
                    "name": "Georg Ostrovski"
                },
                {
                    "authorId": "48348688",
                    "name": "Stig Petersen"
                },
                {
                    "authorId": "50388928",
                    "name": "Charlie Beattie"
                },
                {
                    "authorId": "49813280",
                    "name": "Amir Sadik"
                },
                {
                    "authorId": "2460849",
                    "name": "Ioannis Antonoglou"
                },
                {
                    "authorId": "143776287",
                    "name": "Helen King"
                },
                {
                    "authorId": "2106164",
                    "name": "D. Kumaran"
                },
                {
                    "authorId": "1688276",
                    "name": "Daan Wierstra"
                },
                {
                    "authorId": "34313265",
                    "name": "S. Legg"
                },
                {
                    "authorId": "48987704",
                    "name": "D. Hassabis"
                }
            ],
            "doi": "10.1038/nature14236",
            "intent": [],
            "isInfluential": false,
            "paperId": "340f48901f72278f6bf78a04ee5b01df208cc508",
            "title": "Human-level control through deep reinforcement learning",
            "url": "https://www.semanticscholar.org/paper/340f48901f72278f6bf78a04ee5b01df208cc508",
            "venue": "Nature",
            "year": 2015
        },
        {
            "arxivId": "1502.05477",
            "authors": [
                {
                    "authorId": "47971768",
                    "name": "John Schulman"
                },
                {
                    "authorId": "1736651",
                    "name": "S. Levine"
                },
                {
                    "authorId": "1689992",
                    "name": "P. Abbeel"
                },
                {
                    "authorId": "1694621",
                    "name": "Michael I. Jordan"
                },
                {
                    "authorId": "29912342",
                    "name": "Philipp Moritz"
                }
            ],
            "doi": null,
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "449532187c94af3dd3aa55e16d2c50f7854d2199",
            "title": "Trust Region Policy Optimization",
            "url": "https://www.semanticscholar.org/paper/449532187c94af3dd3aa55e16d2c50f7854d2199",
            "venue": "ICML",
            "year": 2015
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "1398184857",
                    "name": "Pablo Escandell-Montero"
                },
                {
                    "authorId": "1398184868",
                    "name": "J. Mart\u00ednez-Mart\u00ednez"
                },
                {
                    "authorId": "84306443",
                    "name": "J. Mart\u00edn-Guerrero"
                },
                {
                    "authorId": "83227156",
                    "name": "E. Soria-Olivas"
                },
                {
                    "authorId": "1396035413",
                    "name": "J. G\u00f3mez-Sanch\u00eds"
                }
            ],
            "doi": "10.1016/J.NEUCOM.2013.11.040",
            "intent": [],
            "isInfluential": false,
            "paperId": "971f80e14eece7cdca7ee26f2af32309c0e81a4d",
            "title": "Least-squares temporal difference learning based on extreme learning machine",
            "url": "https://www.semanticscholar.org/paper/971f80e14eece7cdca7ee26f2af32309c0e81a4d",
            "venue": "ESANN",
            "year": 2014
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2837869",
                    "name": "Tim Brys"
                },
                {
                    "authorId": "3134710",
                    "name": "A. Harutyunyan"
                },
                {
                    "authorId": "2528631",
                    "name": "Peter Vrancx"
                },
                {
                    "authorId": "39286677",
                    "name": "Matthew E. Taylor"
                },
                {
                    "authorId": "2380005",
                    "name": "D. Kudenko"
                },
                {
                    "authorId": "144336828",
                    "name": "A. Now\u00e9"
                }
            ],
            "doi": "10.1109/IJCNN.2014.6889732",
            "intent": [],
            "isInfluential": false,
            "paperId": "b596cbf733fec66e02035bc7b2ef9177e455f232",
            "title": "Multi-objectivization of reinforcement learning problems by reward shaping",
            "url": "https://www.semanticscholar.org/paper/b596cbf733fec66e02035bc7b2ef9177e455f232",
            "venue": "2014 International Joint Conference on Neural Networks (IJCNN)",
            "year": 2014
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "145824029",
                    "name": "David Silver"
                },
                {
                    "authorId": "3276293",
                    "name": "Guy Lever"
                },
                {
                    "authorId": "2801204",
                    "name": "N. Heess"
                },
                {
                    "authorId": "1804488",
                    "name": "T. Degris"
                },
                {
                    "authorId": "1688276",
                    "name": "Daan Wierstra"
                },
                {
                    "authorId": "3137672",
                    "name": "Martin A. Riedmiller"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "687d0e59d5c35f022ce4638b3e3a6142068efc94",
            "title": "Deterministic Policy Gradient Algorithms",
            "url": "https://www.semanticscholar.org/paper/687d0e59d5c35f022ce4638b3e3a6142068efc94",
            "venue": "ICML",
            "year": 2014
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2825294",
                    "name": "Mikhail Frank"
                },
                {
                    "authorId": "40548044",
                    "name": "J. Leitner"
                },
                {
                    "authorId": "1997185",
                    "name": "Marijn F. Stollenga"
                },
                {
                    "authorId": "30478864",
                    "name": "A. F\u00f6rster"
                },
                {
                    "authorId": "145341374",
                    "name": "J. Schmidhuber"
                }
            ],
            "doi": "10.3389/fnbot.2013.00025",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "b90d2afa62b42e7790480fbab9cc5b1e4dd49598",
            "title": "Curiosity driven reinforcement learning for motion planning on humanoids",
            "url": "https://www.semanticscholar.org/paper/b90d2afa62b42e7790480fbab9cc5b1e4dd49598",
            "venue": "Front. Neurorobot.",
            "year": 2014
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2991731",
                    "name": "B. B. Doll"
                },
                {
                    "authorId": "3172220",
                    "name": "Dylan A. Simon"
                },
                {
                    "authorId": "1784997",
                    "name": "N. Daw"
                }
            ],
            "doi": "10.1016/j.conb.2012.08.003",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "23a165c12b138cdaa726ef375b0930c8b56d4821",
            "title": "The ubiquity of model-based reinforcement learning",
            "url": "https://www.semanticscholar.org/paper/23a165c12b138cdaa726ef375b0930c8b56d4821",
            "venue": "Current Opinion in Neurobiology",
            "year": 2012
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2151203",
                    "name": "J. Gl\u00e4scher"
                },
                {
                    "authorId": "1784997",
                    "name": "N. Daw"
                },
                {
                    "authorId": "1790646",
                    "name": "P. Dayan"
                },
                {
                    "authorId": "101096038",
                    "name": "J. O\u2019Doherty"
                }
            ],
            "doi": "10.1016/j.neuron.2010.04.016",
            "intent": [],
            "isInfluential": false,
            "paperId": "2910ee0ac40abb61dbdd0d38861129a54eae5070",
            "title": "States versus Rewards: Dissociable Neural Prediction Error Signals Underlying Model-Based and Model-Free Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/2910ee0ac40abb61dbdd0d38861129a54eae5070",
            "venue": "Neuron",
            "year": 2010
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2059358552",
                    "name": "P. Cochat"
                },
                {
                    "authorId": "13267685",
                    "name": "L. Vaucoret"
                },
                {
                    "authorId": "2097644863",
                    "name": "J. Sarles"
                }
            ],
            "doi": "10.1136/ebmh.11.4.102",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "bc6dff14a130c57a91d5a21339c23471faf1d46f",
            "title": "Et al",
            "url": "https://www.semanticscholar.org/paper/bc6dff14a130c57a91d5a21339c23471faf1d46f",
            "venue": "Archives de pediatrie : organe officiel de la Societe francaise de pediatrie",
            "year": 2008
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "1753269",
                    "name": "Brian D. Ziebart"
                },
                {
                    "authorId": "2306081367",
                    "name": "Andrew L. Maas"
                },
                {
                    "authorId": "1756566",
                    "name": "J. Bagnell"
                },
                {
                    "authorId": "144021446",
                    "name": "A. Dey"
                }
            ],
            "doi": null,
            "intent": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "paperId": "c8221c054459e37edbf313668523d667fe5c1536",
            "title": "Maximum Entropy Inverse Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/c8221c054459e37edbf313668523d667fe5c1536",
            "venue": "AAAI",
            "year": 2008
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "1709638",
                    "name": "L. Bu\u015foniu"
                },
                {
                    "authorId": "1705222",
                    "name": "Robert Babu\u0161ka"
                },
                {
                    "authorId": "1724741",
                    "name": "B. Schutter"
                }
            ],
            "doi": "10.1109/TSMCC.2007.913919",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "4aece8df7bd59e2fbfedbf5729bba41abc56d870",
            "title": "A Comprehensive Survey of Multiagent Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/4aece8df7bd59e2fbfedbf5729bba41abc56d870",
            "venue": "IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)",
            "year": 2008
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "1684547",
                    "name": "Ishai Menache"
                },
                {
                    "authorId": "1712535",
                    "name": "Shie Mannor"
                },
                {
                    "authorId": "1742179",
                    "name": "N. Shimkin"
                }
            ],
            "doi": "10.1007/s10479-005-5732-z",
            "intent": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "paperId": "9017a50526ea82496f4b92c625845ea4ead72ac9",
            "title": "Basis Function Adaptation in Temporal Difference Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/9017a50526ea82496f4b92c625845ea4ead72ac9",
            "venue": "Ann. Oper. Res.",
            "year": 2005
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "3214276",
                    "name": "J. Boyan"
                }
            ],
            "doi": "10.1023/A:1017936530646",
            "intent": [
                "background"
            ],
            "isInfluential": true,
            "paperId": "d6aa631d44a7f2cbb3ab07f3b993f4e5c5c4150b",
            "title": "Technical Update: Least-Squares Temporal Difference Learning",
            "url": "https://www.semanticscholar.org/paper/d6aa631d44a7f2cbb3ab07f3b993f4e5c5c4150b",
            "venue": "Machine Learning",
            "year": 2002
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "1796949",
                    "name": "P. Lanzi"
                }
            ],
            "doi": "10.1007/s005000100113",
            "intent": [
                "background"
            ],
            "isInfluential": true,
            "paperId": "9e76f0f006f58cfcb17d62e59c8a0e3b78b97a0d",
            "title": "Learning classifier systems from a reinforcement learning perspective",
            "url": "https://www.semanticscholar.org/paper/9e76f0f006f58cfcb17d62e59c8a0e3b78b97a0d",
            "venue": "Soft Comput.",
            "year": 2002
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "145251954",
                    "name": "J. Holmes"
                },
                {
                    "authorId": "1796949",
                    "name": "P. Lanzi"
                },
                {
                    "authorId": "3092272",
                    "name": "W. Stolzmann"
                },
                {
                    "authorId": "2341152",
                    "name": "Stewart W. Wilson"
                }
            ],
            "doi": "10.1016/S0020-0190(01)00283-6",
            "intent": [],
            "isInfluential": false,
            "paperId": "e8b47830483db76533f676847b42716905cadf1d",
            "title": "Learning classifier systems: New models, successful applications",
            "url": "https://www.semanticscholar.org/paper/e8b47830483db76533f676847b42716905cadf1d",
            "venue": "Inf. Process. Lett.",
            "year": 2002
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "1699645",
                    "name": "R. Sutton"
                },
                {
                    "authorId": "145689002",
                    "name": "David A. McAllester"
                },
                {
                    "authorId": "1699868",
                    "name": "Satinder Singh"
                },
                {
                    "authorId": "144830983",
                    "name": "Y. Mansour"
                }
            ],
            "doi": null,
            "intent": [
                "methodology",
                "background"
            ],
            "isInfluential": false,
            "paperId": "a20f0ce0616def7cc9a87446c228906cd5da093b",
            "title": "Policy Gradient Methods for Reinforcement Learning with Function Approximation",
            "url": "https://www.semanticscholar.org/paper/a20f0ce0616def7cc9a87446c228906cd5da093b",
            "venue": "NIPS",
            "year": 1999
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "40868287",
                    "name": "Csaba Szepesvari"
                },
                {
                    "authorId": "144885169",
                    "name": "M. Littman"
                }
            ],
            "doi": "10.1162/089976699300016070",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "7888be55fb513c20919f94f0274bd9b78bda44b6",
            "title": "A Unified Analysis of Value-Function-Based Reinforcement-Learning Algorithms",
            "url": "https://www.semanticscholar.org/paper/7888be55fb513c20919f94f0274bd9b78bda44b6",
            "venue": "Neural Computation",
            "year": 1999
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "3244824",
                    "name": "H. Kimura"
                },
                {
                    "authorId": "2110064306",
                    "name": "S. Kobayashi"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "5fcb9e6cd2539208c79ed5d818ebf8361fa55c21",
            "title": "An Analysis of Actor/Critic Algorithms Using Eligibility Traces: Reinforcement Learning with Imperfect Value Function",
            "url": "https://www.semanticscholar.org/paper/5fcb9e6cd2539208c79ed5d818ebf8361fa55c21",
            "venue": "ICML",
            "year": 1998
        },
        {
            "arxivId": "cs/9605103",
            "authors": [
                {
                    "authorId": "1709512",
                    "name": "L. Kaelbling"
                },
                {
                    "authorId": "144885169",
                    "name": "M. Littman"
                },
                {
                    "authorId": "1760402",
                    "name": "A. Moore"
                }
            ],
            "doi": "10.1613/jair.301",
            "intent": [
                "background"
            ],
            "isInfluential": true,
            "paperId": "12d1d070a53d4084d88a77b8b143bad51c40c38f",
            "title": "Reinforcement Learning: A Survey",
            "url": "https://www.semanticscholar.org/paper/12d1d070a53d4084d88a77b8b143bad51c40c38f",
            "venue": "J. Artif. Intell. Res.",
            "year": 1996
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "1730590",
                    "name": "A. Barto"
                },
                {
                    "authorId": "47191491",
                    "name": "M. Duff"
                }
            ],
            "doi": null,
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "5e5b25e046f120b296b7c0bad24692ceea492427",
            "title": "Monte Carlo Matrix Inversion and Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/5e5b25e046f120b296b7c0bad24692ceea492427",
            "venue": "NIPS",
            "year": 1993
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "145290695",
                    "name": "C. Watkins"
                },
                {
                    "authorId": "1790646",
                    "name": "P. Dayan"
                }
            ],
            "doi": "10.1007/BF00992698",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "03b7e51c52084ac1db5118342a00b5fbcfc587aa",
            "title": "Q-learning",
            "url": "https://www.semanticscholar.org/paper/03b7e51c52084ac1db5118342a00b5fbcfc587aa",
            "venue": "Machine Learning",
            "year": 1992
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "1699645",
                    "name": "R. Sutton"
                }
            ],
            "doi": "10.1023/A:1022633531479",
            "intent": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "paperId": "a91635f8d0e7fb804efd1c38d9c24ee952ba7076",
            "title": "Learning to predict by the methods of temporal differences",
            "url": "https://www.semanticscholar.org/paper/a91635f8d0e7fb804efd1c38d9c24ee952ba7076",
            "venue": "Machine Learning",
            "year": 1988
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2110194270",
                    "name": "Javier Garc\u00eda"
                },
                {
                    "authorId": "143901279",
                    "name": "F. Fern\u00e1ndez"
                }
            ],
            "doi": "10.5555/2789272.2886795",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "c0f2c4104ef6e36bb67022001179887e6600d24d",
            "title": "A comprehensive survey on safe reinforcement learning",
            "url": "https://www.semanticscholar.org/paper/c0f2c4104ef6e36bb67022001179887e6600d24d",
            "venue": "J. Mach. Learn. Res.",
            "year": 2015
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "67162290",
                    "name": "W. Marsden"
                }
            ],
            "doi": "10.1017/CBO9781139207249.009",
            "intent": [
                "result"
            ],
            "isInfluential": false,
            "paperId": "3d2218b17e7898a222e5fc2079a3f1531990708f",
            "title": "I and J",
            "url": "https://www.semanticscholar.org/paper/3d2218b17e7898a222e5fc2079a3f1531990708f",
            "venue": "",
            "year": 2012
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "3214276",
                    "name": "J. Boyan"
                },
                {
                    "authorId": "2244875693",
                    "name": "Satinder Singh"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "0729b5a6f11aa863182ac5f1fa1372ac693440b6",
            "title": "Technical Update: Least-squares Temporal Diierence Learning",
            "url": "https://www.semanticscholar.org/paper/0729b5a6f11aa863182ac5f1fa1372ac693440b6",
            "venue": "",
            "year": 1999
        }
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "title": "A Survey of Reinforcement Learning Techniques: Strategies, Recent Development, and Future Directions",
    "topics": [],
    "url": "https://www.semanticscholar.org/paper/58d55473fafcaa1f8106052dbe6987863ebc8388",
    "venue": "arXiv.org",
    "year": 2020
}
{
    "abstract": "We suggest a simple practical method to combine the human and artificial intelligence to both learn best investment practices of fund managers, and provide recommendations to improve them. Our approach is based on a combination of Inverse Reinforcement Learning (IRL) and RL. First, the IRL component learns the intent of fund managers as suggested by their trading history, and recovers their implied reward function. At the second step, this reward function is used by a direct RL algorithm to optimize asset allocation decisions. We show that our method is able to improve over the performance of individual fund managers.",
    "arxivId": "2201.01874",
    "authors": [
        {
            "authorId": "12098300",
            "name": "I. Halperin",
            "url": "https://www.semanticscholar.org/author/12098300"
        },
        {
            "authorId": "2118067301",
            "name": "Jiayu Liu",
            "url": "https://www.semanticscholar.org/author/2118067301"
        },
        {
            "authorId": null,
            "name": "Xiao Zhang",
            "url": null
        }
    ],
    "citationVelocity": 0,
    "citations": [
        {
            "arxivId": "2307.09377",
            "authors": [
                {
                    "authorId": "2223753659",
                    "name": "Vikram Duvvur"
                },
                {
                    "authorId": "2047557070",
                    "name": "Aashay Mehta"
                },
                {
                    "authorId": "3189424",
                    "name": "Edward W. Sun"
                },
                {
                    "authorId": "114822447",
                    "name": "Bo Wu"
                },
                {
                    "authorId": "2223829627",
                    "name": "Ken Yew Chan"
                },
                {
                    "authorId": "1753432",
                    "name": "J. Schneider"
                }
            ],
            "doi": "10.48550/arXiv.2307.09377",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "b71f67f1ec99a52537bcf316b18310159136b4d0",
            "title": "Data Cross-Segmentation for Improved Generalization in Reinforcement Learning Based Algorithmic Trading",
            "url": "https://www.semanticscholar.org/paper/b71f67f1ec99a52537bcf316b18310159136b4d0",
            "venue": "ArXiv",
            "year": 2023
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2140150395",
                    "name": "Zhichao Chen"
                },
                {
                    "authorId": "2159686579",
                    "name": "Yutaka Nakamura"
                },
                {
                    "authorId": "1687808",
                    "name": "H. Ishiguro"
                }
            ],
            "doi": "10.1109/LRA.2023.3267385",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "603cbe5be7519223ea2bfb03d90bd575f97c5671",
            "title": "Outperformance of Mall-Receptionist Android as Inverse Reinforcement Learning is Transitioned to Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/603cbe5be7519223ea2bfb03d90bd575f97c5671",
            "venue": "IEEE Robotics and Automation Letters",
            "year": 2023
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2173984813",
                    "name": "Sven Golu\u017ea"
                },
                {
                    "authorId": "2200538471",
                    "name": "Tessa Bauman"
                },
                {
                    "authorId": "35204694",
                    "name": "Tomislav Kova\u010devi\u0107"
                },
                {
                    "authorId": "2116918",
                    "name": "Z. Kostanj\u010dar"
                }
            ],
            "doi": "10.23919/MIPRO57284.2023.10159778",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "bb241b2c14716e2466016fbcea6645b8f00b98cf",
            "title": "Imitation Learning for Financial Applications",
            "url": "https://www.semanticscholar.org/paper/bb241b2c14716e2466016fbcea6645b8f00b98cf",
            "venue": "2023 46th MIPRO ICT and Electronics Convention (MIPRO)",
            "year": 2023
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2322532777",
                    "name": "Song Li"
                },
                {
                    "authorId": "2322450588",
                    "name": "Da-Zi Li"
                },
                {
                    "authorId": "2322404764",
                    "name": "XU Xin"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "cff9a0bf4e8a37816827e167bdcc67723701b78b",
            "title": "A Survey of Inverse Reinforcement Learning Algorithms, Theory and Applications",
            "url": "https://www.semanticscholar.org/paper/cff9a0bf4e8a37816827e167bdcc67723701b78b",
            "venue": "",
            "year": null
        }
    ],
    "corpusId": 245769898,
    "doi": "10.2139/ssrn.4002715",
    "fieldsOfStudy": [
        "Computer Science",
        "Economics"
    ],
    "influentialCitationCount": 0,
    "isOpenAccess": true,
    "isPublisherLicensed": true,
    "is_open_access": true,
    "is_publisher_licensed": true,
    "numCitedBy": 4,
    "numCiting": 8,
    "paperId": "439ff6be2836afd34d5479d5efa36d5d1c7c5bb5",
    "references": [
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "3397503",
                    "name": "Guillaume Coqueret"
                }
            ],
            "doi": "10.1080/14697688.2020.1828609",
            "intent": [
                "background",
                "methodology"
            ],
            "isInfluential": true,
            "paperId": "b494919d0997c3377b091225f4bb6a889c024b5e",
            "title": "Machine Learning in Finance: From Theory to Practice",
            "url": "https://www.semanticscholar.org/paper/b494919d0997c3377b091225f4bb6a889c024b5e",
            "venue": "Quantitative Finance",
            "year": 2020
        },
        {
            "arxivId": "1904.06387",
            "authors": [
                {
                    "authorId": "47627548",
                    "name": "Daniel S. Brown"
                },
                {
                    "authorId": "3461969",
                    "name": "Wonjoon Goo"
                },
                {
                    "authorId": "40608791",
                    "name": "P. Nagarajan"
                },
                {
                    "authorId": "2791038",
                    "name": "S. Niekum"
                }
            ],
            "doi": null,
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "2fc328f3702d6f8730235b1b3ddf7cc5fc096c0d",
            "title": "Extrapolating Beyond Suboptimal Demonstrations via Inverse Reinforcement Learning from Observations",
            "url": "https://www.semanticscholar.org/paper/2fc328f3702d6f8730235b1b3ddf7cc5fc096c0d",
            "venue": "ICML",
            "year": 2019
        },
        {
            "arxivId": "1805.01954",
            "authors": [
                {
                    "authorId": "46221670",
                    "name": "F. Torabi"
                },
                {
                    "authorId": "1938253",
                    "name": "Garrett Warnell"
                },
                {
                    "authorId": "144848112",
                    "name": "P. Stone"
                }
            ],
            "doi": "10.24963/ijcai.2018/687",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "35da1cd669ad5492a6358ea53aea95de28d39ded",
            "title": "Behavioral Cloning from Observation",
            "url": "https://www.semanticscholar.org/paper/35da1cd669ad5492a6358ea53aea95de28d39ded",
            "venue": "IJCAI",
            "year": 2018
        },
        {
            "arxivId": "1512.08562",
            "authors": [
                {
                    "authorId": "145609073",
                    "name": "Roy Fox"
                },
                {
                    "authorId": "3314041",
                    "name": "Ari Pakman"
                },
                {
                    "authorId": "1777660",
                    "name": "Naftali Tishby"
                }
            ],
            "doi": null,
            "intent": [
                "background",
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "4a026fd65af4ba3575e64174de56fee093fa3330",
            "title": "Taming the Noise in Reinforcement Learning via Soft Updates",
            "url": "https://www.semanticscholar.org/paper/4a026fd65af4ba3575e64174de56fee093fa3330",
            "venue": "UAI",
            "year": 2015
        },
        {
            "arxivId": "1011.0686",
            "authors": [
                {
                    "authorId": "1700433",
                    "name": "St\u00e9phane Ross"
                },
                {
                    "authorId": "21889436",
                    "name": "Geoffrey J. Gordon"
                },
                {
                    "authorId": "1756566",
                    "name": "J. Bagnell"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "79ab3c49903ec8cb339437ccf5cf998607fc313e",
            "title": "A Reduction of Imitation Learning and Structured Prediction to No-Regret Online Learning",
            "url": "https://www.semanticscholar.org/paper/79ab3c49903ec8cb339437ccf5cf998607fc313e",
            "venue": "AISTATS",
            "year": 2010
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "34615305",
                    "name": "N. Davies"
                }
            ],
            "doi": "10.1002/0470011815.B2A12044",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "26c81490a84e4a3fd4cae88f833eac49e7ceafb4",
            "title": "Multiple Time Series",
            "url": "https://www.semanticscholar.org/paper/26c81490a84e4a3fd4cae88f833eac49e7ceafb4",
            "venue": "",
            "year": 2005
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "48855558",
                    "name": "D. Pomerleau"
                }
            ],
            "doi": "10.1162/neco.1991.3.1.88",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "8d652a1980e743c7c85ff6066409ea1e3be4d685",
            "title": "Efficient Training of Artificial Neural Networks for Autonomous Navigation",
            "url": "https://www.semanticscholar.org/paper/8d652a1980e743c7c85ff6066409ea1e3be4d685",
            "venue": "Neural Computation",
            "year": 1991
        }
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Economics",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        },
        {
            "category": "Business",
            "source": "s2-fos-model"
        }
    ],
    "title": "Combining Reinforcement Learning and Inverse Reinforcement Learning for Asset Allocation Recommendations",
    "topics": [],
    "url": "https://www.semanticscholar.org/paper/439ff6be2836afd34d5479d5efa36d5d1c7c5bb5",
    "venue": "Social Science Research Network",
    "year": 2022
}
{
    "abstract": "Recent studies show that deep reinforcement learning (DRL) agents tend to overfit to the task on which they were trained and fail to adapt to minor environment changes. To expedite learning when transferring to unseen tasks, we propose a novel approach to representing the current task using reward machines (RMs), state machine abstractions that induce subtasks based on the current task\u2019s rewards and dynamics. Our method provides agents with symbolic representations of optimal transitions from their current abstract state and rewards them for achieving these transitions. These representations are shared across tasks, allowing agents to exploit knowledge of previously encountered symbols and transitions, thus enhancing transfer. Empirical results show that our representations improve sample efficiency and few-shot transfer in a variety of domains.",
    "arxivId": "2307.05209",
    "authors": [
        {
            "authorId": "1972444357",
            "name": "Guy Azran",
            "url": "https://www.semanticscholar.org/author/1972444357"
        },
        {
            "authorId": "1739750274",
            "name": "Mohamad H. Danesh",
            "url": "https://www.semanticscholar.org/author/1739750274"
        },
        {
            "authorId": "1961238",
            "name": "Stefano V. Albrecht",
            "url": "https://www.semanticscholar.org/author/1961238"
        },
        {
            "authorId": "1898340",
            "name": "Sarah Keren",
            "url": "https://www.semanticscholar.org/author/1898340"
        }
    ],
    "citationVelocity": 0,
    "citations": [],
    "corpusId": 259766586,
    "doi": "10.48550/arXiv.2307.05209",
    "fieldsOfStudy": [
        "Computer Science"
    ],
    "influentialCitationCount": 0,
    "isOpenAccess": true,
    "isPublisherLicensed": true,
    "is_open_access": true,
    "is_publisher_licensed": true,
    "numCitedBy": 0,
    "numCiting": 43,
    "paperId": "1633f4662d6ccae0bb5df3ee9ef8c3f20ed9e3af",
    "references": [
        {
            "arxivId": "2305.14133",
            "authors": [
                {
                    "authorId": "2175780695",
                    "name": "Mhairi Dunion"
                },
                {
                    "authorId": "1914794749",
                    "name": "Trevor A. McInroe"
                },
                {
                    "authorId": "3257685",
                    "name": "K. Luck"
                },
                {
                    "authorId": "34719248",
                    "name": "Josiah P. Hanna"
                },
                {
                    "authorId": "1961238",
                    "name": "Stefano V. Albrecht"
                }
            ],
            "doi": "10.48550/arXiv.2305.14133",
            "intent": [
                "background",
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "9e9fa602005193d3c7b7924ef3c50987bd97a07e",
            "title": "Conditional Mutual Information for Disentangled Representations in Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/9e9fa602005193d3c7b7924ef3c50987bd97a07e",
            "venue": "NeurIPS",
            "year": 2023
        },
        {
            "arxivId": "2210.09579",
            "authors": [
                {
                    "authorId": "144150274",
                    "name": "Abhishek Gupta"
                },
                {
                    "authorId": "3124110",
                    "name": "Aldo Pacchiano"
                },
                {
                    "authorId": "119692515",
                    "name": "Yuexiang Zhai"
                },
                {
                    "authorId": "144695232",
                    "name": "S. Kakade"
                },
                {
                    "authorId": "1736651",
                    "name": "S. Levine"
                }
            ],
            "doi": "10.48550/arXiv.2210.09579",
            "intent": [],
            "isInfluential": false,
            "paperId": "203a1c0e5025489a52c030adbbc102a787685ee6",
            "title": "Unpacking Reward Shaping: Understanding the Benefits of Reward Engineering on Sample Complexity",
            "url": "https://www.semanticscholar.org/paper/203a1c0e5025489a52c030adbbc102a787685ee6",
            "venue": "NeurIPS",
            "year": 2022
        },
        {
            "arxivId": "2207.05480",
            "authors": [
                {
                    "authorId": "2175780695",
                    "name": "Mhairi Dunion"
                },
                {
                    "authorId": "1914794749",
                    "name": "Trevor A. McInroe"
                },
                {
                    "authorId": "3257685",
                    "name": "K. Luck"
                },
                {
                    "authorId": "34719248",
                    "name": "Josiah P. Hanna"
                },
                {
                    "authorId": "1961238",
                    "name": "Stefano V. Albrecht"
                }
            ],
            "doi": "10.48550/arXiv.2207.05480",
            "intent": [],
            "isInfluential": false,
            "paperId": "851cfaff3dd0421a9bc2775b135fe3007910eef0",
            "title": "Temporal Disentanglement of Representations for Improved Generalisation in Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/851cfaff3dd0421a9bc2775b135fe3007910eef0",
            "venue": "ICLR",
            "year": 2022
        },
        {
            "arxivId": "2202.04500",
            "authors": [
                {
                    "authorId": "102955418",
                    "name": "C. Benjamins"
                },
                {
                    "authorId": "1944688061",
                    "name": "Theresa Eimer"
                },
                {
                    "authorId": "1859907016",
                    "name": "Frederik Schubert"
                },
                {
                    "authorId": "2064332188",
                    "name": "Aditya Mohan"
                },
                {
                    "authorId": "146024084",
                    "name": "Andr\u00e9 Biedenkapp"
                },
                {
                    "authorId": "1779035",
                    "name": "B. Rosenhahn"
                },
                {
                    "authorId": "144661829",
                    "name": "F. Hutter"
                },
                {
                    "authorId": "145963266",
                    "name": "M. Lindauer"
                }
            ],
            "doi": null,
            "intent": [
                "background",
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "df8e5f2e19b696fc5ed4bec9b61835943c8e8a8f",
            "title": "Contextualize Me - The Case for Context in Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/df8e5f2e19b696fc5ed4bec9b61835943c8e8a8f",
            "venue": "Trans. Mach. Learn. Res.",
            "year": 2022
        },
        {
            "arxivId": "2111.03043",
            "authors": [
                {
                    "authorId": "144799987",
                    "name": "Tao Chen"
                },
                {
                    "authorId": "2145755319",
                    "name": "Jie Xu"
                },
                {
                    "authorId": "33932184",
                    "name": "Pulkit Agrawal"
                }
            ],
            "doi": null,
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "0ee9b633a0914b51f1eec3ad434752aa58e10149",
            "title": "A System for General In-Hand Object Re-Orientation",
            "url": "https://www.semanticscholar.org/paper/0ee9b633a0914b51f1eec3ad434752aa58e10149",
            "venue": "CoRL",
            "year": 2021
        },
        {
            "arxivId": "2108.13264",
            "authors": [
                {
                    "authorId": "29767024",
                    "name": "Rishabh Agarwal"
                },
                {
                    "authorId": "51881243",
                    "name": "Max Schwarzer"
                },
                {
                    "authorId": "39163115",
                    "name": "P. S. Castro"
                },
                {
                    "authorId": "1760871",
                    "name": "Aaron C. Courville"
                },
                {
                    "authorId": "1792298",
                    "name": "Marc G. Bellemare"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "558ca2e8c7eb56edd77a52b084e6cc24dffe5bcd",
            "title": "Deep Reinforcement Learning at the Edge of the Statistical Precipice",
            "url": "https://www.semanticscholar.org/paper/558ca2e8c7eb56edd77a52b084e6cc24dffe5bcd",
            "venue": "NeurIPS",
            "year": 2021
        },
        {
            "arxivId": "2107.04982",
            "authors": [
                {
                    "authorId": "1739750274",
                    "name": "Mohamad H. Danesh"
                },
                {
                    "authorId": "145841336",
                    "name": "Alan Fern"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "dc6ad02d48040c9171f7aca52f169469488c160b",
            "title": "Out-of-Distribution Dynamics Detection: RL-Relevant Benchmarks and Results",
            "url": "https://www.semanticscholar.org/paper/dc6ad02d48040c9171f7aca52f169469488c160b",
            "venue": "ArXiv",
            "year": 2021
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2125292393",
                    "name": "Alberto Camacho"
                },
                {
                    "authorId": "31568090",
                    "name": "Jacob Varley"
                },
                {
                    "authorId": "38591293",
                    "name": "Andy Zeng"
                },
                {
                    "authorId": "2058985645",
                    "name": "Deepali Jain"
                },
                {
                    "authorId": "2106754",
                    "name": "Atil Iscen"
                },
                {
                    "authorId": "48313860",
                    "name": "Dmitry Kalashnikov"
                }
            ],
            "doi": "10.1109/ICRA48506.2021.9561927",
            "intent": [],
            "isInfluential": false,
            "paperId": "c9aefb0081342d0aa9940bcc8eb5171d9cc430f6",
            "title": "Reward Machines for Vision-Based Robotic Manipulation",
            "url": "https://www.semanticscholar.org/paper/c9aefb0081342d0aa9940bcc8eb5171d9cc430f6",
            "venue": "2021 IEEE International Conference on Robotics and Automation (ICRA)",
            "year": 2021
        },
        {
            "arxivId": "2102.06858",
            "authors": [
                {
                    "authorId": "1947192",
                    "name": "Pashootan Vaezipoor"
                },
                {
                    "authorId": "1994454556",
                    "name": "Andrew C. Li"
                },
                {
                    "authorId": "15316342",
                    "name": "Rodrigo Toro Icarte"
                },
                {
                    "authorId": "1683896",
                    "name": "Sheila A. McIlraith"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "98559f4d9acbbaf12c8e83aea1a0940d713c319c",
            "title": "LTL2Action: Generalizing LTL Instructions for Multi-Task RL",
            "url": "https://www.semanticscholar.org/paper/98559f4d9acbbaf12c8e83aea1a0940d713c319c",
            "venue": "ICML",
            "year": 2021
        },
        {
            "arxivId": "2101.05265",
            "authors": [
                {
                    "authorId": "29767024",
                    "name": "Rishabh Agarwal"
                },
                {
                    "authorId": "40066857",
                    "name": "Marlos C. Machado"
                },
                {
                    "authorId": "39163115",
                    "name": "P. S. Castro"
                },
                {
                    "authorId": "1792298",
                    "name": "Marc G. Bellemare"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "7428f65393c19a6ca6381693767cb4f643a49a5c",
            "title": "Contrastive Behavioral Similarity Embeddings for Generalization in Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/7428f65393c19a6ca6381693767cb4f643a49a5c",
            "venue": "ICLR",
            "year": 2021
        },
        {
            "arxivId": "2010.08891",
            "authors": [
                {
                    "authorId": "1999953423",
                    "name": "Aayam Shrestha"
                },
                {
                    "authorId": "1607486000",
                    "name": "Stefan Lee"
                },
                {
                    "authorId": "1729906",
                    "name": "Prasad Tadepalli"
                },
                {
                    "authorId": "145841336",
                    "name": "Alan Fern"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "14e6502e4a63635ef01790471f45f369de72a1c0",
            "title": "DeepAveragers: Offline Reinforcement Learning by Solving Derived Non-Parametric MDPs",
            "url": "https://www.semanticscholar.org/paper/14e6502e4a63635ef01790471f45f369de72a1c0",
            "venue": "ICLR",
            "year": 2020
        },
        {
            "arxivId": "2010.03950",
            "authors": [
                {
                    "authorId": "15316342",
                    "name": "Rodrigo Toro Icarte"
                },
                {
                    "authorId": "1758085",
                    "name": "Toryn Q. Klassen"
                },
                {
                    "authorId": "2682734",
                    "name": "R. Valenzano"
                },
                {
                    "authorId": "1683896",
                    "name": "Sheila A. McIlraith"
                }
            ],
            "doi": "10.1613/jair.1.12440",
            "intent": [],
            "isInfluential": false,
            "paperId": "6778d6a0f959cdcc42718ee9fc279fd1f00f3d88",
            "title": "Reward Machines: Exploiting Reward Function Structure in Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/6778d6a0f959cdcc42718ee9fc279fd1f00f3d88",
            "venue": "J. Artif. Intell. Res.",
            "year": 2020
        },
        {
            "arxivId": "2009.14471",
            "authors": [
                {
                    "authorId": "153204999",
                    "name": "J. K. Terry"
                },
                {
                    "authorId": "2056120610",
                    "name": "Benjamin Black"
                },
                {
                    "authorId": "34659542",
                    "name": "Nathaniel Grammel"
                },
                {
                    "authorId": "2051798853",
                    "name": "Mario Jayakumar"
                },
                {
                    "authorId": "1723419097",
                    "name": "Ananth Hari"
                },
                {
                    "authorId": "2165381307",
                    "name": "Ryan Sullivan"
                },
                {
                    "authorId": "2111820310",
                    "name": "L. Santos"
                },
                {
                    "authorId": "2226755530",
                    "name": "Rodrigo Perez"
                },
                {
                    "authorId": "1972440058",
                    "name": "Caroline Horsch"
                },
                {
                    "authorId": "1976106051",
                    "name": "Clemens Dieffendahl"
                },
                {
                    "authorId": "1693750261",
                    "name": "Niall L. Williams"
                },
                {
                    "authorId": "1976100877",
                    "name": "Yashas Lokesh"
                },
                {
                    "authorId": "145451543",
                    "name": "Praveen Ravi"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "3a70562df004e08d91b125e6d15255e31e445efa",
            "title": "PettingZoo: Gym for Multi-Agent Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/3a70562df004e08d91b125e6d15255e31e445efa",
            "venue": "",
            "year": 2020
        },
        {
            "arxivId": "2006.09447",
            "authors": [
                {
                    "authorId": "27584903",
                    "name": "Georgios Papoudakis"
                },
                {
                    "authorId": "3448899",
                    "name": "Filippos Christianos"
                },
                {
                    "authorId": "1961238",
                    "name": "Stefano V. Albrecht"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "47cbaef8aabdef629183d69faf7bee9a4ad670e5",
            "title": "Agent Modelling under Partial Observability for Deep Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/47cbaef8aabdef629183d69faf7bee9a4ad670e5",
            "venue": "NeurIPS",
            "year": 2020
        },
        {
            "arxivId": "2006.03745",
            "authors": [
                {
                    "authorId": "1739750274",
                    "name": "Mohamad H. Danesh"
                },
                {
                    "authorId": "40135938",
                    "name": "Anurag Koul"
                },
                {
                    "authorId": "145841336",
                    "name": "Alan Fern"
                },
                {
                    "authorId": "33353193",
                    "name": "S. Khorram"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "88e0cf3abc3096cb958d370e95f348272213bdb7",
            "title": "Re-understanding Finite-State Representations of Recurrent Policy Networks",
            "url": "https://www.semanticscholar.org/paper/88e0cf3abc3096cb958d370e95f348272213bdb7",
            "venue": "ICML",
            "year": 2020
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2857025",
                    "name": "Le\u00f3n Illanes"
                },
                {
                    "authorId": "145026971",
                    "name": "Xi Yan"
                },
                {
                    "authorId": "15316342",
                    "name": "Rodrigo Toro Icarte"
                },
                {
                    "authorId": "1683896",
                    "name": "Sheila A. McIlraith"
                }
            ],
            "doi": "10.1609/icaps.v30i1.6750",
            "intent": [],
            "isInfluential": false,
            "paperId": "418a2d5a6c6027e079357d872a0596ec5b344289",
            "title": "Symbolic Plans as High-Level Instructions for Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/418a2d5a6c6027e079357d872a0596ec5b344289",
            "venue": "ICAPS",
            "year": 2020
        },
        {
            "arxivId": "1911.08265",
            "authors": [
                {
                    "authorId": "4337102",
                    "name": "Julian Schrittwieser"
                },
                {
                    "authorId": "2460849",
                    "name": "Ioannis Antonoglou"
                },
                {
                    "authorId": "2067208983",
                    "name": "T. Hubert"
                },
                {
                    "authorId": "34838386",
                    "name": "K. Simonyan"
                },
                {
                    "authorId": "2175946",
                    "name": "L. Sifre"
                },
                {
                    "authorId": "152380508",
                    "name": "Simon Schmitt"
                },
                {
                    "authorId": "35099444",
                    "name": "A. Guez"
                },
                {
                    "authorId": "49860549",
                    "name": "Edward Lockhart"
                },
                {
                    "authorId": "48987704",
                    "name": "D. Hassabis"
                },
                {
                    "authorId": "1686971",
                    "name": "T. Graepel"
                },
                {
                    "authorId": "2542999",
                    "name": "T. Lillicrap"
                },
                {
                    "authorId": "145824029",
                    "name": "David Silver"
                }
            ],
            "doi": "10.1038/s41586-020-03051-4",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "3507bd62a14bd0e8ead28cdedb1c33ba83c39c6b",
            "title": "Mastering Atari, Go, chess and shogi by planning with a learned model",
            "url": "https://www.semanticscholar.org/paper/3507bd62a14bd0e8ead28cdedb1c33ba83c39c6b",
            "venue": "Nature",
            "year": 2019
        },
        {
            "arxivId": "1910.08348",
            "authors": [
                {
                    "authorId": "3378188",
                    "name": "L. Zintgraf"
                },
                {
                    "authorId": "3402736",
                    "name": "K. Shiarlis"
                },
                {
                    "authorId": "27550002",
                    "name": "Maximilian Igl"
                },
                {
                    "authorId": "2071436879",
                    "name": "Sebastian Schulze"
                },
                {
                    "authorId": "2681954",
                    "name": "Y. Gal"
                },
                {
                    "authorId": "1380228856",
                    "name": "Katja Hofmann"
                },
                {
                    "authorId": "1766767",
                    "name": "Shimon Whiteson"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "361e953f792a585496834ee14216b94d0ce9ae74",
            "title": "VariBAD: A Very Good Method for Bayes-Adaptive Deep RL via Meta-Learning",
            "url": "https://www.semanticscholar.org/paper/361e953f792a585496834ee14216b94d0ce9ae74",
            "venue": "ICLR",
            "year": 2019
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "15316342",
                    "name": "Rodrigo Toro Icarte"
                },
                {
                    "authorId": "1396422950",
                    "name": "Ethan Waldie"
                },
                {
                    "authorId": "1758085",
                    "name": "Toryn Q. Klassen"
                },
                {
                    "authorId": "2682734",
                    "name": "R. Valenzano"
                },
                {
                    "authorId": "41036745",
                    "name": "Margarita P. Castro"
                },
                {
                    "authorId": "1683896",
                    "name": "Sheila A. McIlraith"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "a03472a07ac2ef5b5b03358d074d2891c8fba144",
            "title": "Learning Reward Machines for Partially Observable Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/a03472a07ac2ef5b5b03358d074d2891c8fba144",
            "venue": "NeurIPS",
            "year": 2019
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "15316342",
                    "name": "Rodrigo Toro Icarte"
                },
                {
                    "authorId": "1758085",
                    "name": "Toryn Q. Klassen"
                },
                {
                    "authorId": "2682734",
                    "name": "R. Valenzano"
                },
                {
                    "authorId": "1683896",
                    "name": "Sheila A. McIlraith"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "00ec8123dd2ba03afab7c1fa02f774062f769181",
            "title": "Using Reward Machines for High-Level Task Specification and Decomposition in Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/00ec8123dd2ba03afab7c1fa02f774062f769181",
            "venue": "ICML",
            "year": 2018
        },
        {
            "arxivId": "1804.06893",
            "authors": [
                {
                    "authorId": "151505981",
                    "name": "Chiyuan Zhang"
                },
                {
                    "authorId": "1689108",
                    "name": "O. Vinyals"
                },
                {
                    "authorId": "1708654",
                    "name": "R. Munos"
                },
                {
                    "authorId": "1751569",
                    "name": "Samy Bengio"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "041d99f442dc22cf51118dc992095be9aa0972e0",
            "title": "A Study on Overfitting in Deep Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/041d99f442dc22cf51118dc992095be9aa0972e0",
            "venue": "ArXiv",
            "year": 2018
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "3413448",
                    "name": "Phuong D. Ngo"
                },
                {
                    "authorId": "49752592",
                    "name": "Susan Wei"
                },
                {
                    "authorId": "47937706",
                    "name": "A. Holubov\u00e1"
                },
                {
                    "authorId": "144935559",
                    "name": "J. Mu\u017e\u00edk"
                },
                {
                    "authorId": "3091775",
                    "name": "F. Godtliebsen"
                }
            ],
            "doi": "10.1109/BHI.2018.8333436",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "623a2f9a72db332f60107d351a3aefd3aab5f99e",
            "title": "Reinforcement-learning optimal control for type-1 diabetes",
            "url": "https://www.semanticscholar.org/paper/623a2f9a72db332f60107d351a3aefd3aab5f99e",
            "venue": "2018 IEEE EMBS International Conference on Biomedical & Health Informatics (BHI)",
            "year": 2018
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "144162125",
                    "name": "J. Langford"
                }
            ],
            "doi": "10.1109/BigData.2017.8257902",
            "intent": [
                "background",
                "methodology"
            ],
            "isInfluential": true,
            "paperId": "d1229562607f398d94e5d9fc45008d60bdbecd46",
            "title": "Contextual reinforcement learning",
            "url": "https://www.semanticscholar.org/paper/d1229562607f398d94e5d9fc45008d60bdbecd46",
            "venue": "IEEE BigData",
            "year": 2017
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "12931618",
                    "name": "H. Tseng"
                },
                {
                    "authorId": "46185255",
                    "name": "Yi Luo"
                },
                {
                    "authorId": "38609478",
                    "name": "Sunan Cui"
                },
                {
                    "authorId": "1699469",
                    "name": "Jen-Tzung Chien"
                },
                {
                    "authorId": "115533597",
                    "name": "R. T. Ten Haken"
                },
                {
                    "authorId": "18154882",
                    "name": "I. Naqa"
                }
            ],
            "doi": "10.1002/mp.12625",
            "intent": [],
            "isInfluential": false,
            "paperId": "71d7cc5f527554bb54adc32990cbc01eac3aee6b",
            "title": "Deep reinforcement learning for automated radiation adaptation in lung cancer",
            "url": "https://www.semanticscholar.org/paper/71d7cc5f527554bb54adc32990cbc01eac3aee6b",
            "venue": "Medical physics",
            "year": 2017
        },
        {
            "arxivId": "1703.03400",
            "authors": [
                {
                    "authorId": "46881670",
                    "name": "Chelsea Finn"
                },
                {
                    "authorId": "1689992",
                    "name": "P. Abbeel"
                },
                {
                    "authorId": "1736651",
                    "name": "S. Levine"
                }
            ],
            "doi": null,
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "c889d6f98e6d79b89c3a6adf8a921f88fa6ba518",
            "title": "Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks",
            "url": "https://www.semanticscholar.org/paper/c889d6f98e6d79b89c3a6adf8a921f88fa6ba518",
            "venue": "ICML",
            "year": 2017
        },
        {
            "arxivId": "1611.05763",
            "authors": [
                {
                    "authorId": "2116439278",
                    "name": "Jane X. Wang"
                },
                {
                    "authorId": "1399114225",
                    "name": "Z. Kurth-Nelson"
                },
                {
                    "authorId": "2794457",
                    "name": "Hubert Soyer"
                },
                {
                    "authorId": "1700356",
                    "name": "Joel Z. Leibo"
                },
                {
                    "authorId": "7794353",
                    "name": "Dhruva Tirumala"
                },
                {
                    "authorId": "1708654",
                    "name": "R. Munos"
                },
                {
                    "authorId": "1723876",
                    "name": "C. Blundell"
                },
                {
                    "authorId": "2106164",
                    "name": "D. Kumaran"
                },
                {
                    "authorId": "46378362",
                    "name": "M. Botvinick"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "282a380fb5ac26d99667224cef8c630f6882704f",
            "title": "Learning to reinforcement learn",
            "url": "https://www.semanticscholar.org/paper/282a380fb5ac26d99667224cef8c630f6882704f",
            "venue": "CogSci",
            "year": 2016
        },
        {
            "arxivId": "1611.02779",
            "authors": [
                {
                    "authorId": "144581158",
                    "name": "Yan Duan"
                },
                {
                    "authorId": "47971768",
                    "name": "John Schulman"
                },
                {
                    "authorId": "41192764",
                    "name": "Xi Chen"
                },
                {
                    "authorId": "1745169",
                    "name": "P. Bartlett"
                },
                {
                    "authorId": "1701686",
                    "name": "I. Sutskever"
                },
                {
                    "authorId": "1689992",
                    "name": "P. Abbeel"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "954b01151ff13aef416d27adc60cd9a076753b1a",
            "title": "RL$^2$: Fast Reinforcement Learning via Slow Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/954b01151ff13aef416d27adc60cd9a076753b1a",
            "venue": "ArXiv",
            "year": 2016
        },
        {
            "arxivId": "1606.01540",
            "authors": [
                {
                    "authorId": "2065151121",
                    "name": "Greg Brockman"
                },
                {
                    "authorId": "34415167",
                    "name": "Vicki Cheung"
                },
                {
                    "authorId": "152877508",
                    "name": "Ludwig Pettersson"
                },
                {
                    "authorId": "2113526509",
                    "name": "Jonas Schneider"
                },
                {
                    "authorId": "47971768",
                    "name": "John Schulman"
                },
                {
                    "authorId": "2109541439",
                    "name": "Jie Tang"
                },
                {
                    "authorId": "2563432",
                    "name": "Wojciech Zaremba"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "2b10281297ee001a9f3f4ea1aa9bea6b638c27df",
            "title": "OpenAI Gym",
            "url": "https://www.semanticscholar.org/paper/2b10281297ee001a9f3f4ea1aa9bea6b638c27df",
            "venue": "ArXiv",
            "year": 2016
        },
        {
            "arxivId": "1602.02867",
            "authors": [
                {
                    "authorId": "3025260",
                    "name": "Aviv Tamar"
                },
                {
                    "authorId": "1736651",
                    "name": "S. Levine"
                },
                {
                    "authorId": "1689992",
                    "name": "P. Abbeel"
                },
                {
                    "authorId": "31613801",
                    "name": "Yi Wu"
                },
                {
                    "authorId": "8234443",
                    "name": "G. Thomas"
                }
            ],
            "doi": "10.24963/ijcai.2017/700",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "84680b30a20775e5d319419a7f3f2a93e57c2a61",
            "title": "Value Iteration Networks",
            "url": "https://www.semanticscholar.org/paper/84680b30a20775e5d319419a7f3f2a93e57c2a61",
            "venue": "NIPS",
            "year": 2016
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "3255983",
                    "name": "Volodymyr Mnih"
                },
                {
                    "authorId": "2645384",
                    "name": "K. Kavukcuoglu"
                },
                {
                    "authorId": "145824029",
                    "name": "David Silver"
                },
                {
                    "authorId": "2228824",
                    "name": "Andrei A. Rusu"
                },
                {
                    "authorId": "144056327",
                    "name": "J. Veness"
                },
                {
                    "authorId": "1792298",
                    "name": "Marc G. Bellemare"
                },
                {
                    "authorId": "1753223",
                    "name": "Alex Graves"
                },
                {
                    "authorId": "3137672",
                    "name": "Martin A. Riedmiller"
                },
                {
                    "authorId": "145600108",
                    "name": "A. Fidjeland"
                },
                {
                    "authorId": "2273072",
                    "name": "Georg Ostrovski"
                },
                {
                    "authorId": "48348688",
                    "name": "Stig Petersen"
                },
                {
                    "authorId": "50388928",
                    "name": "Charlie Beattie"
                },
                {
                    "authorId": "49813280",
                    "name": "Amir Sadik"
                },
                {
                    "authorId": "2460849",
                    "name": "Ioannis Antonoglou"
                },
                {
                    "authorId": "143776287",
                    "name": "Helen King"
                },
                {
                    "authorId": "2106164",
                    "name": "D. Kumaran"
                },
                {
                    "authorId": "1688276",
                    "name": "Daan Wierstra"
                },
                {
                    "authorId": "34313265",
                    "name": "S. Legg"
                },
                {
                    "authorId": "48987704",
                    "name": "D. Hassabis"
                }
            ],
            "doi": "10.1038/nature14236",
            "intent": [
                "methodology"
            ],
            "isInfluential": true,
            "paperId": "340f48901f72278f6bf78a04ee5b01df208cc508",
            "title": "Human-level control through deep reinforcement learning",
            "url": "https://www.semanticscholar.org/paper/340f48901f72278f6bf78a04ee5b01df208cc508",
            "venue": "Nature",
            "year": 2015
        },
        {
            "arxivId": "1502.02259",
            "authors": [
                {
                    "authorId": "21062872",
                    "name": "Assaf Hallak"
                },
                {
                    "authorId": "9440777",
                    "name": "Dotan Di Castro"
                },
                {
                    "authorId": "1712535",
                    "name": "Shie Mannor"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "04955600df47c66a055591d927c024e6e9c72c61",
            "title": "Contextual Markov Decision Processes",
            "url": "https://www.semanticscholar.org/paper/04955600df47c66a055591d927c024e6e9c72c61",
            "venue": "ArXiv",
            "year": 2015
        },
        {
            "arxivId": "1412.6980",
            "authors": [
                {
                    "authorId": "1726807",
                    "name": "Diederik P. Kingma"
                },
                {
                    "authorId": "2503659",
                    "name": "Jimmy Ba"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "a6cb366736791bcccc5c8639de5a8f9636bf87e8",
            "title": "Adam: A Method for Stochastic Optimization",
            "url": "https://www.semanticscholar.org/paper/a6cb366736791bcccc5c8639de5a8f9636bf87e8",
            "venue": "ICLR",
            "year": 2014
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "39286677",
                    "name": "Matthew E. Taylor"
                },
                {
                    "authorId": "144848112",
                    "name": "P. Stone"
                }
            ],
            "doi": "10.5555/1577069.1755839",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "467568f1777bc51a15a5100516cd4fe8de62b9ab",
            "title": "Transfer Learning for Reinforcement Learning Domains: A Survey",
            "url": "https://www.semanticscholar.org/paper/467568f1777bc51a15a5100516cd4fe8de62b9ab",
            "venue": "J. Mach. Learn. Res.",
            "year": 2009
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "1699645",
                    "name": "R. Sutton"
                },
                {
                    "authorId": "144368601",
                    "name": "Doina Precup"
                },
                {
                    "authorId": "1699868",
                    "name": "Satinder Singh"
                }
            ],
            "doi": "10.1016/S0004-3702(99)00052-1",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "0e7638dc16a5e5e9e46c91272bfb9c3dd242ef6d",
            "title": "Between MDPs and Semi-MDPs: A Framework for Temporal Abstraction in Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/0e7638dc16a5e5e9e46c91272bfb9c3dd242ef6d",
            "venue": "Artif. Intell.",
            "year": 1999
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "34699434",
                    "name": "A. Ng"
                },
                {
                    "authorId": "1868677",
                    "name": "Daishi Harada"
                },
                {
                    "authorId": "145107462",
                    "name": "Stuart J. Russell"
                }
            ],
            "doi": null,
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "94066dc12fe31e96af7557838159bde598cb4f10",
            "title": "Policy Invariance Under Reward Transformations: Theory and Application to Reward Shaping",
            "url": "https://www.semanticscholar.org/paper/94066dc12fe31e96af7557838159bde598cb4f10",
            "venue": "ICML",
            "year": 1999
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "144873562",
                    "name": "R. Bellman"
                }
            ],
            "doi": "10.1512/IUMJ.1957.6.56038",
            "intent": [
                "background",
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "bff20fb30adad8d1c173963089df5fc9664304f0",
            "title": "A Markovian Decision Process",
            "url": "https://www.semanticscholar.org/paper/bff20fb30adad8d1c173963089df5fc9664304f0",
            "venue": "",
            "year": 1957
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2066422293",
                    "name": "Robert Kirk"
                },
                {
                    "authorId": "2111672235",
                    "name": "Amy Zhang"
                },
                {
                    "authorId": "1864353",
                    "name": "Edward Grefenstette"
                },
                {
                    "authorId": "1389854357",
                    "name": "Tim Rocktaschel"
                }
            ],
            "doi": null,
            "intent": [
                "background",
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "42edbc3c29af476c27f102b3de9f04e56b5c642d",
            "title": "A Survey of Generalisation in Deep Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/42edbc3c29af476c27f102b3de9f04e56b5c642d",
            "venue": "ArXiv",
            "year": 2021
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "73773741",
                    "name": "Ron Dorfman"
                },
                {
                    "authorId": "2164041844",
                    "name": "Idan Shenfeld"
                },
                {
                    "authorId": "3025260",
                    "name": "Aviv Tamar"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "d27edce419e1c731c0aeb9e1842d1e022b2cc6ab",
            "title": "Offline Meta Reinforcement Learning - Identifiability Challenges and Effective Data Collection Strategies",
            "url": "https://www.semanticscholar.org/paper/d27edce419e1c731c0aeb9e1842d1e022b2cc6ab",
            "venue": "NeurIPS",
            "year": 2021
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "1406798986",
                    "name": "Hamid Eghbalzadeh"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "064d179055f931dd9f00971620c9ea1ea9434e9b",
            "title": "Context-Adaptive Reinforcement Learning using Unsupervised Learning of Context Variables",
            "url": "https://www.semanticscholar.org/paper/064d179055f931dd9f00971620c9ea1ea9434e9b",
            "venue": "Preregister@NeurIPS",
            "year": 2020
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "36539670",
                    "name": "Rohit Vaish"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "7406e5a698cf77cd62fb151fb5f0fc3903ad5cb2",
            "title": "Real World Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/7406e5a698cf77cd62fb151fb5f0fc3903ad5cb2",
            "venue": "",
            "year": 2011
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "1801209",
                    "name": "Lisa A. Torrey"
                },
                {
                    "authorId": "1734317",
                    "name": "J. Shavlik"
                }
            ],
            "doi": "10.4018/978-1-60566-766-9.ch011",
            "intent": [
                "background",
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "1890c124749d00cce965e0b9495eafe127e16a26",
            "title": "Chapter 11 Transfer Learning",
            "url": "https://www.semanticscholar.org/paper/1890c124749d00cce965e0b9495eafe127e16a26",
            "venue": "",
            "year": 2009
        }
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "title": "Contextual Pre-Planning on Reward Machine Abstractions for Enhanced Transfer in Deep Reinforcement Learning",
    "topics": [],
    "url": "https://www.semanticscholar.org/paper/1633f4662d6ccae0bb5df3ee9ef8c3f20ed9e3af",
    "venue": "AAAI Conference on Artificial Intelligence",
    "year": 2023
}
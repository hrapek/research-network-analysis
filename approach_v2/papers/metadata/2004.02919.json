{
    "abstract": "Potential Based Reward Shaping combined with a potential function based on appropriately defined abstract knowledge has been shown to significantly improve learning speed in Reinforcement Learning. MultiGrid Reinforcement Learning (MRL) has further shown that such abstract knowledge in the form of a potential function can be learned almost solely from agent interaction with the environment. However, we show that MRL faces the problem of not extending well to work with Deep Learning. In this paper we extend and improve MRL to take advantage of modern Deep Learning algorithms such as Deep Q-Networks (DQN). We show that DQN augmented with our approach perform significantly better on continuous control tasks than its Vanilla counterpart and DQN augmented with MRL.",
    "arxivId": "2004.02919",
    "authors": [
        {
            "authorId": "31502027",
            "name": "John Burden",
            "url": "https://www.semanticscholar.org/author/31502027"
        },
        {
            "authorId": "2380005",
            "name": "D. Kudenko",
            "url": "https://www.semanticscholar.org/author/2380005"
        }
    ],
    "citationVelocity": 0,
    "citations": [
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "1556311931",
                    "name": "Yuan Xue"
                },
                {
                    "authorId": "2380005",
                    "name": "D. Kudenko"
                },
                {
                    "authorId": "35070805",
                    "name": "Megha Khosla"
                }
            ],
            "doi": "10.1007/s00521-023-08211-x",
            "intent": [],
            "isInfluential": false,
            "paperId": "57077d0fe4614f8e79a7daf9f459651e56713aec",
            "title": "Graph learning-based generation of abstractions for reinforcement learning",
            "url": "https://www.semanticscholar.org/paper/57077d0fe4614f8e79a7daf9f459651e56713aec",
            "venue": "Neural Computing and Applications",
            "year": 2023
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "66779461",
                    "name": "R. Devidze"
                },
                {
                    "authorId": "2667883",
                    "name": "Goran Radanovic"
                },
                {
                    "authorId": "2197201",
                    "name": "Parameswaran Kamalaruban"
                },
                {
                    "authorId": "1703727",
                    "name": "A. Singla"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "861df6a3727446d2c8f4a78f51224ca64eb9110d",
            "title": "Explicable Reward Design for Reinforcement Learning Agents",
            "url": "https://www.semanticscholar.org/paper/861df6a3727446d2c8f4a78f51224ca64eb9110d",
            "venue": "NeurIPS",
            "year": 2021
        }
    ],
    "corpusId": 215238626,
    "doi": "10.3233/FAIA200198",
    "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
    ],
    "influentialCitationCount": 0,
    "isOpenAccess": false,
    "isPublisherLicensed": true,
    "is_open_access": false,
    "is_publisher_licensed": true,
    "numCitedBy": 2,
    "numCiting": 25,
    "paperId": "9e598383afdb7eea847a422ec6a1fbc36ed42aa0",
    "references": [
        {
            "arxivId": "1710.00459",
            "authors": [
                {
                    "authorId": "32019380",
                    "name": "Melrose Roderick"
                },
                {
                    "authorId": "21471370",
                    "name": "Christopher Grimm"
                },
                {
                    "authorId": "2913681",
                    "name": "Stefanie Tellex"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "55f730385016802dd6452a34d0271b5c47ded332",
            "title": "Deep Abstract Q-Networks",
            "url": "https://www.semanticscholar.org/paper/55f730385016802dd6452a34d0271b5c47ded332",
            "venue": "AAMAS",
            "year": 2017
        },
        {
            "arxivId": "1709.04579",
            "authors": [
                {
                    "authorId": "2138978",
                    "name": "B. Ghazanfari"
                },
                {
                    "authorId": "39286677",
                    "name": "Matthew E. Taylor"
                }
            ],
            "doi": null,
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "3159165e8a454da67ca6a1c13118646225888286",
            "title": "Autonomous Extracting a Hierarchical Structure of Tasks in Reinforcement Learning and Multi-task Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/3159165e8a454da67ca6a1c13118646225888286",
            "venue": "ArXiv",
            "year": 2017
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "65821196",
                    "name": "Ramnandan Krishnamurthy"
                },
                {
                    "authorId": "2943530",
                    "name": "A. Lakshminarayanan"
                },
                {
                    "authorId": "2107879766",
                    "name": "Peeyush Kumar"
                },
                {
                    "authorId": "1723632",
                    "name": "Balaraman Ravindran"
                }
            ],
            "doi": null,
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "0a0316936d335fa74860e1099e97e69c092ee457",
            "title": "Hierarchical Reinforcement Learning using Spatio-Temporal Abstractions and Deep Neural Networks",
            "url": "https://www.semanticscholar.org/paper/0a0316936d335fa74860e1099e97e69c092ee457",
            "venue": "ArXiv",
            "year": 2016
        },
        {
            "arxivId": "1604.06057",
            "authors": [
                {
                    "authorId": "1954876",
                    "name": "Tejas D. Kulkarni"
                },
                {
                    "authorId": "144958935",
                    "name": "Karthik Narasimhan"
                },
                {
                    "authorId": "3231182",
                    "name": "A. Saeedi"
                },
                {
                    "authorId": "1763295",
                    "name": "J. Tenenbaum"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "d37620e6f8fe678a43e12930743281cd8cca6a66",
            "title": "Hierarchical Deep Reinforcement Learning: Integrating Temporal Abstraction and Intrinsic Motivation",
            "url": "https://www.semanticscholar.org/paper/d37620e6f8fe678a43e12930743281cd8cca6a66",
            "venue": "NIPS",
            "year": 2016
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "145824029",
                    "name": "David Silver"
                },
                {
                    "authorId": "1885349",
                    "name": "Aja Huang"
                },
                {
                    "authorId": "2772217",
                    "name": "Chris J. Maddison"
                },
                {
                    "authorId": "35099444",
                    "name": "A. Guez"
                },
                {
                    "authorId": "2175946",
                    "name": "L. Sifre"
                },
                {
                    "authorId": "47568983",
                    "name": "George van den Driessche"
                },
                {
                    "authorId": "4337102",
                    "name": "Julian Schrittwieser"
                },
                {
                    "authorId": "2460849",
                    "name": "Ioannis Antonoglou"
                },
                {
                    "authorId": "2749418",
                    "name": "Vedavyas Panneershelvam"
                },
                {
                    "authorId": "1975889",
                    "name": "Marc Lanctot"
                },
                {
                    "authorId": "48373216",
                    "name": "S. Dieleman"
                },
                {
                    "authorId": "2401609",
                    "name": "Dominik Grewe"
                },
                {
                    "authorId": "4111313",
                    "name": "John Nham"
                },
                {
                    "authorId": "2583391",
                    "name": "Nal Kalchbrenner"
                },
                {
                    "authorId": "1701686",
                    "name": "I. Sutskever"
                },
                {
                    "authorId": "2542999",
                    "name": "T. Lillicrap"
                },
                {
                    "authorId": "40662181",
                    "name": "M. Leach"
                },
                {
                    "authorId": "2645384",
                    "name": "K. Kavukcuoglu"
                },
                {
                    "authorId": "1686971",
                    "name": "T. Graepel"
                },
                {
                    "authorId": "48987704",
                    "name": "D. Hassabis"
                }
            ],
            "doi": "10.1038/nature16961",
            "intent": [],
            "isInfluential": false,
            "paperId": "846aedd869a00c09b40f1f1f35673cb22bc87490",
            "title": "Mastering the game of Go with deep neural networks and tree search",
            "url": "https://www.semanticscholar.org/paper/846aedd869a00c09b40f1f1f35673cb22bc87490",
            "venue": "Nature",
            "year": 2016
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "1875304",
                    "name": "Erkin \u00c7ilden"
                },
                {
                    "authorId": "1761620",
                    "name": "Faruk Polat"
                }
            ],
            "doi": "10.1109/TCYB.2014.2352038",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "7922d51bc971f58ec59d3fe5842f8cc5edbab41d",
            "title": "Toward Generalization of Automated Temporal Abstraction to Partially Observable Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/7922d51bc971f58ec59d3fe5842f8cc5edbab41d",
            "venue": "IEEE Transactions on Cybernetics",
            "year": 2015
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2741488",
                    "name": "Kyriakos Efthymiadis"
                },
                {
                    "authorId": "1693696",
                    "name": "Sam Devlin"
                },
                {
                    "authorId": "2380005",
                    "name": "D. Kudenko"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "a0d63c1882e0b32c082d624f096f42942a9c1437",
            "title": "Knowledge revision for reinforcement learning with abstract MDPs",
            "url": "https://www.semanticscholar.org/paper/a0d63c1882e0b32c082d624f096f42942a9c1437",
            "venue": "AAMAS",
            "year": 2015
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2741488",
                    "name": "Kyriakos Efthymiadis"
                },
                {
                    "authorId": "2380005",
                    "name": "D. Kudenko"
                }
            ],
            "doi": "10.1080/09540091.2014.885283",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "157a843bf4e4d4904283f5350788584d9728dedb",
            "title": "A comparison of plan-based and abstract MDP reward shaping",
            "url": "https://www.semanticscholar.org/paper/157a843bf4e4d4904283f5350788584d9728dedb",
            "venue": "Connect. Sci.",
            "year": 2014
        },
        {
            "arxivId": "1312.5602",
            "authors": [
                {
                    "authorId": "3255983",
                    "name": "Volodymyr Mnih"
                },
                {
                    "authorId": "2645384",
                    "name": "K. Kavukcuoglu"
                },
                {
                    "authorId": "145824029",
                    "name": "David Silver"
                },
                {
                    "authorId": "1753223",
                    "name": "Alex Graves"
                },
                {
                    "authorId": "2460849",
                    "name": "Ioannis Antonoglou"
                },
                {
                    "authorId": "1688276",
                    "name": "Daan Wierstra"
                },
                {
                    "authorId": "3137672",
                    "name": "Martin A. Riedmiller"
                }
            ],
            "doi": null,
            "intent": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "paperId": "2319a491378867c7049b3da055c5df60e1671158",
            "title": "Playing Atari with Deep Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/2319a491378867c7049b3da055c5df60e1671158",
            "venue": "ArXiv",
            "year": 2013
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2767429",
                    "name": "Nasrin Taghizadeh"
                },
                {
                    "authorId": "1761129",
                    "name": "H. Beigy"
                }
            ],
            "doi": "10.1016/j.robot.2013.04.010",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "a9f5bf98b87b8b4fd1d3fbc804018472797d6429",
            "title": "A novel graphical approach to automatic abstraction in reinforcement learning",
            "url": "https://www.semanticscholar.org/paper/a9f5bf98b87b8b4fd1d3fbc804018472797d6429",
            "venue": "Robotics Auton. Syst.",
            "year": 2013
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2065407888",
                    "name": "M. Ghafoorian"
                },
                {
                    "authorId": "2767429",
                    "name": "Nasrin Taghizadeh"
                },
                {
                    "authorId": "1761129",
                    "name": "H. Beigy"
                }
            ],
            "doi": null,
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "ad15cde9bc9c8b93c282c0be35dc72d33ffff8b2",
            "title": "Automatic Abstraction in Reinforcement Learning Using Ant System Algorithm",
            "url": "https://www.semanticscholar.org/paper/ad15cde9bc9c8b93c282c0be35dc72d33ffff8b2",
            "venue": "AAAI Spring Symposium: Lifelong Machine Learning",
            "year": 2013
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2285747715",
                    "name": "Maryam Marashi"
                },
                {
                    "authorId": "2285754713",
                    "name": "Alireza Khalilian"
                },
                {
                    "authorId": "2963682",
                    "name": "M. Shiri"
                }
            ],
            "doi": "10.1109/ICCKE.2012.6395362",
            "intent": [],
            "isInfluential": false,
            "paperId": "7a9759fdf89d2e81ab4aa193f2f86589a9ddbca8",
            "title": "Automatic reward shaping in Reinforcement Learning using graph analysis",
            "url": "https://www.semanticscholar.org/paper/7a9759fdf89d2e81ab4aa193f2f86589a9ddbca8",
            "venue": "2012 2nd International eConference on Computer and Knowledge Engineering (ICCKE)",
            "year": 2012
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "35022714",
                    "name": "Sertan Girgin"
                },
                {
                    "authorId": "1761620",
                    "name": "Faruk Polat"
                },
                {
                    "authorId": "144451975",
                    "name": "R. Alhajj"
                }
            ],
            "doi": "10.1007/s10994-010-5182-y",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "0ae2c69573673c16e96ab48aa9fc8b6ed807b451",
            "title": "Improving reinforcement learning by using sequence trees",
            "url": "https://www.semanticscholar.org/paper/0ae2c69573673c16e96ab48aa9fc8b6ed807b451",
            "venue": "Machine Learning",
            "year": 2010
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2079567",
                    "name": "G. Kheradmandian"
                },
                {
                    "authorId": "143707367",
                    "name": "M. Rahmati"
                }
            ],
            "doi": "10.1016/j.robot.2009.07.002",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "ea8a477d18a403691d02d4a0d8ed650db8f80acd",
            "title": "Automatic abstraction in reinforcement learning using data mining techniques",
            "url": "https://www.semanticscholar.org/paper/ea8a477d18a403691d02d4a0d8ed650db8f80acd",
            "venue": "Robotics Auton. Syst.",
            "year": 2009
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2186376",
                    "name": "M. Grzes"
                },
                {
                    "authorId": "2380005",
                    "name": "D. Kudenko"
                }
            ],
            "doi": "10.1109/IS.2008.4670492",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "923b4a6c8fa30391ad5a17f2c0271c4daa6487b6",
            "title": "Plan-based reward shaping for reinforcement learning",
            "url": "https://www.semanticscholar.org/paper/923b4a6c8fa30391ad5a17f2c0271c4daa6487b6",
            "venue": "2008 4th International IEEE Conference Intelligent Systems",
            "year": 2008
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2186376",
                    "name": "M. Grzes"
                },
                {
                    "authorId": "2380005",
                    "name": "D. Kudenko"
                }
            ],
            "doi": "10.1007/978-3-540-87536-9_37",
            "intent": [],
            "isInfluential": false,
            "paperId": "49ccdd43908144ebc7b8153ba8b221674674944e",
            "title": "Multigrid Reinforcement Learning with Reward Shaping",
            "url": "https://www.semanticscholar.org/paper/49ccdd43908144ebc7b8153ba8b221674674944e",
            "venue": "ICANN",
            "year": 2008
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "1711416",
                    "name": "B. Marthi"
                }
            ],
            "doi": "10.1145/1273496.1273572",
            "intent": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "paperId": "595db90b327390b9499ad28abcd1863fb8d97ced",
            "title": "Automatic shaping and decomposition of reward functions",
            "url": "https://www.semanticscholar.org/paper/595db90b327390b9499ad28abcd1863fb8d97ced",
            "venue": "ICML '07",
            "year": 2007
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "1712535",
                    "name": "Shie Mannor"
                },
                {
                    "authorId": "1684547",
                    "name": "Ishai Menache"
                },
                {
                    "authorId": "2730263",
                    "name": "Amit Hoze"
                },
                {
                    "authorId": "2052826346",
                    "name": "Uri Klein"
                }
            ],
            "doi": "10.1145/1015330.1015355",
            "intent": [],
            "isInfluential": false,
            "paperId": "42af0ed020c2caecafb7dbe826064d7f9ba2022b",
            "title": "Dynamic abstraction in reinforcement learning via clustering",
            "url": "https://www.semanticscholar.org/paper/42af0ed020c2caecafb7dbe826064d7f9ba2022b",
            "venue": "ICML",
            "year": 2004
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "1699645",
                    "name": "R. Sutton"
                },
                {
                    "authorId": "144368601",
                    "name": "Doina Precup"
                },
                {
                    "authorId": "1699868",
                    "name": "Satinder Singh"
                }
            ],
            "doi": "10.1016/S0004-3702(99)00052-1",
            "intent": [],
            "isInfluential": false,
            "paperId": "0e7638dc16a5e5e9e46c91272bfb9c3dd242ef6d",
            "title": "Between MDPs and Semi-MDPs: A Framework for Temporal Abstraction in Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/0e7638dc16a5e5e9e46c91272bfb9c3dd242ef6d",
            "venue": "Artif. Intell.",
            "year": 1999
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "34699434",
                    "name": "A. Ng"
                },
                {
                    "authorId": "1868677",
                    "name": "Daishi Harada"
                },
                {
                    "authorId": "145107462",
                    "name": "Stuart J. Russell"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "94066dc12fe31e96af7557838159bde598cb4f10",
            "title": "Policy Invariance Under Reward Transformations: Theory and Application to Reward Shaping",
            "url": "https://www.semanticscholar.org/paper/94066dc12fe31e96af7557838159bde598cb4f10",
            "venue": "ICML",
            "year": 1999
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "30710621",
                    "name": "J. Randl\u00f8v"
                },
                {
                    "authorId": "1816463",
                    "name": "P. Alstr\u00f8m"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "9d8f6219fbd2da14d8d55562dcedf43fe671d0e3",
            "title": "Learning to Drive a Bicycle Using Reinforcement Learning and Shaping",
            "url": "https://www.semanticscholar.org/paper/9d8f6219fbd2da14d8d55562dcedf43fe671d0e3",
            "venue": "ICML",
            "year": 1998
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "21285272",
                    "name": "S. Carden"
                }
            ],
            "doi": null,
            "intent": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "paperId": "d193b76178412e99e310e90668a498fa8fe11a5c",
            "title": "An Introduction to Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/d193b76178412e99e310e90668a498fa8fe11a5c",
            "venue": "",
            "year": 2013
        }
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Mathematics",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "title": "Uniform State Abstraction For Reinforcement Learning",
    "topics": [
        {
            "topic": "Reinforcement learning",
            "topicId": "2557",
            "url": "https://www.semanticscholar.org/topic/2557"
        },
        {
            "topic": "Deep learning",
            "topicId": "2762",
            "url": "https://www.semanticscholar.org/topic/2762"
        },
        {
            "topic": "Media resource locator",
            "topicId": "3717699",
            "url": "https://www.semanticscholar.org/topic/3717699"
        },
        {
            "topic": "Norm (social)",
            "topicId": "76329",
            "url": "https://www.semanticscholar.org/topic/76329"
        },
        {
            "topic": "Algorithm",
            "topicId": "305",
            "url": "https://www.semanticscholar.org/topic/305"
        },
        {
            "topic": "Noise shaping",
            "topicId": "135480",
            "url": "https://www.semanticscholar.org/topic/135480"
        },
        {
            "topic": "Multigrid method",
            "topicId": "58484",
            "url": "https://www.semanticscholar.org/topic/58484"
        }
    ],
    "url": "https://www.semanticscholar.org/paper/9e598383afdb7eea847a422ec6a1fbc36ed42aa0",
    "venue": "European Conference on Artificial Intelligence",
    "year": 2020
}
{
    "abstract": "We propose a novel approach to significantly improve the intelligibility in the Non-Audible Murmur (NAM)-to-speech conversion task, leveraging self-supervision and sequence-to-sequence (Seq2Seq) learning techniques. Unlike conventional methods that explicitly record ground-truth speech, our methodology relies on self-supervision and speech-to-speech synthesis to simulate ground-truth speech. Despite utilizing simulated speech, our method surpasses the current state-of-the-art (SOTA) by 29.08% improvement in the Mel-Cepstral Distortion (MCD) metric. Additionally, we present error rates and demonstrate our model's proficiency to synthesize speech in novel voices of interest. Moreover, we present a methodology for augmenting the existing CSTR NAM TIMIT Plus corpus, setting a benchmark with a Word Error Rate (WER) of 42.57% to gauge the intelligibility of the synthesized speech. Speech samples can be found at https://nam2speech.github.io/NAM2Speech/",
    "arxivId": "2407.18541",
    "authors": [
        {
            "authorId": "2269435322",
            "name": "N. Shah",
            "url": "https://www.semanticscholar.org/author/2269435322"
        },
        {
            "authorId": "40151143",
            "name": "S. Karande",
            "url": "https://www.semanticscholar.org/author/40151143"
        },
        {
            "authorId": "2269149088",
            "name": "Vineet Gandhi",
            "url": "https://www.semanticscholar.org/author/2269149088"
        }
    ],
    "citationVelocity": 0,
    "citations": [],
    "corpusId": 271516639,
    "doi": "10.48550/arXiv.2407.18541",
    "fieldsOfStudy": [
        "Computer Science",
        "Engineering"
    ],
    "influentialCitationCount": 0,
    "isOpenAccess": false,
    "isPublisherLicensed": true,
    "is_open_access": false,
    "is_publisher_licensed": true,
    "numCitedBy": 0,
    "numCiting": 35,
    "paperId": "1259d060cdc1b1531685fb4cec5c809370401653",
    "references": [
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2229490672",
                    "name": "Yuto Otani"
                },
                {
                    "authorId": "2059595087",
                    "name": "Shun Sawada"
                },
                {
                    "authorId": "20966634",
                    "name": "Hidefumi Ohmura"
                },
                {
                    "authorId": "50368245",
                    "name": "Kouichi Katsurada"
                }
            ],
            "doi": "10.21437/interspeech.2023-286",
            "intent": [
                "background",
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "977f2f760d0eb99d73182fd8334c1986989c5b07",
            "title": "Speech Synthesis from Articulatory Movements Recorded by Real-time MRI",
            "url": "https://www.semanticscholar.org/paper/977f2f760d0eb99d73182fd8334c1986989c5b07",
            "venue": "INTERSPEECH",
            "year": 2023
        },
        {
            "arxivId": "2308.06112",
            "authors": [
                {
                    "authorId": "1582477446",
                    "name": "Y. A. D. Djilali"
                },
                {
                    "authorId": "3347447",
                    "name": "Sanath Narayan"
                },
                {
                    "authorId": "4616261",
                    "name": "Haithem Boussaid"
                },
                {
                    "authorId": "1967677",
                    "name": "Ebtesam Almazrouei"
                },
                {
                    "authorId": "2065834880",
                    "name": "M. Debbah"
                }
            ],
            "doi": "10.1109/ICCV51070.2023.01268",
            "intent": [
                "background",
                "result"
            ],
            "isInfluential": false,
            "paperId": "19ea2ec1582fdf34e68d9307292e1108293f81be",
            "title": "Lip2Vec: Efficient and Robust Visual Speech Recognition via Latent-to-Latent Visual to Audio Representation Mapping",
            "url": "https://www.semanticscholar.org/paper/19ea2ec1582fdf34e68d9307292e1108293f81be",
            "venue": "2023 IEEE/CVF International Conference on Computer Vision (ICCV)",
            "year": 2023
        },
        {
            "arxivId": "2307.01233",
            "authors": [
                {
                    "authorId": "2221129770",
                    "name": "Neha Sahipjohn"
                },
                {
                    "authorId": "2048008219",
                    "name": "Neil Shah"
                },
                {
                    "authorId": "2210292967",
                    "name": "Vishal Tambrahalli"
                },
                {
                    "authorId": "145091336",
                    "name": "Vineet Gandhi"
                }
            ],
            "doi": "10.1109/APSIPAASC58517.2023.10317357",
            "intent": [
                "background",
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "dcc24fa24f9379fbc716622d3c27c4bbc7c9c5ab",
            "title": "RobustL2S: Speaker-Specific Lip-to-Speech Synthesis exploiting Self-Supervised Representations",
            "url": "https://www.semanticscholar.org/paper/dcc24fa24f9379fbc716622d3c27c4bbc7c9c5ab",
            "venue": "2023 Asia Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)",
            "year": 2023
        },
        {
            "arxivId": "2303.01639",
            "authors": [
                {
                    "authorId": "1685962",
                    "name": "J. Rekimoto"
                }
            ],
            "doi": "10.1145/3544548.3580706",
            "intent": [
                "result",
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "85ae43df8abb2bafd558c2a51c4697c3be0114eb",
            "title": "WESPER: Zero-shot and Realtime Whisper to Normal Voice Conversion for Whisper-based Speech Interactions",
            "url": "https://www.semanticscholar.org/paper/85ae43df8abb2bafd558c2a51c4697c3be0114eb",
            "venue": "CHI",
            "year": 2023
        },
        {
            "arxivId": "2212.04356",
            "authors": [
                {
                    "authorId": "38909097",
                    "name": "Alec Radford"
                },
                {
                    "authorId": "2110935237",
                    "name": "Jong Wook Kim"
                },
                {
                    "authorId": "2118717067",
                    "name": "Tao Xu"
                },
                {
                    "authorId": "2065151121",
                    "name": "Greg Brockman"
                },
                {
                    "authorId": "3028785",
                    "name": "C. McLeavey"
                },
                {
                    "authorId": "1701686",
                    "name": "I. Sutskever"
                }
            ],
            "doi": "10.48550/arXiv.2212.04356",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "a02fbaf22237a1aedacb1320b6007cd70c1fe6ec",
            "title": "Robust Speech Recognition via Large-Scale Weak Supervision",
            "url": "https://www.semanticscholar.org/paper/a02fbaf22237a1aedacb1320b6007cd70c1fe6ec",
            "venue": "ICML",
            "year": 2022
        },
        {
            "arxivId": "2106.07447",
            "authors": [
                {
                    "authorId": "2957796",
                    "name": "Wei-Ning Hsu"
                },
                {
                    "authorId": "2306979",
                    "name": "Benjamin Bolte"
                },
                {
                    "authorId": "145639633",
                    "name": "Yao-Hung Hubert Tsai"
                },
                {
                    "authorId": "1410624139",
                    "name": "Kushal Lakhotia"
                },
                {
                    "authorId": "145124475",
                    "name": "R. Salakhutdinov"
                },
                {
                    "authorId": "113947684",
                    "name": "Abdel-rahman Mohamed"
                }
            ],
            "doi": "10.1109/taslp.2021.3122291",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "4fffa5245d3972077c83614c2a08a47cb578631e",
            "title": "HuBERT: Self-Supervised Speech Representation Learning by Masked Prediction of Hidden Units",
            "url": "https://www.semanticscholar.org/paper/4fffa5245d3972077c83614c2a08a47cb578631e",
            "venue": "IEEE/ACM Transactions on Audio, Speech, and Language Processing",
            "year": 2021
        },
        {
            "arxivId": "2104.00355",
            "authors": [
                {
                    "authorId": "33964593",
                    "name": "Adam Polyak"
                },
                {
                    "authorId": "2727584",
                    "name": "Yossi Adi"
                },
                {
                    "authorId": "1805998294",
                    "name": "Jade Copet"
                },
                {
                    "authorId": "144875326",
                    "name": "E. Kharitonov"
                },
                {
                    "authorId": "1410624139",
                    "name": "Kushal Lakhotia"
                },
                {
                    "authorId": "2957796",
                    "name": "Wei-Ning Hsu"
                },
                {
                    "authorId": "40360972",
                    "name": "Abdel-rahman Mohamed"
                },
                {
                    "authorId": "2202008",
                    "name": "Emmanuel Dupoux"
                }
            ],
            "doi": "10.21437/interspeech.2021-475",
            "intent": [
                "result",
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "51a79a45e2577bffca0a50992a852c73d7a13ffa",
            "title": "Speech Resynthesis from Discrete Disentangled Self-Supervised Representations",
            "url": "https://www.semanticscholar.org/paper/51a79a45e2577bffca0a50992a852c73d7a13ffa",
            "venue": "Interspeech",
            "year": 2021
        },
        {
            "arxivId": "2010.05646",
            "authors": [
                {
                    "authorId": "1712238254",
                    "name": "Jungil Kong"
                },
                {
                    "authorId": "94862572",
                    "name": "Jaehyeon Kim"
                },
                {
                    "authorId": "1703883959",
                    "name": "Jaekyoung Bae"
                }
            ],
            "doi": null,
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "4e468d3da1797d791db8d514d695b183acb027ee",
            "title": "HiFi-GAN: Generative Adversarial Networks for Efficient and High Fidelity Speech Synthesis",
            "url": "https://www.semanticscholar.org/paper/4e468d3da1797d791db8d514d695b183acb027ee",
            "venue": "NeurIPS",
            "year": 2020
        },
        {
            "arxivId": "2006.11477",
            "authors": [
                {
                    "authorId": "51428394",
                    "name": "Alexei Baevski"
                },
                {
                    "authorId": "2110147709",
                    "name": "Henry Zhou"
                },
                {
                    "authorId": "40360972",
                    "name": "Abdel-rahman Mohamed"
                },
                {
                    "authorId": "2325985",
                    "name": "Michael Auli"
                }
            ],
            "doi": null,
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "49a049dc85e2380dde80501a984878341dd8efdf",
            "title": "wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations",
            "url": "https://www.semanticscholar.org/paper/49a049dc85e2380dde80501a984878341dd8efdf",
            "venue": "NeurIPS",
            "year": 2020
        },
        {
            "arxivId": "2006.04558",
            "authors": [
                {
                    "authorId": "1500435161",
                    "name": "Yi Ren"
                },
                {
                    "authorId": "2118956725",
                    "name": "Chenxu Hu"
                },
                {
                    "authorId": "48391466",
                    "name": "Xu Tan"
                },
                {
                    "authorId": "143826491",
                    "name": "Tao Qin"
                },
                {
                    "authorId": "47601191",
                    "name": "Sheng Zhao"
                },
                {
                    "authorId": "47122432",
                    "name": "Zhou Zhao"
                },
                {
                    "authorId": "2110264337",
                    "name": "Tie-Yan Liu"
                }
            ],
            "doi": null,
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "1623d6ffb6efd94d21537db2b96b91a196842aef",
            "title": "FastSpeech 2: Fast and High-Quality End-to-End Text to Speech",
            "url": "https://www.semanticscholar.org/paper/1623d6ffb6efd94d21537db2b96b91a196842aef",
            "venue": "ICLR",
            "year": 2020
        },
        {
            "arxivId": "2005.08209",
            "authors": [
                {
                    "authorId": "1380234931",
                    "name": "Prajwal K R"
                },
                {
                    "authorId": "41052499",
                    "name": "Rudrabha Mukhopadhyay"
                },
                {
                    "authorId": "145460361",
                    "name": "Vinay P. Namboodiri"
                },
                {
                    "authorId": "1694502",
                    "name": "C. V. Jawahar"
                }
            ],
            "doi": "10.1109/cvpr42600.2020.01381",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "ba684a9966995e5a8c6efef46aeb57bd387ff51f",
            "title": "Learning Individual Speaking Styles for Accurate Lip to Speech Synthesis",
            "url": "https://www.semanticscholar.org/paper/ba684a9966995e5a8c6efef46aeb57bd387ff51f",
            "venue": "2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)",
            "year": 2020
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "1659379256",
                    "name": "Harshit Malaviya"
                },
                {
                    "authorId": "82951319",
                    "name": "Jui Shah"
                },
                {
                    "authorId": "81331041",
                    "name": "Maitreya Patel"
                },
                {
                    "authorId": "1659387925",
                    "name": "Jalansh Munshi"
                },
                {
                    "authorId": "1705449",
                    "name": "H. Patil"
                }
            ],
            "doi": "10.1109/ICASSP40776.2020.9052966",
            "intent": [
                "background",
                "methodology"
            ],
            "isInfluential": true,
            "paperId": "2ac0ccf5e294dd86ed0907ee7a1277221b7c0eef",
            "title": "Mspec-Net : Multi-Domain Speech Conversion Network",
            "url": "https://www.semanticscholar.org/paper/2ac0ccf5e294dd86ed0907ee7a1277221b7c0eef",
            "venue": "ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)",
            "year": 2020
        },
        {
            "arxivId": "1904.02882",
            "authors": [
                {
                    "authorId": "1691713",
                    "name": "H. Zen"
                },
                {
                    "authorId": "1656710403",
                    "name": "Viet Dang"
                },
                {
                    "authorId": "144318214",
                    "name": "R. Clark"
                },
                {
                    "authorId": "2153632494",
                    "name": "Yu Zhang"
                },
                {
                    "authorId": "39571582",
                    "name": "Ron J. Weiss"
                },
                {
                    "authorId": "1691944",
                    "name": "Ye Jia"
                },
                {
                    "authorId": "2545358",
                    "name": "Z. Chen"
                },
                {
                    "authorId": "48607963",
                    "name": "Yonghui Wu"
                }
            ],
            "doi": "10.21437/interspeech.2019-2441",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "2789b6c84ba1422746246685001accba5563e7c1",
            "title": "LibriTTS: A Corpus Derived from LibriSpeech for Text-to-Speech",
            "url": "https://www.semanticscholar.org/paper/2789b6c84ba1422746246685001accba5563e7c1",
            "venue": "INTERSPEECH",
            "year": 2019
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2048008219",
                    "name": "Neil Shah"
                },
                {
                    "authorId": "3169034",
                    "name": "Nirmesh J. Shah"
                },
                {
                    "authorId": "1705449",
                    "name": "H. Patil"
                }
            ],
            "doi": "10.21437/Interspeech.2018-1565",
            "intent": [
                "background",
                "methodology"
            ],
            "isInfluential": true,
            "paperId": "bdfe1762702114ac31c86192247236696cc64a3c",
            "title": "Effectiveness of Generative Adversarial Network for Non-Audible Murmur-to-Whisper Speech Conversion",
            "url": "https://www.semanticscholar.org/paper/bdfe1762702114ac31c86192247236696cc64a3c",
            "venue": "INTERSPEECH",
            "year": 2018
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "145307542",
                    "name": "L. T\u00f3th"
                },
                {
                    "authorId": "70611138",
                    "name": "G. Gosztolya"
                },
                {
                    "authorId": "31357535",
                    "name": "Tam\u00e1s Gr\u00f3sz"
                },
                {
                    "authorId": "49403217",
                    "name": "Alexandra Mark\u00f3"
                },
                {
                    "authorId": "2649433",
                    "name": "T. Csap\u00f3"
                }
            ],
            "doi": "10.21437/Interspeech.2018-1078",
            "intent": [
                "background",
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "42a8ecf3370a3a3d25c32e5c1047c337b7970a14",
            "title": "Multi-Task Learning of Speech Recognition and Speech Synthesis Parameters for Ultrasound-based Silent Speech Interfaces",
            "url": "https://www.semanticscholar.org/paper/42a8ecf3370a3a3d25c32e5c1047c337b7970a14",
            "venue": "INTERSPEECH",
            "year": 2018
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "32307156",
                    "name": "Arnav Kapur"
                },
                {
                    "authorId": "40609354",
                    "name": "Shreyas Kapur"
                },
                {
                    "authorId": "1701876",
                    "name": "P. Maes"
                }
            ],
            "doi": "10.1145/3172944.3172977",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "9e2af148acbf7d4623ca8a946be089a774ce5258",
            "title": "AlterEgo: A Personalized Wearable Silent Speech Interface",
            "url": "https://www.semanticscholar.org/paper/9e2af148acbf7d4623ca8a946be089a774ce5258",
            "venue": "IUI",
            "year": 2018
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "78010581",
                    "name": "Jos\u00e9 A. Gonz\u00e1lez"
                },
                {
                    "authorId": "3448329",
                    "name": "L. A. Cheah"
                },
                {
                    "authorId": "144269522",
                    "name": "A. G\u00f3mez"
                },
                {
                    "authorId": "144220752",
                    "name": "P. Green"
                },
                {
                    "authorId": "145056544",
                    "name": "J. M. Gilbert"
                },
                {
                    "authorId": "34988792",
                    "name": "S. Ell"
                },
                {
                    "authorId": "145914568",
                    "name": "Roger K. Moore"
                },
                {
                    "authorId": "33134678",
                    "name": "E. Holdsworth"
                }
            ],
            "doi": "10.1109/TASLP.2017.2757263",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "0ac510ba6e635ad438ee67769329f2f6bd2d3c2f",
            "title": "Direct Speech Reconstruction From Articulatory Sensor Data by Machine Learning",
            "url": "https://www.semanticscholar.org/paper/0ac510ba6e635ad438ee67769329f2f6bd2d3c2f",
            "venue": "IEEE/ACM Transactions on Audio, Speech, and Language Processing",
            "year": 2017
        },
        {
            "arxivId": "1706.03762",
            "authors": [
                {
                    "authorId": "40348417",
                    "name": "Ashish Vaswani"
                },
                {
                    "authorId": "1846258",
                    "name": "Noam M. Shazeer"
                },
                {
                    "authorId": "3877127",
                    "name": "Niki Parmar"
                },
                {
                    "authorId": "39328010",
                    "name": "Jakob Uszkoreit"
                },
                {
                    "authorId": "145024664",
                    "name": "Llion Jones"
                },
                {
                    "authorId": "19177000",
                    "name": "Aidan N. Gomez"
                },
                {
                    "authorId": "40527594",
                    "name": "Lukasz Kaiser"
                },
                {
                    "authorId": "3443442",
                    "name": "Illia Polosukhin"
                }
            ],
            "doi": null,
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776",
            "title": "Attention is All you Need",
            "url": "https://www.semanticscholar.org/paper/204e3073870fae3d05bcbc2f6a8e263d9b72e776",
            "venue": "NIPS",
            "year": 2017
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "152147546",
                    "name": "Chen-Yu Yang"
                },
                {
                    "authorId": "40650589",
                    "name": "Georgina Brown"
                },
                {
                    "authorId": "145705748",
                    "name": "Liang Lu"
                },
                {
                    "authorId": "1716857",
                    "name": "J. Yamagishi"
                },
                {
                    "authorId": "144783569",
                    "name": "Simon King"
                }
            ],
            "doi": "10.1109/ISCSLP.2012.6423522",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "d0650f02d7421129d59ee955cd1457324037befa",
            "title": "Noise-robust whispered speech recognition using a non-audible-murmur microphone with VTS compensation",
            "url": "https://www.semanticscholar.org/paper/d0650f02d7421129d59ee955cd1457324037befa",
            "venue": "2012 8th International Symposium on Chinese Spoken Language Processing",
            "year": 2012
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "13030353",
                    "name": "Juerg Kolbrunner"
                },
                {
                    "authorId": "48187007",
                    "name": "A. Menet"
                },
                {
                    "authorId": "39737631",
                    "name": "E. Seifert"
                }
            ],
            "doi": "10.7892/BORIS.1509",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "3c606cce74594140e077382aa1910e016691bbdb",
            "title": "Psychogenic aphonia: no fixation even after a lengthy period of aphonia.",
            "url": "https://www.semanticscholar.org/paper/3c606cce74594140e077382aa1910e016691bbdb",
            "venue": "Swiss medical weekly",
            "year": 2010
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "1726559",
                    "name": "T. Toda"
                },
                {
                    "authorId": "2110884008",
                    "name": "Keigo Nakamura"
                },
                {
                    "authorId": "2751553",
                    "name": "Hidehiko Sekimoto"
                },
                {
                    "authorId": "9243990",
                    "name": "K. Shikano"
                }
            ],
            "doi": "10.1109/ICASSP.2009.4960405",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "685a8c37c33712610221e959294b883571073604",
            "title": "Voice conversion for various types of body transmitted speech",
            "url": "https://www.semanticscholar.org/paper/685a8c37c33712610221e959294b883571073604",
            "venue": "2009 IEEE International Conference on Acoustics, Speech and Signal Processing",
            "year": 2009
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "49407003",
                    "name": "Shota Shimizu"
                },
                {
                    "authorId": "144795344",
                    "name": "M. Otani"
                },
                {
                    "authorId": "20922453",
                    "name": "T. Hirahara"
                }
            ],
            "doi": "10.1250/AST.30.139",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "67b947123f093dd69fc81c6e9ca6eeb13de18def",
            "title": "Frequency characteristics of several non-audible murmur (NAM) microphones",
            "url": "https://www.semanticscholar.org/paper/67b947123f093dd69fc81c6e9ca6eeb13de18def",
            "venue": "",
            "year": 2009
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2917627",
                    "name": "Y. Nakajima"
                },
                {
                    "authorId": "9243990",
                    "name": "K. Shikano"
                }
            ],
            "doi": "10.1121/1.4781262",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "5d950e78ae03151420c13de8cadd00bb4ae942de",
            "title": "Methods of fitting a nonaudible murmur microphone for daily use and development of urethane elastmer duplex structure type nonaudible murmur microphone",
            "url": "https://www.semanticscholar.org/paper/5d950e78ae03151420c13de8cadd00bb4ae942de",
            "venue": "",
            "year": 2006
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "1726559",
                    "name": "T. Toda"
                },
                {
                    "authorId": "9243990",
                    "name": "K. Shikano"
                }
            ],
            "doi": "10.21437/Interspeech.2005-611",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "bdc3e7180c58aaef16d0f6fef1f3285654da84de",
            "title": "NAM-to-speech conversion with Gaussian mixture models",
            "url": "https://www.semanticscholar.org/paper/bdc3e7180c58aaef16d0f6fef1f3285654da84de",
            "venue": "INTERSPEECH",
            "year": 2005
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "49189818",
                    "name": "Y. Kikuchi"
                },
                {
                    "authorId": "34584174",
                    "name": "H. Kasuya"
                }
            ],
            "doi": "10.21437/speechprosody.2004-176",
            "intent": [
                "background",
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "8853a4cb20d37bb2fc7b10ea730f9cd8b722538b",
            "title": "Development and evaluation of pitch adjustable electrolarynx",
            "url": "https://www.semanticscholar.org/paper/8853a4cb20d37bb2fc7b10ea730f9cd8b722538b",
            "venue": "Speech Prosody 2004",
            "year": 2004
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2917627",
                    "name": "Y. Nakajima"
                },
                {
                    "authorId": "1799065",
                    "name": "H. Kashioka"
                },
                {
                    "authorId": "9243990",
                    "name": "K. Shikano"
                },
                {
                    "authorId": "143731137",
                    "name": "N. Campbell"
                }
            ],
            "doi": "10.1109/ICASSP.2003.1200069",
            "intent": [
                "background",
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "58be8c94e62f4d38b9e199f27170e663061acd7e",
            "title": "Non-audible murmur recognition input interface using stethoscopic microphone attached to the skin",
            "url": "https://www.semanticscholar.org/paper/58be8c94e62f4d38b9e199f27170e663061acd7e",
            "venue": "2003 IEEE International Conference on Acoustics, Speech, and Signal Processing, 2003. Proceedings. (ICASSP '03).",
            "year": 2003
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "144857312",
                    "name": "Caetano Veloso"
                },
                {
                    "authorId": "39913210",
                    "name": "Andrew F. Jones"
                },
                {
                    "authorId": "1420290746",
                    "name": "E. Allina-Pisano"
                }
            ],
            "doi": "10.1215/10679847-11-1-v",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "e94c9575f9baa8a4c9c34eea48f76d92bd81ec60",
            "title": "An Indian",
            "url": "https://www.semanticscholar.org/paper/e94c9575f9baa8a4c9c34eea48f76d92bd81ec60",
            "venue": "",
            "year": 2003
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "92792852",
                    "name": "H. Horn"
                },
                {
                    "authorId": "2242954668",
                    "name": "Gernot G\u00f6z"
                },
                {
                    "authorId": "2251377454",
                    "name": "Margit Bacher"
                },
                {
                    "authorId": "6844504",
                    "name": "M. M\u00fcllauer"
                },
                {
                    "authorId": "82922568",
                    "name": "I. Kretschmer"
                },
                {
                    "authorId": "1414273133",
                    "name": "D. Axmann-Krcmar"
                }
            ],
            "doi": "10.1093/EJO/19.6.647",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "45455283f0f342c9c804b6f9a5100c2ddd69dad1",
            "title": "Reliability of electromagnetic articulography recording during speaking sequences.",
            "url": "https://www.semanticscholar.org/paper/45455283f0f342c9c804b6f9a5100c2ddd69dad1",
            "venue": "European journal of orthodontics",
            "year": 1997
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2134556434",
                    "name": "Saiteja Kosgi"
                },
                {
                    "authorId": "2269435322",
                    "name": "N. Shah"
                },
                {
                    "authorId": "2210292967",
                    "name": "Vishal Tambrahalli"
                },
                {
                    "authorId": "2275053192",
                    "name": "Neha Sherin"
                },
                {
                    "authorId": "2269149088",
                    "name": "Vineet Gandhi"
                }
            ],
            "doi": "10.48550/arXiv.2303.01261",
            "intent": [
                "result"
            ],
            "isInfluential": false,
            "paperId": "c2c832f9138aa46ac59d2a97e14a6a5489779bcf",
            "title": "ParrotTTS: Text-to-Speech synthesis by exploiting self-supervised representations",
            "url": "https://www.semanticscholar.org/paper/c2c832f9138aa46ac59d2a97e14a6a5489779bcf",
            "venue": "ArXiv",
            "year": 2023
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "8777676",
                    "name": "Simon Stone"
                },
                {
                    "authorId": "2263832",
                    "name": "P. Birkholz"
                }
            ],
            "doi": null,
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "b5672984aa81a78db5a5fa7f19fbd4e1f4bf527e",
            "title": "Silent-Speech Command Word Recognition Using Electro-Optical Stomatography",
            "url": "https://www.semanticscholar.org/paper/b5672984aa81a78db5a5fa7f19fbd4e1f4bf527e",
            "venue": "INTERSPEECH",
            "year": 2016
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "20922453",
                    "name": "T. Hirahara"
                },
                {
                    "authorId": "49407003",
                    "name": "Shota Shimizu"
                },
                {
                    "authorId": "144795344",
                    "name": "M. Otani"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "7b8f99288352bc0f812410c87ed0edd8b86ebc07",
            "title": "ACOUSTIC CHARACTERISTICS OF NON-AUDIBLE MURMUR",
            "url": "https://www.semanticscholar.org/paper/7b8f99288352bc0f812410c87ed0edd8b86ebc07",
            "venue": "",
            "year": 2007
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2461919",
                    "name": "S. Salvador"
                },
                {
                    "authorId": "144316325",
                    "name": "P. Chan"
                }
            ],
            "doi": null,
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "05a20cde15e172fc82f32774dd0cf4fe5827cad2",
            "title": "FastDTW: Toward Accurate Dynamic Time Warping in Linear Time and Space",
            "url": "https://www.semanticscholar.org/paper/05a20cde15e172fc82f32774dd0cf4fe5827cad2",
            "venue": "",
            "year": 2004
        }
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Engineering",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "title": "Towards Improving NAM-to-Speech Synthesis Intelligibility using Self-Supervised Speech Models",
    "topics": [],
    "url": "https://www.semanticscholar.org/paper/1259d060cdc1b1531685fb4cec5c809370401653",
    "venue": "Interspeech",
    "year": 2024
}
{
    "abstract": "Model-based Reinforcement Learning has shown considerable experimental success. However, a theoretical understanding of it is still lacking. To this end, we analyze the error in cumulative reward for both stochastic and deterministic transitions using a contraction approach. We show that this approach doesn't require strong assumptions and can recover the typical quadratic error to the horizon. We prove that branched rollouts can reduce this error and are essential for deterministic transitions to have a Bellman contraction. Our results also apply to Imitation Learning, where we prove that GAN-type learning is better than Behavioral Cloning in continuous state and action spaces.",
    "arxivId": "2009.08586",
    "authors": [
        {
            "authorId": "32037089",
            "name": "Ting-Han Fan",
            "url": "https://www.semanticscholar.org/author/32037089"
        },
        {
            "authorId": "1693135",
            "name": "P. Ramadge",
            "url": "https://www.semanticscholar.org/author/1693135"
        }
    ],
    "citationVelocity": 0,
    "citations": [
        {
            "arxivId": "2110.02421",
            "authors": [
                {
                    "authorId": "32037089",
                    "name": "Ting-Han Fan"
                },
                {
                    "authorId": "1693135",
                    "name": "P. Ramadge"
                }
            ],
            "doi": null,
            "intent": [
                "result"
            ],
            "isInfluential": false,
            "paperId": "ca45179dda56e9502d77e1d39d9c8b80ec1c277d",
            "title": "Explaining Off-Policy Actor-Critic From A Bias-Variance Perspective",
            "url": "https://www.semanticscholar.org/paper/ca45179dda56e9502d77e1d39d9c8b80ec1c277d",
            "venue": "ArXiv",
            "year": 2021
        }
    ],
    "corpusId": 221802544,
    "doi": null,
    "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
    ],
    "influentialCitationCount": 0,
    "isOpenAccess": false,
    "isPublisherLicensed": true,
    "is_open_access": false,
    "is_publisher_licensed": true,
    "numCitedBy": 1,
    "numCiting": 33,
    "paperId": "7be93daa9412136af577f0e55c7398aad524e27d",
    "references": [
        {
            "arxivId": "2005.13239",
            "authors": [
                {
                    "authorId": "10909315",
                    "name": "Tianhe Yu"
                },
                {
                    "authorId": "8234443",
                    "name": "G. Thomas"
                },
                {
                    "authorId": "3469209",
                    "name": "Lantao Yu"
                },
                {
                    "authorId": "2490652",
                    "name": "Stefano Ermon"
                },
                {
                    "authorId": "145085305",
                    "name": "James Y. Zou"
                },
                {
                    "authorId": "1736651",
                    "name": "S. Levine"
                },
                {
                    "authorId": "46881670",
                    "name": "Chelsea Finn"
                },
                {
                    "authorId": "1901958",
                    "name": "Tengyu Ma"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "dea0f1c5949f8d898b9b6ff68226a781558e413c",
            "title": "MOPO: Model-based Offline Policy Optimization",
            "url": "https://www.semanticscholar.org/paper/dea0f1c5949f8d898b9b6ff68226a781558e413c",
            "venue": "NeurIPS",
            "year": 2020
        },
        {
            "arxivId": "2002.09516",
            "authors": [
                {
                    "authorId": "2088205356",
                    "name": "Yaqi Duan"
                },
                {
                    "authorId": "145731462",
                    "name": "Mengdi Wang"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "8664713793dbb1f6f935c617dd34be93d5b096ed",
            "title": "Minimax-Optimal Off-Policy Evaluation with Linear Function Approximation",
            "url": "https://www.semanticscholar.org/paper/8664713793dbb1f6f935c617dd34be93d5b096ed",
            "venue": "ICML",
            "year": 2020
        },
        {
            "arxivId": "1912.11206",
            "authors": [
                {
                    "authorId": "3363788",
                    "name": "Chenjun Xiao"
                },
                {
                    "authorId": "2013680445",
                    "name": "Yifan Wu"
                },
                {
                    "authorId": "2112461997",
                    "name": "Chen Ma"
                },
                {
                    "authorId": "50319359",
                    "name": "D. Schuurmans"
                },
                {
                    "authorId": "2116237915",
                    "name": "Martin M\u00fcller"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "5d5e01193e36a77c836fe8ee3ebb13d57520d050",
            "title": "Learning to Combat Compounding-Error in Model-Based Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/5d5e01193e36a77c836fe8ee3ebb13d57520d050",
            "venue": "ArXiv",
            "year": 2019
        },
        {
            "arxivId": "1907.05388",
            "authors": [
                {
                    "authorId": "3335298",
                    "name": "Chi Jin"
                },
                {
                    "authorId": "150358650",
                    "name": "Zhuoran Yang"
                },
                {
                    "authorId": "50218397",
                    "name": "Zhaoran Wang"
                },
                {
                    "authorId": "123333909",
                    "name": "Michael I. Jordan"
                }
            ],
            "doi": "10.1287/moor.2022.1309",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "d423fa6cd0f4d088941d9fe4bebd834d0137c9b9",
            "title": "Provably Efficient Reinforcement Learning with Linear Function Approximation",
            "url": "https://www.semanticscholar.org/paper/d423fa6cd0f4d088941d9fe4bebd834d0137c9b9",
            "venue": "COLT",
            "year": 2019
        },
        {
            "arxivId": "1907.02057",
            "authors": [
                {
                    "authorId": "3428549",
                    "name": "Tingwu Wang"
                },
                {
                    "authorId": "8538131",
                    "name": "Xuchan Bao"
                },
                {
                    "authorId": "15593386",
                    "name": "I. Clavera"
                },
                {
                    "authorId": "150148498",
                    "name": "Jerrick Hoang"
                },
                {
                    "authorId": "38356166",
                    "name": "Yeming Wen"
                },
                {
                    "authorId": "144006195",
                    "name": "Eric D. Langlois"
                },
                {
                    "authorId": "6303990",
                    "name": "Matthew Shunshi Zhang"
                },
                {
                    "authorId": "46266081",
                    "name": "Guodong Zhang"
                },
                {
                    "authorId": "1689992",
                    "name": "P. Abbeel"
                },
                {
                    "authorId": "2503659",
                    "name": "Jimmy Ba"
                }
            ],
            "doi": null,
            "intent": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "paperId": "4ee70fb32981f84f9dddc57bd59a69e677c91759",
            "title": "Benchmarking Model-Based Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/4ee70fb32981f84f9dddc57bd59a69e677c91759",
            "venue": "ArXiv",
            "year": 2019
        },
        {
            "arxivId": "1906.08253",
            "authors": [
                {
                    "authorId": "35163402",
                    "name": "Michael Janner"
                },
                {
                    "authorId": "2550764",
                    "name": "Justin Fu"
                },
                {
                    "authorId": "2634261",
                    "name": "Marvin Zhang"
                },
                {
                    "authorId": "1736651",
                    "name": "S. Levine"
                }
            ],
            "doi": null,
            "intent": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "paperId": "9001698e033524864d4d45f051a5ba362d4afd9e",
            "title": "When to Trust Your Model: Model-Based Policy Optimization",
            "url": "https://www.semanticscholar.org/paper/9001698e033524864d4d45f051a5ba362d4afd9e",
            "venue": "NeurIPS",
            "year": 2019
        },
        {
            "arxivId": "1809.05214",
            "authors": [
                {
                    "authorId": "15593386",
                    "name": "I. Clavera"
                },
                {
                    "authorId": "35309584",
                    "name": "Jonas Rothfuss"
                },
                {
                    "authorId": "47971768",
                    "name": "John Schulman"
                },
                {
                    "authorId": "2055409786",
                    "name": "Yasuhiro Fujita"
                },
                {
                    "authorId": "1722677",
                    "name": "T. Asfour"
                },
                {
                    "authorId": "1689992",
                    "name": "P. Abbeel"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "a7e07e0ecd1727778ade42d2e1df856171ec0898",
            "title": "Model-Based Reinforcement Learning via Meta-Policy Optimization",
            "url": "https://www.semanticscholar.org/paper/a7e07e0ecd1727778ade42d2e1df856171ec0898",
            "venue": "CoRL",
            "year": 2018
        },
        {
            "arxivId": "1807.03858",
            "authors": [
                {
                    "authorId": "3286703",
                    "name": "Huazhe Xu"
                },
                {
                    "authorId": "2110486765",
                    "name": "Yuanzhi Li"
                },
                {
                    "authorId": "39402399",
                    "name": "Yuandong Tian"
                },
                {
                    "authorId": "1753210",
                    "name": "Trevor Darrell"
                },
                {
                    "authorId": "1901958",
                    "name": "Tengyu Ma"
                }
            ],
            "doi": null,
            "intent": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "paperId": "d333f99881b09426283a9c7a1d25f7ac30d63062",
            "title": "Algorithmic Framework for Model-based Deep Reinforcement Learning with Theoretical Guarantees",
            "url": "https://www.semanticscholar.org/paper/d333f99881b09426283a9c7a1d25f7ac30d63062",
            "venue": "ICLR",
            "year": 2018
        },
        {
            "arxivId": "1807.01675",
            "authors": [
                {
                    "authorId": "47619311",
                    "name": "Jacob Buckman"
                },
                {
                    "authorId": "35006479",
                    "name": "Danijar Hafner"
                },
                {
                    "authorId": "145499435",
                    "name": "G. Tucker"
                },
                {
                    "authorId": "2445241",
                    "name": "E. Brevdo"
                },
                {
                    "authorId": "1697141",
                    "name": "Honglak Lee"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "08555bf7d6a483f783b7508ed2df5b1a4d29661c",
            "title": "Sample-Efficient Reinforcement Learning with Stochastic Ensemble Value Expansion",
            "url": "https://www.semanticscholar.org/paper/08555bf7d6a483f783b7508ed2df5b1a4d29661c",
            "venue": "NeurIPS",
            "year": 2018
        },
        {
            "arxivId": "1805.12114",
            "authors": [
                {
                    "authorId": "46224156",
                    "name": "Kurtland Chua"
                },
                {
                    "authorId": "35159852",
                    "name": "R. Calandra"
                },
                {
                    "authorId": "49686609",
                    "name": "R. McAllister"
                },
                {
                    "authorId": "1736651",
                    "name": "S. Levine"
                }
            ],
            "doi": null,
            "intent": [
                "methodology",
                "background"
            ],
            "isInfluential": false,
            "paperId": "56136aa0b2c347cbcf3d50821f310c4253155026",
            "title": "Deep Reinforcement Learning in a Handful of Trials using Probabilistic Dynamics Models",
            "url": "https://www.semanticscholar.org/paper/56136aa0b2c347cbcf3d50821f310c4253155026",
            "venue": "NeurIPS",
            "year": 2018
        },
        {
            "arxivId": "1802.09477",
            "authors": [
                {
                    "authorId": "14637819",
                    "name": "Scott Fujimoto"
                },
                {
                    "authorId": "47662867",
                    "name": "H. V. Hoof"
                },
                {
                    "authorId": "2462512",
                    "name": "D. Meger"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "4debb99c0c63bfaa97dd433bc2828e4dac81c48b",
            "title": "Addressing Function Approximation Error in Actor-Critic Methods",
            "url": "https://www.semanticscholar.org/paper/4debb99c0c63bfaa97dd433bc2828e4dac81c48b",
            "venue": "ICML",
            "year": 2018
        },
        {
            "arxivId": "1802.07564",
            "authors": [
                {
                    "authorId": "2055409786",
                    "name": "Yasuhiro Fujita"
                },
                {
                    "authorId": "35647224",
                    "name": "S. Maeda"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": true,
            "paperId": "13d624cd70787e6e13e38c40a2a50df0189838ee",
            "title": "Clipped Action Policy Gradient",
            "url": "https://www.semanticscholar.org/paper/13d624cd70787e6e13e38c40a2a50df0189838ee",
            "venue": "ICML",
            "year": 2018
        },
        {
            "arxivId": "1802.10592",
            "authors": [
                {
                    "authorId": "2765564",
                    "name": "Thanard Kurutach"
                },
                {
                    "authorId": "15593386",
                    "name": "I. Clavera"
                },
                {
                    "authorId": "144581158",
                    "name": "Yan Duan"
                },
                {
                    "authorId": "3025260",
                    "name": "Aviv Tamar"
                },
                {
                    "authorId": "1689992",
                    "name": "P. Abbeel"
                }
            ],
            "doi": null,
            "intent": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "paperId": "27dfecb6bb0308c7484e13dcaefd5eeebba677d3",
            "title": "Model-Ensemble Trust-Region Policy Optimization",
            "url": "https://www.semanticscholar.org/paper/27dfecb6bb0308c7484e13dcaefd5eeebba677d3",
            "venue": "ICLR",
            "year": 2018
        },
        {
            "arxivId": "1802.05957",
            "authors": [
                {
                    "authorId": "3213400",
                    "name": "Takeru Miyato"
                },
                {
                    "authorId": "2056971870",
                    "name": "Toshiki Kataoka"
                },
                {
                    "authorId": "2877296",
                    "name": "Masanori Koyama"
                },
                {
                    "authorId": "51462146",
                    "name": "Yuichi Yoshida"
                }
            ],
            "doi": null,
            "intent": [
                "methodology",
                "background"
            ],
            "isInfluential": false,
            "paperId": "84de7d27e2f6160f634a483e8548c499a2cda7fa",
            "title": "Spectral Normalization for Generative Adversarial Networks",
            "url": "https://www.semanticscholar.org/paper/84de7d27e2f6160f634a483e8548c499a2cda7fa",
            "venue": "ICLR",
            "year": 2018
        },
        {
            "arxivId": "1801.01290",
            "authors": [
                {
                    "authorId": "2587648",
                    "name": "Tuomas Haarnoja"
                },
                {
                    "authorId": "35499972",
                    "name": "Aurick Zhou"
                },
                {
                    "authorId": "1689992",
                    "name": "P. Abbeel"
                },
                {
                    "authorId": "1736651",
                    "name": "S. Levine"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "811df72e210e20de99719539505da54762a11c6d",
            "title": "Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor",
            "url": "https://www.semanticscholar.org/paper/811df72e210e20de99719539505da54762a11c6d",
            "venue": "ICML",
            "year": 2018
        },
        {
            "arxivId": "1708.02596",
            "authors": [
                {
                    "authorId": "3195183",
                    "name": "Anusha Nagabandi"
                },
                {
                    "authorId": "46292812",
                    "name": "G. Kahn"
                },
                {
                    "authorId": "1773013",
                    "name": "R. Fearing"
                },
                {
                    "authorId": "1736651",
                    "name": "S. Levine"
                }
            ],
            "doi": "10.1109/ICRA.2018.8463189",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "cce22bf6405042a965a86557684c46a441f2a736",
            "title": "Neural Network Dynamics for Model-Based Deep Reinforcement Learning with Model-Free Fine-Tuning",
            "url": "https://www.semanticscholar.org/paper/cce22bf6405042a965a86557684c46a441f2a736",
            "venue": "2018 IEEE International Conference on Robotics and Automation (ICRA)",
            "year": 2017
        },
        {
            "arxivId": "1704.00028",
            "authors": [
                {
                    "authorId": "2708454",
                    "name": "Ishaan Gulrajani"
                },
                {
                    "authorId": "2054472270",
                    "name": "Faruk Ahmed"
                },
                {
                    "authorId": "2877311",
                    "name": "Mart\u00edn Arjovsky"
                },
                {
                    "authorId": "3074927",
                    "name": "Vincent Dumoulin"
                },
                {
                    "authorId": "1760871",
                    "name": "Aaron C. Courville"
                }
            ],
            "doi": null,
            "intent": [
                "methodology",
                "background"
            ],
            "isInfluential": false,
            "paperId": "edf73ab12595c6709f646f542a0d2b33eb20a3f4",
            "title": "Improved Training of Wasserstein GANs",
            "url": "https://www.semanticscholar.org/paper/edf73ab12595c6709f646f542a0d2b33eb20a3f4",
            "venue": "NIPS",
            "year": 2017
        },
        {
            "arxivId": "1701.07875",
            "authors": [
                {
                    "authorId": "2066311389",
                    "name": "Mart\u00edn Arjovsky"
                },
                {
                    "authorId": "2066272844",
                    "name": "Soumith Chintala"
                },
                {
                    "authorId": "2065210987",
                    "name": "L\u00e9on Bottou"
                }
            ],
            "doi": null,
            "intent": [
                "methodology"
            ],
            "isInfluential": true,
            "paperId": "2f85b7376769473d2bed56f855f115e23d727094",
            "title": "Wasserstein GAN",
            "url": "https://www.semanticscholar.org/paper/2f85b7376769473d2bed56f855f115e23d727094",
            "venue": "ArXiv",
            "year": 2017
        },
        {
            "arxivId": "1606.03476",
            "authors": [
                {
                    "authorId": "2126278",
                    "name": "Jonathan Ho"
                },
                {
                    "authorId": "2490652",
                    "name": "Stefano Ermon"
                }
            ],
            "doi": null,
            "intent": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "paperId": "4ab53de69372ec2cd2d90c126b6a100165dc8ed1",
            "title": "Generative Adversarial Imitation Learning",
            "url": "https://www.semanticscholar.org/paper/4ab53de69372ec2cd2d90c126b6a100165dc8ed1",
            "venue": "NIPS",
            "year": 2016
        },
        {
            "arxivId": "1603.00748",
            "authors": [
                {
                    "authorId": "2046135",
                    "name": "S. Gu"
                },
                {
                    "authorId": "2542999",
                    "name": "T. Lillicrap"
                },
                {
                    "authorId": "1701686",
                    "name": "I. Sutskever"
                },
                {
                    "authorId": "1736651",
                    "name": "S. Levine"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "d358d41c69450b171327ebd99462b6afef687269",
            "title": "Continuous Deep Q-Learning with Model-based Acceleration",
            "url": "https://www.semanticscholar.org/paper/d358d41c69450b171327ebd99462b6afef687269",
            "venue": "ICML",
            "year": 2016
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "144832491",
                    "name": "E. Todorov"
                },
                {
                    "authorId": "1968210",
                    "name": "Tom Erez"
                },
                {
                    "authorId": "2109481",
                    "name": "Yuval Tassa"
                }
            ],
            "doi": "10.1109/IROS.2012.6386109",
            "intent": [
                "background"
            ],
            "isInfluential": true,
            "paperId": "b354ee518bfc1ac0d8ac447eece9edb69e92eae1",
            "title": "MuJoCo: A physics engine for model-based control",
            "url": "https://www.semanticscholar.org/paper/b354ee518bfc1ac0d8ac447eece9edb69e92eae1",
            "venue": "2012 IEEE/RSJ International Conference on Intelligent Robots and Systems",
            "year": 2012
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "38473726",
                    "name": "Umar Syed"
                },
                {
                    "authorId": "1716301",
                    "name": "R. Schapire"
                }
            ],
            "doi": null,
            "intent": [
                "methodology",
                "background"
            ],
            "isInfluential": false,
            "paperId": "46095704841634a0483106a31b7a52df54b25de2",
            "title": "A Reduction from Apprenticeship Learning to Classification",
            "url": "https://www.semanticscholar.org/paper/46095704841634a0483106a31b7a52df54b25de2",
            "venue": "NIPS",
            "year": 2010
        },
        {
            "arxivId": "1011.0686",
            "authors": [
                {
                    "authorId": "1700433",
                    "name": "St\u00e9phane Ross"
                },
                {
                    "authorId": "21889436",
                    "name": "Geoffrey J. Gordon"
                },
                {
                    "authorId": "1756566",
                    "name": "J. Bagnell"
                }
            ],
            "doi": null,
            "intent": [
                "methodology"
            ],
            "isInfluential": true,
            "paperId": "79ab3c49903ec8cb339437ccf5cf998607fc313e",
            "title": "A Reduction of Imitation Learning and Structured Prediction to No-Regret Online Learning",
            "url": "https://www.semanticscholar.org/paper/79ab3c49903ec8cb339437ccf5cf998607fc313e",
            "venue": "AISTATS",
            "year": 2010
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "16614521",
                    "name": "C. Villani"
                }
            ],
            "doi": "10.1007/978-3-540-71050-9",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "7f05b312f2de7e59c7869558507fa4a9fa0d0971",
            "title": "Optimal Transport: Old and New",
            "url": "https://www.semanticscholar.org/paper/7f05b312f2de7e59c7869558507fa4a9fa0d0971",
            "venue": "",
            "year": 2008
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "38473726",
                    "name": "Umar Syed"
                },
                {
                    "authorId": "1687780",
                    "name": "Michael Bowling"
                },
                {
                    "authorId": "1716301",
                    "name": "R. Schapire"
                }
            ],
            "doi": "10.1145/1390156.1390286",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "45c16943fb8cffd1a23ac45345107cf79ad2bb79",
            "title": "Apprenticeship learning using linear programming",
            "url": "https://www.semanticscholar.org/paper/45c16943fb8cffd1a23ac45345107cf79ad2bb79",
            "venue": "ICML '08",
            "year": 2008
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "1788010",
                    "name": "M. Alamir"
                },
                {
                    "authorId": "2270409907",
                    "name": "Frank Allg\u00f6wer"
                }
            ],
            "doi": "10.1002/RNC.1266",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "3c3fbadbcfe98e3dd096865948c486bb3b3ac386",
            "title": "Model Predictive Control",
            "url": "https://www.semanticscholar.org/paper/3c3fbadbcfe98e3dd096865948c486bb3b3ac386",
            "venue": "",
            "year": 2008
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "31010503",
                    "name": "J. K. Hunter"
                },
                {
                    "authorId": "3276002",
                    "name": "B. Nachtergaele"
                }
            ],
            "doi": "10.1142/9789812810670_0003",
            "intent": [],
            "isInfluential": false,
            "paperId": "f2a240cc908ebd9799c48281552489fed1487fe0",
            "title": "The Contraction Mapping Theorem",
            "url": "https://www.semanticscholar.org/paper/f2a240cc908ebd9799c48281552489fed1487fe0",
            "venue": "",
            "year": 2001
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "1699645",
                    "name": "R. Sutton"
                }
            ],
            "doi": "10.1145/122344.122377",
            "intent": [],
            "isInfluential": false,
            "paperId": "831edc3d67457db83da40d260e93bfd7559347ae",
            "title": "Dyna, an integrated architecture for learning, planning, and reacting",
            "url": "https://www.semanticscholar.org/paper/831edc3d67457db83da40d260e93bfd7559347ae",
            "venue": "SGAR",
            "year": 1990
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "40629484",
                    "name": "Keith Conrad"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "5fb8487ccfbedc099ee185682b67ba09e7bf9b56",
            "title": "THE CONTRACTION MAPPING THEOREM",
            "url": "https://www.semanticscholar.org/paper/5fb8487ccfbedc099ee185682b67ba09e7bf9b56",
            "venue": "",
            "year": 2009
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "46232398",
                    "name": "R. Lipsman"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": true,
            "paperId": "e5f2a837dc7fc2b3be2a5e2407b58c28118884a5",
            "title": "Abstract harmonic analysis",
            "url": "https://www.semanticscholar.org/paper/e5f2a837dc7fc2b3be2a5e2407b58c28118884a5",
            "venue": "",
            "year": 1968
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "12463616",
                    "name": "E. Hewitt"
                },
                {
                    "authorId": "2070446392",
                    "name": "K. Ross"
                }
            ],
            "doi": "10.1007/978-3-642-62008-9",
            "intent": [
                "background"
            ],
            "isInfluential": true,
            "paperId": "5cd7eace7b8be4d19c2bfda4d4457d7fb72bb630",
            "title": "Abstract Harmonic Analysis",
            "url": "https://www.semanticscholar.org/paper/5cd7eace7b8be4d19c2bfda4d4457d7fb72bb630",
            "venue": "",
            "year": 1963
        }
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Mathematics",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "title": "A Contraction Approach to Model-based Reinforcement Learning",
    "topics": [],
    "url": "https://www.semanticscholar.org/paper/7be93daa9412136af577f0e55c7398aad524e27d",
    "venue": "International Conference on Artificial Intelligence and Statistics",
    "year": 2020
}
{
    "abstract": "The proliferation of artificial intelligence is increasingly dependent on model understanding. Understanding demands both an interpretation - a human reasoning about a model's behavior - and an explanation - a symbolic representation of the functioning of the model. Notwithstanding the imperative of transparency for safety, trust, and acceptance, the opacity of state-of-the-art reinforcement learning algorithms conceals the rudiments of their learned strategies. We have developed a policy regularization method that asserts the global intrinsic affinities of learned strategies. These affinities provide a means of reasoning about a policy's behavior, thus making it inherently interpretable. We have demonstrated our method in personalized prosperity management where individuals' spending behavior in time dictate their investment strategies, i.e. distinct spending personalities may have dissimilar associations with different investment classes. We now explain our model by reproducing the underlying prototypical policies with discretized Markov models. These global surrogates are symbolic representations of the prototypical policies.",
    "arxivId": "2208.12627",
    "authors": [
        {
            "authorId": "96648620",
            "name": "Charl Maree",
            "url": "https://www.semanticscholar.org/author/96648620"
        },
        {
            "authorId": "1740471",
            "name": "C. Omlin",
            "url": "https://www.semanticscholar.org/author/1740471"
        }
    ],
    "citationVelocity": 0,
    "citations": [],
    "corpusId": 251881721,
    "doi": "10.48550/arXiv.2208.12627",
    "fieldsOfStudy": [
        "Computer Science"
    ],
    "influentialCitationCount": 0,
    "isOpenAccess": true,
    "isPublisherLicensed": true,
    "is_open_access": true,
    "is_publisher_licensed": true,
    "numCitedBy": 0,
    "numCiting": 35,
    "paperId": "1b487fcba57c425044d89230c88be2b7c8604335",
    "references": [
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2268790255",
                    "name": "Ali Shavandi"
                },
                {
                    "authorId": "2100043",
                    "name": "Majid Khedmati"
                }
            ],
            "doi": "10.1016/j.eswa.2022.118124",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "6953061c26f50ba7fd02a7dee15255471cf9a7a1",
            "title": "A multi-agent deep reinforcement learning framework for algorithmic trading in financial markets",
            "url": "https://www.semanticscholar.org/paper/6953061c26f50ba7fd02a7dee15255471cf9a7a1",
            "venue": "Expert Syst. Appl.",
            "year": 2022
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "33773039",
                    "name": "S. Carta"
                },
                {
                    "authorId": "1748453",
                    "name": "S. Consoli"
                },
                {
                    "authorId": "2308276",
                    "name": "Alessandro Sebastian Podda"
                },
                {
                    "authorId": "3349721",
                    "name": "D. Recupero"
                },
                {
                    "authorId": "2062981386",
                    "name": "Maria Madalina Stanciu"
                }
            ],
            "doi": "10.1016/j.eswa.2022.117763",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "f9ec032d656667ca74f3c79715fdc6a89c4ac233",
            "title": "Statistical arbitrage powered by Explainable Artificial Intelligence",
            "url": "https://www.semanticscholar.org/paper/f9ec032d656667ca74f3c79715fdc6a89c4ac233",
            "venue": "Expert Syst. Appl.",
            "year": 2022
        },
        {
            "arxivId": "2204.09218",
            "authors": [
                {
                    "authorId": "96648620",
                    "name": "Charl Maree"
                },
                {
                    "authorId": "1740471",
                    "name": "C. Omlin"
                }
            ],
            "doi": "10.1007/s42521-022-00068-4",
            "intent": [
                "background",
                "methodology"
            ],
            "isInfluential": true,
            "paperId": "b989b0d806ac6e6a9d869e995fba3206ffd98b34",
            "title": "Reinforcement learning with intrinsic affinity for personalized prosperity management",
            "url": "https://www.semanticscholar.org/paper/b989b0d806ac6e6a9d869e995fba3206ffd98b34",
            "venue": "Digital Finance",
            "year": 2022
        },
        {
            "arxivId": "2203.04303",
            "authors": [
                {
                    "authorId": "11708658",
                    "name": "Michele Persiani"
                },
                {
                    "authorId": "1840894",
                    "name": "T. Hellstr\u00f6m"
                }
            ],
            "doi": "10.1007/s00521-022-07942-7",
            "intent": [],
            "isInfluential": false,
            "paperId": "ad735f36d585596f19edd177936c51aad421df87",
            "title": "Policy regularization for legible behavior",
            "url": "https://www.semanticscholar.org/paper/ad735f36d585596f19edd177936c51aad421df87",
            "venue": "Neural Computing and Applications",
            "year": 2022
        },
        {
            "arxivId": "2202.12174",
            "authors": [
                {
                    "authorId": "2129699286",
                    "name": "Alain Andres"
                },
                {
                    "authorId": "1399096304",
                    "name": "Esther Villar-Rodriguez"
                },
                {
                    "authorId": "9221552",
                    "name": "J. Ser"
                }
            ],
            "doi": "10.1007/s00521-022-07774-5",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "ce126d14a148210b12e69150f8b0905d01f76504",
            "title": "Collaborative training of heterogeneous reinforcement learning agents in environments with sparse rewards: what and when to share?",
            "url": "https://www.semanticscholar.org/paper/ce126d14a148210b12e69150f8b0905d01f76504",
            "venue": "Neural Computing and Applications",
            "year": 2022
        },
        {
            "arxivId": "2202.09064",
            "authors": [
                {
                    "authorId": "96648620",
                    "name": "Charl Maree"
                },
                {
                    "authorId": "1740471",
                    "name": "C. Omlin"
                }
            ],
            "doi": "10.3390/ai3020030",
            "intent": [],
            "isInfluential": false,
            "paperId": "131e81940f1509895f8579d9db5c03b38ce8fa7f",
            "title": "Can Interpretable Reinforcement Learning Manage Prosperity Your Way?",
            "url": "https://www.semanticscholar.org/paper/131e81940f1509895f8579d9db5c03b38ce8fa7f",
            "venue": "AI",
            "year": 2022
        },
        {
            "arxivId": "2201.10003",
            "authors": [
                {
                    "authorId": "96648620",
                    "name": "Charl Maree"
                },
                {
                    "authorId": "1740471",
                    "name": "C. Omlin"
                }
            ],
            "doi": "10.3390/ai3020015",
            "intent": [
                "background",
                "methodology"
            ],
            "isInfluential": true,
            "paperId": "337b8ab61c6a6da21098a6fd6e46095d85a376ec",
            "title": "Reinforcement Learning Your Way: Agent Characterization through Policy Regularization",
            "url": "https://www.semanticscholar.org/paper/337b8ab61c6a6da21098a6fd6e46095d85a376ec",
            "venue": "AI",
            "year": 2022
        },
        {
            "arxivId": "2111.06908",
            "authors": [
                {
                    "authorId": "1443435204",
                    "name": "Yanou Ramon"
                },
                {
                    "authorId": "49769499",
                    "name": "S. Matz"
                },
                {
                    "authorId": "1659374403",
                    "name": "R. Farrokhnia"
                },
                {
                    "authorId": "145147309",
                    "name": "David Martens"
                }
            ],
            "doi": "10.3390/info12120518",
            "intent": [],
            "isInfluential": false,
            "paperId": "0af4802b3cd144b8ca533a4437812cfbe616c16e",
            "title": "Explainable AI for Psychological Profiling from Digital Footprints: A Case Study of Big Five Personality Predictions from Spending Data",
            "url": "https://www.semanticscholar.org/paper/0af4802b3cd144b8ca533a4437812cfbe616c16e",
            "venue": "Inf.",
            "year": 2021
        },
        {
            "arxivId": "2107.09051",
            "authors": [
                {
                    "authorId": "2148761004",
                    "name": "Longbing Cao"
                }
            ],
            "doi": "10.1145/3502289",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "6a85586fb2c87f303f2da32ba5f1863db2a31072",
            "title": "AI in Finance: Challenges, Techniques, and Opportunities",
            "url": "https://www.semanticscholar.org/paper/6a85586fb2c87f303f2da32ba5f1863db2a31072",
            "venue": "ACM Comput. Surv.",
            "year": 2021
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2031446876",
                    "name": "Lindsay Wells"
                },
                {
                    "authorId": "2094175297",
                    "name": "T. Bednarz"
                }
            ],
            "doi": "10.3389/frai.2021.550030",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "bfbc532ef307c1ad2e7ff51d9dadcda57b6f1d7c",
            "title": "Explainable AI and Reinforcement Learning\u2014A Systematic Review of Current Approaches and Trends",
            "url": "https://www.semanticscholar.org/paper/bfbc532ef307c1ad2e7ff51d9dadcda57b6f1d7c",
            "venue": "Frontiers in Artificial Intelligence",
            "year": 2021
        },
        {
            "arxivId": "2102.04022",
            "authors": [
                {
                    "authorId": "2047998201",
                    "name": "Luca Marzari"
                },
                {
                    "authorId": "1490633330",
                    "name": "Ameya Pore"
                },
                {
                    "authorId": "1404346140",
                    "name": "D. Dall\u2019Alba"
                },
                {
                    "authorId": "1403128480",
                    "name": "G. Aragon-Camarasa"
                },
                {
                    "authorId": "1690281",
                    "name": "A. Farinelli"
                },
                {
                    "authorId": "1779713",
                    "name": "P. Fiorini"
                }
            ],
            "doi": "10.1109/ICAR53236.2021.9659344",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "2f2e2ac0832d1ceab3b8d09a05099db3528a18d8",
            "title": "Towards Hierarchical Task Decomposition using Deep Reinforcement Learning for Pick and Place Subtasks",
            "url": "https://www.semanticscholar.org/paper/2f2e2ac0832d1ceab3b8d09a05099db3528a18d8",
            "venue": "2021 20th International Conference on Advanced Robotics (ICAR)",
            "year": 2021
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "138497788",
                    "name": "Nino Vieillard"
                },
                {
                    "authorId": "27750973",
                    "name": "Tadashi Kozuno"
                },
                {
                    "authorId": "1689774",
                    "name": "B. Scherrer"
                },
                {
                    "authorId": "1721354",
                    "name": "O. Pietquin"
                },
                {
                    "authorId": "1708654",
                    "name": "R. Munos"
                },
                {
                    "authorId": "1737555",
                    "name": "M. Geist"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "11d6833bf57d9f482ee259501f5f1abead82404a",
            "title": "Leverage the Average: an Analysis of KL Regularization in Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/11d6833bf57d9f482ee259501f5f1abead82404a",
            "venue": "NeurIPS",
            "year": 2020
        },
        {
            "arxivId": "2008.06693",
            "authors": [
                {
                    "authorId": "1896559552",
                    "name": "Alexandre Heuillet"
                },
                {
                    "authorId": "1896559908",
                    "name": "Fabien Couthouis"
                },
                {
                    "authorId": "2058921025",
                    "name": "Natalia D\u00edaz Rodr\u00edguez"
                }
            ],
            "doi": "10.1016/j.knosys.2020.106685",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "ea5988da726cb50d2376584b04d668008aad0a3f",
            "title": "Explainability in Deep Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/ea5988da726cb50d2376584b04d668008aad0a3f",
            "venue": "Knowl. Based Syst.",
            "year": 2020
        },
        {
            "arxivId": "1910.10045",
            "authors": [
                {
                    "authorId": "1379511816",
                    "name": "Alejandro Barredo Arrieta"
                },
                {
                    "authorId": "2058921025",
                    "name": "Natalia D\u00edaz Rodr\u00edguez"
                },
                {
                    "authorId": "9221552",
                    "name": "J. Ser"
                },
                {
                    "authorId": "1379511786",
                    "name": "Adrien Bennetot"
                },
                {
                    "authorId": "3030006",
                    "name": "S. Tabik"
                },
                {
                    "authorId": "50449165",
                    "name": "A. Barbado"
                },
                {
                    "authorId": "39558258",
                    "name": "S. Garc\u00eda"
                },
                {
                    "authorId": "1402195255",
                    "name": "S. Gil-Lopez"
                },
                {
                    "authorId": "145337392",
                    "name": "D. Molina"
                },
                {
                    "authorId": "2445552",
                    "name": "Richard Benjamins"
                },
                {
                    "authorId": "2091924780",
                    "name": "Raja Chatila"
                },
                {
                    "authorId": "2098723448",
                    "name": "Francisco Herrera"
                }
            ],
            "doi": "10.1016/j.inffus.2019.12.012",
            "intent": [
                "background",
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "530a059cb48477ad1e3d4f8f4b153274c8997332",
            "title": "Explainable Artificial Intelligence (XAI): Concepts, Taxonomies, Opportunities and Challenges toward Responsible AI",
            "url": "https://www.semanticscholar.org/paper/530a059cb48477ad1e3d4f8f4b153274c8997332",
            "venue": "Inf. Fusion",
            "year": 2019
        },
        {
            "arxivId": "1908.06976",
            "authors": [
                {
                    "authorId": "1387894646",
                    "name": "A. Aubret"
                },
                {
                    "authorId": "2335305",
                    "name": "L. Matignon"
                },
                {
                    "authorId": "1730965",
                    "name": "S. Hassas"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "895735cace0de940aa647dbafc046b7f30316fe5",
            "title": "A survey on intrinsic motivation in reinforcement learning",
            "url": "https://www.semanticscholar.org/paper/895735cace0de940aa647dbafc046b7f30316fe5",
            "venue": "ArXiv",
            "year": 2019
        },
        {
            "arxivId": "1906.09323",
            "authors": [
                {
                    "authorId": "138875199",
                    "name": "Sobhan Miryoosefi"
                },
                {
                    "authorId": "11963742",
                    "name": "Kiant\u00e9 Brantley"
                },
                {
                    "authorId": "1722360",
                    "name": "Hal Daum\u00e9"
                },
                {
                    "authorId": "144652072",
                    "name": "Miroslav Dud\u00edk"
                },
                {
                    "authorId": "1716301",
                    "name": "R. Schapire"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "9c5ab1e836acdba0c1f91360909e9e81c56d2f15",
            "title": "Reinforcement Learning with Convex Constraints",
            "url": "https://www.semanticscholar.org/paper/9c5ab1e836acdba0c1f91360909e9e81c56d2f15",
            "venue": "NeurIPS",
            "year": 2019
        },
        {
            "arxivId": "1905.10958",
            "authors": [
                {
                    "authorId": "9303604",
                    "name": "Prashan Madumal"
                },
                {
                    "authorId": "144658641",
                    "name": "Tim Miller"
                },
                {
                    "authorId": "1719425",
                    "name": "L. Sonenberg"
                },
                {
                    "authorId": "97607538",
                    "name": "F. Vetere"
                }
            ],
            "doi": "10.1609/AAAI.V34I03.5631",
            "intent": [],
            "isInfluential": false,
            "paperId": "cfb68baa23048e3e0f8845c099fa013797bd623f",
            "title": "Explainable Reinforcement Learning Through a Causal Lens",
            "url": "https://www.semanticscholar.org/paper/cfb68baa23048e3e0f8845c099fa013797bd623f",
            "venue": "AAAI",
            "year": 2019
        },
        {
            "arxivId": "1905.01240",
            "authors": [
                {
                    "authorId": "51980959",
                    "name": "Alexandre Galashov"
                },
                {
                    "authorId": "35880964",
                    "name": "Siddhant M. Jayakumar"
                },
                {
                    "authorId": "40401956",
                    "name": "Leonard Hasenclever"
                },
                {
                    "authorId": "7794353",
                    "name": "Dhruva Tirumala"
                },
                {
                    "authorId": "144735987",
                    "name": "Jonathan Schwarz"
                },
                {
                    "authorId": "2755582",
                    "name": "Guillaume Desjardins"
                },
                {
                    "authorId": "144792148",
                    "name": "Wojciech M. Czarnecki"
                },
                {
                    "authorId": "1725303",
                    "name": "Y. Teh"
                },
                {
                    "authorId": "1996134",
                    "name": "Razvan Pascanu"
                },
                {
                    "authorId": "2801204",
                    "name": "N. Heess"
                }
            ],
            "doi": null,
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "549c9dfb32e85d9ef5a48566767be42ad132a3c4",
            "title": "Information asymmetry in KL-regularized RL",
            "url": "https://www.semanticscholar.org/paper/549c9dfb32e85d9ef5a48566767be42ad132a3c4",
            "venue": "ICLR",
            "year": 2019
        },
        {
            "arxivId": "1904.06703",
            "authors": [
                {
                    "authorId": "102928633",
                    "name": "Benjamin Beyret"
                },
                {
                    "authorId": "2216790",
                    "name": "A. Shafti"
                },
                {
                    "authorId": "144683767",
                    "name": "A. Faisal"
                }
            ],
            "doi": "10.1109/IROS40897.2019.8968488",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "adc4ddeb10dd8da115d4bde9569794ff409fcd40",
            "title": "Dot-to-Dot: Explainable Hierarchical Reinforcement Learning for Robotic Manipulation",
            "url": "https://www.semanticscholar.org/paper/adc4ddeb10dd8da115d4bde9569794ff409fcd40",
            "venue": "2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)",
            "year": 2019
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2658218",
                    "name": "R\u00e9gis Riveret"
                },
                {
                    "authorId": "152128108",
                    "name": "Yang Gao"
                },
                {
                    "authorId": "1712534",
                    "name": "Guido Governatori"
                },
                {
                    "authorId": "1788487",
                    "name": "A. Rotolo"
                },
                {
                    "authorId": "1729790",
                    "name": "J. Pitt"
                },
                {
                    "authorId": "145466735",
                    "name": "G. Sartor"
                }
            ],
            "doi": "10.1007/s10458-019-09404-2",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "ee322bceab47da6db71863485d00189ba22703c6",
            "title": "A probabilistic argumentation framework for reinforcement learning agents",
            "url": "https://www.semanticscholar.org/paper/ee322bceab47da6db71863485d00189ba22703c6",
            "venue": "Autonomous Agents and Multi-Agent Systems",
            "year": 2019
        },
        {
            "arxivId": "1802.04181",
            "authors": [
                {
                    "authorId": "26418330",
                    "name": "Timoth\u00e9e Lesort"
                },
                {
                    "authorId": "2058921025",
                    "name": "Natalia D\u00edaz Rodr\u00edguez"
                },
                {
                    "authorId": "3411801",
                    "name": "Jean-Fran\u00e7ois Goudou"
                },
                {
                    "authorId": "1771194",
                    "name": "David Filliat"
                }
            ],
            "doi": "10.1016/j.neunet.2018.07.006",
            "intent": [],
            "isInfluential": false,
            "paperId": "eed8cae46eb28311e88f6fc41f788528ca2d0f00",
            "title": "State Representation Learning for Control: An Overview",
            "url": "https://www.semanticscholar.org/paper/eed8cae46eb28311e88f6fc41f788528ca2d0f00",
            "venue": "Neural Networks",
            "year": 2018
        },
        {
            "arxivId": "1706.04208",
            "authors": [
                {
                    "authorId": "1748153",
                    "name": "H. V. Seijen"
                },
                {
                    "authorId": "35189291",
                    "name": "Mehdi Fatemi"
                },
                {
                    "authorId": "144100820",
                    "name": "R. Laroche"
                },
                {
                    "authorId": "8365320",
                    "name": "Joshua Romoff"
                },
                {
                    "authorId": "48316034",
                    "name": "Tavian Barnes"
                },
                {
                    "authorId": "32963261",
                    "name": "Jeffrey Tsang"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "3c63f8b8263cd6cc4c8c7429d46bb656accddc49",
            "title": "Hybrid Reward Architecture for Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/3c63f8b8263cd6cc4c8c7429d46bb656accddc49",
            "venue": "NIPS",
            "year": 2017
        },
        {
            "arxivId": "1702.08165",
            "authors": [
                {
                    "authorId": "2587648",
                    "name": "Tuomas Haarnoja"
                },
                {
                    "authorId": "4990833",
                    "name": "Haoran Tang"
                },
                {
                    "authorId": "1689992",
                    "name": "P. Abbeel"
                },
                {
                    "authorId": "1736651",
                    "name": "S. Levine"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "9172cd6c253edf7c3a1568e03577db20648ad0c4",
            "title": "Reinforcement Learning with Deep Energy-Based Policies",
            "url": "https://www.semanticscholar.org/paper/9172cd6c253edf7c3a1568e03577db20648ad0c4",
            "venue": "ICML",
            "year": 2017
        },
        {
            "arxivId": "1512.01629",
            "authors": [
                {
                    "authorId": "1819830",
                    "name": "Yinlam Chow"
                },
                {
                    "authorId": "1678622",
                    "name": "M. Ghavamzadeh"
                },
                {
                    "authorId": "2542753",
                    "name": "Lucas Janson"
                },
                {
                    "authorId": "1696085",
                    "name": "M. Pavone"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "759bbd8dd50cb4790cad7a3bccbdfcbfee5e3e89",
            "title": "Risk-Constrained Reinforcement Learning with Percentile Risk Criteria",
            "url": "https://www.semanticscholar.org/paper/759bbd8dd50cb4790cad7a3bccbdfcbfee5e3e89",
            "venue": "J. Mach. Learn. Res.",
            "year": 2015
        },
        {
            "arxivId": "1509.02971",
            "authors": [
                {
                    "authorId": "2542999",
                    "name": "T. Lillicrap"
                },
                {
                    "authorId": "2323922",
                    "name": "Jonathan J. Hunt"
                },
                {
                    "authorId": "1863250",
                    "name": "A. Pritzel"
                },
                {
                    "authorId": "2801204",
                    "name": "N. Heess"
                },
                {
                    "authorId": "1968210",
                    "name": "Tom Erez"
                },
                {
                    "authorId": "2109481",
                    "name": "Yuval Tassa"
                },
                {
                    "authorId": "145824029",
                    "name": "David Silver"
                },
                {
                    "authorId": "1688276",
                    "name": "Daan Wierstra"
                }
            ],
            "doi": null,
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "024006d4c2a89f7acacc6e4438d156525b60a98f",
            "title": "Continuous control with deep reinforcement learning",
            "url": "https://www.semanticscholar.org/paper/024006d4c2a89f7acacc6e4438d156525b60a98f",
            "venue": "ICLR",
            "year": 2015
        },
        {
            "arxivId": "1512.08269",
            "authors": [
                {
                    "authorId": "2151252957",
                    "name": "Fanny Yang"
                },
                {
                    "authorId": "3261943",
                    "name": "Sivaraman Balakrishnan"
                },
                {
                    "authorId": "1721860",
                    "name": "M. Wainwright"
                }
            ],
            "doi": "10.1109/ALLERTON.2015.7447067",
            "intent": [],
            "isInfluential": false,
            "paperId": "5b433f3304a9628153ed91669cf9a623636adc84",
            "title": "Statistical and computational guarantees for the Baum-Welch algorithm",
            "url": "https://www.semanticscholar.org/paper/5b433f3304a9628153ed91669cf9a623636adc84",
            "venue": "2015 53rd Annual Allerton Conference on Communication, Control, and Computing (Allerton)",
            "year": 2015
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "90923007",
                    "name": "T. Chong"
                },
                {
                    "authorId": "143643110",
                    "name": "W. Ng"
                },
                {
                    "authorId": "40018446",
                    "name": "V. K. Liew"
                }
            ],
            "doi": "10.3390/JRFM7010001",
            "intent": [
                "background",
                "methodology"
            ],
            "isInfluential": true,
            "paperId": "ab47906565d42b724276f64becb89959fa2bb484",
            "title": "Revisiting the Performance of MACD and RSI Oscillators",
            "url": "https://www.semanticscholar.org/paper/ab47906565d42b724276f64becb89959fa2bb484",
            "venue": "",
            "year": 2014
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "144873562",
                    "name": "R. Bellman"
                }
            ],
            "doi": "10.1512/IUMJ.1957.6.56038",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "bff20fb30adad8d1c173963089df5fc9664304f0",
            "title": "A Markovian Decision Process",
            "url": "https://www.semanticscholar.org/paper/bff20fb30adad8d1c173963089df5fc9664304f0",
            "venue": "",
            "year": 1957
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "1974372841",
                    "name": "Marius-Constantin Dinu"
                },
                {
                    "authorId": "66798949",
                    "name": "M. Hofmarcher"
                },
                {
                    "authorId": "1973667445",
                    "name": "Vihang Patil"
                },
                {
                    "authorId": "2874052",
                    "name": "Matthias Dorfer"
                },
                {
                    "authorId": "102984313",
                    "name": "P. Blies"
                },
                {
                    "authorId": "78843496",
                    "name": "Johannes Brandstetter"
                },
                {
                    "authorId": "1409265458",
                    "name": "J. Arjona-Medina"
                },
                {
                    "authorId": "3308557",
                    "name": "Sepp Hochreiter"
                }
            ],
            "doi": "10.1007/978-3-031-04083-2_10",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "95cfa4a07e1f4958bd7ae27d033686f873af9565",
            "title": "XAI and Strategy Extraction via Reward Redistribution",
            "url": "https://www.semanticscholar.org/paper/95cfa4a07e1f4958bd7ae27d033686f873af9565",
            "venue": "xxAI@ICML",
            "year": 2020
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "1744526",
                    "name": "P. Sequeira"
                },
                {
                    "authorId": "40950555",
                    "name": "Eric Yeh"
                },
                {
                    "authorId": "2720925",
                    "name": "M. Gervasio"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": true,
            "paperId": "84da891b283bfd56859f9d1431b3b4c7d58b49b1",
            "title": "Interestingness Elements for Explainable Reinforcement Learning through Introspection",
            "url": "https://www.semanticscholar.org/paper/84da891b283bfd56859f9d1431b3b4c7d58b49b1",
            "venue": "IUI Workshops",
            "year": 2019
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "88728623",
                    "name": "Zoe Juozapaitis"
                },
                {
                    "authorId": "40135938",
                    "name": "Anurag Koul"
                },
                {
                    "authorId": "145841336",
                    "name": "Alan Fern"
                },
                {
                    "authorId": "1796494",
                    "name": "Martin Erwig"
                },
                {
                    "authorId": "1388372395",
                    "name": "F. Doshi-Velez"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "d47677337b1083d6bfa940748da0780b2c9faf7d",
            "title": "Explainable Reinforcement Learning via Reward Decomposition",
            "url": "https://www.semanticscholar.org/paper/d47677337b1083d6bfa940748da0780b2c9faf7d",
            "venue": "",
            "year": 2019
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "144389295",
                    "name": "Christian Wirth"
                },
                {
                    "authorId": "1688702",
                    "name": "R. Akrour"
                },
                {
                    "authorId": "26599977",
                    "name": "G. Neumann"
                },
                {
                    "authorId": "1747752",
                    "name": "Johannes F\u00fcrnkranz"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "84082634110fcedaaa32632f6cc16a034eedb2a0",
            "title": "A Survey of Preference-Based Reinforcement Learning Methods",
            "url": "https://www.semanticscholar.org/paper/84082634110fcedaaa32632f6cc16a034eedb2a0",
            "venue": "J. Mach. Learn. Res.",
            "year": 2017
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "1712517",
                    "name": "L. Rabiner"
                },
                {
                    "authorId": "143604406",
                    "name": "B. Juang"
                }
            ],
            "doi": "10.1109/MASSP.1986.1165342",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "385622a5862c989653a648ac8abc59ae3fe785f7",
            "title": "An introduction to hidden Markov models",
            "url": "https://www.semanticscholar.org/paper/385622a5862c989653a648ac8abc59ae3fe785f7",
            "venue": "IEEE ASSP Magazine",
            "year": 1986
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "48432901",
                    "name": "Swati Sachan"
                },
                {
                    "authorId": "47987932",
                    "name": "Jianbo Yang"
                },
                {
                    "authorId": "145864171",
                    "name": "Dongling Xu"
                },
                {
                    "authorId": "1491977074",
                    "name": "David Eraso Benavides"
                },
                {
                    "authorId": "98177814",
                    "name": "Y. Li"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "51dfa7c8194f71ecdc5a336f7a950c49b7b070dd",
            "title": "Expert Systems With Applications",
            "url": "https://www.semanticscholar.org/paper/51dfa7c8194f71ecdc5a336f7a950c49b7b070dd",
            "venue": "",
            "year": null
        }
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "title": "Symbolic Explanation of Affinity-Based Reinforcement Learning Agents with Markov Models",
    "topics": [],
    "url": "https://www.semanticscholar.org/paper/1b487fcba57c425044d89230c88be2b7c8604335",
    "venue": "arXiv.org",
    "year": 2022
}
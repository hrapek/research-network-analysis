{
    "abstract": "Within one decade, Deep Learning overtook the dominating solution methods of countless problems of artificial intelligence. ``Deep'' refers to the deep architectures with operations in manifolds of which there are no immediate observations. For these deep architectures some kind of structure is pre-defined -- but what is this structure? With a formal definition for structures of neural networks, neural architecture search problems and solution methods can be formulated under a common framework. Both practical and theoretical questions arise from closing the gap between applied neural architecture search and learning theory. Does structure make a difference or can it be chosen arbitrarily? This work is concerned with deep structures of artificial neural networks and examines automatic construction methods under empirical principles to shed light on to the so called ``black-box models''. Our contributions include a formulation of graph-induced neural networks that is used to pose optimisation problems for neural architecture. We analyse structural properties for different neural network objectives such as correctness, robustness or energy consumption and discuss how structure affects them. Selected automation methods for neural architecture optimisation problems are discussed and empirically analysed. With the insights gained from formalising graph-induced neural networks, analysing structural properties and comparing the applicability of neural architecture search methods qualitatively and quantitatively we advance these methods in two ways. First, new predictive models are presented for replacing computationally expensive evaluation schemes, and second, new generative models for informed sampling during neural architecture search are analysed and discussed.",
    "arxivId": "2410.09579",
    "authors": [
        {
            "authorId": "2325904384",
            "name": "Julian Stier",
            "url": "https://www.semanticscholar.org/author/2325904384"
        }
    ],
    "citationVelocity": 0,
    "citations": [],
    "corpusId": 273345916,
    "doi": "10.48550/arXiv.2410.09579",
    "fieldsOfStudy": [
        "Computer Science"
    ],
    "influentialCitationCount": 0,
    "isOpenAccess": false,
    "isPublisherLicensed": true,
    "is_open_access": false,
    "is_publisher_licensed": true,
    "numCitedBy": 0,
    "numCiting": 0,
    "paperId": "a9537e726180ceb92504aa9aee4f069f04dd97aa",
    "references": [],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        },
        {
            "category": "Mathematics",
            "source": "s2-fos-model"
        }
    ],
    "title": "Structure of Artificial Neural Networks - Empirical Investigations",
    "topics": [],
    "url": "https://www.semanticscholar.org/paper/a9537e726180ceb92504aa9aee4f069f04dd97aa",
    "venue": "arXiv.org",
    "year": 2024
}
{
    "abstract": "The critical challenge of prompt injection attacks in Large Language Models (LLMs) integrated applications, a growing concern in the Artificial Intelligence (AI) field. Such attacks, which manipulate LLMs through natural language inputs, pose a significant threat to the security of these applications. Traditional defense strategies, including output and input filtering, as well as delimiter use, have proven inadequate. This paper introduces the 'Signed-Prompt' method as a novel solution. The study involves signing sensitive instructions within command segments by authorized users, enabling the LLM to discern trusted instruction sources. The paper presents a comprehensive analysis of prompt injection attack patterns, followed by a detailed explanation of the Signed-Prompt concept, including its basic architecture and implementation through both prompt engineering and fine-tuning of LLMs. Experiments demonstrate the effectiveness of the Signed-Prompt method, showing substantial resistance to various types of prompt injection attacks, thus validating its potential as a robust defense strategy in AI security.",
    "arxivId": "2401.07612",
    "authors": [
        {
            "authorId": "2279549073",
            "name": "Xuchen Suo",
            "url": "https://www.semanticscholar.org/author/2279549073"
        }
    ],
    "citationVelocity": 8,
    "citations": [
        {
            "arxivId": "2411.00348",
            "authors": [
                {
                    "authorId": "2282954816",
                    "name": "Kuo-Han Hung"
                },
                {
                    "authorId": "2314713611",
                    "name": "Ching-Yun Ko"
                },
                {
                    "authorId": "22261698",
                    "name": "Ambrish Rawat"
                },
                {
                    "authorId": "2287632316",
                    "name": "I-Hsin Chung"
                },
                {
                    "authorId": "2237782993",
                    "name": "Winston H. Hsu"
                },
                {
                    "authorId": "2298413577",
                    "name": "Pin-Yu Chen"
                }
            ],
            "doi": null,
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "2b289e1d136edeb6354496518af5230bddc09e61",
            "title": "Attention Tracker: Detecting Prompt Injection Attacks in LLMs",
            "url": "https://www.semanticscholar.org/paper/2b289e1d136edeb6354496518af5230bddc09e61",
            "venue": "",
            "year": 2024
        },
        {
            "arxivId": "2411.00459",
            "authors": [
                {
                    "authorId": "2258786348",
                    "name": "Yulin Chen"
                },
                {
                    "authorId": "2260286743",
                    "name": "Haoran Li"
                },
                {
                    "authorId": "2301174367",
                    "name": "Zihao Zheng"
                },
                {
                    "authorId": "2258804099",
                    "name": "Yangqiu Song"
                },
                {
                    "authorId": "2329054353",
                    "name": "Dekai Wu"
                },
                {
                    "authorId": "2328978055",
                    "name": "Bryan Hooi"
                }
            ],
            "doi": null,
            "intent": [
                "background",
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "9cfaa1cad9f1601bdd75d1de89dd56e18f24ff58",
            "title": "Defense Against Prompt Injection Attack by Leveraging Attack Techniques",
            "url": "https://www.semanticscholar.org/paper/9cfaa1cad9f1601bdd75d1de89dd56e18f24ff58",
            "venue": "",
            "year": 2024
        },
        {
            "arxivId": "2410.21218",
            "authors": [
                {
                    "authorId": "11360887",
                    "name": "Kaifeng Huang"
                },
                {
                    "authorId": "144943089",
                    "name": "Bihuan Chen"
                },
                {
                    "authorId": "2321047089",
                    "name": "You Lu"
                },
                {
                    "authorId": "2158301246",
                    "name": "Susheng Wu"
                },
                {
                    "authorId": "2265775781",
                    "name": "Dingji Wang"
                },
                {
                    "authorId": "2326803313",
                    "name": "Yiheng Huang"
                },
                {
                    "authorId": "2328267663",
                    "name": "Haowen Jiang"
                },
                {
                    "authorId": "2257371495",
                    "name": "Zhuotong Zhou"
                },
                {
                    "authorId": "2241242920",
                    "name": "Junming Cao"
                },
                {
                    "authorId": "2215501537",
                    "name": "Xin Peng"
                }
            ],
            "doi": "10.48550/arXiv.2410.21218",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "1d38827e627ac2be2d53d61a2a7c34b90e1e8ab7",
            "title": "Lifting the Veil on the Large Language Model Supply Chain: Composition, Risks, and Mitigations",
            "url": "https://www.semanticscholar.org/paper/1d38827e627ac2be2d53d61a2a7c34b90e1e8ab7",
            "venue": "ArXiv",
            "year": 2024
        },
        {
            "arxivId": "2410.21146",
            "authors": [
                {
                    "authorId": "2328009629",
                    "name": "Sahasra Kokkula"
                },
                {
                    "authorId": "2328009391",
                    "name": "R. Somanathan"
                },
                {
                    "authorId": "2328009611",
                    "name": "R. Nandavardhan"
                },
                {
                    "authorId": "2328011484",
                    "name": "Aashishkumar"
                },
                {
                    "authorId": "2328009609",
                    "name": "G. Divya"
                }
            ],
            "doi": "10.48550/arXiv.2410.21146",
            "intent": [
                "background",
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "9679b07906f5b040434ee57fe96279a860344604",
            "title": "Palisade - Prompt Injection Detection Framework",
            "url": "https://www.semanticscholar.org/paper/9679b07906f5b040434ee57fe96279a860344604",
            "venue": "ArXiv",
            "year": 2024
        },
        {
            "arxivId": "2410.18114",
            "authors": [
                {
                    "authorId": "2327502074",
                    "name": "Shanshan Han"
                }
            ],
            "doi": "10.48550/arXiv.2410.18114",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "188b35043c43bc6ca032ae4234f101cf7eab952c",
            "title": "Bridging Today and the Future of Humanity: AI Safety in 2024 and Beyond",
            "url": "https://www.semanticscholar.org/paper/188b35043c43bc6ca032ae4234f101cf7eab952c",
            "venue": "ArXiv",
            "year": 2024
        },
        {
            "arxivId": "2410.05451",
            "authors": [
                {
                    "authorId": "2265760726",
                    "name": "Sizhe Chen"
                },
                {
                    "authorId": "3461866",
                    "name": "Arman Zharmagambetov"
                },
                {
                    "authorId": "2290845753",
                    "name": "Saeed Mahloujifar"
                },
                {
                    "authorId": "2256991985",
                    "name": "Kamalika Chaudhuri"
                },
                {
                    "authorId": "2298951327",
                    "name": "Chuan Guo"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "a4365f8779326da0ea2b5b873342996f6b2d3a3d",
            "title": "Aligning LLMs to Be Robust Against Prompt Injection",
            "url": "https://www.semanticscholar.org/paper/a4365f8779326da0ea2b5b873342996f6b2d3a3d",
            "venue": "",
            "year": 2024
        },
        {
            "arxivId": "2409.19091",
            "authors": [
                {
                    "authorId": "2272936285",
                    "name": "Fangzhou Wu"
                },
                {
                    "authorId": "2323503838",
                    "name": "Ethan Cecchetti"
                },
                {
                    "authorId": "2273519476",
                    "name": "Chaowei Xiao"
                }
            ],
            "doi": "10.48550/arXiv.2409.19091",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "19a45c70463edc755d54f3d5343e44cd571fe226",
            "title": "System-Level Defense against Indirect Prompt Injection Attacks: An Information Flow Control Perspective",
            "url": "https://www.semanticscholar.org/paper/19a45c70463edc755d54f3d5343e44cd571fe226",
            "venue": "ArXiv",
            "year": 2024
        },
        {
            "arxivId": "2409.03274",
            "authors": [
                {
                    "authorId": "2275131059",
                    "name": "Jing Cui"
                },
                {
                    "authorId": "2319848551",
                    "name": "Yishi Xu"
                },
                {
                    "authorId": "2151326157",
                    "name": "Zhewei Huang"
                },
                {
                    "authorId": "2261909771",
                    "name": "Shuchang Zhou"
                },
                {
                    "authorId": "2275191645",
                    "name": "Jianbin Jiao"
                },
                {
                    "authorId": "2275271323",
                    "name": "Junge Zhang"
                }
            ],
            "doi": "10.48550/arXiv.2409.03274",
            "intent": [],
            "isInfluential": false,
            "paperId": "3d7cc47f10a1b55e3c7af24bf43f7f9206fcda4e",
            "title": "Recent Advances in Attack and Defense Approaches of Large Language Models",
            "url": "https://www.semanticscholar.org/paper/3d7cc47f10a1b55e3c7af24bf43f7f9206fcda4e",
            "venue": "ArXiv",
            "year": 2024
        },
        {
            "arxivId": "2408.07291",
            "authors": [
                {
                    "authorId": "1604963563",
                    "name": "Yupei Liu"
                },
                {
                    "authorId": "2260844526",
                    "name": "Yuqi Jia"
                },
                {
                    "authorId": "2257508100",
                    "name": "Jinyuan Jia"
                },
                {
                    "authorId": "144516687",
                    "name": "N. Gong"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "f8a065986ce18364c7cbe7a6f6fd44e4c60f57df",
            "title": "Evaluating Large Language Model based Personal Information Extraction and Countermeasures",
            "url": "https://www.semanticscholar.org/paper/f8a065986ce18364c7cbe7a6f6fd44e4c60f57df",
            "venue": "",
            "year": 2024
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2323891593",
                    "name": "Himani Deshpande"
                },
                {
                    "authorId": "2323890474",
                    "name": "Dhawal Chaudhari"
                },
                {
                    "authorId": "2323891673",
                    "name": "Tanmay Sarode"
                },
                {
                    "authorId": "2323888807",
                    "name": "Ayush Kamath"
                }
            ],
            "doi": "10.1109/ICESC60852.2024.10690068",
            "intent": [],
            "isInfluential": false,
            "paperId": "4bf910a648031c5e936a558abc2412b9a360dc10",
            "title": "Exploring LLM and Neural Networks Towards Malicious Prompt Detection",
            "url": "https://www.semanticscholar.org/paper/4bf910a648031c5e936a558abc2412b9a360dc10",
            "venue": "2024 5th International Conference on Electronics and Sustainable Communication Systems (ICESC)",
            "year": 2024
        },
        {
            "arxivId": "2407.20529",
            "authors": [
                {
                    "authorId": "2290848807",
                    "name": "Sara Abdali"
                },
                {
                    "authorId": "2290712336",
                    "name": "Jia He"
                },
                {
                    "authorId": "103032630",
                    "name": "C. Barberan"
                },
                {
                    "authorId": "2290852185",
                    "name": "Richard Anarfi"
                }
            ],
            "doi": "10.48550/arXiv.2407.20529",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "cd91ee010c39c6727dbb17dbd9efb056ff2845ac",
            "title": "Can LLMs be Fooled? Investigating Vulnerabilities in LLMs",
            "url": "https://www.semanticscholar.org/paper/cd91ee010c39c6727dbb17dbd9efb056ff2845ac",
            "venue": "ArXiv",
            "year": 2024
        },
        {
            "arxivId": "2407.14937",
            "authors": [
                {
                    "authorId": "3363380",
                    "name": "Apurv Verma"
                },
                {
                    "authorId": "2143841730",
                    "name": "Satyapriya Krishna"
                },
                {
                    "authorId": "2265058484",
                    "name": "Sebastian Gehrmann"
                },
                {
                    "authorId": "38672865",
                    "name": "Madhavan Seshadri"
                },
                {
                    "authorId": "2312322748",
                    "name": "Anu Pradhan"
                },
                {
                    "authorId": "2312322007",
                    "name": "Tom Ault"
                },
                {
                    "authorId": "2312324819",
                    "name": "Leslie Barrett"
                },
                {
                    "authorId": "2312323661",
                    "name": "David Rabinowitz"
                },
                {
                    "authorId": "2312322306",
                    "name": "John Doucette"
                },
                {
                    "authorId": "11032760",
                    "name": "Nhathai Phan"
                }
            ],
            "doi": "10.48550/arXiv.2407.14937",
            "intent": [],
            "isInfluential": false,
            "paperId": "9fa830e5c3a108f13cdb25c05a9e6107e365ad83",
            "title": "Operationalizing a Threat Model for Red-Teaming Large Language Models (LLMs)",
            "url": "https://www.semanticscholar.org/paper/9fa830e5c3a108f13cdb25c05a9e6107e365ad83",
            "venue": "ArXiv",
            "year": 2024
        },
        {
            "arxivId": "2405.13068",
            "authors": [
                {
                    "authorId": "2298010971",
                    "name": "Yuxi Li"
                },
                {
                    "authorId": "2284875313",
                    "name": "Yi Liu"
                },
                {
                    "authorId": "22799258",
                    "name": "Yuekang Li"
                },
                {
                    "authorId": "2282280043",
                    "name": "Ling Shi"
                },
                {
                    "authorId": "73776889",
                    "name": "Gelei Deng"
                },
                {
                    "authorId": "2302855501",
                    "name": "Shengquan Chen"
                },
                {
                    "authorId": "2284035726",
                    "name": "Kailong Wang"
                }
            ],
            "doi": "10.48550/arXiv.2405.13068",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "9baeb262c3961f46636c9a657a6996640af6a092",
            "title": "Lockpicking LLMs: A Logit-Based Jailbreak Using Token-level Manipulation",
            "url": "https://www.semanticscholar.org/paper/9baeb262c3961f46636c9a657a6996640af6a092",
            "venue": "ArXiv",
            "year": 2024
        },
        {
            "arxivId": "2404.06921",
            "authors": [
                {
                    "authorId": "2257979820",
                    "name": "Shishir G. Patil"
                },
                {
                    "authorId": "1993655237",
                    "name": "Tianjun Zhang"
                },
                {
                    "authorId": "2257345072",
                    "name": "Vivian Fang"
                },
                {
                    "authorId": "2295894329",
                    "name": "Noppapon C Roy Huang"
                },
                {
                    "authorId": "2295893114",
                    "name": "Aaron Hao"
                },
                {
                    "authorId": "2295893072",
                    "name": "Martin Casado"
                },
                {
                    "authorId": "2295893050",
                    "name": "Joseph E. Gonzalez Raluca"
                },
                {
                    "authorId": "2295893148",
                    "name": "Ada Popa"
                },
                {
                    "authorId": "2290576964",
                    "name": "Ion Stoica"
                },
                {
                    "authorId": "2285241527",
                    "name": "Uc Berkeley"
                },
                {
                    "authorId": "2286899755",
                    "name": "Andreessen Horowitz"
                }
            ],
            "doi": "10.48550/arXiv.2404.06921",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "566a950f335cf7f2aa256697a4ecd28bf2476667",
            "title": "GoEX: Perspectives and Designs Towards a Runtime for Autonomous LLM Applications",
            "url": "https://www.semanticscholar.org/paper/566a950f335cf7f2aa256697a4ecd28bf2476667",
            "venue": "ArXiv",
            "year": 2024
        },
        {
            "arxivId": "2403.02691",
            "authors": [
                {
                    "authorId": "2167027235",
                    "name": "Qiusi Zhan"
                },
                {
                    "authorId": "2290249799",
                    "name": "Zhixiang Liang"
                },
                {
                    "authorId": "2290021230",
                    "name": "Zifan Ying"
                },
                {
                    "authorId": "2266051282",
                    "name": "Daniel Kang"
                }
            ],
            "doi": "10.48550/arXiv.2403.02691",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "c8eee9766f0968e8f1b1be0731bc70b85be0ac97",
            "title": "InjecAgent: Benchmarking Indirect Prompt Injections in Tool-Integrated Large Language Model Agents",
            "url": "https://www.semanticscholar.org/paper/c8eee9766f0968e8f1b1be0731bc70b85be0ac97",
            "venue": "ACL",
            "year": 2024
        },
        {
            "arxivId": "2402.06363",
            "authors": [
                {
                    "authorId": "2265760726",
                    "name": "Sizhe Chen"
                },
                {
                    "authorId": "83755654",
                    "name": "Julien Piet"
                },
                {
                    "authorId": "30175233",
                    "name": "Chawin Sitawarin"
                },
                {
                    "authorId": "2265651533",
                    "name": "David Wagner"
                }
            ],
            "doi": "10.48550/arXiv.2402.06363",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "f5e7e22036c3fe7d6660eee90642f716c3b303f5",
            "title": "StruQ: Defending Against Prompt Injection with Structured Queries",
            "url": "https://www.semanticscholar.org/paper/f5e7e22036c3fe7d6660eee90642f716c3b303f5",
            "venue": "ArXiv",
            "year": 2024
        },
        {
            "arxivId": "2310.10383",
            "authors": [
                {
                    "authorId": "2260286743",
                    "name": "Haoran Li"
                },
                {
                    "authorId": "2258786348",
                    "name": "Yulin Chen"
                },
                {
                    "authorId": "2258746675",
                    "name": "Jinglong Luo"
                },
                {
                    "authorId": "2259685797",
                    "name": "Yan Kang"
                },
                {
                    "authorId": "2258790972",
                    "name": "Xiaojin Zhang"
                },
                {
                    "authorId": "2258708733",
                    "name": "Qi Hu"
                },
                {
                    "authorId": null,
                    "name": "Chunkit Chan"
                },
                {
                    "authorId": "2258804099",
                    "name": "Yangqiu Song"
                }
            ],
            "doi": "10.48550/arXiv.2310.10383",
            "intent": [
                "background",
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "34113ce993100c4cbb3b05c3414ce80da38380be",
            "title": "Privacy in Large Language Models: Attacks, Defenses and Future Directions",
            "url": "https://www.semanticscholar.org/paper/34113ce993100c4cbb3b05c3414ce80da38380be",
            "venue": "ArXiv",
            "year": 2023
        }
    ],
    "corpusId": 266999840,
    "doi": "10.48550/arXiv.2401.07612",
    "fieldsOfStudy": [
        "Computer Science"
    ],
    "influentialCitationCount": 0,
    "isOpenAccess": false,
    "isPublisherLicensed": true,
    "is_open_access": false,
    "is_publisher_licensed": true,
    "numCitedBy": 17,
    "numCiting": 10,
    "paperId": "2742c3d77c4aa6d023b7dfc77984ad10e6aae274",
    "references": [
        {
            "arxivId": "2311.11538",
            "authors": [
                {
                    "authorId": "11305882",
                    "name": "Jiahao Yu"
                },
                {
                    "authorId": "2155399888",
                    "name": "Yuhang Wu"
                },
                {
                    "authorId": "2267332168",
                    "name": "Dong Shu"
                },
                {
                    "authorId": "2267333980",
                    "name": "Mingyu Jin"
                },
                {
                    "authorId": "2242944254",
                    "name": "Xinyu Xing"
                }
            ],
            "doi": "10.48550/arXiv.2311.11538",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "910a4623f7732b1ea32dc2cdda7a30a227b89a11",
            "title": "Assessing Prompt Injection Risks in 200+ Custom GPTs",
            "url": "https://www.semanticscholar.org/paper/910a4623f7732b1ea32dc2cdda7a30a227b89a11",
            "venue": "ArXiv",
            "year": 2023
        },
        {
            "arxivId": "2311.01011",
            "authors": [
                {
                    "authorId": "22192824",
                    "name": "S. Toyer"
                },
                {
                    "authorId": "145695607",
                    "name": "Olivia Watkins"
                },
                {
                    "authorId": "2059422875",
                    "name": "Ethan Mendes"
                },
                {
                    "authorId": "2389770",
                    "name": "Justin Svegliato"
                },
                {
                    "authorId": "2237426918",
                    "name": "Luke Bailey"
                },
                {
                    "authorId": "2264975713",
                    "name": "Tiffany Wang"
                },
                {
                    "authorId": "2264826408",
                    "name": "Isaac Ong"
                },
                {
                    "authorId": "21120197",
                    "name": "Karim Elmaaroufi"
                },
                {
                    "authorId": "2262214983",
                    "name": "Pieter Abbeel"
                },
                {
                    "authorId": "2263437012",
                    "name": "Trevor Darrell"
                },
                {
                    "authorId": "2264962879",
                    "name": "Alan Ritter"
                },
                {
                    "authorId": "2237426863",
                    "name": "Stuart Russell"
                }
            ],
            "doi": "10.48550/arXiv.2311.01011",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "e25b4bdfc3f5a8293ea6cd687a0203e446594188",
            "title": "Tensor Trust: Interpretable Prompt Injection Attacks from an Online Game",
            "url": "https://www.semanticscholar.org/paper/e25b4bdfc3f5a8293ea6cd687a0203e446594188",
            "venue": "ICLR",
            "year": 2023
        },
        {
            "arxivId": "2310.12815",
            "authors": [
                {
                    "authorId": "1604963563",
                    "name": "Yupei Liu"
                },
                {
                    "authorId": "2260844526",
                    "name": "Yuqi Jia"
                },
                {
                    "authorId": "2260340372",
                    "name": "Runpeng Geng"
                },
                {
                    "authorId": "2257508100",
                    "name": "Jinyuan Jia"
                },
                {
                    "authorId": "144516687",
                    "name": "N. Gong"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "9adddfe5a596d20b534a29d9937efcd3cb85d3cf",
            "title": "Formalizing and Benchmarking Prompt Injection Attacks and Defenses",
            "url": "https://www.semanticscholar.org/paper/9adddfe5a596d20b534a29d9937efcd3cb85d3cf",
            "venue": "USENIX Security Symposium",
            "year": 2023
        },
        {
            "arxivId": "2307.00855",
            "authors": [
                {
                    "authorId": "2221022947",
                    "name": "Jiaqi Wang"
                },
                {
                    "authorId": "2145977326",
                    "name": "Zheng Liu"
                },
                {
                    "authorId": "2111641126",
                    "name": "Lin Zhao"
                },
                {
                    "authorId": "47039788",
                    "name": "Zihao Wu"
                },
                {
                    "authorId": "2132543537",
                    "name": "Chong Ma"
                },
                {
                    "authorId": "2157834222",
                    "name": "Sigang Yu"
                },
                {
                    "authorId": "29944950",
                    "name": "Haixing Dai"
                },
                {
                    "authorId": "2143047073",
                    "name": "Qiushi Yang"
                },
                {
                    "authorId": "2116426849",
                    "name": "Yi-Hsueh Liu"
                },
                {
                    "authorId": "2108965026",
                    "name": "Songyao Zhang"
                },
                {
                    "authorId": "2131108859",
                    "name": "Enze Shi"
                },
                {
                    "authorId": "2221032216",
                    "name": "Yi Pan"
                },
                {
                    "authorId": "49104946",
                    "name": "Tuo Zhang"
                },
                {
                    "authorId": "2181182",
                    "name": "Dajiang Zhu"
                },
                {
                    "authorId": "2144438902",
                    "name": "Xiang Li"
                },
                {
                    "authorId": "143796247",
                    "name": "Xi Jiang"
                },
                {
                    "authorId": "144691205",
                    "name": "Bao Ge"
                },
                {
                    "authorId": "3080513",
                    "name": "Yixuan Yuan"
                },
                {
                    "authorId": "2150038187",
                    "name": "Dinggang Shen"
                },
                {
                    "authorId": "2115345993",
                    "name": "Tianming Liu"
                },
                {
                    "authorId": "2108086798",
                    "name": "Shu Zhang"
                }
            ],
            "doi": "10.48550/arXiv.2307.00855",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "7619a98ef077c8f75e0bfb98953457649209e07e",
            "title": "Review of Large Vision Models and Visual Prompt Engineering",
            "url": "https://www.semanticscholar.org/paper/7619a98ef077c8f75e0bfb98953457649209e07e",
            "venue": "Meta-Radiology",
            "year": 2023
        },
        {
            "arxivId": "2306.05499",
            "authors": [
                {
                    "authorId": "2153627626",
                    "name": "Yi Liu"
                },
                {
                    "authorId": "73776889",
                    "name": "Gelei Deng"
                },
                {
                    "authorId": "22799258",
                    "name": "Yuekang Li"
                },
                {
                    "authorId": "3088630",
                    "name": "Kailong Wang"
                },
                {
                    "authorId": "2146331573",
                    "name": "Tianwei Zhang"
                },
                {
                    "authorId": "39584070",
                    "name": "Yepang Liu"
                },
                {
                    "authorId": null,
                    "name": "Haoyu Wang"
                },
                {
                    "authorId": "2124949853",
                    "name": "Yanhong Zheng"
                },
                {
                    "authorId": "2152798056",
                    "name": "Yang Liu"
                }
            ],
            "doi": "10.48550/arXiv.2306.05499",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "db4cf9f6a653d5c15973e836c800ea47743251ae",
            "title": "Prompt Injection attack against LLM-integrated Applications",
            "url": "https://www.semanticscholar.org/paper/db4cf9f6a653d5c15973e836c800ea47743251ae",
            "venue": "ArXiv",
            "year": 2023
        },
        {
            "arxivId": "2302.12173",
            "authors": [
                {
                    "authorId": "2209385653",
                    "name": "Kai Greshake"
                },
                {
                    "authorId": "1383113350",
                    "name": "Sahar Abdelnabi"
                },
                {
                    "authorId": "2112134932",
                    "name": "Shailesh Mishra"
                },
                {
                    "authorId": "93808977",
                    "name": "C. Endres"
                },
                {
                    "authorId": "144227650",
                    "name": "Thorsten Holz"
                },
                {
                    "authorId": "1739548",
                    "name": "Mario Fritz"
                }
            ],
            "doi": "10.1145/3605764.3623985",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "705e49afd92130f2bc1e0d4d0b1f6cb14e88803f",
            "title": "Not What You've Signed Up For: Compromising Real-World LLM-Integrated Applications with Indirect Prompt Injection",
            "url": "https://www.semanticscholar.org/paper/705e49afd92130f2bc1e0d4d0b1f6cb14e88803f",
            "venue": "AISec@CCS",
            "year": 2023
        },
        {
            "arxivId": "2209.02128",
            "authors": [
                {
                    "authorId": "2184138316",
                    "name": "Hezekiah J. Branch"
                },
                {
                    "authorId": "2184139310",
                    "name": "Jonathan Rodriguez Cefalu"
                },
                {
                    "authorId": "2184138769",
                    "name": "Jeremy McHugh"
                },
                {
                    "authorId": "2184138995",
                    "name": "Leyla Hujer"
                },
                {
                    "authorId": "2125938586",
                    "name": "Aditya Bahl"
                },
                {
                    "authorId": "2184138072",
                    "name": "Daniel del Castillo Iglesias"
                },
                {
                    "authorId": "104440832",
                    "name": "Ron Heichman"
                },
                {
                    "authorId": "2184138704",
                    "name": "Ramesh Darwishi"
                }
            ],
            "doi": "10.48550/arXiv.2209.02128",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "2098244c530933e92cbb72217e43b918dce25e23",
            "title": "Evaluating the Susceptibility of Pre-Trained Language Models via Handcrafted Adversarial Examples",
            "url": "https://www.semanticscholar.org/paper/2098244c530933e92cbb72217e43b918dce25e23",
            "venue": "ArXiv",
            "year": 2022
        },
        {
            "arxivId": "2202.10054",
            "authors": [
                {
                    "authorId": "32423266",
                    "name": "Ananya Kumar"
                },
                {
                    "authorId": "2655157",
                    "name": "Aditi Raghunathan"
                },
                {
                    "authorId": "48368647",
                    "name": "Robbie Jones"
                },
                {
                    "authorId": "2114186424",
                    "name": "Tengyu Ma"
                },
                {
                    "authorId": "145419642",
                    "name": "Percy Liang"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "29b77089a0a40f46372ce2dca9c3bb2dd5d46b1d",
            "title": "Fine-Tuning can Distort Pretrained Features and Underperform Out-of-Distribution",
            "url": "https://www.semanticscholar.org/paper/29b77089a0a40f46372ce2dca9c3bb2dd5d46b1d",
            "venue": "ICLR",
            "year": 2022
        },
        {
            "arxivId": "2111.04578",
            "authors": [
                {
                    "authorId": "2115199173",
                    "name": "Dongyue Li"
                },
                {
                    "authorId": "40975176",
                    "name": "Hongyang Zhang"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "2e078383ab13a22eb84b749a902a5c60935b427b",
            "title": "Improved Regularization and Robustness for Fine-tuning in Neural Networks",
            "url": "https://www.semanticscholar.org/paper/2e078383ab13a22eb84b749a902a5c60935b427b",
            "venue": "NeurIPS",
            "year": 2021
        }
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "title": "Signed-Prompt: A New Approach to Prevent Prompt Injection Attacks Against LLM-Integrated Applications",
    "topics": [],
    "url": "https://www.semanticscholar.org/paper/2742c3d77c4aa6d023b7dfc77984ad10e6aae274",
    "venue": "arXiv.org",
    "year": 2024
}
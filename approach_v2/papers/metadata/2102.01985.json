{
    "abstract": "Reinforcement learning algorithms are typically geared towards optimizing the expected return of an agent. However, in many practical applications, low variance in the return is desired to ensure the reliability of an algorithm. In this paper, we propose on-policy and off-policy actor-critic algorithms that optimize a performance criterion involving both mean and variance in the return. Previous work uses the second moment of return to estimate the variance indirectly. Instead, we use a much simpler recently proposed direct variance estimator which updates the estimates incrementally using temporal difference methods. Using the variance-penalized criterion, we guarantee the convergence of our algorithm to locally optimal policies for finite state action Markov decision processes. We demonstrate the utility of our algorithm in tabular and continuous MuJoCo domains. Our approach not only performs on par with actor-critic and prior variance-penalization baselines in terms of expected return, but also generates trajectories which have lower variance in the return.",
    "arxivId": "2102.01985",
    "authors": [
        {
            "authorId": "47636292",
            "name": "Arushi Jain",
            "url": "https://www.semanticscholar.org/author/47636292"
        },
        {
            "authorId": "2047712887",
            "name": "Gandharv Patil",
            "url": "https://www.semanticscholar.org/author/2047712887"
        },
        {
            "authorId": "50658722",
            "name": "Ayush Jain",
            "url": "https://www.semanticscholar.org/author/50658722"
        },
        {
            "authorId": "38562041",
            "name": "Khimya Khetarpal",
            "url": "https://www.semanticscholar.org/author/38562041"
        },
        {
            "authorId": "144368601",
            "name": "Doina Precup",
            "url": "https://www.semanticscholar.org/author/144368601"
        }
    ],
    "citationVelocity": 0,
    "citations": [
        {
            "arxivId": "2408.08812",
            "authors": [
                {
                    "authorId": "2312329643",
                    "name": "Mohamad Fares El Hajj Chehade"
                },
                {
                    "authorId": "3387859",
                    "name": "A. S. Bedi"
                },
                {
                    "authorId": "2316522826",
                    "name": "Amy Zhang"
                },
                {
                    "authorId": "2312399789",
                    "name": "Hao Zhu"
                }
            ],
            "doi": "10.48550/arXiv.2408.08812",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "afe50a912cd743f24a820b3e6495ff4923432a8a",
            "title": "CAT: Caution Aware Transfer in Reinforcement Learning via Distributional Risk",
            "url": "https://www.semanticscholar.org/paper/afe50a912cd743f24a820b3e6495ff4923432a8a",
            "venue": "ArXiv",
            "year": 2024
        },
        {
            "arxivId": "2405.07838",
            "authors": [
                {
                    "authorId": "2301177158",
                    "name": "Arushi Jain"
                },
                {
                    "authorId": "34719248",
                    "name": "Josiah P. Hanna"
                },
                {
                    "authorId": "2249762747",
                    "name": "D. Precup"
                }
            ],
            "doi": "10.48550/arXiv.2405.07838",
            "intent": [
                "background",
                "methodology"
            ],
            "isInfluential": true,
            "paperId": "4ed4fff9e100dbfffa23a905b65fdec66436c656",
            "title": "Adaptive Exploration for Data-Efficient General Value Function Evaluations",
            "url": "https://www.semanticscholar.org/paper/4ed4fff9e100dbfffa23a905b65fdec66436c656",
            "venue": "ArXiv",
            "year": 2024
        },
        {
            "arxivId": "2310.13230",
            "authors": [
                {
                    "authorId": "123903496",
                    "name": "Weiye Zhao"
                },
                {
                    "authorId": "2261358544",
                    "name": "Feihan Li"
                },
                {
                    "authorId": "2108935699",
                    "name": "Yifan Sun"
                },
                {
                    "authorId": "2118230590",
                    "name": "Rui Chen"
                },
                {
                    "authorId": "51045762",
                    "name": "Tianhao Wei"
                },
                {
                    "authorId": "2238180276",
                    "name": "Changliu Liu"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "ff437eb6108d35b1b70ebb98f5085a5c0154086b",
            "title": "Absolute Policy Optimization: Enhancing Lower Probability Bound of Performance with High Confidence",
            "url": "https://www.semanticscholar.org/paper/ff437eb6108d35b1b70ebb98f5085a5c0154086b",
            "venue": "ICML",
            "year": 2023
        },
        {
            "arxivId": "2302.14182",
            "authors": [
                {
                    "authorId": "1400599328",
                    "name": "Michele Garibbo"
                },
                {
                    "authorId": "2155503163",
                    "name": "Maxime Robeyns"
                },
                {
                    "authorId": "2724259",
                    "name": "L. Aitchison"
                }
            ],
            "doi": "10.48550/arXiv.2302.14182",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "9b8a0da395016bb27da95acd5402511e6857e456",
            "title": "Taylor TD-learning",
            "url": "https://www.semanticscholar.org/paper/9b8a0da395016bb27da95acd5402511e6857e456",
            "venue": "NeurIPS",
            "year": 2023
        },
        {
            "arxivId": "2212.13379",
            "authors": [
                {
                    "authorId": "24907680",
                    "name": "Tanvi Verma"
                },
                {
                    "authorId": "1718824",
                    "name": "Pradeep Varakantham"
                }
            ],
            "doi": "10.48550/arXiv.2212.13379",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "1790e1e4f86cad6d823898010b45694fdb80692c",
            "title": "Learning Individual Policies in Large Multi-agent Systems through Local Variance Minimization",
            "url": "https://www.semanticscholar.org/paper/1790e1e4f86cad6d823898010b45694fdb80692c",
            "venue": "ArXiv",
            "year": 2022
        },
        {
            "arxivId": "2206.06841",
            "authors": [
                {
                    "authorId": "94347766",
                    "name": "Pierre Clavier"
                },
                {
                    "authorId": "3316868",
                    "name": "S. Allassonni\u00e8re"
                },
                {
                    "authorId": "1845031",
                    "name": "E. L. Pennec"
                }
            ],
            "doi": "10.48550/arXiv.2206.06841",
            "intent": [],
            "isInfluential": false,
            "paperId": "bbfbd585ca143a69afa26101d7a5a0cf2548aec0",
            "title": "Robust Reinforcement Learning with Distributional Risk-averse formulation",
            "url": "https://www.semanticscholar.org/paper/bbfbd585ca143a69afa26101d7a5a0cf2548aec0",
            "venue": "ArXiv",
            "year": 2022
        },
        {
            "arxivId": "2107.02711",
            "authors": [
                {
                    "authorId": "51020953",
                    "name": "Tengyu Xu"
                },
                {
                    "authorId": "150358650",
                    "name": "Zhuoran Yang"
                },
                {
                    "authorId": "50218397",
                    "name": "Zhaoran Wang"
                },
                {
                    "authorId": "50014661",
                    "name": "Yingbin Liang"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "7b200d0435ca9594f16d37e1cbea665928d9a9a8",
            "title": "A Unified Off-Policy Evaluation Approach for General Value Function",
            "url": "https://www.semanticscholar.org/paper/7b200d0435ca9594f16d37e1cbea665928d9a9a8",
            "venue": "ArXiv",
            "year": 2021
        },
        {
            "arxivId": "2105.14127",
            "authors": [
                {
                    "authorId": "52225987",
                    "name": "Michael Gimelfarb"
                },
                {
                    "authorId": "143999673",
                    "name": "Andr\u00e9 Barreto"
                },
                {
                    "authorId": "1732536",
                    "name": "S. Sanner"
                },
                {
                    "authorId": "2143724945",
                    "name": "Chi-Guhn Lee"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "daa02add19d5951a447a5d452c540c93b9d029af",
            "title": "Risk-Aware Transfer in Reinforcement Learning using Successor Features",
            "url": "https://www.semanticscholar.org/paper/daa02add19d5951a447a5d452c540c93b9d029af",
            "venue": "NeurIPS",
            "year": 2021
        },
        {
            "arxivId": "1807.08060",
            "authors": [
                {
                    "authorId": "47636292",
                    "name": "Arushi Jain"
                },
                {
                    "authorId": "38562041",
                    "name": "Khimya Khetarpal"
                },
                {
                    "authorId": "144368601",
                    "name": "Doina Precup"
                }
            ],
            "doi": "10.1017/S0269888921000035",
            "intent": [],
            "isInfluential": false,
            "paperId": "24594fd86012b69078ea7283e1334b05a5ce3afb",
            "title": "Safe option-critic: learning safety in the option-critic architecture",
            "url": "https://www.semanticscholar.org/paper/24594fd86012b69078ea7283e1334b05a5ce3afb",
            "venue": "The Knowledge Engineering Review",
            "year": 2018
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "51020953",
                    "name": "Tengyu Xu"
                },
                {
                    "authorId": "150358650",
                    "name": "Zhuoran Yang"
                },
                {
                    "authorId": "50218397",
                    "name": "Zhaoran Wang"
                },
                {
                    "authorId": "50014661",
                    "name": "Yingbin Liang"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "87665b61f29bd9803d4056110a9d760ae45e8e38",
            "title": "A Unifying Framework of Off-Policy General Value Function Evaluation",
            "url": "https://www.semanticscholar.org/paper/87665b61f29bd9803d4056110a9d760ae45e8e38",
            "venue": "NeurIPS",
            "year": 2022
        }
    ],
    "corpusId": 231786293,
    "doi": "10.1609/aaai.v35i9.16964",
    "fieldsOfStudy": [
        "Computer Science"
    ],
    "influentialCitationCount": 1,
    "isOpenAccess": true,
    "isPublisherLicensed": true,
    "is_open_access": true,
    "is_publisher_licensed": true,
    "numCitedBy": 10,
    "numCiting": 47,
    "paperId": "08e7fda8b3077db9dbf7630ff5424582909a002a",
    "references": [
        {
            "arxivId": "1912.03193",
            "authors": [
                {
                    "authorId": "153641684",
                    "name": "Qianggang Ding"
                },
                {
                    "authorId": "50425528",
                    "name": "Sifan Wu"
                },
                {
                    "authorId": "2156232554",
                    "name": "Hao Sun"
                },
                {
                    "authorId": "15563288",
                    "name": "Jiadong Guo"
                },
                {
                    "authorId": "2148902488",
                    "name": "Jian Guo"
                }
            ],
            "doi": "10.24963/ijcai.2020/632",
            "intent": [],
            "isInfluential": false,
            "paperId": "2bcda4b9698f1315d40c692b403b379db6d276f5",
            "title": "Risk-Averse Trust Region Optimization for Reward-Volatility Reduction",
            "url": "https://www.semanticscholar.org/paper/2bcda4b9698f1315d40c692b403b379db6d276f5",
            "venue": "IJCAI",
            "year": 2019
        },
        {
            "arxivId": "1906.09090",
            "authors": [
                {
                    "authorId": "2082107242",
                    "name": "David Nass"
                },
                {
                    "authorId": "29505409",
                    "name": "B. Belousov"
                },
                {
                    "authorId": "145197867",
                    "name": "Jan Peters"
                }
            ],
            "doi": "10.1109/IROS40897.2019.8967699",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "f4d49838d22cfb290bebaa4cf3adbb993e99d012",
            "title": "Entropic Risk Measure in Policy Search",
            "url": "https://www.semanticscholar.org/paper/f4d49838d22cfb290bebaa4cf3adbb993e99d012",
            "venue": "2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)",
            "year": 2019
        },
        {
            "arxivId": "1805.11074",
            "authors": [
                {
                    "authorId": "3393407",
                    "name": "Chen Tessler"
                },
                {
                    "authorId": "3187297",
                    "name": "D. Mankowitz"
                },
                {
                    "authorId": "1712535",
                    "name": "Shie Mannor"
                }
            ],
            "doi": null,
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "cb7c479a36520da1caeeec67db10772351a390c6",
            "title": "Reward Constrained Policy Optimization",
            "url": "https://www.semanticscholar.org/paper/cb7c479a36520da1caeeec67db10772351a390c6",
            "venue": "ICLR",
            "year": 2018
        },
        {
            "arxivId": "1707.06347",
            "authors": [
                {
                    "authorId": "47971768",
                    "name": "John Schulman"
                },
                {
                    "authorId": "143909660",
                    "name": "Filip Wolski"
                },
                {
                    "authorId": "6515819",
                    "name": "Prafulla Dhariwal"
                },
                {
                    "authorId": "38909097",
                    "name": "Alec Radford"
                },
                {
                    "authorId": "2067138712",
                    "name": "Oleg Klimov"
                }
            ],
            "doi": null,
            "intent": [
                "background",
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "dce6f9d4017b1785979e7520fd0834ef8cf02f4b",
            "title": "Proximal Policy Optimization Algorithms",
            "url": "https://www.semanticscholar.org/paper/dce6f9d4017b1785979e7520fd0834ef8cf02f4b",
            "venue": "ArXiv",
            "year": 2017
        },
        {
            "arxivId": "1707.06887",
            "authors": [
                {
                    "authorId": "1792298",
                    "name": "Marc G. Bellemare"
                },
                {
                    "authorId": "2605877",
                    "name": "Will Dabney"
                },
                {
                    "authorId": "1708654",
                    "name": "R. Munos"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "c1f4ef741242d629d1f56e442a09a7ba29595a0e",
            "title": "A Distributional Perspective on Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/c1f4ef741242d629d1f56e442a09a7ba29595a0e",
            "venue": "ICML",
            "year": 2017
        },
        {
            "arxivId": "1606.02647",
            "authors": [
                {
                    "authorId": "1708654",
                    "name": "R. Munos"
                },
                {
                    "authorId": "3382781",
                    "name": "T. Stepleton"
                },
                {
                    "authorId": "3134710",
                    "name": "A. Harutyunyan"
                },
                {
                    "authorId": "1792298",
                    "name": "Marc G. Bellemare"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "dc3e905bfb27d21675ee1720413e007b014b37d3",
            "title": "Safe and Efficient Off-Policy Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/dc3e905bfb27d21675ee1720413e007b014b37d3",
            "venue": "NIPS",
            "year": 2016
        },
        {
            "arxivId": "1606.01540",
            "authors": [
                {
                    "authorId": "2065151121",
                    "name": "Greg Brockman"
                },
                {
                    "authorId": "34415167",
                    "name": "Vicki Cheung"
                },
                {
                    "authorId": "152877508",
                    "name": "Ludwig Pettersson"
                },
                {
                    "authorId": "2113526509",
                    "name": "Jonas Schneider"
                },
                {
                    "authorId": "47971768",
                    "name": "John Schulman"
                },
                {
                    "authorId": "2109541439",
                    "name": "Jie Tang"
                },
                {
                    "authorId": "2563432",
                    "name": "Wojciech Zaremba"
                }
            ],
            "doi": null,
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "2b10281297ee001a9f3f4ea1aa9bea6b638c27df",
            "title": "OpenAI Gym",
            "url": "https://www.semanticscholar.org/paper/2b10281297ee001a9f3f4ea1aa9bea6b638c27df",
            "venue": "ArXiv",
            "year": 2016
        },
        {
            "arxivId": "1607.00446",
            "authors": [
                {
                    "authorId": "144542337",
                    "name": "Martha White"
                },
                {
                    "authorId": "35367799",
                    "name": "A. White"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "669ed7cf06ad2ab9a9658897ad67515235f2f7c4",
            "title": "A Greedy Approach to Adapting the Trace Parameter for Temporal Difference Learning",
            "url": "https://www.semanticscholar.org/paper/669ed7cf06ad2ab9a9658897ad67515235f2f7c4",
            "venue": "AAMAS",
            "year": 2016
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "143640165",
                    "name": "P. Thomas"
                },
                {
                    "authorId": "1709005",
                    "name": "Georgios Theocharous"
                },
                {
                    "authorId": "1678622",
                    "name": "M. Ghavamzadeh"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "127cf09abf45c9d3cb4d859a72e6cc67acc2b57b",
            "title": "High Confidence Policy Improvement",
            "url": "https://www.semanticscholar.org/paper/127cf09abf45c9d3cb4d859a72e6cc67acc2b57b",
            "venue": "ICML",
            "year": 2015
        },
        {
            "arxivId": "1506.02438",
            "authors": [
                {
                    "authorId": "47971768",
                    "name": "John Schulman"
                },
                {
                    "authorId": "29912342",
                    "name": "Philipp Moritz"
                },
                {
                    "authorId": "1736651",
                    "name": "S. Levine"
                },
                {
                    "authorId": "1694621",
                    "name": "Michael I. Jordan"
                },
                {
                    "authorId": "1689992",
                    "name": "P. Abbeel"
                }
            ],
            "doi": null,
            "intent": [
                "methodology"
            ],
            "isInfluential": true,
            "paperId": "d316c82c12cf4c45f9e85211ef3d1fa62497bff8",
            "title": "High-Dimensional Continuous Control Using Generalized Advantage Estimation",
            "url": "https://www.semanticscholar.org/paper/d316c82c12cf4c45f9e85211ef3d1fa62497bff8",
            "venue": "ICLR",
            "year": 2015
        },
        {
            "arxivId": "1406.3339",
            "authors": [
                {
                    "authorId": "1819830",
                    "name": "Yinlam Chow"
                },
                {
                    "authorId": "1678622",
                    "name": "M. Ghavamzadeh"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "fd85c9deeee062cf4aeeb682274b3c3c073270ba",
            "title": "Algorithms for CVaR Optimization in MDPs",
            "url": "https://www.semanticscholar.org/paper/fd85c9deeee062cf4aeeb682274b3c3c073270ba",
            "venue": "NIPS",
            "year": 2014
        },
        {
            "arxivId": "1404.3862",
            "authors": [
                {
                    "authorId": "3025260",
                    "name": "Aviv Tamar"
                },
                {
                    "authorId": "2136461",
                    "name": "Yonatan Glassner"
                },
                {
                    "authorId": "1712535",
                    "name": "Shie Mannor"
                }
            ],
            "doi": "10.1609/aaai.v29i1.9561",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "2e939ed3bb378ea966bf9f710fc1138f4e16ef38",
            "title": "Optimizing the CVaR via Sampling",
            "url": "https://www.semanticscholar.org/paper/2e939ed3bb378ea966bf9f710fc1138f4e16ef38",
            "venue": "AAAI",
            "year": 2014
        },
        {
            "arxivId": "1403.6530",
            "authors": [
                {
                    "authorId": "1389984923",
                    "name": "Prashanth L.A."
                },
                {
                    "authorId": "1678622",
                    "name": "M. Ghavamzadeh"
                }
            ],
            "doi": "10.1007/s10994-016-5569-5",
            "intent": [
                "background",
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "e1b05335f3ffd5bd1b7555e0b3a1b19f9ec07f0f",
            "title": "Variance-constrained actor-critic algorithms for discounted and average reward MDPs",
            "url": "https://www.semanticscholar.org/paper/e1b05335f3ffd5bd1b7555e0b3a1b19f9ec07f0f",
            "venue": "Machine Learning",
            "year": 2014
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "1389984923",
                    "name": "Prashanth L.A."
                },
                {
                    "authorId": "1678622",
                    "name": "M. Ghavamzadeh"
                }
            ],
            "doi": null,
            "intent": [
                "background",
                "methodology"
            ],
            "isInfluential": true,
            "paperId": "b6bd3281d095aefe77f360edf8f7776524aba20b",
            "title": "Actor-Critic Algorithms for Risk-Sensitive MDPs",
            "url": "https://www.semanticscholar.org/paper/b6bd3281d095aefe77f360edf8f7776524aba20b",
            "venue": "NIPS",
            "year": 2013
        },
        {
            "arxivId": "1311.2097",
            "authors": [
                {
                    "authorId": "2117688020",
                    "name": "Yun Shen"
                },
                {
                    "authorId": "2485388",
                    "name": "Michael J. Tobia"
                },
                {
                    "authorId": "1746788",
                    "name": "T. Sommer"
                },
                {
                    "authorId": "1743272",
                    "name": "K. Obermayer"
                }
            ],
            "doi": "10.1162/NECO_a_00600",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "f0c4b7568f378e652645232e66a1dab4c5b5293f",
            "title": "Risk-Sensitive Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/f0c4b7568f378e652645232e66a1dab4c5b5293f",
            "venue": "Neural Computation",
            "year": 2013
        },
        {
            "arxivId": "1310.3697",
            "authors": [
                {
                    "authorId": "3025260",
                    "name": "Aviv Tamar"
                },
                {
                    "authorId": "1712535",
                    "name": "Shie Mannor"
                }
            ],
            "doi": null,
            "intent": [
                "background",
                "methodology"
            ],
            "isInfluential": true,
            "paperId": "3c3843fa74ac0c06dfa086c5f425c235551106f6",
            "title": "Variance Adjusted Actor Critic Algorithms",
            "url": "https://www.semanticscholar.org/paper/3c3843fa74ac0c06dfa086c5f425c235551106f6",
            "venue": "ArXiv",
            "year": 2013
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "3025260",
                    "name": "Aviv Tamar"
                },
                {
                    "authorId": "9440777",
                    "name": "Dotan Di Castro"
                },
                {
                    "authorId": "1712535",
                    "name": "Shie Mannor"
                }
            ],
            "doi": null,
            "intent": [
                "background",
                "methodology"
            ],
            "isInfluential": true,
            "paperId": "f9c8a7c319c303bac15a2bdd79cb16351f1fcd39",
            "title": "Temporal Difference Methods for the Variance of the Reward To Go",
            "url": "https://www.semanticscholar.org/paper/f9c8a7c319c303bac15a2bdd79cb16351f1fcd39",
            "venue": "ICML",
            "year": 2013
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "40603378",
                    "name": "Xianping Guo"
                },
                {
                    "authorId": "2878900",
                    "name": "Liuer Ye"
                },
                {
                    "authorId": "145050324",
                    "name": "G. Yin"
                }
            ],
            "doi": "10.1016/j.ejor.2012.01.051",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "843ebaa9630601c12e7b898d6878b5c5d51544a4",
            "title": "A mean-variance optimization problem for discounted Markov decision processes",
            "url": "https://www.semanticscholar.org/paper/843ebaa9630601c12e7b898d6878b5c5d51544a4",
            "venue": "Eur. J. Oper. Res.",
            "year": 2012
        },
        {
            "arxivId": "1206.6404",
            "authors": [
                {
                    "authorId": "9440777",
                    "name": "Dotan Di Castro"
                },
                {
                    "authorId": "3025260",
                    "name": "Aviv Tamar"
                },
                {
                    "authorId": "1712535",
                    "name": "Shie Mannor"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "e27fb84fccd3d9724df8ce35fe14149da5de3251",
            "title": "Policy Gradients with Variance Related Risk Criteria",
            "url": "https://www.semanticscholar.org/paper/e27fb84fccd3d9724df8ce35fe14149da5de3251",
            "venue": "ICML",
            "year": 2012
        },
        {
            "arxivId": "1203.3497",
            "authors": [
                {
                    "authorId": "2273298",
                    "name": "Tetsuro Morimura"
                },
                {
                    "authorId": "67154907",
                    "name": "Masashi Sugiyama"
                },
                {
                    "authorId": "2785830",
                    "name": "H. Kashima"
                },
                {
                    "authorId": "40308003",
                    "name": "Hirotaka Hachiya"
                },
                {
                    "authorId": "145876882",
                    "name": "Toshiyuki TANAKA"
                }
            ],
            "doi": null,
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "8948464fc8dbe49311fcd6610f96bcd75a03bae0",
            "title": "Parametric Return Density Estimation for Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/8948464fc8dbe49311fcd6610f96bcd75a03bae0",
            "venue": "UAI",
            "year": 2010
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2066770",
                    "name": "A. Basu"
                },
                {
                    "authorId": "32838090",
                    "name": "Tirthankar Bhattacharyya"
                },
                {
                    "authorId": "2136886",
                    "name": "V. Borkar"
                }
            ],
            "doi": "10.1287/moor.1080.0324",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "aa59dedb151926bce19789eae750010d4ee94f02",
            "title": "A Learning Algorithm for Risk-Sensitive Cost",
            "url": "https://www.semanticscholar.org/paper/aa59dedb151926bce19789eae750010d4ee94f02",
            "venue": "Math. Oper. Res.",
            "year": 2008
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2136886",
                    "name": "V. Borkar"
                }
            ],
            "doi": "10.1007/978-93-86279-38-5",
            "intent": [
                "background",
                "methodology"
            ],
            "isInfluential": true,
            "paperId": "d889403623f3e4717b233fc4ed19718f950e3428",
            "title": "Stochastic Approximation: A Dynamical Systems Viewpoint",
            "url": "https://www.semanticscholar.org/paper/d889403623f3e4717b233fc4ed19718f950e3428",
            "venue": "",
            "year": 2008
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "1722628",
                    "name": "A. Nilim"
                },
                {
                    "authorId": "1701847",
                    "name": "L. Ghaoui"
                }
            ],
            "doi": "10.1287/opre.1050.0216",
            "intent": [],
            "isInfluential": false,
            "paperId": "6db16608fccddef51202af84112b34cfebfbe20a",
            "title": "Robust Control of Markov Decision Processes with Uncertain Transition Matrices",
            "url": "https://www.semanticscholar.org/paper/6db16608fccddef51202af84112b34cfebfbe20a",
            "venue": "Oper. Res.",
            "year": 2005
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "145570534",
                    "name": "G. Iyengar"
                }
            ],
            "doi": "10.1287/MOOR.1040.0129",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "ab4a1c4dfe23b3a1e3d077df467452cc68f64de8",
            "title": "Robust Dynamic Programming",
            "url": "https://www.semanticscholar.org/paper/ab4a1c4dfe23b3a1e3d077df467452cc68f64de8",
            "venue": "Math. Oper. Res.",
            "year": 2005
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2136886",
                    "name": "V. Borkar"
                }
            ],
            "doi": "10.1287/moor.27.2.294.324",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "0eded48f3879d261d254dfbd1ff7e13f899a9f01",
            "title": "Q-Learning for Risk-Sensitive Control",
            "url": "https://www.semanticscholar.org/paper/0eded48f3879d261d254dfbd1ff7e13f899a9f01",
            "venue": "Math. Oper. Res.",
            "year": 2002
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2136886",
                    "name": "V. Borkar"
                }
            ],
            "doi": "10.1016/S0167-6911(01)00152-9",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "0993d3afc4c74500919c35e3254acd360f14be78",
            "title": "A sensitivity formula for risk-sensitive cost and the actor-critic algorithm",
            "url": "https://www.semanticscholar.org/paper/0993d3afc4c74500919c35e3254acd360f14be78",
            "venue": "Syst. Control. Lett.",
            "year": 2001
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "1699645",
                    "name": "R. Sutton"
                },
                {
                    "authorId": "145689002",
                    "name": "David A. McAllester"
                },
                {
                    "authorId": "1699868",
                    "name": "Satinder Singh"
                },
                {
                    "authorId": "144830983",
                    "name": "Y. Mansour"
                }
            ],
            "doi": null,
            "intent": [
                "background",
                "methodology"
            ],
            "isInfluential": true,
            "paperId": "a20f0ce0616def7cc9a87446c228906cd5da093b",
            "title": "Policy Gradient Methods for Reinforcement Learning with Function Approximation",
            "url": "https://www.semanticscholar.org/paper/a20f0ce0616def7cc9a87446c228906cd5da093b",
            "venue": "NIPS",
            "year": 1999
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "1699645",
                    "name": "R. Sutton"
                },
                {
                    "authorId": "144368601",
                    "name": "Doina Precup"
                },
                {
                    "authorId": "1699868",
                    "name": "Satinder Singh"
                }
            ],
            "doi": "10.1016/S0004-3702(99)00052-1",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "0e7638dc16a5e5e9e46c91272bfb9c3dd242ef6d",
            "title": "Between MDPs and Semi-MDPs: A Framework for Temporal Abstraction in Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/0e7638dc16a5e5e9e46c91272bfb9c3dd242ef6d",
            "venue": "Artif. Intell.",
            "year": 1999
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "143665732",
                    "name": "E. Altman"
                }
            ],
            "doi": "10.1201/9781315140223",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "3cc2608fd77b9b65f5bd378e8797b2ab1b8acde7",
            "title": "Constrained Markov Decision Processes",
            "url": "https://www.semanticscholar.org/paper/3cc2608fd77b9b65f5bd378e8797b2ab1b8acde7",
            "venue": "",
            "year": 1999
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "3121291",
                    "name": "D. Duffie"
                },
                {
                    "authorId": "144656245",
                    "name": "Jun Pan"
                }
            ],
            "doi": "10.3905/jod.1997.407971",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "209987cddd1174114072c15fb7b6c440b835237e",
            "title": "An Overview of Value at Risk",
            "url": "https://www.semanticscholar.org/paper/209987cddd1174114072c15fb7b6c440b835237e",
            "venue": "",
            "year": 1997
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2136886",
                    "name": "V. Borkar"
                }
            ],
            "doi": "10.1016/S0167-6911(97)90015-3",
            "intent": [
                "background",
                "methodology"
            ],
            "isInfluential": true,
            "paperId": "5c29049c6cc7e93bd42ccd55d70a5b92120ceec6",
            "title": "Stochastic approximation with two time scales",
            "url": "https://www.semanticscholar.org/paper/5c29049c6cc7e93bd42ccd55d70a5b92120ceec6",
            "venue": "",
            "year": 1997
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "143664817",
                    "name": "D. White"
                }
            ],
            "doi": "10.1007/BF01719453",
            "intent": [
                "background"
            ],
            "isInfluential": true,
            "paperId": "dff1e062bb295eff9d8b9470999a37975a332173",
            "title": "A mathematical programming approach to a problem in variance penalised Markov decision processes",
            "url": "https://www.semanticscholar.org/paper/dff1e062bb295eff9d8b9470999a37975a332173",
            "venue": "",
            "year": 1994
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "3159358",
                    "name": "W. Sharpe"
                }
            ],
            "doi": "10.3905/JPM.1994.409501",
            "intent": [
                "background"
            ],
            "isInfluential": true,
            "paperId": "bb460c37a38bf9655a931a42f1c7ae4be8146455",
            "title": "The Sharpe Ratio",
            "url": "https://www.semanticscholar.org/paper/bb460c37a38bf9655a931a42f1c7ae4be8146455",
            "venue": "",
            "year": 1994
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "1701499",
                    "name": "J. Filar"
                },
                {
                    "authorId": "2513431",
                    "name": "L. Kallenberg"
                },
                {
                    "authorId": "2110727312",
                    "name": "Huey-Miin Lee"
                }
            ],
            "doi": "10.1287/moor.14.1.147",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "05fde9039a3c7db11a7e0f933a59fe94505c46ad",
            "title": "Variance-Penalized Markov Decision Processes",
            "url": "https://www.semanticscholar.org/paper/05fde9039a3c7db11a7e0f933a59fe94505c46ad",
            "venue": "Math. Oper. Res.",
            "year": 1989
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2067386926",
                    "name": "P. Todd"
                },
                {
                    "authorId": "3159358",
                    "name": "W. Sharpe"
                },
                {
                    "authorId": "50018942",
                    "name": "H. Markowitz"
                },
                {
                    "authorId": "123643325",
                    "name": "G. P. Todd"
                },
                {
                    "authorId": "3159358",
                    "name": "W. Sharpe"
                }
            ],
            "doi": "10.2307/2328607",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "157e5e15bb706fa1cf4df426a9835f45af2b4a12",
            "title": "Mean-Variance Analysis in Portfolio Choice and Capital Markets",
            "url": "https://www.semanticscholar.org/paper/157e5e15bb706fa1cf4df426a9835f45af2b4a12",
            "venue": "",
            "year": 1987
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2948080",
                    "name": "M. J. Sobel"
                }
            ],
            "doi": "10.2307/3213832",
            "intent": [
                "background",
                "methodology"
            ],
            "isInfluential": true,
            "paperId": "216ef8a1d170e88776b7b65f2342a94efdf4d68e",
            "title": "The variance of discounted Markov decision processes",
            "url": "https://www.semanticscholar.org/paper/216ef8a1d170e88776b7b65f2342a94efdf4d68e",
            "venue": "Journal of Applied Probability",
            "year": 1982
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2237724978",
                    "name": "Alan Stuart"
                },
                {
                    "authorId": "2237725584",
                    "name": "Harry M. Markowitz"
                }
            ],
            "doi": "10.2307/3006625",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "1d8f723ae85b96e29380752ac598889fca8cc653",
            "title": "Portfolio Selection: Efficient Diversification of Investments",
            "url": "https://www.semanticscholar.org/paper/1d8f723ae85b96e29380752ac598889fca8cc653",
            "venue": "",
            "year": 1959
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "3420168",
                    "name": "Craig Sherstan"
                },
                {
                    "authorId": "35497986",
                    "name": "Dylan R. Ashley"
                },
                {
                    "authorId": "34467301",
                    "name": "Brendan Bennett"
                },
                {
                    "authorId": "145991379",
                    "name": "K. Young"
                },
                {
                    "authorId": "145240145",
                    "name": "Adam White"
                },
                {
                    "authorId": "144542337",
                    "name": "Martha White"
                },
                {
                    "authorId": "1699645",
                    "name": "R. Sutton"
                }
            ],
            "doi": null,
            "intent": [
                "background",
                "methodology"
            ],
            "isInfluential": true,
            "paperId": "e96e9a2c7b02b5200c70f8fee116463d450c65b5",
            "title": "Comparing Direct and Indirect Temporal-Difference Methods for Estimating the Variance of the Return",
            "url": "https://www.semanticscholar.org/paper/e96e9a2c7b02b5200c70f8fee116463d450c65b5",
            "venue": "UAI",
            "year": 2018
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2087057589",
                    "name": "Jonas Schmitt"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "fdee709aef718de16df6a876080aea9abeff79eb",
            "title": "Portfolio Selection Efficient Diversification Of Investments",
            "url": "https://www.semanticscholar.org/paper/fdee709aef718de16df6a876080aea9abeff79eb",
            "venue": "",
            "year": 2016
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2110194270",
                    "name": "Javier Garc\u00eda"
                },
                {
                    "authorId": "143901279",
                    "name": "F. Fern\u00e1ndez"
                }
            ],
            "doi": "10.5555/2789272.2886795",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "c0f2c4104ef6e36bb67022001179887e6600d24d",
            "title": "A comprehensive survey on safe reinforcement learning",
            "url": "https://www.semanticscholar.org/paper/c0f2c4104ef6e36bb67022001179887e6600d24d",
            "venue": "J. Mach. Learn. Res.",
            "year": 2015
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "1786249",
                    "name": "D. Bertsekas"
                }
            ],
            "doi": "10.1007/978-0-387-74759-0_440",
            "intent": [
                "background",
                "methodology"
            ],
            "isInfluential": true,
            "paperId": "b225a9eb169a3530289bf834d3b6e785947959ee",
            "title": "Neuro-Dynamic Programming",
            "url": "https://www.semanticscholar.org/paper/b225a9eb169a3530289bf834d3b6e785947959ee",
            "venue": "Encyclopedia of Optimization",
            "year": 2009
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2587310",
                    "name": "R. Rockafellar"
                },
                {
                    "authorId": "2023902",
                    "name": "S. Uryasev"
                }
            ],
            "doi": "10.21314/JOR.2000.038",
            "intent": [],
            "isInfluential": false,
            "paperId": "58444c142b6ea5c71a435cac7a0b4c66d6c68869",
            "title": "Optimization of conditional value-at risk",
            "url": "https://www.semanticscholar.org/paper/58444c142b6ea5c71a435cac7a0b4c66d6c68869",
            "venue": "",
            "year": 2000
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "50844636",
                    "name": "Vijay R. Konda"
                },
                {
                    "authorId": "144224173",
                    "name": "J. Tsitsiklis"
                }
            ],
            "doi": null,
            "intent": [
                "background",
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "ac4af1df88e178386d782705acc159eaa0c3904a",
            "title": "Actor-Critic Algorithms",
            "url": "https://www.semanticscholar.org/paper/ac4af1df88e178386d782705acc159eaa0c3904a",
            "venue": "NIPS",
            "year": 1999
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2238176724",
                    "name": "R. S. Sutton"
                },
                {
                    "authorId": "1730590",
                    "name": "A. Barto"
                }
            ],
            "doi": "10.1109/TNN.1998.712192",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "97efafdb4a3942ab3efba53ded7413199f79c054",
            "title": "Reinforcement Learning: An Introduction",
            "url": "https://www.semanticscholar.org/paper/97efafdb4a3942ab3efba53ded7413199f79c054",
            "venue": "IEEE Trans. Neural Networks",
            "year": 1998
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2666238",
                    "name": "S. Marcus"
                },
                {
                    "authorId": "2240846045",
                    "name": "Emmanuel Fernn Andez-Gaucherand"
                },
                {
                    "authorId": "2240836608",
                    "name": "Daniel Hernn Andez-Hernn Andez"
                },
                {
                    "authorId": "1718340",
                    "name": "S. Coraluppi"
                },
                {
                    "authorId": "2675288",
                    "name": "P. Fard"
                }
            ],
            "doi": "10.1007/978-1-4612-4120-1_14",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "aa2eb0a72ad35846a1d0d1cff2a2b21cf6902624",
            "title": "Risk Sensitive Markov Decision Processes",
            "url": "https://www.semanticscholar.org/paper/aa2eb0a72ad35846a1d0d1cff2a2b21cf6902624",
            "venue": "",
            "year": 1997
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "49684355",
                    "name": "M. Heger"
                }
            ],
            "doi": "10.1016/b978-1-55860-335-6.50021-0",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "f5d5a699770808228a2de1b5f99e76ce4bd2b9ee",
            "title": "Consideration of Risk in Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/f5d5a699770808228a2de1b5f99e76ce4bd2b9ee",
            "venue": "ICML",
            "year": 1994
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "50018942",
                    "name": "H. Markowitz"
                }
            ],
            "doi": "10.1007/978-1-349-20213-3_21",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "677be75cd088a664d25194c657717cb00c075d17",
            "title": "Mean\u2014Variance Analysis",
            "url": "https://www.semanticscholar.org/paper/677be75cd088a664d25194c657717cb00c075d17",
            "venue": "",
            "year": 1989
        }
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "title": "Variance Penalized On-Policy and Off-Policy Actor-Critic",
    "topics": [],
    "url": "https://www.semanticscholar.org/paper/08e7fda8b3077db9dbf7630ff5424582909a002a",
    "venue": "AAAI Conference on Artificial Intelligence",
    "year": 2021
}
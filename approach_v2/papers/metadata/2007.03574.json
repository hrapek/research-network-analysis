{
    "abstract": "A key challenge in applying reinforcement learning to safety-critical domains is understanding how to balance exploration (needed to attain good performance on the task) with safety (needed to avoid catastrophic failure). Although a growing line of work in reinforcement learning has investigated this area of \"safe exploration,\" most existing techniques either 1) do not guarantee safety during the actual exploration process; and/or 2) limit the problem to a priori known and/or deterministic transition dynamics with strong smoothness assumptions. Addressing this gap, we propose Analogous Safe-state Exploration (ASE), an algorithm for provably safe exploration in MDPs with unknown, stochastic dynamics. Our method exploits analogies between state-action pairs to safely learn a near-optimal policy in a PAC-MDP sense. Additionally, ASE also guides exploration towards the most task-relevant states, which empirically results in significant improvements in terms of sample efficiency, when compared to existing methods.",
    "arxivId": "2007.03574",
    "authors": [
        {
            "authorId": "32019380",
            "name": "Melrose Roderick",
            "url": "https://www.semanticscholar.org/author/32019380"
        },
        {
            "authorId": "34602162",
            "name": "Vaishnavh Nagarajan",
            "url": "https://www.semanticscholar.org/author/34602162"
        },
        {
            "authorId": "145116464",
            "name": "J. Z. Kolter",
            "url": "https://www.semanticscholar.org/author/145116464"
        }
    ],
    "citationVelocity": 0,
    "citations": [
        {
            "arxivId": "2410.23637",
            "authors": [
                {
                    "authorId": "2264461559",
                    "name": "Jeremy McMahan"
                },
                {
                    "authorId": "2263569405",
                    "name": "Xiaojin Zhu"
                }
            ],
            "doi": "10.48550/arXiv.2410.23637",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "e3710e96f186c74962584d55fe9a34810ff10e9f",
            "title": "Anytime-Constrained Multi-Agent Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/e3710e96f186c74962584d55fe9a34810ff10e9f",
            "venue": "ArXiv",
            "year": 2024
        },
        {
            "arxivId": "2405.14183",
            "authors": [
                {
                    "authorId": "2264461559",
                    "name": "Jeremy McMahan"
                }
            ],
            "doi": "10.48550/arXiv.2405.14183",
            "intent": [],
            "isInfluential": false,
            "paperId": "bdea63dc347aff4d3acb86cab079e291e2c38584",
            "title": "Deterministic Policies for Constrained Reinforcement Learning in Polynomial-Time",
            "url": "https://www.semanticscholar.org/paper/bdea63dc347aff4d3acb86cab079e291e2c38584",
            "venue": "ArXiv",
            "year": 2024
        },
        {
            "arxivId": "2401.03786",
            "authors": [
                {
                    "authorId": "41036308",
                    "name": "Akifumi Wachi"
                },
                {
                    "authorId": "1485728632",
                    "name": "Wataru Hashimoto"
                },
                {
                    "authorId": "3066887",
                    "name": "Kazumune Hashimoto"
                }
            ],
            "doi": "10.48550/arXiv.2401.03786",
            "intent": [
                "result"
            ],
            "isInfluential": false,
            "paperId": "38487ea01c8634bdf0ff80287d9e0a0fc5b59adf",
            "title": "Long-term Safe Reinforcement Learning with Binary Feedback",
            "url": "https://www.semanticscholar.org/paper/38487ea01c8634bdf0ff80287d9e0a0fc5b59adf",
            "venue": "AAAI",
            "year": 2024
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "3195342",
                    "name": "A. Zehfroosh"
                },
                {
                    "authorId": "2262456049",
                    "name": "Zhaodan Kong"
                },
                {
                    "authorId": "2249319201",
                    "name": "Stavros G. Vougioukas"
                }
            ],
            "doi": "10.1109/CDC49753.2023.10384242",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "2a11c32e6bf23616bc48a1ee359b218ab375e814",
            "title": "Efficient Re-synthesis of Control Barrier Function via Safe Exploration",
            "url": "https://www.semanticscholar.org/paper/2a11c32e6bf23616bc48a1ee359b218ab375e814",
            "venue": "2023 62nd IEEE Conference on Decision and Control (CDC)",
            "year": 2023
        },
        {
            "arxivId": "2311.05511",
            "authors": [
                {
                    "authorId": "2264461559",
                    "name": "Jeremy McMahan"
                },
                {
                    "authorId": "2263569405",
                    "name": "Xiaojin Zhu"
                }
            ],
            "doi": "10.48550/arXiv.2311.05511",
            "intent": [
                "background"
            ],
            "isInfluential": true,
            "paperId": "08fa6464ecad38a0bae38a54446d768a141558cd",
            "title": "Anytime-Constrained Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/08fa6464ecad38a0bae38a54446d768a141558cd",
            "venue": "AISTATS",
            "year": 2023
        },
        {
            "arxivId": "2311.02119",
            "authors": [
                {
                    "authorId": "2127008384",
                    "name": "Durgesh Kalwar"
                },
                {
                    "authorId": "2265491194",
                    "name": "S. VineethB."
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "9338eab4244edfee6560db06154d5cb9dbe2274d",
            "title": "Safe Sequential Optimization for Switching Environments",
            "url": "https://www.semanticscholar.org/paper/9338eab4244edfee6560db06154d5cb9dbe2274d",
            "venue": "",
            "year": 2023
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "103751119",
                    "name": "Pranay Thangeda"
                },
                {
                    "authorId": "1814528",
                    "name": "Melkior Ornik"
                },
                {
                    "authorId": "3199888",
                    "name": "U. Topcu"
                }
            ],
            "doi": "10.1109/TAC.2022.3153278",
            "intent": [
                "background"
            ],
            "isInfluential": true,
            "paperId": "56bdb6033843a7387eceb61a950261f8f920f462",
            "title": "Expedited Online Learning With Spatial Side Information",
            "url": "https://www.semanticscholar.org/paper/56bdb6033843a7387eceb61a950261f8f920f462",
            "venue": "IEEE Transactions on Automatic Control",
            "year": 2023
        },
        {
            "arxivId": "2210.14492",
            "authors": [
                {
                    "authorId": "143885573",
                    "name": "Andrew Bennett"
                },
                {
                    "authorId": "31498163",
                    "name": "Dipendra Kumar Misra"
                },
                {
                    "authorId": "3174388",
                    "name": "Nathan Kallus"
                }
            ],
            "doi": "10.48550/arXiv.2210.14492",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "c63bc70acbd823a758f8707a6b4da6061728c20a",
            "title": "Provable Safe Reinforcement Learning with Binary Feedback",
            "url": "https://www.semanticscholar.org/paper/c63bc70acbd823a758f8707a6b4da6061728c20a",
            "venue": "AISTATS",
            "year": 2022
        },
        {
            "arxivId": "2202.07789",
            "authors": [
                {
                    "authorId": "8234443",
                    "name": "G. Thomas"
                },
                {
                    "authorId": "1491625903",
                    "name": "Yuping Luo"
                },
                {
                    "authorId": "2114186424",
                    "name": "Tengyu Ma"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "d8da5d28807fe5f8af2e6942c67738bd9f12a1ec",
            "title": "Safe Reinforcement Learning by Imagining the Near Future",
            "url": "https://www.semanticscholar.org/paper/d8da5d28807fe5f8af2e6942c67738bd9f12a1ec",
            "venue": "NeurIPS",
            "year": 2022
        },
        {
            "arxivId": "2108.01846",
            "authors": [
                {
                    "authorId": "1491625903",
                    "name": "Yuping Luo"
                },
                {
                    "authorId": "2114186424",
                    "name": "Tengyu Ma"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "36d55c909e8c1be84f3a4f2631e3303ef5392fb0",
            "title": "Learning Barrier Certificates: Towards Safe Reinforcement Learning with Zero Training-time Violations",
            "url": "https://www.semanticscholar.org/paper/36d55c909e8c1be84f3a4f2631e3303ef5392fb0",
            "venue": "NeurIPS",
            "year": 2021
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2275196126",
                    "name": "Thiago D. Sim\u00e3o"
                },
                {
                    "authorId": "2275195129",
                    "name": "Nils Jansen"
                },
                {
                    "authorId": "1723205",
                    "name": "M. Spaan"
                }
            ],
            "doi": "10.5555/3463952.3464094",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "3831317011533d226c7e0a51fb987092401bbcfe",
            "title": "AlwaysSafe: Reinforcement Learning without Safety Constraint Violations during Training",
            "url": "https://www.semanticscholar.org/paper/3831317011533d226c7e0a51fb987092401bbcfe",
            "venue": "AAMAS",
            "year": 2021
        }
    ],
    "corpusId": 220381033,
    "doi": null,
    "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
    ],
    "influentialCitationCount": 2,
    "isOpenAccess": false,
    "isPublisherLicensed": true,
    "is_open_access": false,
    "is_publisher_licensed": true,
    "numCitedBy": 11,
    "numCiting": 41,
    "paperId": "3fdb10b01d980840f3235b18a50f5bcdb8d51c50",
    "references": [
        {
            "arxivId": "1904.01068",
            "authors": [
                {
                    "authorId": "8307674",
                    "name": "Erdem Biyik"
                },
                {
                    "authorId": "89699981",
                    "name": "Jonathan Margoliash"
                },
                {
                    "authorId": "35687448",
                    "name": "S. R. Alimo"
                },
                {
                    "authorId": "1779671",
                    "name": "Dorsa Sadigh"
                }
            ],
            "doi": "10.23919/ACC.2019.8815276",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "7203c12fc8e4ecae4b4c7b86b0c4e2a9f27fed22",
            "title": "Efficient and Safe Exploration in Deterministic Markov Decision Processes with Unknown Transition Models",
            "url": "https://www.semanticscholar.org/paper/7203c12fc8e4ecae4b4c7b86b0c4e2a9f27fed22",
            "venue": "2019 American Control Conference (ACC)",
            "year": 2019
        },
        {
            "arxivId": "1808.09819",
            "authors": [
                {
                    "authorId": "51243889",
                    "name": "Adrien Ali Ta\u00efga"
                },
                {
                    "authorId": "1760871",
                    "name": "Aaron C. Courville"
                },
                {
                    "authorId": "1792298",
                    "name": "Marc G. Bellemare"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "b4c44c57807bafc7ac1ff30650e10f48d6c273dc",
            "title": "Approximate Exploration through State Abstraction",
            "url": "https://www.semanticscholar.org/paper/b4c44c57807bafc7ac1ff30650e10f48d6c273dc",
            "venue": "ArXiv",
            "year": 2018
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "41036308",
                    "name": "Akifumi Wachi"
                },
                {
                    "authorId": "3285568",
                    "name": "Yanan Sui"
                },
                {
                    "authorId": "1740159",
                    "name": "Yisong Yue"
                },
                {
                    "authorId": "50124086",
                    "name": "M. Ono"
                }
            ],
            "doi": "10.1609/aaai.v32i1.12103",
            "intent": [
                "background",
                "result"
            ],
            "isInfluential": true,
            "paperId": "f3b78a8b96eec9b30721022e10604a4b04a4f23b",
            "title": "Safe Exploration and Optimization of Constrained MDPs Using Gaussian Processes",
            "url": "https://www.semanticscholar.org/paper/f3b78a8b96eec9b30721022e10604a4b04a4f23b",
            "venue": "AAAI",
            "year": 2018
        },
        {
            "arxivId": "1705.10528",
            "authors": [
                {
                    "authorId": "3381809",
                    "name": "Joshua Achiam"
                },
                {
                    "authorId": "145641013",
                    "name": "David Held"
                },
                {
                    "authorId": "3025260",
                    "name": "Aviv Tamar"
                },
                {
                    "authorId": "1689992",
                    "name": "P. Abbeel"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "7a4193d0b042643a8bb9ec262ed7f9d509bdb12e",
            "title": "Constrained Policy Optimization",
            "url": "https://www.semanticscholar.org/paper/7a4193d0b042643a8bb9ec262ed7f9d509bdb12e",
            "venue": "ICML",
            "year": 2017
        },
        {
            "arxivId": "1705.08551",
            "authors": [
                {
                    "authorId": "2064772",
                    "name": "Felix Berkenkamp"
                },
                {
                    "authorId": "3422558",
                    "name": "M. Turchetta"
                },
                {
                    "authorId": "143633801",
                    "name": "Angela P. Schoellig"
                },
                {
                    "authorId": "145343838",
                    "name": "Andreas Krause"
                }
            ],
            "doi": null,
            "intent": [
                "background",
                "result"
            ],
            "isInfluential": true,
            "paperId": "88880d88073a99107bbc009c9f4a4197562e1e44",
            "title": "Safe Model-based Reinforcement Learning with Stability Guarantees",
            "url": "https://www.semanticscholar.org/paper/88880d88073a99107bbc009c9f4a4197562e1e44",
            "venue": "NIPS",
            "year": 2017
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "3089865",
                    "name": "C. Ostafew"
                },
                {
                    "authorId": "143633801",
                    "name": "Angela P. Schoellig"
                },
                {
                    "authorId": "87222581",
                    "name": "T. Barfoot"
                }
            ],
            "doi": "10.1177/0278364916645661",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "9c156e62dd04a86224cab1f78c9e09d857736cfd",
            "title": "Robust Constrained Learning-based NMPC enabling reliable mobile robot path tracking",
            "url": "https://www.semanticscholar.org/paper/9c156e62dd04a86224cab1f78c9e09d857736cfd",
            "venue": "Int. J. Robotics Res.",
            "year": 2016
        },
        {
            "arxivId": "1701.04113",
            "authors": [
                {
                    "authorId": "152422014",
                    "name": "David Abel"
                },
                {
                    "authorId": "145661994",
                    "name": "D. E. Hershkowitz"
                },
                {
                    "authorId": "144885169",
                    "name": "M. Littman"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "3ab308a469439917204c5e9eab833e0f5f2f74da",
            "title": "Near Optimal Behavior via Approximate State Abstraction",
            "url": "https://www.semanticscholar.org/paper/3ab308a469439917204c5e9eab833e0f5f2f74da",
            "venue": "ICML",
            "year": 2016
        },
        {
            "arxivId": "1606.04753",
            "authors": [
                {
                    "authorId": "3422558",
                    "name": "M. Turchetta"
                },
                {
                    "authorId": "2064772",
                    "name": "Felix Berkenkamp"
                },
                {
                    "authorId": "145343838",
                    "name": "Andreas Krause"
                }
            ],
            "doi": null,
            "intent": [
                "background",
                "result"
            ],
            "isInfluential": true,
            "paperId": "a9beebe284b2c70895d4f51fe14fc50eda41fc60",
            "title": "Safe Exploration in Finite Markov Decision Processes with Gaussian Processes",
            "url": "https://www.semanticscholar.org/paper/a9beebe284b2c70895d4f51fe14fc50eda41fc60",
            "venue": "NIPS",
            "year": 2016
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "50124086",
                    "name": "M. Ono"
                },
                {
                    "authorId": "1696085",
                    "name": "M. Pavone"
                },
                {
                    "authorId": "1791484",
                    "name": "Y. Kuwata"
                },
                {
                    "authorId": "122105408",
                    "name": "B. Balaram"
                }
            ],
            "doi": "10.1007/s10514-015-9467-7",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "1b1d53d49e9a24d1bc53726f09f7c5d7c368cc42",
            "title": "Chance-constrained dynamic programming with application to risk-aware robotic space exploration",
            "url": "https://www.semanticscholar.org/paper/1b1d53d49e9a24d1bc53726f09f7c5d7c368cc42",
            "venue": "Autonomous Robots",
            "year": 2015
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "3047508",
                    "name": "Anayo K. Akametalu"
                },
                {
                    "authorId": "1688521",
                    "name": "Shahab Kaynama"
                },
                {
                    "authorId": "1843342",
                    "name": "J. Fisac"
                },
                {
                    "authorId": "2176899",
                    "name": "M. Zeilinger"
                },
                {
                    "authorId": "1704714",
                    "name": "J. Gillula"
                },
                {
                    "authorId": "1693894",
                    "name": "C. Tomlin"
                }
            ],
            "doi": "10.1109/CDC.2014.7039601",
            "intent": [
                "background",
                "result"
            ],
            "isInfluential": true,
            "paperId": "410c3573849dfb673ce5c6f5b3108db7a0745551",
            "title": "Reachability-based safe learning with Gaussian processes",
            "url": "https://www.semanticscholar.org/paper/410c3573849dfb673ce5c6f5b3108db7a0745551",
            "venue": "53rd IEEE Conference on Decision and Control",
            "year": 2014
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "1794487",
                    "name": "Shiau Hong Lim"
                },
                {
                    "authorId": "143719795",
                    "name": "Huan Xu"
                },
                {
                    "authorId": "1712535",
                    "name": "Shie Mannor"
                }
            ],
            "doi": "10.1287/moor.2016.0779",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "e201e95b88a230c5d57a71bcd62b6307bfa11c1b",
            "title": "Reinforcement Learning in Robust Markov Decision Processes",
            "url": "https://www.semanticscholar.org/paper/e201e95b88a230c5d57a71bcd62b6307bfa11c1b",
            "venue": "Math. Oper. Res.",
            "year": 2013
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "7425260",
                    "name": "W. Wiesemann"
                },
                {
                    "authorId": "2500534",
                    "name": "D. Kuhn"
                },
                {
                    "authorId": "1722652",
                    "name": "B. Rustem"
                }
            ],
            "doi": "10.1287/MOOR.1120.0566",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "9eae0c6ca4a52fc5e6b6f9eb111ab6fdbecdf9a6",
            "title": "Robust Markov Decision Processes",
            "url": "https://www.semanticscholar.org/paper/9eae0c6ca4a52fc5e6b6f9eb111ab6fdbecdf9a6",
            "venue": "Math. Oper. Res.",
            "year": 2013
        },
        {
            "arxivId": "1205.4810",
            "authors": [
                {
                    "authorId": "46756560",
                    "name": "T. Moldovan"
                },
                {
                    "authorId": "1689992",
                    "name": "P. Abbeel"
                }
            ],
            "doi": null,
            "intent": [
                "background",
                "result"
            ],
            "isInfluential": true,
            "paperId": "d66ab178e941e3a79954c858d3c1bcdee8e1d17d",
            "title": "Safe Exploration in Markov Decision Processes",
            "url": "https://www.semanticscholar.org/paper/d66ab178e941e3a79954c858d3c1bcdee8e1d17d",
            "venue": "ICML",
            "year": 2012
        },
        {
            "arxivId": "1202.3890",
            "authors": [
                {
                    "authorId": "2989692",
                    "name": "Tor Lattimore"
                },
                {
                    "authorId": "144154444",
                    "name": "Marcus Hutter"
                }
            ],
            "doi": "10.1007/978-3-642-34106-9_26",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "8e4d0530499fdbbc0581894371013da9fec8ed95",
            "title": "PAC Bounds for Discounted MDPs",
            "url": "https://www.semanticscholar.org/paper/8e4d0530499fdbbc0581894371013da9fec8ed95",
            "venue": "ALT",
            "year": 2012
        },
        {
            "arxivId": "1107.2487",
            "authors": [
                {
                    "authorId": "144775461",
                    "name": "A. Aswani"
                },
                {
                    "authorId": "118369188",
                    "name": "Humberto Gonz\u00e1lez"
                },
                {
                    "authorId": "2062932428",
                    "name": "S. Sastry"
                },
                {
                    "authorId": "1693894",
                    "name": "C. Tomlin"
                }
            ],
            "doi": "10.1016/j.automatica.2013.02.003",
            "intent": [
                "background"
            ],
            "isInfluential": true,
            "paperId": "a358009295134ecb6454f6587847268e4839135c",
            "title": "Provably safe and robust learning-based model predictive control",
            "url": "https://www.semanticscholar.org/paper/a358009295134ecb6454f6587847268e4839135c",
            "venue": "Autom.",
            "year": 2011
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "1742557",
                    "name": "I. Szita"
                },
                {
                    "authorId": "40868287",
                    "name": "Csaba Szepesvari"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "75c827ed14c8794b6babf05b944751877e7d2b77",
            "title": "Model-based reinforcement learning with nearly tight exploration complexity bounds",
            "url": "https://www.semanticscholar.org/paper/75c827ed14c8794b6babf05b944751877e7d2b77",
            "venue": "ICML",
            "year": 2010
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "1894226",
                    "name": "L. Blackmore"
                },
                {
                    "authorId": "50124086",
                    "name": "M. Ono"
                },
                {
                    "authorId": "2627962",
                    "name": "Askar Bektassov"
                },
                {
                    "authorId": "2259528736",
                    "name": "B. Williams"
                }
            ],
            "doi": "10.1109/TRO.2010.2044948",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "2831d442f4db15c7a8bce00f33f94a9b2dcc967e",
            "title": "A Probabilistic Particle-Control Approximation of Chance-Constrained Stochastic Predictive Control",
            "url": "https://www.semanticscholar.org/paper/2831d442f4db15c7a8bce00f33f94a9b2dcc967e",
            "venue": "IEEE Transactions on Robotics",
            "year": 2010
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "1990806",
                    "name": "Alexander L. Strehl"
                },
                {
                    "authorId": "47681372",
                    "name": "Lihong Li"
                },
                {
                    "authorId": "144885169",
                    "name": "M. Littman"
                }
            ],
            "doi": "10.5555/1577069.1755867",
            "intent": [
                "background",
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "5d8e1eeeb0e4b0e0846a355532d0f9452249e68a",
            "title": "Reinforcement Learning in Finite MDPs: PAC Analysis",
            "url": "https://www.semanticscholar.org/paper/5d8e1eeeb0e4b0e0846a355532d0f9452249e68a",
            "venue": "J. Mach. Learn. Res.",
            "year": 2009
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2137760143",
                    "name": "Thomas Jaksch"
                },
                {
                    "authorId": "1786887",
                    "name": "R. Ortner"
                },
                {
                    "authorId": "144543541",
                    "name": "P. Auer"
                }
            ],
            "doi": "10.5555/1756006.1859902",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "0cafe2903b097fc042782c359cb231ea34ef7ed3",
            "title": "Near-optimal Regret Bounds for Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/0cafe2903b097fc042782c359cb231ea34ef7ed3",
            "venue": "J. Mach. Learn. Res.",
            "year": 2008
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2110315975",
                    "name": "Jonathan Taylor"
                },
                {
                    "authorId": "144368601",
                    "name": "Doina Precup"
                },
                {
                    "authorId": "1784317",
                    "name": "P. Panangaden"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "935f58066e63518f4e519ea44119772bc5b4ce1b",
            "title": "Bounding Performance Loss in Approximate MDP Homomorphisms",
            "url": "https://www.semanticscholar.org/paper/935f58066e63518f4e519ea44119772bc5b4ce1b",
            "venue": "NIPS",
            "year": 2008
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "1990806",
                    "name": "Alexander L. Strehl"
                },
                {
                    "authorId": "144885169",
                    "name": "M. Littman"
                }
            ],
            "doi": "10.1016/j.jcss.2007.08.009",
            "intent": [
                "methodology"
            ],
            "isInfluential": true,
            "paperId": "237a1cf18ed83bb3ad852b34f443c6c1ff3336c1",
            "title": "An analysis of model-based Interval Estimation for Markov Decision Processes",
            "url": "https://www.semanticscholar.org/paper/237a1cf18ed83bb3ad852b34f443c6c1ff3336c1",
            "venue": "J. Comput. Syst. Sci.",
            "year": 2008
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "1990806",
                    "name": "Alexander L. Strehl"
                },
                {
                    "authorId": "47681372",
                    "name": "Lihong Li"
                },
                {
                    "authorId": "2271288182",
                    "name": "Eric Wiewiora"
                },
                {
                    "authorId": "144162125",
                    "name": "J. Langford"
                },
                {
                    "authorId": "144885169",
                    "name": "M. Littman"
                }
            ],
            "doi": "10.1145/1143844.1143955",
            "intent": [
                "background",
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "187f3f984e6f375178f41827ab90c4e748773fa7",
            "title": "PAC model-free reinforcement learning",
            "url": "https://www.semanticscholar.org/paper/187f3f984e6f375178f41827ab90c4e748773fa7",
            "venue": "ICML",
            "year": 2006
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "1722628",
                    "name": "A. Nilim"
                },
                {
                    "authorId": "1701847",
                    "name": "L. Ghaoui"
                }
            ],
            "doi": "10.1287/opre.1050.0216",
            "intent": [],
            "isInfluential": false,
            "paperId": "6db16608fccddef51202af84112b34cfebfbe20a",
            "title": "Robust Control of Markov Decision Processes with Uncertain Transition Matrices",
            "url": "https://www.semanticscholar.org/paper/6db16608fccddef51202af84112b34cfebfbe20a",
            "venue": "Oper. Res.",
            "year": 2005
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "144695232",
                    "name": "S. Kakade"
                },
                {
                    "authorId": "81338045",
                    "name": "Michael Kearns"
                },
                {
                    "authorId": "144162125",
                    "name": "J. Langford"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "6bddcc4ff63e80fe576d379776284ede0be0a80c",
            "title": "Exploration in Metric State Spaces",
            "url": "https://www.semanticscholar.org/paper/6bddcc4ff63e80fe576d379776284ede0be0a80c",
            "venue": "ICML",
            "year": 2003
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "1718146",
                    "name": "R. Givan"
                },
                {
                    "authorId": "1680510",
                    "name": "T. Dean"
                },
                {
                    "authorId": "47158391",
                    "name": "M. Greig"
                }
            ],
            "doi": "10.1016/S0004-3702(02)00376-4",
            "intent": [],
            "isInfluential": false,
            "paperId": "2020aca3838a0e8a723761e74899b183d6b56f30",
            "title": "Equivalence notions and model minimization in Markov decision processes",
            "url": "https://www.semanticscholar.org/paper/2020aca3838a0e8a723761e74899b183d6b56f30",
            "venue": "Artif. Intell.",
            "year": 2003
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2261353",
                    "name": "T. Perkins"
                },
                {
                    "authorId": "1730590",
                    "name": "A. Barto"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "1c0f7087367315e4e8cd1d8654ab33db12663c2b",
            "title": "Lyapunov Design for Safe Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/1c0f7087367315e4e8cd1d8654ab33db12663c2b",
            "venue": "J. Mach. Learn. Res.",
            "year": 2003
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "81338045",
                    "name": "Michael Kearns"
                },
                {
                    "authorId": "1699868",
                    "name": "Satinder Singh"
                }
            ],
            "doi": "10.1023/A:1017984413808",
            "intent": [],
            "isInfluential": false,
            "paperId": "dc649486b881e672eea6546da48c46e1f98daf32",
            "title": "Near-Optimal Reinforcement Learning in Polynomial Time",
            "url": "https://www.semanticscholar.org/paper/dc649486b881e672eea6546da48c46e1f98daf32",
            "venue": "Machine Learning",
            "year": 2002
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "1699645",
                    "name": "R. Sutton"
                },
                {
                    "authorId": "145689002",
                    "name": "David A. McAllester"
                },
                {
                    "authorId": "1699868",
                    "name": "Satinder Singh"
                },
                {
                    "authorId": "144830983",
                    "name": "Y. Mansour"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "a20f0ce0616def7cc9a87446c228906cd5da093b",
            "title": "Policy Gradient Methods for Reinforcement Learning with Function Approximation",
            "url": "https://www.semanticscholar.org/paper/a20f0ce0616def7cc9a87446c228906cd5da093b",
            "venue": "NIPS",
            "year": 1999
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "143665732",
                    "name": "E. Altman"
                }
            ],
            "doi": "10.1201/9781315140223",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "3cc2608fd77b9b65f5bd378e8797b2ab1b8acde7",
            "title": "Constrained Markov Decision Processes",
            "url": "https://www.semanticscholar.org/paper/3cc2608fd77b9b65f5bd378e8797b2ab1b8acde7",
            "venue": "",
            "year": 1999
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "34793579",
                    "name": "W. Fleming"
                },
                {
                    "authorId": "1884953",
                    "name": "W. McEneaney"
                }
            ],
            "doi": "10.1137/S0363012993258720",
            "intent": [
                "background",
                "methodology"
            ],
            "isInfluential": true,
            "paperId": "c0dd3f0c88993b256ab4fa7028e929d01374d15c",
            "title": "Risk-Sensitive Control on an Infinite Time Horizon",
            "url": "https://www.semanticscholar.org/paper/c0dd3f0c88993b256ab4fa7028e929d01374d15c",
            "venue": "",
            "year": 1995
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2590047",
                    "name": "C. Fiechter"
                }
            ],
            "doi": "10.1145/180139.181019",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "f67cd79df4f62742d6f3d9f1e8cd5c0cc9194d38",
            "title": "Efficient reinforcement learning",
            "url": "https://www.semanticscholar.org/paper/f67cd79df4f62742d6f3d9f1e8cd5c0cc9194d38",
            "venue": "COLT '94",
            "year": 1994
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "37814588",
                    "name": "M. Puterman"
                }
            ],
            "doi": "10.2307/2291177",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "a9cd8efe9184dddb1bedbbec3a356c4dfb22fe63",
            "title": "Markov Decision Processes: Discrete Stochastic Dynamic Programming",
            "url": "https://www.semanticscholar.org/paper/a9cd8efe9184dddb1bedbbec3a356c4dfb22fe63",
            "venue": "",
            "year": 1994
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2563916",
                    "name": "Majid Alkaee Taleghan"
                },
                {
                    "authorId": "144299726",
                    "name": "Thomas G. Dietterich"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "fde4234a537f35167acbab2c1e179fa896a92ecb",
            "title": "Efficient Exploration for Constrained MDPs",
            "url": "https://www.semanticscholar.org/paper/fde4234a537f35167acbab2c1e179fa896a92ecb",
            "venue": "AAAI Spring Symposia",
            "year": 2018
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2972848",
                    "name": "A. Hans"
                },
                {
                    "authorId": "2766932",
                    "name": "Daniel Schneega\u00df"
                },
                {
                    "authorId": "34962728",
                    "name": "A. Sch\u00e4fer"
                },
                {
                    "authorId": "1699265",
                    "name": "S. Udluft"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "5ee27e9db2ae248d1254107852311117c4cda1c9",
            "title": "Safe exploration for reinforcement learning",
            "url": "https://www.semanticscholar.org/paper/5ee27e9db2ae248d1254107852311117c4cda1c9",
            "venue": "ESANN",
            "year": 2008
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "1680506",
                    "name": "R. Brafman"
                },
                {
                    "authorId": "1708847",
                    "name": "Moshe Tennenholtz"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "c7dbf5ed7e9b63e104adb4e18bfbc98f5d6afdae",
            "title": "R-MAX - A General Polynomial Time Algorithm for Near-Optimal Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/c7dbf5ed7e9b63e104adb4e18bfbc98f5d6afdae",
            "venue": "J. Mach. Learn. Res.",
            "year": 2001
        }
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Mathematics",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "title": "Provably Safe PAC-MDP Exploration Using Analogies",
    "topics": [],
    "url": "https://www.semanticscholar.org/paper/3fdb10b01d980840f3235b18a50f5bcdb8d51c50",
    "venue": "International Conference on Artificial Intelligence and Statistics",
    "year": 2020
}
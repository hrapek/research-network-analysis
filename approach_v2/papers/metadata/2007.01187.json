{
    "abstract": "The rule extraction literature contains the notion of a fidelity-accuracy dilemma: when building an interpretable model of a black box function, optimising for fidelity is likely to reduce performance on the underlying task, and vice versa. I reassert the relevance of this dilemma for the modern field of explainable artificial intelligence, and highlight how it is compounded when the black box is an agent interacting with a dynamic environment. I then discuss two independent research directions - building white box agents and interpreting black box agents - which are both coherent and worthy of attention, but must not be conflated by researchers embarking on projects in the domain of agent interpretability.",
    "arxivId": "2007.01187",
    "authors": [
        {
            "authorId": "151751382",
            "name": "Tom Bewley",
            "url": "https://www.semanticscholar.org/author/151751382"
        }
    ],
    "citationVelocity": 0,
    "citations": [
        {
            "arxivId": "2107.06317",
            "authors": [
                {
                    "authorId": "83246796",
                    "name": "Alihan H\u00fcy\u00fck"
                },
                {
                    "authorId": "123723354",
                    "name": "Daniel Jarrett"
                },
                {
                    "authorId": "1729969",
                    "name": "M. Schaar"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "9b969e22973b4d3ead02d69a678c5dfd2e83b560",
            "title": "Inverse Contextual Bandits: Learning How Behavior Evolves over Time",
            "url": "https://www.semanticscholar.org/paper/9b969e22973b4d3ead02d69a678c5dfd2e83b560",
            "venue": "ICML",
            "year": 2021
        }
    ],
    "corpusId": 220302866,
    "doi": null,
    "fieldsOfStudy": [
        "Computer Science"
    ],
    "influentialCitationCount": 0,
    "isOpenAccess": false,
    "isPublisherLicensed": true,
    "is_open_access": false,
    "is_publisher_licensed": true,
    "numCitedBy": 1,
    "numCiting": 17,
    "paperId": "ddf2f710aa9c8d7bdf7010c12c5b8f2b6a90cd34",
    "references": [
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2257319065",
                    "name": "Andrew Silva"
                },
                {
                    "authorId": "145223968",
                    "name": "M. Gombolay"
                },
                {
                    "authorId": "2257296138",
                    "name": "Taylor W. Killian"
                },
                {
                    "authorId": "2257294707",
                    "name": "Ivan Dario Jimenez Jimenez"
                },
                {
                    "authorId": "2891663",
                    "name": "Sung-Hyun Son"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "a4d3a5c81cf3d19fde3ae6c8b2feaa32300cb9ff",
            "title": "Optimization Methods for Interpretable Differentiable Decision Trees Applied to Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/a4d3a5c81cf3d19fde3ae6c8b2feaa32300cb9ff",
            "venue": "AISTATS",
            "year": 2020
        },
        {
            "arxivId": "2006.11309",
            "authors": [
                {
                    "authorId": "151751382",
                    "name": "Tom Bewley"
                },
                {
                    "authorId": "1926684",
                    "name": "J. Lawry"
                },
                {
                    "authorId": "39402452",
                    "name": "Arthur G. Richards"
                }
            ],
            "doi": "10.1007/978-3-030-73959-1_16",
            "intent": [
                "methodology",
                "background"
            ],
            "isInfluential": false,
            "paperId": "06417f30251f8d67b32ddc745fe5dd5aecacee34",
            "title": "Modelling Agent Policies with Interpretable Imitation Learning",
            "url": "https://www.semanticscholar.org/paper/06417f30251f8d67b32ddc745fe5dd5aecacee34",
            "venue": "TAILOR",
            "year": 2020
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2627610",
                    "name": "S. Nageshrao"
                },
                {
                    "authorId": "150933019",
                    "name": "Bruno Costa"
                },
                {
                    "authorId": "1760459",
                    "name": "Dimitar Filev"
                }
            ],
            "doi": "10.1109/ICMLA.2019.00041",
            "intent": [
                "methodology",
                "background"
            ],
            "isInfluential": false,
            "paperId": "2867642d66d6be2b615ee5c70279fe3464e98357",
            "title": "Interpretable Approximation of a Deep Reinforcement Learning Agent as a Set of If-Then Rules",
            "url": "https://www.semanticscholar.org/paper/2867642d66d6be2b615ee5c70279fe3464e98357",
            "venue": "2019 18th IEEE International Conference On Machine Learning And Applications (ICMLA)",
            "year": 2019
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "40995853",
                    "name": "Youri Coppens"
                },
                {
                    "authorId": "2741488",
                    "name": "Kyriakos Efthymiadis"
                },
                {
                    "authorId": "152865649",
                    "name": "Tom Lenaerts"
                },
                {
                    "authorId": "144336828",
                    "name": "A. Now\u00e9"
                }
            ],
            "doi": null,
            "intent": [
                "methodology",
                "background"
            ],
            "isInfluential": false,
            "paperId": "e7dd5c54ee6f39159d6e60bd7ce92ec4cf5e473d",
            "title": "Distilling Deep Reinforcement Learning Policies in Soft Decision Trees",
            "url": "https://www.semanticscholar.org/paper/e7dd5c54ee6f39159d6e60bd7ce92ec4cf5e473d",
            "venue": "IJCAI 2019",
            "year": 2019
        },
        {
            "arxivId": "1907.01180",
            "authors": [
                {
                    "authorId": "51033581",
                    "name": "Aaron M. Roth"
                },
                {
                    "authorId": "34887814",
                    "name": "Nicholay Topin"
                },
                {
                    "authorId": "31948108",
                    "name": "Pooyan Jamshidi"
                },
                {
                    "authorId": "1956361",
                    "name": "M. Veloso"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "4cc8c3801ab3cbdfed7aa8997da210fcf1d11f81",
            "title": "Conservative Q-Improvement: Reinforcement Learning for an Interpretable Decision-Tree Policy",
            "url": "https://www.semanticscholar.org/paper/4cc8c3801ab3cbdfed7aa8997da210fcf1d11f81",
            "venue": "ArXiv",
            "year": 2019
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "48395540",
                    "name": "C. Rudin"
                }
            ],
            "doi": "10.1038/s42256-019-0048-x",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "bc00ff34ec7772080c7039b17f7069a2f7df0889",
            "title": "Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead",
            "url": "https://www.semanticscholar.org/paper/bc00ff34ec7772080c7039b17f7069a2f7df0889",
            "venue": "Nature Machine Intelligence",
            "year": 2018
        },
        {
            "arxivId": "1807.05887",
            "authors": [
                {
                    "authorId": "48573981",
                    "name": "Guiliang Liu"
                },
                {
                    "authorId": "2166203",
                    "name": "O. Schulte"
                },
                {
                    "authorId": "143750633",
                    "name": "Wang Zhu"
                },
                {
                    "authorId": "51132651",
                    "name": "Qingcan Li"
                }
            ],
            "doi": "10.1007/978-3-030-10928-8_25",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "787c0a21cdcf59b50db201a564ce57fe0318360c",
            "title": "Toward Interpretable Deep Reinforcement Learning with Linear Model U-Trees",
            "url": "https://www.semanticscholar.org/paper/787c0a21cdcf59b50db201a564ce57fe0318360c",
            "venue": "ECML/PKDD",
            "year": 2018
        },
        {
            "arxivId": "1805.08328",
            "authors": [
                {
                    "authorId": "1697444",
                    "name": "O. Bastani"
                },
                {
                    "authorId": "2155555",
                    "name": "Yewen Pu"
                },
                {
                    "authorId": "1389870240",
                    "name": "Armando Solar-Lezama"
                }
            ],
            "doi": null,
            "intent": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "paperId": "9a8e6feb271bf1cce8b1393cf41e70692a7f6625",
            "title": "Verifiable Reinforcement Learning via Policy Extraction",
            "url": "https://www.semanticscholar.org/paper/9a8e6feb271bf1cce8b1393cf41e70692a7f6625",
            "venue": "NeurIPS",
            "year": 2018
        },
        {
            "arxivId": "1606.03476",
            "authors": [
                {
                    "authorId": "2126278",
                    "name": "Jonathan Ho"
                },
                {
                    "authorId": "2490652",
                    "name": "Stefano Ermon"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "4ab53de69372ec2cd2d90c126b6a100165dc8ed1",
            "title": "Generative Adversarial Imitation Learning",
            "url": "https://www.semanticscholar.org/paper/4ab53de69372ec2cd2d90c126b6a100165dc8ed1",
            "venue": "NIPS",
            "year": 2016
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "3255983",
                    "name": "Volodymyr Mnih"
                },
                {
                    "authorId": "2645384",
                    "name": "K. Kavukcuoglu"
                },
                {
                    "authorId": "145824029",
                    "name": "David Silver"
                },
                {
                    "authorId": "2228824",
                    "name": "Andrei A. Rusu"
                },
                {
                    "authorId": "144056327",
                    "name": "J. Veness"
                },
                {
                    "authorId": "1792298",
                    "name": "Marc G. Bellemare"
                },
                {
                    "authorId": "1753223",
                    "name": "Alex Graves"
                },
                {
                    "authorId": "3137672",
                    "name": "Martin A. Riedmiller"
                },
                {
                    "authorId": "145600108",
                    "name": "A. Fidjeland"
                },
                {
                    "authorId": "2273072",
                    "name": "Georg Ostrovski"
                },
                {
                    "authorId": "48348688",
                    "name": "Stig Petersen"
                },
                {
                    "authorId": "50388928",
                    "name": "Charlie Beattie"
                },
                {
                    "authorId": "49813280",
                    "name": "Amir Sadik"
                },
                {
                    "authorId": "2460849",
                    "name": "Ioannis Antonoglou"
                },
                {
                    "authorId": "143776287",
                    "name": "Helen King"
                },
                {
                    "authorId": "2106164",
                    "name": "D. Kumaran"
                },
                {
                    "authorId": "1688276",
                    "name": "Daan Wierstra"
                },
                {
                    "authorId": "34313265",
                    "name": "S. Legg"
                },
                {
                    "authorId": "48987704",
                    "name": "D. Hassabis"
                }
            ],
            "doi": "10.1038/nature14236",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "340f48901f72278f6bf78a04ee5b01df208cc508",
            "title": "Human-level control through deep reinforcement learning",
            "url": "https://www.semanticscholar.org/paper/340f48901f72278f6bf78a04ee5b01df208cc508",
            "venue": "Nature",
            "year": 2015
        },
        {
            "arxivId": "1011.0686",
            "authors": [
                {
                    "authorId": "1700433",
                    "name": "St\u00e9phane Ross"
                },
                {
                    "authorId": "21889436",
                    "name": "Geoffrey J. Gordon"
                },
                {
                    "authorId": "1756566",
                    "name": "J. Bagnell"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": true,
            "paperId": "79ab3c49903ec8cb339437ccf5cf998607fc313e",
            "title": "A Reduction of Imitation Learning and Structured Prediction to No-Regret Online Learning",
            "url": "https://www.semanticscholar.org/paper/79ab3c49903ec8cb339437ccf5cf998607fc313e",
            "venue": "AISTATS",
            "year": 2010
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "145624000",
                    "name": "Zhi-Hua Zhou"
                }
            ],
            "doi": "10.1007/BF02944803",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "bef0875bc23eecdbb6e4fb9edd6771599c978598",
            "title": "Rule extraction: Using neural networks or for neural networks?",
            "url": "https://www.semanticscholar.org/paper/bef0875bc23eecdbb6e4fb9edd6771599c978598",
            "venue": "Journal of Computer Science and Technology",
            "year": 2004
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "145624000",
                    "name": "Zhi-Hua Zhou"
                },
                {
                    "authorId": "2192443",
                    "name": "Yuan Jiang"
                },
                {
                    "authorId": "2700301",
                    "name": "Shifu Chen"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "0064efdb8008e433c4a18eb6f17c157f12742dc3",
            "title": "Extracting symbolic rules from trained neural network ensembles",
            "url": "https://www.semanticscholar.org/paper/0064efdb8008e433c4a18eb6f17c157f12742dc3",
            "venue": "AI Commun.",
            "year": 2003
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "1697083",
                    "name": "R. Setiono"
                }
            ],
            "doi": "10.1109/72.839020",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "df2701ed2bff5c195341a22f94257d4d453f70b6",
            "title": "Extracting M-of-N rules from trained neural networks",
            "url": "https://www.semanticscholar.org/paper/df2701ed2bff5c195341a22f94257d4d453f70b6",
            "venue": "IEEE Trans. Neural Networks Learn. Syst.",
            "year": 2000
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "145619750",
                    "name": "R. Andrews"
                },
                {
                    "authorId": "1715247",
                    "name": "J. Diederich"
                },
                {
                    "authorId": "7493862",
                    "name": "Alan B. Tickle"
                }
            ],
            "doi": "10.1016/0950-7051(96)81920-4",
            "intent": [],
            "isInfluential": false,
            "paperId": "7d196ad6907b12ebb24faa57219770917e506493",
            "title": "Survey and critique of techniques for extracting rules from trained artificial neural networks",
            "url": "https://www.semanticscholar.org/paper/7d196ad6907b12ebb24faa57219770917e506493",
            "venue": "Knowl. Based Syst.",
            "year": 1995
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2800737",
                    "name": "Larry D. Pyeatt"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "f9b30e1f6d85cb77e95ff1d580ee67d7406f1dd6",
            "title": "Reinforcement Learning with Decision Trees",
            "url": "https://www.semanticscholar.org/paper/f9b30e1f6d85cb77e95ff1d580ee67d7406f1dd6",
            "venue": "Applied Informatics",
            "year": 2003
        }
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        },
        {
            "category": "Philosophy",
            "source": "s2-fos-model"
        }
    ],
    "title": "Am I Building a White Box Agent or Interpreting a Black Box Agent?",
    "topics": [
        {
            "topic": "Black box",
            "topicId": "16977",
            "url": "https://www.semanticscholar.org/topic/16977"
        },
        {
            "topic": "White box (software engineering)",
            "topicId": "243964",
            "url": "https://www.semanticscholar.org/topic/243964"
        },
        {
            "topic": "Artificial intelligence",
            "topicId": "8286",
            "url": "https://www.semanticscholar.org/topic/8286"
        },
        {
            "topic": "Coherence (physics)",
            "topicId": "921",
            "url": "https://www.semanticscholar.org/topic/921"
        },
        {
            "topic": "Rule induction",
            "topicId": "160076",
            "url": "https://www.semanticscholar.org/topic/160076"
        },
        {
            "topic": "White box (computer hardware)",
            "topicId": "3930851",
            "url": "https://www.semanticscholar.org/topic/3930851"
        },
        {
            "topic": "Mathematical optimization",
            "topicId": "89",
            "url": "https://www.semanticscholar.org/topic/89"
        },
        {
            "topic": "Approximation",
            "topicId": "3247",
            "url": "https://www.semanticscholar.org/topic/3247"
        },
        {
            "topic": "Agent-based model",
            "topicId": "4774",
            "url": "https://www.semanticscholar.org/topic/4774"
        },
        {
            "topic": "Regular expression",
            "topicId": "48721",
            "url": "https://www.semanticscholar.org/topic/48721"
        },
        {
            "topic": "Interaction",
            "topicId": "72",
            "url": "https://www.semanticscholar.org/topic/72"
        },
        {
            "topic": "Relevance",
            "topicId": "503",
            "url": "https://www.semanticscholar.org/topic/503"
        },
        {
            "topic": "Prisoner's dilemma",
            "topicId": "31464",
            "url": "https://www.semanticscholar.org/topic/31464"
        },
        {
            "topic": "White-box testing",
            "topicId": "446166",
            "url": "https://www.semanticscholar.org/topic/446166"
        }
    ],
    "url": "https://www.semanticscholar.org/paper/ddf2f710aa9c8d7bdf7010c12c5b8f2b6a90cd34",
    "venue": "arXiv.org",
    "year": 2020
}
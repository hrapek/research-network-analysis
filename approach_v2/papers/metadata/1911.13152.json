{
    "abstract": "In this work we present ISA, a novel approach for learning and exploiting subgoals in reinforcement learning (RL). Our method relies on inducing an automaton whose transitions are subgoals expressed as propositional formulas over a set of observable events. A state-of-the-art inductive logic programming system is used to learn the automaton from observation traces perceived by the RL agent. The reinforcement learning and automaton learning processes are interleaved: a new refined automaton is learned whenever the RL agent generates a trace not recognized by the current automaton. We evaluate ISA in several gridworld problems and show that it performs similarly to a method for which automata are given in advance. We also show that the learned automata can be exploited to speed up convergence through reward shaping and transfer learning across multiple tasks. Finally, we analyze the running time and the number of traces that ISA needs to learn an automata, and the impact that the number of observable events has on the learner's performance.",
    "arxivId": "1911.13152",
    "authors": [
        {
            "authorId": "1405134785",
            "name": "Daniel Furelos-Blanco",
            "url": "https://www.semanticscholar.org/author/1405134785"
        },
        {
            "authorId": "46264950",
            "name": "Mark Law",
            "url": "https://www.semanticscholar.org/author/46264950"
        },
        {
            "authorId": "145277911",
            "name": "A. Russo",
            "url": "https://www.semanticscholar.org/author/145277911"
        },
        {
            "authorId": "1731914",
            "name": "K. Broda",
            "url": "https://www.semanticscholar.org/author/1731914"
        },
        {
            "authorId": "143808510",
            "name": "Anders Jonsson",
            "url": "https://www.semanticscholar.org/author/143808510"
        }
    ],
    "citationVelocity": 7,
    "citations": [
        {
            "arxivId": "2408.14871",
            "authors": [
                {
                    "authorId": "2317009712",
                    "name": "Roko Para\u0107"
                },
                {
                    "authorId": "2266751836",
                    "name": "Lorenzo Nodari"
                },
                {
                    "authorId": "2132438942",
                    "name": "Leo Ardon"
                },
                {
                    "authorId": "1405134785",
                    "name": "Daniel Furelos-Blanco"
                },
                {
                    "authorId": "2317005332",
                    "name": "Federico Cerutti"
                },
                {
                    "authorId": "2317009740",
                    "name": "Alessandra Russo"
                }
            ],
            "doi": "10.48550/arXiv.2408.14871",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "0880fa562f20f20d795b2891b38d1a637abccbd3",
            "title": "Learning Robust Reward Machines from Noisy Labels",
            "url": "https://www.semanticscholar.org/paper/0880fa562f20f20d795b2891b38d1a637abccbd3",
            "venue": "Proceedings of the TwentyFirst International Conference on Principles of Knowledge Representation and Reasoning",
            "year": 2024
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2245381886",
                    "name": "Hosein Hasanbeig"
                },
                {
                    "authorId": "31076941",
                    "name": "N. Jeppu"
                },
                {
                    "authorId": "2313020683",
                    "name": "Alessandro Abate"
                },
                {
                    "authorId": "2313019431",
                    "name": "Tom Melham"
                },
                {
                    "authorId": "2241088916",
                    "name": "Daniel Kroening"
                }
            ],
            "doi": "10.1613/jair.1.14063",
            "intent": [
                "background",
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "9747da7115d0cd146b954b9c02931b5a24ee74c7",
            "title": "Symbolic Task Inference in Deep Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/9747da7115d0cd146b954b9c02931b5a24ee74c7",
            "venue": "J. Artif. Intell. Res.",
            "year": 2024
        },
        {
            "arxivId": "2406.00120",
            "authors": [
                {
                    "authorId": "2307735039",
                    "name": "Andrew C. Li"
                },
                {
                    "authorId": "2305156749",
                    "name": "Zizhao Chen"
                },
                {
                    "authorId": "1758085",
                    "name": "Toryn Q. Klassen"
                },
                {
                    "authorId": "2304473925",
                    "name": "Pashootan Vaezipoor"
                },
                {
                    "authorId": "15316342",
                    "name": "Rodrigo Toro Icarte"
                },
                {
                    "authorId": "1683896",
                    "name": "Sheila A. McIlraith"
                }
            ],
            "doi": "10.48550/arXiv.2406.00120",
            "intent": [],
            "isInfluential": false,
            "paperId": "4933bae93008709e8d7ac213e95ddca78e4cb9f6",
            "title": "Reward Machines for Deep RL in Noisy and Uncertain Environments",
            "url": "https://www.semanticscholar.org/paper/4933bae93008709e8d7ac213e95ddca78e4cb9f6",
            "venue": "ArXiv",
            "year": 2024
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "3379045",
                    "name": "Martin Tappler"
                },
                {
                    "authorId": "52183983",
                    "name": "Edi Mu\u0161kardin"
                },
                {
                    "authorId": "2762698",
                    "name": "B. Aichernig"
                },
                {
                    "authorId": "2283146278",
                    "name": "Bettina K\u00f6nighofer"
                }
            ],
            "doi": "10.1109/ICST60714.2024.00026",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "4bc29c3720b96da06b3137011d0c79fb88823afc",
            "title": "Learning Environment Models with Continuous Stochastic Dynamics - with an Application to Deep RL Testing",
            "url": "https://www.semanticscholar.org/paper/4bc29c3720b96da06b3137011d0c79fb88823afc",
            "venue": "2024 IEEE Conference on Software Testing, Verification and Validation (ICST)",
            "year": 2024
        },
        {
            "arxivId": "2403.07005",
            "authors": [
                {
                    "authorId": "2290967787",
                    "name": "Xuejing Zheng"
                },
                {
                    "authorId": "2290970797",
                    "name": "Chao Yu"
                }
            ],
            "doi": "10.48550/arXiv.2403.07005",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "3b0e4db07b5682d0f9e0c9da5e776ce27b3146ed",
            "title": "Multi-Agent Reinforcement Learning with a Hierarchy of Reward Machines",
            "url": "https://www.semanticscholar.org/paper/3b0e4db07b5682d0f9e0c9da5e776ce27b3146ed",
            "venue": "ArXiv",
            "year": 2024
        },
        {
            "arxivId": "2401.14226",
            "authors": [
                {
                    "authorId": "2218232881",
                    "name": "Shuai Han"
                },
                {
                    "authorId": "1707738",
                    "name": "M. Dastani"
                },
                {
                    "authorId": "2109511123",
                    "name": "Shihan Wang"
                }
            ],
            "doi": "10.48550/arXiv.2401.14226",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "571288214b8ada4983866ee17a4bb4fd134e0b9d",
            "title": "Sample Efficient Reinforcement Learning by Automatically Learning to Compose Subtasks",
            "url": "https://www.semanticscholar.org/paper/571288214b8ada4983866ee17a4bb4fd134e0b9d",
            "venue": "ArXiv",
            "year": 2024
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "15316342",
                    "name": "Rodrigo Toro Icarte"
                },
                {
                    "authorId": "1758085",
                    "name": "Toryn Q. Klassen"
                },
                {
                    "authorId": "2682734",
                    "name": "R. Valenzano"
                },
                {
                    "authorId": "41036745",
                    "name": "Margarita P. Castro"
                },
                {
                    "authorId": "1396422950",
                    "name": "Ethan Waldie"
                },
                {
                    "authorId": "1683896",
                    "name": "Sheila A. McIlraith"
                }
            ],
            "doi": "10.1016/j.artint.2023.103989",
            "intent": [],
            "isInfluential": false,
            "paperId": "c32d54d9f80fa79c3bd309cb56ddfffa404dcbcd",
            "title": "Learning reward machines: A study in partially observable reinforcement learning",
            "url": "https://www.semanticscholar.org/paper/c32d54d9f80fa79c3bd309cb56ddfffa404dcbcd",
            "venue": "Artif. Intell.",
            "year": 2023
        },
        {
            "arxivId": "2306.17204",
            "authors": [
                {
                    "authorId": "3379045",
                    "name": "Martin Tappler"
                },
                {
                    "authorId": "52183983",
                    "name": "Edi Mu\u0161kardin"
                },
                {
                    "authorId": "2762698",
                    "name": "B. Aichernig"
                },
                {
                    "authorId": "2283146278",
                    "name": "Bettina K\u00f6nighofer"
                }
            ],
            "doi": "10.48550/arXiv.2306.17204",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "f21f838b6f9de3dbdbfb3026b90da35f1b687415",
            "title": "Learning Environment Models with Continuous Stochastic Dynamics",
            "url": "https://www.semanticscholar.org/paper/f21f838b6f9de3dbdbfb3026b90da35f1b687415",
            "venue": "ArXiv",
            "year": 2023
        },
        {
            "arxivId": "2304.12090",
            "authors": [
                {
                    "authorId": "2155747980",
                    "name": "Chao Yu"
                },
                {
                    "authorId": "1506972528",
                    "name": "Xuejing Zheng"
                },
                {
                    "authorId": "74076606",
                    "name": "H. Zhuo"
                },
                {
                    "authorId": "2105531615",
                    "name": "Hai Wan"
                },
                {
                    "authorId": "2114375748",
                    "name": "Weilin Luo"
                }
            ],
            "doi": "10.48550/arXiv.2304.12090",
            "intent": [],
            "isInfluential": false,
            "paperId": "28e536d4b425a8743af9b074ddb11baba66f8b47",
            "title": "Reinforcement Learning with Knowledge Representation and Reasoning: A Brief Survey",
            "url": "https://www.semanticscholar.org/paper/28e536d4b425a8743af9b074ddb11baba66f8b47",
            "venue": "ArXiv",
            "year": 2023
        },
        {
            "arxivId": "2212.01838",
            "authors": [
                {
                    "authorId": "3379045",
                    "name": "Martin Tappler"
                },
                {
                    "authorId": "150304935",
                    "name": "Stefan Pranger"
                },
                {
                    "authorId": "1908784",
                    "name": "Bettina K\u00f6nighofer"
                },
                {
                    "authorId": "52183983",
                    "name": "Edi Mu\u0161kardin"
                },
                {
                    "authorId": "1745765",
                    "name": "R. Bloem"
                },
                {
                    "authorId": "1679646",
                    "name": "K. Larsen"
                }
            ],
            "doi": "10.1007/978-3-031-19849-6_20",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "482723cd38b20a1d9b5a94159a3719313155cc0b",
            "title": "Automata Learning Meets Shielding",
            "url": "https://www.semanticscholar.org/paper/482723cd38b20a1d9b5a94159a3719313155cc0b",
            "venue": "ISoLA",
            "year": 2022
        },
        {
            "arxivId": "2211.10902",
            "authors": [
                {
                    "authorId": "1994454556",
                    "name": "Andrew C. Li"
                },
                {
                    "authorId": "2117099576",
                    "name": "Zizhao Chen"
                },
                {
                    "authorId": "1947192",
                    "name": "Pashootan Vaezipoor"
                },
                {
                    "authorId": "1758085",
                    "name": "Toryn Q. Klassen"
                },
                {
                    "authorId": "15316342",
                    "name": "Rodrigo Toro Icarte"
                },
                {
                    "authorId": "1683896",
                    "name": "Sheila A. McIlraith"
                }
            ],
            "doi": "10.48550/arXiv.2211.10902",
            "intent": [],
            "isInfluential": false,
            "paperId": "89294e0b8bc32c563291f261f1172fdc11214f4b",
            "title": "Noisy Symbolic Abstractions for Deep RL: A case study with Reward Machines",
            "url": "https://www.semanticscholar.org/paper/89294e0b8bc32c563291f261f1172fdc11214f4b",
            "venue": "ArXiv",
            "year": 2022
        },
        {
            "arxivId": "2208.11838",
            "authors": [
                {
                    "authorId": "144938187",
                    "name": "A. Abate"
                },
                {
                    "authorId": "104283116",
                    "name": "Y. Almulla"
                },
                {
                    "authorId": "2105894098",
                    "name": "James Fox"
                },
                {
                    "authorId": "2182691758",
                    "name": "David Hyland"
                },
                {
                    "authorId": "2059979020",
                    "name": "M. Wooldridge"
                }
            ],
            "doi": "10.48550/arXiv.2208.11838",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "1046565b3eeae47298bd751162f2c13902af299f",
            "title": "Learning Task Automata for Reinforcement Learning using Hidden Markov Models",
            "url": "https://www.semanticscholar.org/paper/1046565b3eeae47298bd751162f2c13902af299f",
            "venue": "ECAI",
            "year": 2022
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2174905100",
                    "name": "Jan Corazza"
                },
                {
                    "authorId": "2202693",
                    "name": "I. Gavran"
                },
                {
                    "authorId": "1779795",
                    "name": "D. Neider"
                }
            ],
            "doi": "10.1609/aaai.v36i6.20594",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "44f925cad517464c61c0bd21f397cce556a5dbc2",
            "title": "Reinforcement Learning with Stochastic Reward Machines",
            "url": "https://www.semanticscholar.org/paper/44f925cad517464c61c0bd21f397cce556a5dbc2",
            "venue": "AAAI",
            "year": 2022
        },
        {
            "arxivId": "2206.11708",
            "authors": [
                {
                    "authorId": "52183983",
                    "name": "Edi Mu\u0161kardin"
                },
                {
                    "authorId": "3379045",
                    "name": "Martin Tappler"
                },
                {
                    "authorId": "2762698",
                    "name": "B. Aichernig"
                },
                {
                    "authorId": "1835640",
                    "name": "Ingo Pill"
                }
            ],
            "doi": "10.48550/arXiv.2206.11708",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "87f18b0f0ab628d8897f3dafc6d280029be858a3",
            "title": "Reinforcement Learning under Partial Observability Guided by Learned Environment Models",
            "url": "https://www.semanticscholar.org/paper/87f18b0f0ab628d8897f3dafc6d280029be858a3",
            "venue": "iFM",
            "year": 2022
        },
        {
            "arxivId": "2204.11833",
            "authors": [
                {
                    "authorId": "1845367",
                    "name": "Christos K. Verginis"
                },
                {
                    "authorId": "2047238995",
                    "name": "Cevahir K\u00f6pr\u00fcl\u00fc"
                },
                {
                    "authorId": "2277751990",
                    "name": "Sandeep P. Chinchali"
                },
                {
                    "authorId": "3199888",
                    "name": "U. Topcu"
                }
            ],
            "doi": "10.48550/arXiv.2204.11833",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "f8a5e3efff7d00182f24e1b006e5b480c92fe1d8",
            "title": "Joint Learning of Reward Machines and Policies in Environments with Partially Known Semantics",
            "url": "https://www.semanticscholar.org/paper/f8a5e3efff7d00182f24e1b006e5b480c92fe1d8",
            "venue": "Artif. Intell.",
            "year": 2022
        },
        {
            "arxivId": "2112.09477",
            "authors": [
                {
                    "authorId": "15316342",
                    "name": "Rodrigo Toro Icarte"
                },
                {
                    "authorId": "1396422950",
                    "name": "Ethan Waldie"
                },
                {
                    "authorId": "1758085",
                    "name": "Toryn Q. Klassen"
                },
                {
                    "authorId": "2682734",
                    "name": "R. Valenzano"
                },
                {
                    "authorId": "41036745",
                    "name": "Margarita P. Castro"
                },
                {
                    "authorId": "1683896",
                    "name": "Sheila A. McIlraith"
                }
            ],
            "doi": null,
            "intent": [
                "background",
                "methodology"
            ],
            "isInfluential": true,
            "paperId": "dc2856df42783fc821624c6a8bd82683d17726d1",
            "title": "Learning Reward Machines: A Study in Partially Observable Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/dc2856df42783fc821624c6a8bd82683d17726d1",
            "venue": "ArXiv",
            "year": 2021
        },
        {
            "arxivId": "2110.00096",
            "authors": [
                {
                    "authorId": "103373151",
                    "name": "Jueming Hu"
                },
                {
                    "authorId": "2149236364",
                    "name": "Zhe Xu"
                },
                {
                    "authorId": "1684964253",
                    "name": "Weichang Wang"
                },
                {
                    "authorId": "2501723",
                    "name": "Guannan Qu"
                },
                {
                    "authorId": "150350912",
                    "name": "Yutian Pang"
                },
                {
                    "authorId": "2143062695",
                    "name": "Yongming Liu"
                }
            ],
            "doi": "10.1016/j.neucom.2023.126974",
            "intent": [],
            "isInfluential": false,
            "paperId": "1185f0f7b90d8c70e12f013631be18c69a750f81",
            "title": "Decentralized Graph-Based Multi-Agent Reinforcement Learning Using Reward Machines",
            "url": "https://www.semanticscholar.org/paper/1185f0f7b90d8c70e12f013631be18c69a750f81",
            "venue": "Neurocomputing",
            "year": 2021
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "1779795",
                    "name": "D. Neider"
                },
                {
                    "authorId": "2086348569",
                    "name": "Jean-Raphael Gaglione"
                },
                {
                    "authorId": "2202693",
                    "name": "I. Gavran"
                },
                {
                    "authorId": "3199888",
                    "name": "U. Topcu"
                },
                {
                    "authorId": "152365289",
                    "name": "Bo Wu"
                },
                {
                    "authorId": "50070268",
                    "name": "Zhe Xu"
                }
            ],
            "doi": "10.1609/aaai.v35i10.17096",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "4a5cbc5e734130c9aac28c6195f8c2b1ec305654",
            "title": "Advice-Guided Reinforcement Learning in a non-Markovian Environment",
            "url": "https://www.semanticscholar.org/paper/4a5cbc5e734130c9aac28c6195f8c2b1ec305654",
            "venue": "AAAI",
            "year": 2021
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "35302287",
                    "name": "Mohammadhosein Hasanbeig"
                },
                {
                    "authorId": "31076941",
                    "name": "N. Jeppu"
                },
                {
                    "authorId": "144938187",
                    "name": "A. Abate"
                },
                {
                    "authorId": "35119090",
                    "name": "T. Melham"
                },
                {
                    "authorId": "145763733",
                    "name": "D. Kroening"
                }
            ],
            "doi": "10.1609/aaai.v35i9.16935",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "d7e8c8bef0c27bcfc62d7d88e30f511d2bad971a",
            "title": "DeepSynth: Automata Synthesis for Automatic Task Segmentation in Deep Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/d7e8c8bef0c27bcfc62d7d88e30f511d2bad971a",
            "venue": "AAAI",
            "year": 2021
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "1656712399",
                    "name": "Yohei Hayamizu"
                },
                {
                    "authorId": "145306763",
                    "name": "S. Amiri"
                },
                {
                    "authorId": "1383234530",
                    "name": "Kishan Chandan"
                },
                {
                    "authorId": "144087825",
                    "name": "K. Takadama"
                },
                {
                    "authorId": "40295359",
                    "name": "Shiqi Zhang"
                }
            ],
            "doi": "10.1609/icaps.v31i1.16011",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "dd3e47ba20e45321929eea64008bcdc6d2f9750d",
            "title": "Guiding Robot Exploration in Reinforcement Learning via Automated Planning",
            "url": "https://www.semanticscholar.org/paper/dd3e47ba20e45321929eea64008bcdc6d2f9750d",
            "venue": "ICAPS",
            "year": 2021
        },
        {
            "arxivId": "2101.00058",
            "authors": [
                {
                    "authorId": "46264950",
                    "name": "Mark Law"
                }
            ],
            "doi": "10.1017/s1471068422000011",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "c8d8491e7b666b614c549666a0d3e524ed1134e7",
            "title": "Conflict-driven Inductive Logic Programming",
            "url": "https://www.semanticscholar.org/paper/c8d8491e7b666b614c549666a0d3e524ed1134e7",
            "venue": "Theory Pract. Log. Program.",
            "year": 2020
        },
        {
            "arxivId": "2010.03950",
            "authors": [
                {
                    "authorId": "15316342",
                    "name": "Rodrigo Toro Icarte"
                },
                {
                    "authorId": "1758085",
                    "name": "Toryn Q. Klassen"
                },
                {
                    "authorId": "2682734",
                    "name": "R. Valenzano"
                },
                {
                    "authorId": "1683896",
                    "name": "Sheila A. McIlraith"
                }
            ],
            "doi": "10.1613/jair.1.12440",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "6778d6a0f959cdcc42718ee9fc279fd1f00f3d88",
            "title": "Reward Machines: Exploiting Reward Function Structure in Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/6778d6a0f959cdcc42718ee9fc279fd1f00f3d88",
            "venue": "J. Artif. Intell. Res.",
            "year": 2020
        },
        {
            "arxivId": "2009.03855",
            "authors": [
                {
                    "authorId": "1405134785",
                    "name": "Daniel Furelos-Blanco"
                },
                {
                    "authorId": "46264950",
                    "name": "Mark Law"
                },
                {
                    "authorId": "143808510",
                    "name": "Anders Jonsson"
                },
                {
                    "authorId": "1731914",
                    "name": "K. Broda"
                },
                {
                    "authorId": "145277911",
                    "name": "A. Russo"
                }
            ],
            "doi": "10.1613/jair.1.12372",
            "intent": [
                "background",
                "methodology"
            ],
            "isInfluential": true,
            "paperId": "5a14b037a5d73e48fc723c40328769d5561fd372",
            "title": "Induction and Exploitation of Subgoal Automata for Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/5a14b037a5d73e48fc723c40328769d5561fd372",
            "venue": "J. Artif. Intell. Res.",
            "year": 2020
        },
        {
            "arxivId": "2008.08548",
            "authors": [
                {
                    "authorId": "40295359",
                    "name": "Shiqi Zhang"
                },
                {
                    "authorId": "1714890",
                    "name": "M. Sridharan"
                }
            ],
            "doi": "10.1002/aaai.12053",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "afa4e8ccaac9401637216d98b120a6245524f220",
            "title": "A Survey of Knowledge-based Sequential Decision Making under Uncertainty",
            "url": "https://www.semanticscholar.org/paper/afa4e8ccaac9401637216d98b120a6245524f220",
            "venue": "AI Mag.",
            "year": 2020
        },
        {
            "arxivId": "2006.15714",
            "authors": [
                {
                    "authorId": "50070268",
                    "name": "Zhe Xu"
                },
                {
                    "authorId": "152365289",
                    "name": "Bo Wu"
                },
                {
                    "authorId": "1779795",
                    "name": "D. Neider"
                },
                {
                    "authorId": "3199888",
                    "name": "U. Topcu"
                }
            ],
            "doi": "10.1007/978-3-030-84060-0_8",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "a918f0ec2c1e4d605ad3697208dba68654572933",
            "title": "Active Finite Reward Automaton Inference and Reinforcement Learning Using Queries and Counterexamples",
            "url": "https://www.semanticscholar.org/paper/a918f0ec2c1e4d605ad3697208dba68654572933",
            "venue": "CD-MAKE",
            "year": 2020
        },
        {
            "arxivId": "2005.00904",
            "authors": [
                {
                    "authorId": "46264950",
                    "name": "Mark Law"
                },
                {
                    "authorId": "145277911",
                    "name": "A. Russo"
                },
                {
                    "authorId": "1731914",
                    "name": "K. Broda"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "98a82db7de514c1c61e2d25cb5f2002c2bee5c20",
            "title": "The ILASP system for Inductive Learning of Answer Set Programs",
            "url": "https://www.semanticscholar.org/paper/98a82db7de514c1c61e2d25cb5f2002c2bee5c20",
            "venue": "ArXiv",
            "year": 2020
        },
        {
            "arxivId": "2004.11456",
            "authors": [
                {
                    "authorId": "1656712399",
                    "name": "Yohei Hayamizu"
                },
                {
                    "authorId": "145306763",
                    "name": "S. Amiri"
                },
                {
                    "authorId": "1383234530",
                    "name": "Kishan Chandan"
                },
                {
                    "authorId": "2601786",
                    "name": "Shiqi Zhang"
                },
                {
                    "authorId": "144087825",
                    "name": "K. Takadama"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "b9037d81b7cb4fcf9823b7f49ee9924a7df27b21",
            "title": "Guided Dyna-Q for Mobile Robot Exploration and Navigation",
            "url": "https://www.semanticscholar.org/paper/b9037d81b7cb4fcf9823b7f49ee9924a7df27b21",
            "venue": "ArXiv",
            "year": 2020
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2218232881",
                    "name": "Shuai Han"
                },
                {
                    "authorId": "2282072513",
                    "name": "Mehdi Dastani"
                },
                {
                    "authorId": "2109511123",
                    "name": "Shihan Wang"
                }
            ],
            "doi": "10.3233/FAIA240751",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "79f9d10c28efb3b07f530c716917a70988130f1f",
            "title": "Learning Reward Structure with Subtasks in Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/79f9d10c28efb3b07f530c716917a70988130f1f",
            "venue": "ECAI",
            "year": 2024
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2226597353",
                    "name": "Vaishak Belle"
                },
                {
                    "authorId": "2296689971",
                    "name": "Michael Fisher"
                },
                {
                    "authorId": "2296632608",
                    "name": "Alessandra Russo"
                },
                {
                    "authorId": "2296605997",
                    "name": "Ekaterina Komendantskaya"
                },
                {
                    "authorId": "2296606025",
                    "name": "Alistair Nottle"
                }
            ],
            "doi": "10.1007/978-3-031-56255-6_10",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "7ddcb0a36a80488d23f368d07bad736e561eeb3d",
            "title": "Neuro-Symbolic AI + Agent Systems: A First Reflection on Trends, Opportunities and Challenges",
            "url": "https://www.semanticscholar.org/paper/7ddcb0a36a80488d23f368d07bad736e561eeb3d",
            "venue": "AAMAS Workshops",
            "year": 2023
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "40295359",
                    "name": "Shiqi Zhang"
                },
                {
                    "authorId": "1714890",
                    "name": "M. Sridharan"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "da98d6e5807c7a62bb1ceb1a6dabd390356a5e71",
            "title": "Knowledge-based Sequential Decision Making under Uncertainty: A Survey",
            "url": "https://www.semanticscholar.org/paper/da98d6e5807c7a62bb1ceb1a6dabd390356a5e71",
            "venue": "",
            "year": 2021
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "1656712399",
                    "name": "Yohei Hayamizu"
                },
                {
                    "authorId": "1383234530",
                    "name": "Kishan Chandan"
                },
                {
                    "authorId": "144087825",
                    "name": "K. Takadama"
                },
                {
                    "authorId": "2274148002",
                    "name": "Shiqi Zhang"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "3327d53ea4757b3edaeb76891aed6c3d0969502f",
            "title": "Ef\ufb01cient Exploration in Reinforcement Learning Leveraging Automated Planning",
            "url": "https://www.semanticscholar.org/paper/3327d53ea4757b3edaeb76891aed6c3d0969502f",
            "venue": "",
            "year": 2020
        }
    ],
    "corpusId": 208512685,
    "doi": "10.1609/AAAI.V34I04.5802",
    "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
    ],
    "influentialCitationCount": 1,
    "isOpenAccess": true,
    "isPublisherLicensed": true,
    "is_open_access": true,
    "is_publisher_licensed": true,
    "numCitedBy": 31,
    "numCiting": 36,
    "paperId": "c62d84f3d4753d7e3c4747b966cb050d4b667280",
    "references": [
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "1765407",
                    "name": "G. Konidaris"
                }
            ],
            "doi": "10.1016/j.cobeha.2018.11.005",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "05a73861f46fb42d682fcdac86a475ad748f036e",
            "title": "On the necessity of abstraction",
            "url": "https://www.semanticscholar.org/paper/05a73861f46fb42d682fcdac86a475ad748f036e",
            "venue": "Current Opinion in Behavioral Sciences",
            "year": 2019
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "15316342",
                    "name": "Rodrigo Toro Icarte"
                },
                {
                    "authorId": "1396422950",
                    "name": "Ethan Waldie"
                },
                {
                    "authorId": "1758085",
                    "name": "Toryn Q. Klassen"
                },
                {
                    "authorId": "2682734",
                    "name": "R. Valenzano"
                },
                {
                    "authorId": "41036745",
                    "name": "Margarita P. Castro"
                },
                {
                    "authorId": "1683896",
                    "name": "Sheila A. McIlraith"
                }
            ],
            "doi": null,
            "intent": [
                "background",
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "a03472a07ac2ef5b5b03358d074d2891c8fba144",
            "title": "Learning Reward Machines for Partially Observable Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/a03472a07ac2ef5b5b03358d074d2891c8fba144",
            "venue": "NeurIPS",
            "year": 2019
        },
        {
            "arxivId": "1909.05912",
            "authors": [
                {
                    "authorId": "50070268",
                    "name": "Zhe Xu"
                },
                {
                    "authorId": "2202693",
                    "name": "I. Gavran"
                },
                {
                    "authorId": "2059612900",
                    "name": "Yousef Ahmad"
                },
                {
                    "authorId": "144029582",
                    "name": "R. Majumdar"
                },
                {
                    "authorId": "1779795",
                    "name": "D. Neider"
                },
                {
                    "authorId": "3199888",
                    "name": "U. Topcu"
                },
                {
                    "authorId": "152365289",
                    "name": "Bo Wu"
                }
            ],
            "doi": "10.1609/icaps.v30i1.6756",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "f6d0d9785ba4444d10a84d01bdd01f0bf9871152",
            "title": "Joint Inference of Reward Machines and Policies for Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/f6d0d9785ba4444d10a84d01bdd01f0bf9871152",
            "venue": "ICAPS",
            "year": 2019
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "47505744",
                    "name": "Alberto Camacho"
                },
                {
                    "authorId": "15316342",
                    "name": "Rodrigo Toro Icarte"
                },
                {
                    "authorId": "1758085",
                    "name": "Toryn Q. Klassen"
                },
                {
                    "authorId": "2682734",
                    "name": "R. Valenzano"
                },
                {
                    "authorId": "1683896",
                    "name": "Sheila A. McIlraith"
                }
            ],
            "doi": "10.24963/ijcai.2019/840",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "c3d0e3c5ca9fa56cf2ff7303a2f67bf44694e6d4",
            "title": "LTL and Beyond: Formal Languages for Reward Function Specification in Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/c3d0e3c5ca9fa56cf2ff7303a2f67bf44694e6d4",
            "venue": "IJCAI",
            "year": 2019
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2066450047",
                    "name": "R. Lange"
                },
                {
                    "authorId": "49796804",
                    "name": "A. Faisal"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "3944f15e0c2d39d114e5a44aedd079630607521e",
            "title": "Semantic RL with Action Grammars: Data-Efficient Learning of Hierarchical Task Abstractions",
            "url": "https://www.semanticscholar.org/paper/3944f15e0c2d39d114e5a44aedd079630607521e",
            "venue": "",
            "year": 2019
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2543534",
                    "name": "Mark K. Ho"
                },
                {
                    "authorId": "152422014",
                    "name": "David Abel"
                },
                {
                    "authorId": "1799860",
                    "name": "T. Griffiths"
                },
                {
                    "authorId": "144885169",
                    "name": "M. Littman"
                }
            ],
            "doi": "10.1016/j.cobeha.2019.05.001",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "1a1af8f6eebda877157393e6dd56e52ec2a99dba",
            "title": "The value of abstraction",
            "url": "https://www.semanticscholar.org/paper/1a1af8f6eebda877157393e6dd56e52ec2a99dba",
            "venue": "Current Opinion in Behavioral Sciences",
            "year": 2019
        },
        {
            "arxivId": "1902.10297",
            "authors": [
                {
                    "authorId": "9926805",
                    "name": "Joshua J. Michalenko"
                },
                {
                    "authorId": "14060854",
                    "name": "Ameesh Shah"
                },
                {
                    "authorId": "2973529",
                    "name": "Abhinav Verma"
                },
                {
                    "authorId": "144908066",
                    "name": "Richard Baraniuk"
                },
                {
                    "authorId": "35865989",
                    "name": "Swarat Chaudhuri"
                },
                {
                    "authorId": "46463998",
                    "name": "Ankit B. Patel"
                }
            ],
            "doi": null,
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "9fac39c702724732188ff61090d2e2b498a34eb2",
            "title": "Representing Formal Languages: A Comparison Between Finite Automata and Recurrent Neural Networks",
            "url": "https://www.semanticscholar.org/paper/9fac39c702724732188ff61090d2e2b498a34eb2",
            "venue": "ICLR",
            "year": 2019
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "145824029",
                    "name": "David Silver"
                },
                {
                    "authorId": "2067208983",
                    "name": "T. Hubert"
                },
                {
                    "authorId": "4337102",
                    "name": "Julian Schrittwieser"
                },
                {
                    "authorId": "2460849",
                    "name": "Ioannis Antonoglou"
                },
                {
                    "authorId": "40227832",
                    "name": "Matthew Lai"
                },
                {
                    "authorId": "35099444",
                    "name": "A. Guez"
                },
                {
                    "authorId": "1975889",
                    "name": "Marc Lanctot"
                },
                {
                    "authorId": "2175946",
                    "name": "L. Sifre"
                },
                {
                    "authorId": "2106164",
                    "name": "D. Kumaran"
                },
                {
                    "authorId": "1686971",
                    "name": "T. Graepel"
                },
                {
                    "authorId": "2542999",
                    "name": "T. Lillicrap"
                },
                {
                    "authorId": "34838386",
                    "name": "K. Simonyan"
                },
                {
                    "authorId": "48987704",
                    "name": "D. Hassabis"
                }
            ],
            "doi": "10.1126/science.aar6404",
            "intent": [],
            "isInfluential": false,
            "paperId": "f9717d29840f4d8f1cc19d1b1e80c5d12ec40608",
            "title": "A general reinforcement learning algorithm that masters chess, shogi, and Go through self-play",
            "url": "https://www.semanticscholar.org/paper/f9717d29840f4d8f1cc19d1b1e80c5d12ec40608",
            "venue": "Science",
            "year": 2018
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2312066313",
                    "name": "Javier Segovia-Aguas"
                },
                {
                    "authorId": "145410477",
                    "name": "Sergio Jim\u00e9nez"
                },
                {
                    "authorId": "143808510",
                    "name": "Anders Jonsson"
                }
            ],
            "doi": "10.1613/jair.1.11227",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "dbfc5666606694e64fe4f4a53987290ecc89ca90",
            "title": "Computing Hierarchical Finite State Controllers With Classical Planning",
            "url": "https://www.semanticscholar.org/paper/dbfc5666606694e64fe4f4a53987290ecc89ca90",
            "venue": "J. Artif. Intell. Res.",
            "year": 2018
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "15316342",
                    "name": "Rodrigo Toro Icarte"
                },
                {
                    "authorId": "1758085",
                    "name": "Toryn Q. Klassen"
                },
                {
                    "authorId": "2682734",
                    "name": "R. Valenzano"
                },
                {
                    "authorId": "1683896",
                    "name": "Sheila A. McIlraith"
                }
            ],
            "doi": null,
            "intent": [
                "methodology"
            ],
            "isInfluential": true,
            "paperId": "00ec8123dd2ba03afab7c1fa02f774062f769181",
            "title": "Using Reward Machines for High-Level Task Specification and Decomposition in Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/00ec8123dd2ba03afab7c1fa02f774062f769181",
            "venue": "ICML",
            "year": 2018
        },
        {
            "arxivId": "1711.09576",
            "authors": [
                {
                    "authorId": "145909798",
                    "name": "Gail Weiss"
                },
                {
                    "authorId": "2089067",
                    "name": "Yoav Goldberg"
                },
                {
                    "authorId": "1743232",
                    "name": "Eran Yahav"
                }
            ],
            "doi": null,
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "4e4cae6d93a1c2bdc2ac0fa2810a270052378fe2",
            "title": "Extracting Automata from Recurrent Neural Networks Using Queries and Counterexamples",
            "url": "https://www.semanticscholar.org/paper/4e4cae6d93a1c2bdc2ac0fa2810a270052378fe2",
            "venue": "ICML",
            "year": 2017
        },
        {
            "arxivId": "1703.00956",
            "authors": [
                {
                    "authorId": "40066857",
                    "name": "Marlos C. Machado"
                },
                {
                    "authorId": "1792298",
                    "name": "Marc G. Bellemare"
                },
                {
                    "authorId": "1687780",
                    "name": "Michael Bowling"
                }
            ],
            "doi": null,
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "8423cc50c18d68f797adaa4f571f5e4efbe325a5",
            "title": "A Laplacian Framework for Option Discovery in Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/8423cc50c18d68f797adaa4f571f5e4efbe325a5",
            "venue": "ICML",
            "year": 2017
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "3255983",
                    "name": "Volodymyr Mnih"
                },
                {
                    "authorId": "2645384",
                    "name": "K. Kavukcuoglu"
                },
                {
                    "authorId": "145824029",
                    "name": "David Silver"
                },
                {
                    "authorId": "2228824",
                    "name": "Andrei A. Rusu"
                },
                {
                    "authorId": "144056327",
                    "name": "J. Veness"
                },
                {
                    "authorId": "1792298",
                    "name": "Marc G. Bellemare"
                },
                {
                    "authorId": "1753223",
                    "name": "Alex Graves"
                },
                {
                    "authorId": "3137672",
                    "name": "Martin A. Riedmiller"
                },
                {
                    "authorId": "145600108",
                    "name": "A. Fidjeland"
                },
                {
                    "authorId": "2273072",
                    "name": "Georg Ostrovski"
                },
                {
                    "authorId": "48348688",
                    "name": "Stig Petersen"
                },
                {
                    "authorId": "50388928",
                    "name": "Charlie Beattie"
                },
                {
                    "authorId": "49813280",
                    "name": "Amir Sadik"
                },
                {
                    "authorId": "2460849",
                    "name": "Ioannis Antonoglou"
                },
                {
                    "authorId": "143776287",
                    "name": "Helen King"
                },
                {
                    "authorId": "2106164",
                    "name": "D. Kumaran"
                },
                {
                    "authorId": "1688276",
                    "name": "Daan Wierstra"
                },
                {
                    "authorId": "34313265",
                    "name": "S. Legg"
                },
                {
                    "authorId": "48987704",
                    "name": "D. Hassabis"
                }
            ],
            "doi": "10.1038/nature14236",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "340f48901f72278f6bf78a04ee5b01df208cc508",
            "title": "Human-level control through deep reinforcement learning",
            "url": "https://www.semanticscholar.org/paper/340f48901f72278f6bf78a04ee5b01df208cc508",
            "venue": "Nature",
            "year": 2015
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "1719720",
                    "name": "M. Gelfond"
                },
                {
                    "authorId": "69444152",
                    "name": "Yulia Kahl"
                }
            ],
            "doi": "10.1017/cbo9781139342124",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "eb9997203fd6510a56eb42144121ef7e048f00f1",
            "title": "Knowledge Representation, Reasoning, and the Design of Intelligent Agents: The Answer-Set Programming Approach",
            "url": "https://www.semanticscholar.org/paper/eb9997203fd6510a56eb42144121ef7e048f00f1",
            "venue": "",
            "year": 2014
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "1696726",
                    "name": "M. Leonetti"
                },
                {
                    "authorId": "1712013",
                    "name": "L. Iocchi"
                },
                {
                    "authorId": "1698994",
                    "name": "F. Patrizi"
                }
            ],
            "doi": "10.1007/978-3-642-33185-5_15",
            "intent": [],
            "isInfluential": false,
            "paperId": "c582673b0126bf8d25bf5f6811daadc6aea5d11e",
            "title": "Automatic Generation and Learning of Finite-State Controllers",
            "url": "https://www.semanticscholar.org/paper/c582673b0126bf8d25bf5f6811daadc6aea5d11e",
            "venue": "AIMSA",
            "year": 2012
        },
        {
            "arxivId": "1008.1809",
            "authors": [
                {
                    "authorId": "40117299",
                    "name": "C. Drescher"
                },
                {
                    "authorId": "1404543780",
                    "name": "Oana Tifrea-Marciuska"
                },
                {
                    "authorId": "1733716",
                    "name": "T. Walsh"
                }
            ],
            "doi": "10.3233/AIC-2011-0495",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "e1fb299c70f411cf4a1be8073bb73af62dabcf2d",
            "title": "Symmetry-breaking answer set solving",
            "url": "https://www.semanticscholar.org/paper/e1fb299c70f411cf4a1be8073bb73af62dabcf2d",
            "venue": "AI Commun.",
            "year": 2010
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "1694156",
                    "name": "Blai Bonet"
                },
                {
                    "authorId": "143740864",
                    "name": "H\u00e9ctor Palacios"
                },
                {
                    "authorId": "1806598",
                    "name": "Hector Geffner"
                }
            ],
            "doi": "10.1609/icaps.v19i1.13379",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "75cfd8385fd9964f6b4d95ba7757ea53d5e0a102",
            "title": "Automatic Derivation of Memoryless Policies and Finite-State Controllers Using Classical Planners",
            "url": "https://www.semanticscholar.org/paper/75cfd8385fd9964f6b4d95ba7757ea53d5e0a102",
            "venue": "ICAPS",
            "year": 2009
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2510156",
                    "name": "\u00d6zg\u00fcr Simsek"
                },
                {
                    "authorId": "1759756",
                    "name": "Alicia P. Wolfe"
                },
                {
                    "authorId": "1730590",
                    "name": "A. Barto"
                }
            ],
            "doi": "10.1145/1102351.1102454",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "1c59bfa0e8654ebea94277064f82062875cae8b6",
            "title": "Identifying useful subgoals in reinforcement learning by local graph partitioning",
            "url": "https://www.semanticscholar.org/paper/1c59bfa0e8654ebea94277064f82062875cae8b6",
            "venue": "ICML",
            "year": 2005
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2510156",
                    "name": "\u00d6zg\u00fcr Simsek"
                },
                {
                    "authorId": "1730590",
                    "name": "A. Barto"
                }
            ],
            "doi": "10.1145/1015330.1015353",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "fd4de76fadddd1cc9a91cea954200c8d656e1dbb",
            "title": "Using relative novelty to identify useful temporal abstractions in reinforcement learning",
            "url": "https://www.semanticscholar.org/paper/fd4de76fadddd1cc9a91cea954200c8d656e1dbb",
            "venue": "ICML",
            "year": 2004
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "1684547",
                    "name": "Ishai Menache"
                },
                {
                    "authorId": "1712535",
                    "name": "Shie Mannor"
                },
                {
                    "authorId": "1742179",
                    "name": "N. Shimkin"
                }
            ],
            "doi": "10.1007/3-540-36755-1_25",
            "intent": [],
            "isInfluential": false,
            "paperId": "dca9444e1c69eee36c0be04703d71114a762c84a",
            "title": "Q-Cut - Dynamic Discovery of Sub-goals in Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/dca9444e1c69eee36c0be04703d71114a762c84a",
            "venue": "ECML",
            "year": 2002
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2856542",
                    "name": "M. Stolle"
                },
                {
                    "authorId": "144368601",
                    "name": "Doina Precup"
                }
            ],
            "doi": "10.1007/3-540-45622-8_16",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "48bf148ca96f928d762c5be9231f1cdff8090cc7",
            "title": "Learning Options in Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/48bf148ca96f928d762c5be9231f1cdff8090cc7",
            "venue": "SARA",
            "year": 2002
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2299685",
                    "name": "A. McGovern"
                },
                {
                    "authorId": "1730590",
                    "name": "A. Barto"
                }
            ],
            "doi": null,
            "intent": [
                "background",
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "03dbb37d2373500115735ed69871e94c7f6b2c5e",
            "title": "Automatic Discovery of Subgoals in Reinforcement Learning using Diverse Density",
            "url": "https://www.semanticscholar.org/paper/03dbb37d2373500115735ed69871e94c7f6b2c5e",
            "venue": "ICML",
            "year": 2001
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "1699645",
                    "name": "R. Sutton"
                },
                {
                    "authorId": "144368601",
                    "name": "Doina Precup"
                },
                {
                    "authorId": "1699868",
                    "name": "Satinder Singh"
                }
            ],
            "doi": "10.1016/S0004-3702(99)00052-1",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "0e7638dc16a5e5e9e46c91272bfb9c3dd242ef6d",
            "title": "Between MDPs and Semi-MDPs: A Framework for Temporal Abstraction in Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/0e7638dc16a5e5e9e46c91272bfb9c3dd242ef6d",
            "venue": "Artif. Intell.",
            "year": 1999
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "34699434",
                    "name": "A. Ng"
                },
                {
                    "authorId": "1868677",
                    "name": "Daishi Harada"
                },
                {
                    "authorId": "145107462",
                    "name": "Stuart J. Russell"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "94066dc12fe31e96af7557838159bde598cb4f10",
            "title": "Policy Invariance Under Reward Transformations: Theory and Application to Reward Shaping",
            "url": "https://www.semanticscholar.org/paper/94066dc12fe31e96af7557838159bde598cb4f10",
            "venue": "ICML",
            "year": 1999
        },
        {
            "arxivId": "cs/9905014",
            "authors": [
                {
                    "authorId": "144299726",
                    "name": "Thomas G. Dietterich"
                }
            ],
            "doi": "10.1613/jair.639",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "4c96ca25d889251e20e33d01f24eec175301ab94",
            "title": "Hierarchical Reinforcement Learning with the MAXQ Value Function Decomposition",
            "url": "https://www.semanticscholar.org/paper/4c96ca25d889251e20e33d01f24eec175301ab94",
            "venue": "J. Artif. Intell. Res.",
            "year": 1999
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "1699645",
                    "name": "R. Sutton"
                },
                {
                    "authorId": "144368601",
                    "name": "Doina Precup"
                },
                {
                    "authorId": "1699868",
                    "name": "Satinder Singh"
                }
            ],
            "doi": null,
            "intent": [
                "background",
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "390ec126ebc0f7f2719e9b2598decc58294b4350",
            "title": "Intra-Option Learning about Temporally Abstract Actions",
            "url": "https://www.semanticscholar.org/paper/390ec126ebc0f7f2719e9b2598decc58294b4350",
            "venue": "ICML",
            "year": 1998
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "145726861",
                    "name": "Ronald E. Parr"
                },
                {
                    "authorId": "145107462",
                    "name": "Stuart J. Russell"
                }
            ],
            "doi": null,
            "intent": [
                "methodology"
            ],
            "isInfluential": true,
            "paperId": "52e2ac397f0c8d5f533959905df899bc328d9f85",
            "title": "Reinforcement Learning with Hierarchies of Machines",
            "url": "https://www.semanticscholar.org/paper/52e2ac397f0c8d5f533959905df899bc328d9f85",
            "venue": "NIPS",
            "year": 1997
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "1804676",
                    "name": "B. Kr\u00f6se"
                }
            ],
            "doi": "10.1016/0921-8890(95)00026-C",
            "intent": [
                "background",
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "59b50a775542e87f078db35b868ac10ab43d4c75",
            "title": "Learning from delayed rewards",
            "url": "https://www.semanticscholar.org/paper/59b50a775542e87f078db35b868ac10ab43d4c75",
            "venue": "Robotics Auton. Syst.",
            "year": 1995
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2220060264",
                    "name": "Richard S. Suttona"
                },
                {
                    "authorId": "2220060262",
                    "name": "Doina Precupb"
                },
                {
                    "authorId": "2220060327",
                    "name": "Satinder Singha"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "eae22f46217dc8becef3b67cd71cef46bfc3a749",
            "title": "Between MDPs and semi-MDPs: A framework for temporal abstraction in reinforcement learning",
            "url": "https://www.semanticscholar.org/paper/eae22f46217dc8becef3b67cd71cef46bfc3a749",
            "venue": "",
            "year": 1999
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2238176724",
                    "name": "R. S. Sutton"
                },
                {
                    "authorId": "1730590",
                    "name": "A. Barto"
                }
            ],
            "doi": "10.1109/TNN.1998.712192",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "97efafdb4a3942ab3efba53ded7413199f79c054",
            "title": "Reinforcement Learning: An Introduction",
            "url": "https://www.semanticscholar.org/paper/97efafdb4a3942ab3efba53ded7413199f79c054",
            "venue": "IEEE Trans. Neural Networks",
            "year": 1998
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "46264950",
                    "name": "Mark Law"
                },
                {
                    "authorId": "145277911",
                    "name": "A. Russo"
                },
                {
                    "authorId": "1731914",
                    "name": "K. Broda"
                }
            ],
            "doi": null,
            "intent": [
                "background",
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "fffff682d74cadaa94e6f407942a160d3f0a40dd",
            "title": "Under Consideration for Publication in Theory and Practice of Logic Programming Iterative Learning of Answer Set Programs from Context Dependent Examples",
            "url": "https://www.semanticscholar.org/paper/fffff682d74cadaa94e6f407942a160d3f0a40dd",
            "venue": "",
            "year": null
        },
        {
            "arxivId": null,
            "authors": [],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "31e9ffdfc70a5c5930fc18c937c38c1e72f9c5e1",
            "title": "Proceedings of the Twenty-Second International Joint Conference on Artificial Intelligence Generalized Planning: Synthesizing Plans that Work for Multiple Environments",
            "url": "https://www.semanticscholar.org/paper/31e9ffdfc70a5c5930fc18c937c38c1e72f9c5e1",
            "venue": "",
            "year": null
        }
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Mathematics",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "title": "Induction of Subgoal Automata for Reinforcement Learning",
    "topics": [],
    "url": "https://www.semanticscholar.org/paper/c62d84f3d4753d7e3c4747b966cb050d4b667280",
    "venue": "AAAI Conference on Artificial Intelligence",
    "year": 2019
}
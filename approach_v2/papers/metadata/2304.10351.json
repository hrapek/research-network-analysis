{
    "abstract": "In multi-agent reinforcement learning (MARL), self-interested agents attempt to establish equilibrium and achieve coordination depending on game structure. However, existing MARL approaches are mostly bound by the simultaneous actions of all agents in the Markov game (MG) framework, and few works consider the formation of equilibrium strategies via asynchronous action coordination. In view of the advantages of Stackelberg equilibrium (SE) over Nash equilibrium, we construct a spatio-temporal sequential decision-making structure derived from the MG and propose an N-level policy model based on a conditional hypernetwork shared by all agents. This approach allows for asymmetric training with symmetric execution, with each agent responding optimally conditioned on the decisions made by superior agents. Agents can learn heterogeneous SE policies while still maintaining parameter sharing, which leads to reduced cost for learning and storage and enhanced scalability as the number of agents increases. Experiments demonstrate that our method effectively converges to the SE policies in repeated matrix game scenarios, and performs admirably in immensely complex settings including cooperative tasks and mixed tasks.",
    "arxivId": "2304.10351",
    "authors": [
        {
            "authorId": "2119453124",
            "name": "Bin Zhang",
            "url": "https://www.semanticscholar.org/author/2119453124"
        },
        {
            "authorId": "2214835116",
            "name": "Lijuan Li",
            "url": "https://www.semanticscholar.org/author/2214835116"
        },
        {
            "authorId": "153008118",
            "name": "Zhiwei Xu",
            "url": "https://www.semanticscholar.org/author/153008118"
        },
        {
            "authorId": "2115499783",
            "name": "Dapeng Li",
            "url": "https://www.semanticscholar.org/author/2115499783"
        },
        {
            "authorId": "2067827377",
            "name": "Guoliang Fan",
            "url": "https://www.semanticscholar.org/author/2067827377"
        }
    ],
    "citationVelocity": 0,
    "citations": [
        {
            "arxivId": "2312.09009",
            "authors": [
                {
                    "authorId": "2115499783",
                    "name": "Dapeng Li"
                },
                {
                    "authorId": "2274104055",
                    "name": "Na Lou"
                },
                {
                    "authorId": "2119453124",
                    "name": "Bin Zhang"
                },
                {
                    "authorId": "153008118",
                    "name": "Zhiwei Xu"
                },
                {
                    "authorId": "2067827377",
                    "name": "Guoliang Fan"
                }
            ],
            "doi": "10.1109/ICASSP48485.2024.10447262",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "ce48c51027c3626274ddedeeec6094ba8cb4b7a2",
            "title": "Adaptive Parameter Sharing for Multi-Agent Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/ce48c51027c3626274ddedeeec6094ba8cb4b7a2",
            "venue": "ICASSP 2024 - 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)",
            "year": 2023
        },
        {
            "arxivId": "2311.13884",
            "authors": [
                {
                    "authorId": "2119453124",
                    "name": "Bin Zhang"
                },
                {
                    "authorId": "2262446566",
                    "name": "Hangyu Mao"
                },
                {
                    "authorId": "2135060971",
                    "name": "Jingqing Ruan"
                },
                {
                    "authorId": "2155576705",
                    "name": "Ying Wen"
                },
                {
                    "authorId": "2321328048",
                    "name": "Yang Li"
                },
                {
                    "authorId": "2116577679",
                    "name": "Shao Zhang"
                },
                {
                    "authorId": "153008118",
                    "name": "Zhiwei Xu"
                },
                {
                    "authorId": "2115499783",
                    "name": "Dapeng Li"
                },
                {
                    "authorId": "2262543561",
                    "name": "Ziyue Li"
                },
                {
                    "authorId": "2263456785",
                    "name": "Rui Zhao"
                },
                {
                    "authorId": "2214835116",
                    "name": "Lijuan Li"
                },
                {
                    "authorId": "2067827377",
                    "name": "Guoliang Fan"
                }
            ],
            "doi": "10.48550/arXiv.2311.13884",
            "intent": [],
            "isInfluential": false,
            "paperId": "bc8d248fb86a3b6a285e8b9a6fe2c09e7f0b19c9",
            "title": "Controlling Large Language Model-based Agents for Large-Scale Decision-Making: An Actor-Critic Approach",
            "url": "https://www.semanticscholar.org/paper/bc8d248fb86a3b6a285e8b9a6fe2c09e7f0b19c9",
            "venue": "ArXiv",
            "year": 2023
        },
        {
            "arxivId": "2305.07856",
            "authors": [
                {
                    "authorId": "2119453124",
                    "name": "Bin Zhang"
                },
                {
                    "authorId": "8595845",
                    "name": "Hangyu Mao"
                },
                {
                    "authorId": "2214835116",
                    "name": "Lijuan Li"
                },
                {
                    "authorId": "153008118",
                    "name": "Zhiwei Xu"
                },
                {
                    "authorId": "2115499783",
                    "name": "Dapeng Li"
                },
                {
                    "authorId": "2114012077",
                    "name": "Rui Zhao"
                },
                {
                    "authorId": "2067827377",
                    "name": "Guoliang Fan"
                }
            ],
            "doi": "10.48550/arXiv.2305.07856",
            "intent": [
                "result",
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "paperId": "698d51d648056fc31b1af21debe090e6254fd134",
            "title": "Stackelberg Decision Transformer for Asynchronous Action Coordination in Multi-Agent Systems",
            "url": "https://www.semanticscholar.org/paper/698d51d648056fc31b1af21debe090e6254fd134",
            "venue": "ArXiv",
            "year": 2023
        },
        {
            "arxivId": "2302.02180",
            "authors": [
                {
                    "authorId": "153008118",
                    "name": "Zhiwei Xu"
                },
                {
                    "authorId": "2119453124",
                    "name": "Bin Zhang"
                },
                {
                    "authorId": "2115499783",
                    "name": "Dapeng Li"
                },
                {
                    "authorId": "2168379436",
                    "name": "Guangchong Zhou"
                },
                {
                    "authorId": "2048590587",
                    "name": "Zeren Zhang"
                },
                {
                    "authorId": "2067827377",
                    "name": "Guoliang Fan"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "0cc100ab78fc807724745a3cbcd671a1adf91f34",
            "title": "Dual Self-Awareness Value Decomposition Framework without Individual Global Max for Cooperative Multi-Agent Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/0cc100ab78fc807724745a3cbcd671a1adf91f34",
            "venue": "",
            "year": 2023
        },
        {
            "arxivId": "2210.08872",
            "authors": [
                {
                    "authorId": "2117947833",
                    "name": "Yiqun Chen"
                },
                {
                    "authorId": "8595845",
                    "name": "Hangyu Mao"
                },
                {
                    "authorId": "2146332776",
                    "name": "Tianle Zhang"
                },
                {
                    "authorId": "14196556",
                    "name": "Shiguang Wu"
                },
                {
                    "authorId": "2119453124",
                    "name": "Bin Zhang"
                },
                {
                    "authorId": "2069718816",
                    "name": "Jianye Hao"
                },
                {
                    "authorId": "2108821147",
                    "name": "Dong Li"
                },
                {
                    "authorId": "2152593803",
                    "name": "Bin Wang"
                },
                {
                    "authorId": "2116284935",
                    "name": "Hong Chang"
                }
            ],
            "doi": "10.24963/ijcai.2024/4",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "d1694d8ca454574d9f141446364f21ed505e189a",
            "title": "PTDE: Personalized Training with Distilled Execution for Multi-Agent Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/d1694d8ca454574d9f141446364f21ed505e189a",
            "venue": "IJCAI",
            "year": 2022
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2119453124",
                    "name": "Bin Zhang"
                },
                {
                    "authorId": "2262446566",
                    "name": "Hangyu Mao"
                },
                {
                    "authorId": "2214835116",
                    "name": "Lijuan Li"
                },
                {
                    "authorId": "2267204947",
                    "name": "Zhiwei Xu"
                },
                {
                    "authorId": "2115499783",
                    "name": "Dapeng Li"
                },
                {
                    "authorId": "2316607996",
                    "name": "Rui Zhao"
                },
                {
                    "authorId": "2067827377",
                    "name": "Guoliang Fan"
                }
            ],
            "doi": null,
            "intent": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "paperId": "22f0ec8efccfd358c2f0b509cad4453dacfa1298",
            "title": "Sequential Asynchronous Action Coordination in Multi-Agent Systems: A Stackelberg Decision Transformer Approach",
            "url": "https://www.semanticscholar.org/paper/22f0ec8efccfd358c2f0b509cad4453dacfa1298",
            "venue": "ICML",
            "year": 2024
        }
    ],
    "corpusId": 258236291,
    "doi": "10.48550/arXiv.2304.10351",
    "fieldsOfStudy": [
        "Computer Science"
    ],
    "influentialCitationCount": 1,
    "isOpenAccess": true,
    "isPublisherLicensed": true,
    "is_open_access": true,
    "is_publisher_licensed": true,
    "numCitedBy": 6,
    "numCiting": 32,
    "paperId": "45567a7cc048a0c90265b472643f391cd2fba06e",
    "references": [
        {
            "arxivId": "2210.08872",
            "authors": [
                {
                    "authorId": "2117947833",
                    "name": "Yiqun Chen"
                },
                {
                    "authorId": "8595845",
                    "name": "Hangyu Mao"
                },
                {
                    "authorId": "2146332776",
                    "name": "Tianle Zhang"
                },
                {
                    "authorId": "14196556",
                    "name": "Shiguang Wu"
                },
                {
                    "authorId": "2119453124",
                    "name": "Bin Zhang"
                },
                {
                    "authorId": "2069718816",
                    "name": "Jianye Hao"
                },
                {
                    "authorId": "2108821147",
                    "name": "Dong Li"
                },
                {
                    "authorId": "2152593803",
                    "name": "Bin Wang"
                },
                {
                    "authorId": "2116284935",
                    "name": "Hong Chang"
                }
            ],
            "doi": "10.24963/ijcai.2024/4",
            "intent": [],
            "isInfluential": false,
            "paperId": "d1694d8ca454574d9f141446364f21ed505e189a",
            "title": "PTDE: Personalized Training with Distilled Execution for Multi-Agent Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/d1694d8ca454574d9f141446364f21ed505e189a",
            "venue": "IJCAI",
            "year": 2022
        },
        {
            "arxivId": "2203.03265",
            "authors": [
                {
                    "authorId": "2119453124",
                    "name": "Bin Zhang"
                },
                {
                    "authorId": "153802746",
                    "name": "Yunru Bai"
                },
                {
                    "authorId": "153008118",
                    "name": "Zhiwei Xu"
                },
                {
                    "authorId": "2115499783",
                    "name": "Dapeng Li"
                },
                {
                    "authorId": "2067827377",
                    "name": "Guoliang Fan"
                }
            ],
            "doi": "10.1007/978-3-031-30108-7_19",
            "intent": [],
            "isInfluential": false,
            "paperId": "acd39771d33dee72826d2debbe1d5a2a623d450d",
            "title": "Efficient Policy Generation in Multi-agent Systems via Hypergraph Neural Network",
            "url": "https://www.semanticscholar.org/paper/acd39771d33dee72826d2debbe1d5a2a623d450d",
            "venue": "ICONIP",
            "year": 2022
        },
        {
            "arxivId": "2109.11251",
            "authors": [
                {
                    "authorId": "2126704872",
                    "name": "J. Kuba"
                },
                {
                    "authorId": "2118230909",
                    "name": "Ruiqing Chen"
                },
                {
                    "authorId": "2130205050",
                    "name": "Munning Wen"
                },
                {
                    "authorId": "50531782",
                    "name": "Ying Wen"
                },
                {
                    "authorId": "3003954",
                    "name": "Fanglei Sun"
                },
                {
                    "authorId": "48094081",
                    "name": "Jun Wang"
                },
                {
                    "authorId": "47796324",
                    "name": "Yaodong Yang"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "27302766f8d0eb6c052eb400e234c5be0e7a767e",
            "title": "Trust Region Policy Optimisation in Multi-Agent Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/27302766f8d0eb6c052eb400e234c5be0e7a767e",
            "venue": "ICLR",
            "year": 2021
        },
        {
            "arxivId": "2105.05701",
            "authors": [
                {
                    "authorId": "2158192013",
                    "name": "Dong Chen"
                },
                {
                    "authorId": "1582053711",
                    "name": "Mohammad R. Hajidavalloo"
                },
                {
                    "authorId": "7719355",
                    "name": "Zhaojian Li"
                },
                {
                    "authorId": "1576210249",
                    "name": "Kaian Chen"
                },
                {
                    "authorId": "2143454052",
                    "name": "Yongqiang Wang"
                },
                {
                    "authorId": "2316539",
                    "name": "Longsheng Jiang"
                },
                {
                    "authorId": "2144334027",
                    "name": "Yue Wang"
                }
            ],
            "doi": "10.1109/TITS.2023.3285442",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "387a5c917656242be53b3d763bf4c5c70ee9f877",
            "title": "Deep Multi-Agent Reinforcement Learning for Highway On-Ramp Merging in Mixed Traffic",
            "url": "https://www.semanticscholar.org/paper/387a5c917656242be53b3d763bf4c5c70ee9f877",
            "venue": "IEEE Transactions on Intelligent Transportation Systems",
            "year": 2021
        },
        {
            "arxivId": "2104.03503",
            "authors": [
                {
                    "authorId": "153008118",
                    "name": "Zhiwei Xu"
                },
                {
                    "authorId": "2119453124",
                    "name": "Bin Zhang"
                },
                {
                    "authorId": "46931357",
                    "name": "Yunpeng Bai"
                },
                {
                    "authorId": "2115499783",
                    "name": "Dapeng Li"
                },
                {
                    "authorId": "2067827377",
                    "name": "Guoliang Fan"
                }
            ],
            "doi": "10.1007/978-3-030-92238-2_5",
            "intent": [],
            "isInfluential": false,
            "paperId": "122c368bc1d013c8a1f759301b1e19fcf7d2a8dc",
            "title": "Learning to Coordinate via Multiple Graph Neural Networks",
            "url": "https://www.semanticscholar.org/paper/122c368bc1d013c8a1f759301b1e19fcf7d2a8dc",
            "venue": "ICONIP",
            "year": 2021
        },
        {
            "arxivId": "2103.01955",
            "authors": [
                {
                    "authorId": "2110962386",
                    "name": "Chao Yu"
                },
                {
                    "authorId": "1999664196",
                    "name": "Akash Velu"
                },
                {
                    "authorId": "13430868",
                    "name": "Eugene Vinitsky"
                },
                {
                    "authorId": "2153607473",
                    "name": "Yu Wang"
                },
                {
                    "authorId": "1705102",
                    "name": "A. Bayen"
                },
                {
                    "authorId": "2108052525",
                    "name": "Yi Wu"
                }
            ],
            "doi": null,
            "intent": [
                "result",
                "background"
            ],
            "isInfluential": false,
            "paperId": "3a315c81a98851f0614c09fef6a14c30d6a1e63c",
            "title": "The Surprising Effectiveness of PPO in Cooperative Multi-Agent Games",
            "url": "https://www.semanticscholar.org/paper/3a315c81a98851f0614c09fef6a14c30d6a1e63c",
            "venue": "NeurIPS",
            "year": 2021
        },
        {
            "arxivId": "2003.06709",
            "authors": [
                {
                    "authorId": "2323268",
                    "name": "Bei Peng"
                },
                {
                    "authorId": "36054740",
                    "name": "Tabish Rashid"
                },
                {
                    "authorId": "47542438",
                    "name": "C. S. D. Witt"
                },
                {
                    "authorId": "1565543388",
                    "name": "Pierre-Alexandre Kamienny"
                },
                {
                    "authorId": "143635540",
                    "name": "Philip H. S. Torr"
                },
                {
                    "authorId": "84187676",
                    "name": "Wendelin Bohmer"
                },
                {
                    "authorId": "1766767",
                    "name": "Shimon Whiteson"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "7e61f1787cbf97bb59eb7f5f383e654d66947f0d",
            "title": "FACMAC: Factored Multi-Agent Centralised Policy Gradients",
            "url": "https://www.semanticscholar.org/paper/7e61f1787cbf97bb59eb7f5f383e654d66947f0d",
            "venue": "NeurIPS",
            "year": 2020
        },
        {
            "arxivId": "1909.03510",
            "authors": [
                {
                    "authorId": "2108784295",
                    "name": "Haifeng Zhang"
                },
                {
                    "authorId": null,
                    "name": "Weizhe Chen"
                },
                {
                    "authorId": "153857894",
                    "name": "Zeren Huang"
                },
                {
                    "authorId": "36069327",
                    "name": "Minne Li"
                },
                {
                    "authorId": "47796324",
                    "name": "Yaodong Yang"
                },
                {
                    "authorId": "2108309275",
                    "name": "Weinan Zhang"
                },
                {
                    "authorId": "48094081",
                    "name": "Jun Wang"
                }
            ],
            "doi": "10.1609/AAAI.V34I05.6226",
            "intent": [],
            "isInfluential": false,
            "paperId": "f1328905c42a53b84701cb72bc05788e83f628ac",
            "title": "Bi-level Actor-Critic for Multi-agent Coordination",
            "url": "https://www.semanticscholar.org/paper/f1328905c42a53b84701cb72bc05788e83f628ac",
            "venue": "AAAI",
            "year": 2019
        },
        {
            "arxivId": "1906.00695",
            "authors": [
                {
                    "authorId": "145167136",
                    "name": "J. Oswald"
                },
                {
                    "authorId": "2364999",
                    "name": "Christian Henning"
                },
                {
                    "authorId": "3105061",
                    "name": "J. Sacramento"
                },
                {
                    "authorId": "48117063",
                    "name": "B. Grewe"
                }
            ],
            "doi": "10.5167/UZH-200390",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "191461705e9961a3b07273c19d89eb214819002c",
            "title": "Continual learning with hypernetworks",
            "url": "https://www.semanticscholar.org/paper/191461705e9961a3b07273c19d89eb214819002c",
            "venue": "ICLR",
            "year": 2019
        },
        {
            "arxivId": "1905.08087",
            "authors": [
                {
                    "authorId": "152307789",
                    "name": "Zheng Tian"
                },
                {
                    "authorId": "50531782",
                    "name": "Ying Wen"
                },
                {
                    "authorId": "8200689",
                    "name": "Zhichen Gong"
                },
                {
                    "authorId": "1383122034",
                    "name": "Faiz Punakkath"
                },
                {
                    "authorId": "9399556",
                    "name": "Shihao Zou"
                },
                {
                    "authorId": "48094081",
                    "name": "Jun Wang"
                }
            ],
            "doi": "10.24963/IJCAI.2019/85",
            "intent": [],
            "isInfluential": false,
            "paperId": "6dd89f30a5a0e8c5404f23d05c27ef32149b9179",
            "title": "A Regularized Opponent Model with Maximum Entropy Objective",
            "url": "https://www.semanticscholar.org/paper/6dd89f30a5a0e8c5404f23d05c27ef32149b9179",
            "venue": "IJCAI",
            "year": 2019
        },
        {
            "arxivId": "1810.02912",
            "authors": [
                {
                    "authorId": "2899335",
                    "name": "Shariq Iqbal"
                },
                {
                    "authorId": "145757665",
                    "name": "Fei Sha"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "929bef0066bad871ba971b673c053112d055d29f",
            "title": "Actor-Attention-Critic for Multi-Agent Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/929bef0066bad871ba971b673c053112d055d29f",
            "venue": "ICML",
            "year": 2018
        },
        {
            "arxivId": "1803.11485",
            "authors": [
                {
                    "authorId": "36054740",
                    "name": "Tabish Rashid"
                },
                {
                    "authorId": "49089678",
                    "name": "Mikayel Samvelyan"
                },
                {
                    "authorId": "47542438",
                    "name": "C. S. D. Witt"
                },
                {
                    "authorId": "38698094",
                    "name": "Gregory Farquhar"
                },
                {
                    "authorId": "145356667",
                    "name": "Jakob N. Foerster"
                },
                {
                    "authorId": "1766767",
                    "name": "Shimon Whiteson"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "ffc211476f2e40e79466ffc198c919a97da3bb76",
            "title": "QMIX: Monotonic Value Function Factorisation for Deep Multi-Agent Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/ffc211476f2e40e79466ffc198c919a97da3bb76",
            "venue": "ICML",
            "year": 2018
        },
        {
            "arxivId": "1802.08757",
            "authors": [
                {
                    "authorId": "1776230",
                    "name": "K. Zhang"
                },
                {
                    "authorId": "150358650",
                    "name": "Zhuoran Yang"
                },
                {
                    "authorId": "2118959751",
                    "name": "Han Liu"
                },
                {
                    "authorId": "2146324552",
                    "name": "Tong Zhang"
                },
                {
                    "authorId": "2243689",
                    "name": "T. Ba\u015far"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "50df19aff9e4a68fedfc7dad3fca48a060fc9085",
            "title": "Fully Decentralized Multi-Agent Reinforcement Learning with Networked Agents",
            "url": "https://www.semanticscholar.org/paper/50df19aff9e4a68fedfc7dad3fca48a060fc9085",
            "venue": "ICML",
            "year": 2018
        },
        {
            "arxivId": "1802.05438",
            "authors": [
                {
                    "authorId": "47796324",
                    "name": "Yaodong Yang"
                },
                {
                    "authorId": "48846956",
                    "name": "Rui Luo"
                },
                {
                    "authorId": "36069327",
                    "name": "Minne Li"
                },
                {
                    "authorId": "143849609",
                    "name": "M. Zhou"
                },
                {
                    "authorId": "2108309275",
                    "name": "Weinan Zhang"
                },
                {
                    "authorId": "48094081",
                    "name": "Jun Wang"
                }
            ],
            "doi": null,
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "633870d249f03d39849224adc3381712fbb23ed8",
            "title": "Mean Field Multi-Agent Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/633870d249f03d39849224adc3381712fbb23ed8",
            "venue": "ICML",
            "year": 2018
        },
        {
            "arxivId": "1711.08946",
            "authors": [
                {
                    "authorId": "80675449",
                    "name": "Arash Tavakoli"
                },
                {
                    "authorId": "34758368",
                    "name": "Fabio Pardo"
                },
                {
                    "authorId": "1686032",
                    "name": "Petar Kormushev"
                }
            ],
            "doi": "10.1609/aaai.v32i1.11798",
            "intent": [],
            "isInfluential": false,
            "paperId": "dbcfd796d65cecef0385f30fae6af3e10753fd67",
            "title": "Action Branching Architectures for Deep Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/dbcfd796d65cecef0385f30fae6af3e10753fd67",
            "venue": "AAAI",
            "year": 2017
        },
        {
            "arxivId": "1707.06347",
            "authors": [
                {
                    "authorId": "47971768",
                    "name": "John Schulman"
                },
                {
                    "authorId": "143909660",
                    "name": "Filip Wolski"
                },
                {
                    "authorId": "6515819",
                    "name": "Prafulla Dhariwal"
                },
                {
                    "authorId": "38909097",
                    "name": "Alec Radford"
                },
                {
                    "authorId": "2067138712",
                    "name": "Oleg Klimov"
                }
            ],
            "doi": null,
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "dce6f9d4017b1785979e7520fd0834ef8cf02f4b",
            "title": "Proximal Policy Optimization Algorithms",
            "url": "https://www.semanticscholar.org/paper/dce6f9d4017b1785979e7520fd0834ef8cf02f4b",
            "venue": "ArXiv",
            "year": 2017
        },
        {
            "arxivId": "1706.02275",
            "authors": [
                {
                    "authorId": "2054294",
                    "name": "Ryan Lowe"
                },
                {
                    "authorId": "31613801",
                    "name": "Yi Wu"
                },
                {
                    "authorId": "3025260",
                    "name": "Aviv Tamar"
                },
                {
                    "authorId": "40638357",
                    "name": "J. Harb"
                },
                {
                    "authorId": "1689992",
                    "name": "P. Abbeel"
                },
                {
                    "authorId": "2080746",
                    "name": "Igor Mordatch"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "7c3ece1ba41c415d7e81cfa5ca33a8de66efd434",
            "title": "Multi-Agent Actor-Critic for Mixed Cooperative-Competitive Environments",
            "url": "https://www.semanticscholar.org/paper/7c3ece1ba41c415d7e81cfa5ca33a8de66efd434",
            "venue": "NIPS",
            "year": 2017
        },
        {
            "arxivId": "1705.05035",
            "authors": [
                {
                    "authorId": "2096458",
                    "name": "Luke Metz"
                },
                {
                    "authorId": "46920727",
                    "name": "Julian Ibarz"
                },
                {
                    "authorId": "3111912",
                    "name": "N. Jaitly"
                },
                {
                    "authorId": "2068894907",
                    "name": "James Davidson"
                }
            ],
            "doi": null,
            "intent": [
                "methodology",
                "background"
            ],
            "isInfluential": false,
            "paperId": "0c2954912936b59162881374164fe79e7b2bb66f",
            "title": "Discrete Sequential Prediction of Continuous Actions for Deep RL",
            "url": "https://www.semanticscholar.org/paper/0c2954912936b59162881374164fe79e7b2bb66f",
            "venue": "ArXiv",
            "year": 2017
        },
        {
            "arxivId": "1605.06676",
            "authors": [
                {
                    "authorId": "145356667",
                    "name": "Jakob N. Foerster"
                },
                {
                    "authorId": "3365565",
                    "name": "Yannis Assael"
                },
                {
                    "authorId": "1737568",
                    "name": "Nando de Freitas"
                },
                {
                    "authorId": "1766767",
                    "name": "Shimon Whiteson"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "0772905d40b9afa3dc087a88184f09f3b3e1464f",
            "title": "Learning to Communicate with Deep Multi-Agent Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/0772905d40b9afa3dc087a88184f09f3b3e1464f",
            "venue": "NIPS",
            "year": 2016
        },
        {
            "arxivId": "1509.02971",
            "authors": [
                {
                    "authorId": "2542999",
                    "name": "T. Lillicrap"
                },
                {
                    "authorId": "2323922",
                    "name": "Jonathan J. Hunt"
                },
                {
                    "authorId": "1863250",
                    "name": "A. Pritzel"
                },
                {
                    "authorId": "2801204",
                    "name": "N. Heess"
                },
                {
                    "authorId": "1968210",
                    "name": "Tom Erez"
                },
                {
                    "authorId": "2109481",
                    "name": "Yuval Tassa"
                },
                {
                    "authorId": "145824029",
                    "name": "David Silver"
                },
                {
                    "authorId": "1688276",
                    "name": "Daan Wierstra"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "024006d4c2a89f7acacc6e4438d156525b60a98f",
            "title": "Continuous control with deep reinforcement learning",
            "url": "https://www.semanticscholar.org/paper/024006d4c2a89f7acacc6e4438d156525b60a98f",
            "venue": "ICLR",
            "year": 2015
        },
        {
            "arxivId": "1312.5602",
            "authors": [
                {
                    "authorId": "3255983",
                    "name": "Volodymyr Mnih"
                },
                {
                    "authorId": "2645384",
                    "name": "K. Kavukcuoglu"
                },
                {
                    "authorId": "145824029",
                    "name": "David Silver"
                },
                {
                    "authorId": "1753223",
                    "name": "Alex Graves"
                },
                {
                    "authorId": "2460849",
                    "name": "Ioannis Antonoglou"
                },
                {
                    "authorId": "1688276",
                    "name": "Daan Wierstra"
                },
                {
                    "authorId": "3137672",
                    "name": "Martin A. Riedmiller"
                }
            ],
            "doi": null,
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "2319a491378867c7049b3da055c5df60e1671158",
            "title": "Playing Atari with Deep Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/2319a491378867c7049b3da055c5df60e1671158",
            "venue": "ArXiv",
            "year": 2013
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "66332951",
                    "name": "Heinrich von Stackelberg"
                }
            ],
            "doi": "10.1007/978-3-642-12586-7",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "b1199a19bd0f6dafb4b54dc84e83710d3a8af436",
            "title": "Market Structure and Equilibrium",
            "url": "https://www.semanticscholar.org/paper/b1199a19bd0f6dafb4b54dc84e83710d3a8af436",
            "venue": "",
            "year": 2010
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "73738498",
                    "name": "Junling Hu"
                },
                {
                    "authorId": "1796536",
                    "name": "Michael P. Wellman"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "dc4e9aa01abf579b6e5c8fc43261f9062e77a7f9",
            "title": "Nash Q-Learning for General-Sum Stochastic Games",
            "url": "https://www.semanticscholar.org/paper/dc4e9aa01abf579b6e5c8fc43261f9062e77a7f9",
            "venue": "J. Mach. Learn. Res.",
            "year": 2003
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "70053935",
                    "name": "H. J. Mclaughlin"
                },
                {
                    "authorId": "117057253",
                    "name": "Anna Liljestrom"
                },
                {
                    "authorId": "145752919",
                    "name": "J. Lim"
                },
                {
                    "authorId": "48181154",
                    "name": "Dawn Meyers"
                }
            ],
            "doi": "10.1177/0013124502342006",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "8f96cb4cfc30edaeada36d18336b0e04f9119114",
            "title": "Learn",
            "url": "https://www.semanticscholar.org/paper/8f96cb4cfc30edaeada36d18336b0e04f9119114",
            "venue": "",
            "year": 2002
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "144771028",
                    "name": "C. Claus"
                },
                {
                    "authorId": "145646162",
                    "name": "Craig Boutilier"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "38d35d5581e58dca4e9458501e65c1f85ca754d5",
            "title": "The Dynamics of Reinforcement Learning in Cooperative Multiagent Systems",
            "url": "https://www.semanticscholar.org/paper/38d35d5581e58dca4e9458501e65c1f85ca754d5",
            "venue": "AAAI/IAAI",
            "year": 1998
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "144885169",
                    "name": "M. Littman"
                }
            ],
            "doi": "10.1016/b978-1-55860-335-6.50027-1",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "7fbf55baccbc5fdc7ded1ba18330605909aef5e5",
            "title": "Markov Games as a Framework for Multi-Agent Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/7fbf55baccbc5fdc7ded1ba18330605909aef5e5",
            "venue": "ICML",
            "year": 1994
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2119453124",
                    "name": "Bin Zhang"
                },
                {
                    "authorId": "153008118",
                    "name": "Zhiwei Xu"
                },
                {
                    "authorId": "2117947833",
                    "name": "Yiqun Chen"
                },
                {
                    "authorId": "2115499783",
                    "name": "Dapeng Li"
                },
                {
                    "authorId": "153802746",
                    "name": "Yunru Bai"
                },
                {
                    "authorId": "2067827377",
                    "name": "Guoliang Fan"
                },
                {
                    "authorId": "2107982614",
                    "name": "Lijuan Li"
                }
            ],
            "doi": "10.1007/978-3-031-30105-6_7",
            "intent": [],
            "isInfluential": false,
            "paperId": "c19b5144221ab300b1e3bd7fe2e29fb1c1730d0a",
            "title": "Multi-Agent Hyper-Attention Policy Optimization",
            "url": "https://www.semanticscholar.org/paper/c19b5144221ab300b1e3bd7fe2e29fb1c1730d0a",
            "venue": "ICONIP",
            "year": 2022
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "144885169",
                    "name": "M. Littman"
                },
                {
                    "authorId": "144848112",
                    "name": "P. Stone"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "172fba5c1520d809d6c372c95e2d6145be65bb1b",
            "title": "Leading Best-Response Strategies in Repeated Games",
            "url": "https://www.semanticscholar.org/paper/172fba5c1520d809d6c372c95e2d6145be65bb1b",
            "venue": "IJCAI 2001",
            "year": 2001
        }
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "title": "Inducing Stackelberg Equilibrium through Spatio-Temporal Sequential Decision-Making in Multi-Agent Reinforcement Learning",
    "topics": [],
    "url": "https://www.semanticscholar.org/paper/45567a7cc048a0c90265b472643f391cd2fba06e",
    "venue": "International Joint Conference on Artificial Intelligence",
    "year": 2023
}
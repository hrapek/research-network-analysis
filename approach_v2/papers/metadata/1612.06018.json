{
    "abstract": "\n \n When an agent cannot represent a perfectly accurate model of its environment's dynamics, model-based reinforcement learning (MBRL) can fail catastrophically. Planning involves composing the predictions of the model; when flawed predictions are composed, even minor errors can compound and render the model useless for planning. Hallucinated Replay (Talvitie 2014) trains the model to \"correct\" itself when it produces errors, substantially improving MBRL with flawed models. This paper theoretically analyzes this approach, illuminates settings in which it is likely to be effective or ineffective, and presents a novel error bound, showing that a model's ability to self-correct is more tightly related to MBRL performance than one-step prediction error. These results inspire an MBRL algorithm for deterministic MDPs with performance guarantees that are robust to model class limitations.\n \n",
    "arxivId": "1612.06018",
    "authors": [
        {
            "authorId": "1701322",
            "name": "Erik Talvitie",
            "url": "https://www.semanticscholar.org/author/1701322"
        }
    ],
    "citationVelocity": 11,
    "citations": [
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "3136533",
                    "name": "Fuhan Yan"
                },
                {
                    "authorId": "2325351621",
                    "name": "Kai Di"
                },
                {
                    "authorId": "2325352597",
                    "name": "Bin Ge"
                },
                {
                    "authorId": "2325515228",
                    "name": "Luoliang Liu"
                },
                {
                    "authorId": "2325936037",
                    "name": "Zeren Wang"
                },
                {
                    "authorId": "2325891448",
                    "name": "Wenjian Fan"
                },
                {
                    "authorId": "2325828737",
                    "name": "Didi Hu"
                }
            ],
            "doi": "10.1016/j.engappai.2024.109423",
            "intent": [],
            "isInfluential": false,
            "paperId": "2c88f055f1e16b572db368fa71082c18484a16de",
            "title": "Multi-robot task allocation for optional tasks with hidden workload: Using a model-based hyper-heuristic strategy",
            "url": "https://www.semanticscholar.org/paper/2c88f055f1e16b572db368fa71082c18484a16de",
            "venue": "Eng. Appl. Artif. Intell.",
            "year": 2024
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2303715647",
                    "name": "Jungsun Yoo"
                },
                {
                    "authorId": "2547256",
                    "name": "Elizabeth R. Chrastil"
                },
                {
                    "authorId": "2257825965",
                    "name": "Aaron M. Bornstein"
                }
            ],
            "doi": "10.1037/dec0000249",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "90102a58cd375a5d50ab4364d529154fa20debe5",
            "title": "Cognitive graphs: Representational substrates for planning.",
            "url": "https://www.semanticscholar.org/paper/90102a58cd375a5d50ab4364d529154fa20debe5",
            "venue": "Decision",
            "year": 2024
        },
        {
            "arxivId": "2407.11751",
            "authors": [
                {
                    "authorId": "2311508414",
                    "name": "Philipp Wissmann"
                },
                {
                    "authorId": "2270973537",
                    "name": "Daniel Hein"
                },
                {
                    "authorId": "1699265",
                    "name": "S. Udluft"
                },
                {
                    "authorId": "2271282409",
                    "name": "Volker Tresp"
                }
            ],
            "doi": "10.48550/arXiv.2407.11751",
            "intent": [
                "background",
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "3b031926fc24967ba41d35aa0e9e5b8b847f17e5",
            "title": "Why long model-based rollouts are no reason for bad Q-value estimates",
            "url": "https://www.semanticscholar.org/paper/3b031926fc24967ba41d35aa0e9e5b8b847f17e5",
            "venue": "ESANN 2024 proceesdings",
            "year": 2024
        },
        {
            "arxivId": "2406.19561",
            "authors": [
                {
                    "authorId": "2016284222",
                    "name": "Brad Burega"
                },
                {
                    "authorId": "2309008553",
                    "name": "John D. Martin"
                },
                {
                    "authorId": "2309008009",
                    "name": "Luke Kapeluck"
                },
                {
                    "authorId": "2309008335",
                    "name": "Michael Bowling"
                }
            ],
            "doi": "10.48550/arXiv.2406.19561",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "5bb603996fec345af8f4f0f5f8a4da3cb6842e1f",
            "title": "Meta-Gradient Search Control: A Method for Improving the Efficiency of Dyna-style Planning",
            "url": "https://www.semanticscholar.org/paper/5bb603996fec345af8f4f0f5f8a4da3cb6842e1f",
            "venue": "ArXiv",
            "year": 2024
        },
        {
            "arxivId": "2406.16006",
            "authors": [
                {
                    "authorId": "1739814743",
                    "name": "Erin J. Talvitie"
                },
                {
                    "authorId": "2308022138",
                    "name": "Zilei Shao"
                },
                {
                    "authorId": "2308048848",
                    "name": "Huiying Li"
                },
                {
                    "authorId": "2308112018",
                    "name": "Jinghan Hu"
                },
                {
                    "authorId": "2308031358",
                    "name": "Jacob Boerma"
                },
                {
                    "authorId": "2160534367",
                    "name": "Rory Zhao"
                },
                {
                    "authorId": "2308066787",
                    "name": "Xintong Wang"
                }
            ],
            "doi": "10.48550/arXiv.2406.16006",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "e2cb18407d154736524b515eeb8cdb3acb3f59fb",
            "title": "Bounding-Box Inference for Error-Aware Model-Based Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/e2cb18407d154736524b515eeb8cdb3acb3f59fb",
            "venue": "RLJ",
            "year": 2024
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "9304046",
                    "name": "Farzane Aminmansour"
                },
                {
                    "authorId": "1419479157",
                    "name": "Taher Jafferjee"
                },
                {
                    "authorId": "29905816",
                    "name": "Ehsan Imani"
                },
                {
                    "authorId": "1739814743",
                    "name": "Erin J. Talvitie"
                },
                {
                    "authorId": "2305606436",
                    "name": "Michael Bowling"
                },
                {
                    "authorId": "2284957621",
                    "name": "Martha White"
                }
            ],
            "doi": "10.1613/jair.1.15155",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "1630d4cd62a5e5733796995ded789dd460264ef6",
            "title": "Mitigating Value Hallucination in Dyna-Style Planning via Multistep Predecessor Models",
            "url": "https://www.semanticscholar.org/paper/1630d4cd62a5e5733796995ded789dd460264ef6",
            "venue": "Journal of Artificial Intelligence Research",
            "year": 2024
        },
        {
            "arxivId": "2405.03878",
            "authors": [
                {
                    "authorId": "2300174929",
                    "name": "Aditya A. Ramesh"
                },
                {
                    "authorId": "2300175089",
                    "name": "Kenny Young"
                },
                {
                    "authorId": "3031520",
                    "name": "Louis Kirsch"
                },
                {
                    "authorId": "2252220989",
                    "name": "J\u00fcrgen Schmidhuber"
                }
            ],
            "doi": "10.48550/arXiv.2405.03878",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "b99701e7f9f5b26e201b46128475a708e6b04437",
            "title": "Sequence Compression Speeds Up Credit Assignment in Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/b99701e7f9f5b26e201b46128475a708e6b04437",
            "venue": "ICML",
            "year": 2024
        },
        {
            "arxivId": "2404.09946",
            "authors": [
                {
                    "authorId": "2296717095",
                    "name": "Nan Jiang"
                }
            ],
            "doi": "10.48550/arXiv.2404.09946",
            "intent": [],
            "isInfluential": false,
            "paperId": "e3e25b18a0d7129b52b5e0b7b10003dad9e9e03c",
            "title": "A Note on Loss Functions and Error Compounding in Model-based Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/e3e25b18a0d7129b52b5e0b7b10003dad9e9e03c",
            "venue": "ArXiv",
            "year": 2024
        },
        {
            "arxivId": "2402.03146",
            "authors": [
                {
                    "authorId": "2256991069",
                    "name": "Abdelhakim Benechehab"
                },
                {
                    "authorId": "2257432917",
                    "name": "Albert Thomas"
                },
                {
                    "authorId": "2256994533",
                    "name": "Giuseppe Paolo"
                },
                {
                    "authorId": "2256996157",
                    "name": "Maurizio Filippone"
                },
                {
                    "authorId": "2256623448",
                    "name": "Bal'azs K'egl"
                }
            ],
            "doi": "10.48550/arXiv.2402.03146",
            "intent": [],
            "isInfluential": false,
            "paperId": "e14f826852502042dbff2e9d10a580b47a57fbb9",
            "title": "A Multi-step Loss Function for Robust Learning of the Dynamics in Model-based Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/e14f826852502042dbff2e9d10a580b47a57fbb9",
            "venue": "ArXiv",
            "year": 2024
        },
        {
            "arxivId": "2401.13034",
            "authors": [
                {
                    "authorId": "2117943295",
                    "name": "Zi-Yan Liu"
                },
                {
                    "authorId": "144369497",
                    "name": "Chao Du"
                },
                {
                    "authorId": "2280902347",
                    "name": "Wee Sun Lee"
                },
                {
                    "authorId": "2253977831",
                    "name": "Min Lin"
                }
            ],
            "doi": "10.48550/arXiv.2401.13034",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "534363ddcdddb15decdaf9f8e6c277545518f775",
            "title": "Locality Sensitive Sparse Encoding for Learning World Models Online",
            "url": "https://www.semanticscholar.org/paper/534363ddcdddb15decdaf9f8e6c277545518f775",
            "venue": "ICLR",
            "year": 2024
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2167317595",
                    "name": "Chengxing Jia"
                },
                {
                    "authorId": "2166590799",
                    "name": "Fuxiang Zhang"
                },
                {
                    "authorId": "40084973",
                    "name": "Tian Xu"
                },
                {
                    "authorId": "1432234123",
                    "name": "Jing-Cheng Pang"
                },
                {
                    "authorId": "2079174",
                    "name": "Zongzhang Zhang"
                },
                {
                    "authorId": "2152850415",
                    "name": "Yang Yu"
                }
            ],
            "doi": "10.1007/s11704-023-3150-5",
            "intent": [],
            "isInfluential": false,
            "paperId": "11f20d0342ae10ade1473388829226b8fabd1402",
            "title": "Model gradient: unified model and policy learning in model-based reinforcement learning",
            "url": "https://www.semanticscholar.org/paper/11f20d0342ae10ade1473388829226b8fabd1402",
            "venue": "Frontiers Comput. Sci.",
            "year": 2023
        },
        {
            "arxivId": "2312.11348",
            "authors": [
                {
                    "authorId": "2181009063",
                    "name": "Farnaz Kohankhaki"
                },
                {
                    "authorId": "2044295861",
                    "name": "Kiarash Aghakasiri"
                },
                {
                    "authorId": "2267505899",
                    "name": "Hongming Zhang"
                },
                {
                    "authorId": "2268368983",
                    "name": "T. Wei"
                },
                {
                    "authorId": "2324862790",
                    "name": "Chao Gao"
                },
                {
                    "authorId": "2279670603",
                    "name": "Martin M\u00fcller"
                }
            ],
            "doi": "10.1609/aaai.v38i18.29994",
            "intent": [],
            "isInfluential": false,
            "paperId": "6167cb0b0c4e9d96ec2384daf09bc58640505bc5",
            "title": "Monte Carlo Tree Search in the Presence of Transition Uncertainty",
            "url": "https://www.semanticscholar.org/paper/6167cb0b0c4e9d96ec2384daf09bc58640505bc5",
            "venue": "AAAI",
            "year": 2023
        },
        {
            "arxivId": "2312.01203",
            "authors": [
                {
                    "authorId": "2269466069",
                    "name": "Edan Meyer"
                },
                {
                    "authorId": "2261440541",
                    "name": "Adam White"
                },
                {
                    "authorId": "40066857",
                    "name": "Marlos C. Machado"
                }
            ],
            "doi": "10.48550/arXiv.2312.01203",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "39f21d40df79bbb982c898f7eb863f77e41f92b3",
            "title": "Harnessing Discrete Representations For Continual Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/39f21d40df79bbb982c898f7eb863f77e41f92b3",
            "venue": "RLJ",
            "year": 2023
        },
        {
            "arxivId": "2311.17855",
            "authors": [
                {
                    "authorId": "1598433526",
                    "name": "Amin Rakhsha"
                },
                {
                    "authorId": "1388051930",
                    "name": "Mete Kemertas"
                },
                {
                    "authorId": "1678622",
                    "name": "M. Ghavamzadeh"
                },
                {
                    "authorId": "5689899",
                    "name": "Amir-massoud Farahmand"
                }
            ],
            "doi": "10.48550/arXiv.2311.17855",
            "intent": [
                "background",
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "a4e46c8048baa322965fed3f788d74d7af1caef7",
            "title": "Maximum Entropy Model Correction in Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/a4e46c8048baa322965fed3f788d74d7af1caef7",
            "venue": "ICLR",
            "year": 2023
        },
        {
            "arxivId": "2311.00094",
            "authors": [
                {
                    "authorId": "2264940460",
                    "name": "Xuejie Liu"
                },
                {
                    "authorId": "70097297",
                    "name": "Anji Liu"
                },
                {
                    "authorId": "1749506",
                    "name": "Guy Van den Broeck"
                },
                {
                    "authorId": "2141192339",
                    "name": "Yitao Liang"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "6706f06f1518b3bc7ba332d6f64216954d68418d",
            "title": "A Tractable Inference Perspective of Offline RL",
            "url": "https://www.semanticscholar.org/paper/6706f06f1518b3bc7ba332d6f64216954d68418d",
            "venue": "",
            "year": 2023
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2215004004",
                    "name": "Tuo Qu"
                },
                {
                    "authorId": "2258104556",
                    "name": "Fuqing Duan"
                },
                {
                    "authorId": "2258299772",
                    "name": "Junge Zhang"
                },
                {
                    "authorId": "2258349794",
                    "name": "Bo Zhao"
                },
                {
                    "authorId": "2258321754",
                    "name": "Wenzhen Huang"
                }
            ],
            "doi": "10.1007/s40747-023-01247-5",
            "intent": [],
            "isInfluential": false,
            "paperId": "a853b0d5ff9a6caa0d1f823d5fac94961e70a902",
            "title": "Data-efficient model-based reinforcement learning with trajectory discrimination",
            "url": "https://www.semanticscholar.org/paper/a853b0d5ff9a6caa0d1f823d5fac94961e70a902",
            "venue": "Complex &amp; Intelligent Systems",
            "year": 2023
        },
        {
            "arxivId": "2310.06253",
            "authors": [
                {
                    "authorId": "2256993559",
                    "name": "Ran Wei"
                },
                {
                    "authorId": "2052363815",
                    "name": "Nathan Lambert"
                },
                {
                    "authorId": "2143389347",
                    "name": "Anthony McDonald"
                },
                {
                    "authorId": "2257368542",
                    "name": "Alfredo Garcia"
                },
                {
                    "authorId": "2243192956",
                    "name": "Roberto Calandra"
                }
            ],
            "doi": "10.48550/arXiv.2310.06253",
            "intent": [],
            "isInfluential": false,
            "paperId": "690fe81e99b1486ff49c9fc4da9bcd1a7e674668",
            "title": "A Unified View on Solving Objective Mismatch in Model-Based Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/690fe81e99b1486ff49c9fc4da9bcd1a7e674668",
            "venue": "Trans. Mach. Learn. Res.",
            "year": 2023
        },
        {
            "arxivId": "2310.05672",
            "authors": [
                {
                    "authorId": "2256991069",
                    "name": "Abdelhakim Benechehab"
                },
                {
                    "authorId": "2256994533",
                    "name": "Giuseppe Paolo"
                },
                {
                    "authorId": "2257432917",
                    "name": "Albert Thomas"
                },
                {
                    "authorId": "2256996157",
                    "name": "Maurizio Filippone"
                },
                {
                    "authorId": "2256623448",
                    "name": "Bal'azs K'egl"
                }
            ],
            "doi": "10.48550/arXiv.2310.05672",
            "intent": [],
            "isInfluential": false,
            "paperId": "182c8e48d08b8ff29f0854fe903b3bae8e0c999d",
            "title": "Multi-timestep models for Model-based Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/182c8e48d08b8ff29f0854fe903b3bae8e0c999d",
            "venue": "ArXiv",
            "year": 2023
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2239053431",
                    "name": "Guofeng Zhu"
                },
                {
                    "authorId": "2237863871",
                    "name": "Fei Zhu"
                }
            ],
            "doi": "10.1016/j.eswa.2023.121345",
            "intent": [],
            "isInfluential": false,
            "paperId": "49cfdc7ac43791564c1381965c2a084d0027af48",
            "title": "Draw on advantages and avoid disadvantages by making a multi-step prediction",
            "url": "https://www.semanticscholar.org/paper/49cfdc7ac43791564c1381965c2a084d0027af48",
            "venue": "Expert Systems with Applications",
            "year": 2023
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2150277967",
                    "name": "Yixing Lan"
                },
                {
                    "authorId": "1856580538",
                    "name": "Xin Xu"
                },
                {
                    "authorId": "2100670499",
                    "name": "Qiang Fang"
                },
                {
                    "authorId": "2069718816",
                    "name": "Jianye Hao"
                }
            ],
            "doi": "10.1109/TNNLS.2023.3296642",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "2f7b106abe0a8b661448a373991eebe21ca6634a",
            "title": "Sample Efficient Deep Reinforcement Learning With Online State Abstraction and Causal Transformer Model Prediction",
            "url": "https://www.semanticscholar.org/paper/2f7b106abe0a8b661448a373991eebe21ca6634a",
            "venue": "IEEE Transactions on Neural Networks and Learning Systems",
            "year": 2023
        },
        {
            "arxivId": "2306.17366",
            "authors": [
                {
                    "authorId": "1387979639",
                    "name": "C. Voelcker"
                },
                {
                    "authorId": "2186822213",
                    "name": "Arash Ahmadian"
                },
                {
                    "authorId": "1515553184",
                    "name": "Romina Abachi"
                },
                {
                    "authorId": "2072248",
                    "name": "Igor Gilitschenski"
                },
                {
                    "authorId": "5689899",
                    "name": "Amir-massoud Farahmand"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "06c1d797e363c2f2454e1895b375f0c2a0aec4d4",
            "title": "$\\lambda$-models: Effective Decision-Aware Reinforcement Learning with Latent Models",
            "url": "https://www.semanticscholar.org/paper/06c1d797e363c2f2454e1895b375f0c2a0aec4d4",
            "venue": "",
            "year": 2023
        },
        {
            "arxivId": "2305.18443",
            "authors": [
                {
                    "authorId": "2008151131",
                    "name": "Jiafei Lyu"
                },
                {
                    "authorId": "2187301367",
                    "name": "Le Wan"
                },
                {
                    "authorId": "2265693",
                    "name": "Zongqing Lu"
                },
                {
                    "authorId": "2180539270",
                    "name": "Xiu Li"
                }
            ],
            "doi": "10.48550/arXiv.2305.18443",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "8a84ee6294bc7f88d0343c8615a12f1c763209bd",
            "title": "Off-Policy RL Algorithms Can be Sample-Efficient for Continuous Control via Sample Multiple Reuse",
            "url": "https://www.semanticscholar.org/paper/8a84ee6294bc7f88d0343c8615a12f1c763209bd",
            "venue": "Inf. Sci.",
            "year": 2023
        },
        {
            "arxivId": "2211.03281",
            "authors": [
                {
                    "authorId": "39251318",
                    "name": "Lucas Lehnert"
                },
                {
                    "authorId": "2071345269",
                    "name": "M. Frank"
                },
                {
                    "authorId": "144885169",
                    "name": "M. Littman"
                }
            ],
            "doi": "10.48550/arXiv.2211.03281",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "7ddff9d44d8b04060f1955b83a01836510eb0dc1",
            "title": "Reward-Predictive Clustering",
            "url": "https://www.semanticscholar.org/paper/7ddff9d44d8b04060f1955b83a01836510eb0dc1",
            "venue": "ArXiv",
            "year": 2022
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2120827853",
                    "name": "Junjie Wang"
                },
                {
                    "authorId": "3342918",
                    "name": "Qichao Zhang"
                },
                {
                    "authorId": "1699234",
                    "name": "Dongbin Zhao"
                }
            ],
            "doi": "10.1109/TNNLS.2022.3215788",
            "intent": [
                "result"
            ],
            "isInfluential": false,
            "paperId": "7d167d70176d0e58342f7080e3e6b3cd1aa15616",
            "title": "Dynamic-Horizon Model-Based Value Estimation With Latent Imagination",
            "url": "https://www.semanticscholar.org/paper/7d167d70176d0e58342f7080e3e6b3cd1aa15616",
            "venue": "IEEE Transactions on Neural Networks and Learning Systems",
            "year": 2022
        },
        {
            "arxivId": "2206.02902",
            "authors": [
                {
                    "authorId": "145300593",
                    "name": "Chun-Ping Lo"
                },
                {
                    "authorId": "143900003",
                    "name": "Scott M. Jordan"
                },
                {
                    "authorId": "114605401",
                    "name": "G\u00e1bor Mihucz"
                },
                {
                    "authorId": "145240145",
                    "name": "Adam White"
                },
                {
                    "authorId": "9304046",
                    "name": "Farzane Aminmansour"
                },
                {
                    "authorId": "144542337",
                    "name": "Martha White"
                }
            ],
            "doi": "10.48550/arXiv.2206.02902",
            "intent": [
                "background",
                "methodology"
            ],
            "isInfluential": true,
            "paperId": "558a842b69f516c8646a4d9c2d28508386ec5ee8",
            "title": "Goal-Space Planning with Subgoal Models",
            "url": "https://www.semanticscholar.org/paper/558a842b69f516c8646a4d9c2d28508386ec5ee8",
            "venue": "ArXiv",
            "year": 2022
        },
        {
            "arxivId": "2205.08716",
            "authors": [
                {
                    "authorId": "2113291319",
                    "name": "Han Wang"
                },
                {
                    "authorId": "82946683",
                    "name": "Archit Sakhadeo"
                },
                {
                    "authorId": "145240145",
                    "name": "Adam White"
                },
                {
                    "authorId": "2113296270",
                    "name": "James Bell"
                },
                {
                    "authorId": "2059936479",
                    "name": "Vincent Liu"
                },
                {
                    "authorId": "2165652328",
                    "name": "Xutong Zhao"
                },
                {
                    "authorId": "2165755435",
                    "name": "Puer Liu"
                },
                {
                    "authorId": "2237799351",
                    "name": "Tadashi Kozuno"
                },
                {
                    "authorId": "2655967",
                    "name": "Alona Fyshe"
                },
                {
                    "authorId": "144542337",
                    "name": "Martha White"
                }
            ],
            "doi": "10.48550/arXiv.2205.08716",
            "intent": [
                "background",
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "a64bef0eca44d6f1eda2ac9cd2225414b08f816d",
            "title": "No More Pesky Hyperparameters: Offline Hyperparameter Tuning for RL",
            "url": "https://www.semanticscholar.org/paper/a64bef0eca44d6f1eda2ac9cd2225414b08f816d",
            "venue": "Trans. Mach. Learn. Res.",
            "year": 2022
        },
        {
            "arxivId": "2204.01464",
            "authors": [
                {
                    "authorId": "1387979639",
                    "name": "C. Voelcker"
                },
                {
                    "authorId": "2161339569",
                    "name": "Victor Liao"
                },
                {
                    "authorId": "1873736",
                    "name": "Animesh Garg"
                },
                {
                    "authorId": "5689899",
                    "name": "Amir-massoud Farahmand"
                }
            ],
            "doi": "10.48550/arXiv.2204.01464",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "f0e91a012f447a3ba6692632abbc272cee41d1a0",
            "title": "Value Gradient weighted Model-Based Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/f0e91a012f447a3ba6692632abbc272cee41d1a0",
            "venue": "ICLR",
            "year": 2022
        },
        {
            "arxivId": "2203.15955",
            "authors": [
                {
                    "authorId": "2113291319",
                    "name": "Han Wang"
                },
                {
                    "authorId": "1388010628",
                    "name": "Erfan Miahi"
                },
                {
                    "authorId": "144542337",
                    "name": "Martha White"
                },
                {
                    "authorId": "40066857",
                    "name": "Marlos C. Machado"
                },
                {
                    "authorId": "2160722469",
                    "name": "Zaheer Abbas"
                },
                {
                    "authorId": "2188358",
                    "name": "Raksha Kumaraswamy"
                },
                {
                    "authorId": "2059936479",
                    "name": "Vincent Liu"
                },
                {
                    "authorId": "145240145",
                    "name": "Adam White"
                }
            ],
            "doi": "10.48550/arXiv.2203.15955",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "5460282826b62e267aa496cc9c578b489b4f55f9",
            "title": "Investigating the Properties of Neural Network Representations in Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/5460282826b62e267aa496cc9c578b489b4f55f9",
            "venue": "Artif. Intell.",
            "year": 2022
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2151279",
                    "name": "M. Mattar"
                },
                {
                    "authorId": "40599065",
                    "name": "M. Lengyel"
                }
            ],
            "doi": "10.1016/j.neuron.2021.12.018",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "9f9d89610c3e02e51071ef963c238d5fcafe9f6a",
            "title": "Planning in the brain",
            "url": "https://www.semanticscholar.org/paper/9f9d89610c3e02e51071ef963c238d5fcafe9f6a",
            "venue": "Neuron",
            "year": 2022
        },
        {
            "arxivId": "2110.07985",
            "authors": [
                {
                    "authorId": "2131019148",
                    "name": "Lukas P. Frohlich"
                },
                {
                    "authorId": "2064594336",
                    "name": "Maksym Lefarov"
                },
                {
                    "authorId": "2176899",
                    "name": "M. Zeilinger"
                },
                {
                    "authorId": "2064772",
                    "name": "Felix Berkenkamp"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "c425b527bbeffc2e4b5bc7a42649cd16a3fa216f",
            "title": "On-Policy Model Errors in Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/c425b527bbeffc2e4b5bc7a42649cd16a3fa216f",
            "venue": "ICLR",
            "year": 2021
        },
        {
            "arxivId": "2108.03213",
            "authors": [
                {
                    "authorId": "38562041",
                    "name": "Khimya Khetarpal"
                },
                {
                    "authorId": "41206144",
                    "name": "Zafarali Ahmed"
                },
                {
                    "authorId": "1819858",
                    "name": "Gheorghe Comanici"
                },
                {
                    "authorId": "144368601",
                    "name": "Doina Precup"
                }
            ],
            "doi": null,
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "20c588e0f7f2263437e4023c6df503e91f7c2715",
            "title": "Temporally Abstract Partial Models",
            "url": "https://www.semanticscholar.org/paper/20c588e0f7f2263437e4023c6df503e91f7c2715",
            "venue": "NeurIPS",
            "year": 2021
        },
        {
            "arxivId": "2106.15416",
            "authors": [
                {
                    "authorId": "1745900",
                    "name": "Alexander N Gorban"
                },
                {
                    "authorId": "2208001",
                    "name": "Bogdan Grechuk"
                },
                {
                    "authorId": "34796800",
                    "name": "E. Mirkes"
                },
                {
                    "authorId": "2309588340",
                    "name": "Sergey V. Stasenko"
                },
                {
                    "authorId": "2196121",
                    "name": "I. Tyukin"
                }
            ],
            "doi": "10.3390/e23081090",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "1bb8aa83afca7a3cd1b58cde51c7ad8a240b8b55",
            "title": "High-Dimensional Separability for One- and Few-Shot Learning",
            "url": "https://www.semanticscholar.org/paper/1bb8aa83afca7a3cd1b58cde51c7ad8a240b8b55",
            "venue": "Entropy",
            "year": 2021
        },
        {
            "arxivId": "2104.08543",
            "authors": [
                {
                    "authorId": "1660812666",
                    "name": "Katya Kudashkina"
                },
                {
                    "authorId": "2075389608",
                    "name": "Yi Wan"
                },
                {
                    "authorId": "2064353348",
                    "name": "Abhishek Naik"
                },
                {
                    "authorId": "1699645",
                    "name": "R. Sutton"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "3be325a4eb1386fa190fdeb052fd3f293bba6c53",
            "title": "Planning with Expectation Models for Control",
            "url": "https://www.semanticscholar.org/paper/3be325a4eb1386fa190fdeb052fd3f293bba6c53",
            "venue": "ArXiv",
            "year": 2021
        },
        {
            "arxivId": "2103.07945",
            "authors": [
                {
                    "authorId": "145046554",
                    "name": "Ahmed Touati"
                },
                {
                    "authorId": "1734570",
                    "name": "Y. Ollivier"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "de887347a073106b33f7ebbb5cbd6cffa94a4d37",
            "title": "Learning One Representation to Optimize All Rewards",
            "url": "https://www.semanticscholar.org/paper/de887347a073106b33f7ebbb5cbd6cffa94a4d37",
            "venue": "NeurIPS",
            "year": 2021
        },
        {
            "arxivId": "2011.03859",
            "authors": [
                {
                    "authorId": "33931249",
                    "name": "Sarah Bechtle"
                },
                {
                    "authorId": "2596082",
                    "name": "Bilal Hammoud"
                },
                {
                    "authorId": "2762463",
                    "name": "Akshara Rai"
                },
                {
                    "authorId": "153145615",
                    "name": "Franziska Meier"
                },
                {
                    "authorId": "51204760",
                    "name": "L. Righetti"
                }
            ],
            "doi": "10.1109/ICRA48506.2021.9561396",
            "intent": [],
            "isInfluential": false,
            "paperId": "cd2afabbf1fa46876b8f709ab8c33c22d9a2b9ee",
            "title": "Leveraging Forward Model Prediction Error for Learning Control",
            "url": "https://www.semanticscholar.org/paper/cd2afabbf1fa46876b8f709ab8c33c22d9a2b9ee",
            "venue": "2021 IEEE International Conference on Robotics and Automation (ICRA)",
            "year": 2020
        },
        {
            "arxivId": "2010.14496",
            "authors": [
                {
                    "authorId": "35163402",
                    "name": "Michael Janner"
                },
                {
                    "authorId": "2080746",
                    "name": "Igor Mordatch"
                },
                {
                    "authorId": "1736651",
                    "name": "S. Levine"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "b85a70c16a1f961b42356469618faf279cdc98f1",
            "title": "\u03b3-Models: Generative Temporal Difference Learning for Infinite-Horizon Prediction",
            "url": "https://www.semanticscholar.org/paper/b85a70c16a1f961b42356469618faf279cdc98f1",
            "venue": "ArXiv",
            "year": 2020
        },
        {
            "arxivId": "2010.09546",
            "authors": [
                {
                    "authorId": "2115732606",
                    "name": "Jian Shen"
                },
                {
                    "authorId": "145034731",
                    "name": "Han Zhao"
                },
                {
                    "authorId": "2108309275",
                    "name": "Weinan Zhang"
                },
                {
                    "authorId": "1811427",
                    "name": "Yong Yu"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "372657f609f5a95b378a1aad7b08deb9b9b510c0",
            "title": "Model-based Policy Optimization with Unsupervised Model Adaptation",
            "url": "https://www.semanticscholar.org/paper/372657f609f5a95b378a1aad7b08deb9b9b510c0",
            "venue": "NeurIPS",
            "year": 2020
        },
        {
            "arxivId": "2009.09593",
            "authors": [
                {
                    "authorId": "2120827853",
                    "name": "Junjie Wang"
                },
                {
                    "authorId": "3342918",
                    "name": "Qichao Zhang"
                },
                {
                    "authorId": "1699234",
                    "name": "Dongbin Zhao"
                },
                {
                    "authorId": "3386549",
                    "name": "Mengchen Zhao"
                },
                {
                    "authorId": "40513470",
                    "name": "Jianye Hao"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "f18cd315123f59f6d168188019071b582bf409b6",
            "title": "Dynamic Horizon Value Estimation for Model-based Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/f18cd315123f59f6d168188019071b582bf409b6",
            "venue": "ArXiv",
            "year": 2020
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "50763255",
                    "name": "Junyang Chen"
                },
                {
                    "authorId": "1735422",
                    "name": "Zhiguo Gong"
                },
                {
                    "authorId": "2158627274",
                    "name": "Wei Wang"
                },
                {
                    "authorId": "2109270350",
                    "name": "Weiwen Liu"
                },
                {
                    "authorId": "2150425875",
                    "name": "Ming Yang"
                },
                {
                    "authorId": "2116639171",
                    "name": "Cong Wang"
                }
            ],
            "doi": "10.1109/TNNLS.2020.3009247",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "7c510fc139fb11d73c4ef6d1a59d86734273d7b5",
            "title": "TAM: Targeted Analysis Model With Reinforcement Learning on Short Texts",
            "url": "https://www.semanticscholar.org/paper/7c510fc139fb11d73c4ef6d1a59d86734273d7b5",
            "venue": "IEEE Transactions on Neural Networks and Learning Systems",
            "year": 2020
        },
        {
            "arxivId": "2007.02418",
            "authors": [
                {
                    "authorId": "49249788",
                    "name": "Z. Abbas"
                },
                {
                    "authorId": "82520415",
                    "name": "Samuel Sokota"
                },
                {
                    "authorId": "1739814743",
                    "name": "Erin J. Talvitie"
                },
                {
                    "authorId": "144542337",
                    "name": "Martha White"
                }
            ],
            "doi": null,
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "1146c8b7e10f44134e4e771d792be6ec9a3f8abb",
            "title": "Selective Dyna-style Planning Under Limited Model Capacity",
            "url": "https://www.semanticscholar.org/paper/1146c8b7e10f44134e4e771d792be6ec9a3f8abb",
            "venue": "ICML",
            "year": 2020
        },
        {
            "arxivId": "2007.01995",
            "authors": [
                {
                    "authorId": "2054235888",
                    "name": "Hang Lai"
                },
                {
                    "authorId": "2115732606",
                    "name": "Jian Shen"
                },
                {
                    "authorId": "2108309275",
                    "name": "Weinan Zhang"
                },
                {
                    "authorId": "1811427",
                    "name": "Yong Yu"
                }
            ],
            "doi": null,
            "intent": [
                "background",
                "result"
            ],
            "isInfluential": true,
            "paperId": "1cf3b7ef431c68eeea0f266bc5ec1b89bf223368",
            "title": "Bidirectional Model-based Policy Optimization",
            "url": "https://www.semanticscholar.org/paper/1cf3b7ef431c68eeea0f266bc5ec1b89bf223368",
            "venue": "ICML",
            "year": 2020
        },
        {
            "arxivId": "2006.16712",
            "authors": [
                {
                    "authorId": "13477045",
                    "name": "T. Moerland"
                },
                {
                    "authorId": "1735303",
                    "name": "J. Broekens"
                },
                {
                    "authorId": "1689001",
                    "name": "C. Jonker"
                }
            ],
            "doi": "10.1561/9781638280576",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "1c6435cb353271f3cb87b27ccc6df5b727d55f26",
            "title": "Model-based Reinforcement Learning: A Survey",
            "url": "https://www.semanticscholar.org/paper/1c6435cb353271f3cb87b27ccc6df5b727d55f26",
            "venue": "Found. Trends Mach. Learn.",
            "year": 2020
        },
        {
            "arxivId": "2006.04363",
            "authors": [
                {
                    "authorId": "1419479157",
                    "name": "Taher Jafferjee"
                },
                {
                    "authorId": "29905816",
                    "name": "Ehsan Imani"
                },
                {
                    "authorId": "1739814743",
                    "name": "Erin J. Talvitie"
                },
                {
                    "authorId": "144542337",
                    "name": "Martha White"
                },
                {
                    "authorId": "1739899695",
                    "name": "Micheal Bowling"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "3d2cc26da7001b2ecb711c431e5e31e081792caf",
            "title": "Hallucinating Value: A Pitfall of Dyna-style Planning with Imperfect Environment Models",
            "url": "https://www.semanticscholar.org/paper/3d2cc26da7001b2ecb711c431e5e31e081792caf",
            "venue": "ArXiv",
            "year": 2020
        },
        {
            "arxivId": "2005.13778",
            "authors": [
                {
                    "authorId": "1723435619",
                    "name": "Parth Chadha"
                }
            ],
            "doi": null,
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "267c12592edb6dc9a16b329bc94ce3a0a45f0e0a",
            "title": "Domain Knowledge Integration By Gradient Matching For Sample-Efficient Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/267c12592edb6dc9a16b329bc94ce3a0a45f0e0a",
            "venue": "ArXiv",
            "year": 2020
        },
        {
            "arxivId": "2003.00030",
            "authors": [
                {
                    "authorId": "1515553184",
                    "name": "Romina Abachi"
                },
                {
                    "authorId": "1678622",
                    "name": "M. Ghavamzadeh"
                },
                {
                    "authorId": "5689899",
                    "name": "Amir-massoud Farahmand"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "0c11bebee3a8d51a911fec7282e8d60d5d6cc989",
            "title": "Policy-Aware Model Learning for Policy Gradient Methods",
            "url": "https://www.semanticscholar.org/paper/0c11bebee3a8d51a911fec7282e8d60d5d6cc989",
            "venue": "ArXiv",
            "year": 2020
        },
        {
            "arxivId": "2002.05822",
            "authors": [
                {
                    "authorId": "7303313",
                    "name": "Yangchen Pan"
                },
                {
                    "authorId": "3288319",
                    "name": "Jincheng Mei"
                },
                {
                    "authorId": "5689899",
                    "name": "Amir-massoud Farahmand"
                }
            ],
            "doi": null,
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "eb5f4f0cb8503beefdf8a5efd5061f61cc64764e",
            "title": "Frequency-based Search-control in Dyna",
            "url": "https://www.semanticscholar.org/paper/eb5f4f0cb8503beefdf8a5efd5061f61cc64764e",
            "venue": "ICLR",
            "year": 2020
        },
        {
            "arxivId": "2002.04523",
            "authors": [
                {
                    "authorId": "2052363815",
                    "name": "Nathan Lambert"
                },
                {
                    "authorId": "1773498",
                    "name": "Brandon Amos"
                },
                {
                    "authorId": "2705825",
                    "name": "Omry Yadan"
                },
                {
                    "authorId": "35159852",
                    "name": "R. Calandra"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "ecbdc83a1aa8d196943d8997300be871b1c7c2dc",
            "title": "Objective Mismatch in Model-based Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/ecbdc83a1aa8d196943d8997300be871b1c7c2dc",
            "venue": "L4DC",
            "year": 2020
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "119439163",
                    "name": "Manan Tomar"
                },
                {
                    "authorId": "27098848",
                    "name": "Yonathan Efroni"
                },
                {
                    "authorId": "1678622",
                    "name": "M. Ghavamzadeh"
                }
            ],
            "doi": null,
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "bb4999ad9bb6d24a9a9dd863fad312c5b0018fa9",
            "title": "Multi-step Greedy Reinforcement Learning Algorithms",
            "url": "https://www.semanticscholar.org/paper/bb4999ad9bb6d24a9a9dd863fad312c5b0018fa9",
            "venue": "ICML",
            "year": 2019
        },
        {
            "arxivId": "1910.02919",
            "authors": [
                {
                    "authorId": "119439163",
                    "name": "Manan Tomar"
                },
                {
                    "authorId": "27098848",
                    "name": "Yonathan Efroni"
                },
                {
                    "authorId": "1678622",
                    "name": "M. Ghavamzadeh"
                }
            ],
            "doi": null,
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "56e6485a960d0ef54d965de3b7060fac67c912d9",
            "title": "Multi-step Greedy Policies in Model-Free Deep Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/56e6485a960d0ef54d965de3b7060fac67c912d9",
            "venue": "ArXiv",
            "year": 2019
        },
        {
            "arxivId": "1912.11206",
            "authors": [
                {
                    "authorId": "3363788",
                    "name": "Chenjun Xiao"
                },
                {
                    "authorId": "2013680445",
                    "name": "Yifan Wu"
                },
                {
                    "authorId": "2112461997",
                    "name": "Chen Ma"
                },
                {
                    "authorId": "50319359",
                    "name": "D. Schuurmans"
                },
                {
                    "authorId": "2116237915",
                    "name": "Martin M\u00fcller"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "5d5e01193e36a77c836fe8ee3ebb13d57520d050",
            "title": "Learning to Combat Compounding-Error in Model-Based Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/5d5e01193e36a77c836fe8ee3ebb13d57520d050",
            "venue": "ArXiv",
            "year": 2019
        },
        {
            "arxivId": "1909.11821",
            "authors": [
                {
                    "authorId": "31609618",
                    "name": "Yueh-Hua Wu"
                },
                {
                    "authorId": "32037089",
                    "name": "Ting-Han Fan"
                },
                {
                    "authorId": "1693135",
                    "name": "P. Ramadge"
                },
                {
                    "authorId": "2093560213",
                    "name": "H. Su"
                }
            ],
            "doi": null,
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "2a3173d38a6e2dd613f1ebbd01d1fe485fc4a70d",
            "title": "Model Imitation for Model-Based Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/2a3173d38a6e2dd613f1ebbd01d1fe485fc4a70d",
            "venue": "ArXiv",
            "year": 2019
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2110425522",
                    "name": "Young Joon Park"
                },
                {
                    "authorId": "40075249",
                    "name": "Y. Cho"
                },
                {
                    "authorId": "2144239880",
                    "name": "S. Kim"
                }
            ],
            "doi": "10.1371/journal.pone.0222215",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "d42abbf832b0db88bf887786dec5dabb4c437849",
            "title": "Multi-agent reinforcement learning with approximate model learning for competitive games",
            "url": "https://www.semanticscholar.org/paper/d42abbf832b0db88bf887786dec5dabb4c437849",
            "venue": "PloS one",
            "year": 2019
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "152422014",
                    "name": "David Abel"
                },
                {
                    "authorId": "38912360",
                    "name": "J. Winder"
                },
                {
                    "authorId": "144980202",
                    "name": "Marie desJardins"
                },
                {
                    "authorId": "144885169",
                    "name": "M. Littman"
                }
            ],
            "doi": "10.24963/ijcai.2019/270",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "2f58c0c89e33021c9834115a41db07c1a18f9133",
            "title": "The Expected-Length Model of Options",
            "url": "https://www.semanticscholar.org/paper/2f58c0c89e33021c9834115a41db07c1a18f9133",
            "venue": "IJCAI",
            "year": 2019
        },
        {
            "arxivId": "1907.03613",
            "authors": [
                {
                    "authorId": "2108795581",
                    "name": "Yuxiang Yang"
                },
                {
                    "authorId": "2758571",
                    "name": "Ken Caluwaerts"
                },
                {
                    "authorId": "2106754",
                    "name": "Atil Iscen"
                },
                {
                    "authorId": "28292148",
                    "name": "Tingnan Zhang"
                },
                {
                    "authorId": "1739176520",
                    "name": "Jie Tan"
                },
                {
                    "authorId": "1808676",
                    "name": "Vikas Sindhwani"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "d078f720a7fb0e1961a17ea967332599e6d2b692",
            "title": "Data Efficient Reinforcement Learning for Legged Robots",
            "url": "https://www.semanticscholar.org/paper/d078f720a7fb0e1961a17ea967332599e6d2b692",
            "venue": "CoRL",
            "year": 2019
        },
        {
            "arxivId": "1906.08253",
            "authors": [
                {
                    "authorId": "35163402",
                    "name": "Michael Janner"
                },
                {
                    "authorId": "2550764",
                    "name": "Justin Fu"
                },
                {
                    "authorId": "2634261",
                    "name": "Marvin Zhang"
                },
                {
                    "authorId": "1736651",
                    "name": "S. Levine"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "9001698e033524864d4d45f051a5ba362d4afd9e",
            "title": "When to Trust Your Model: Model-Based Policy Optimization",
            "url": "https://www.semanticscholar.org/paper/9001698e033524864d4d45f051a5ba362d4afd9e",
            "venue": "NeurIPS",
            "year": 2019
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "40066857",
                    "name": "Marlos C. Machado"
                }
            ],
            "doi": "10.7939/R3-0RGA-W005",
            "intent": [],
            "isInfluential": false,
            "paperId": "af581dd2243ba89ba476f790cde876d1e1b6774b",
            "title": "Efficient Exploration in Reinforcement Learning through Time-Based Representations",
            "url": "https://www.semanticscholar.org/paper/af581dd2243ba89ba476f790cde876d1e1b6774b",
            "venue": "",
            "year": 2019
        },
        {
            "arxivId": "1905.13320",
            "authors": [
                {
                    "authorId": "7981071",
                    "name": "Kavosh Asadi"
                },
                {
                    "authorId": "31498163",
                    "name": "Dipendra Kumar Misra"
                },
                {
                    "authorId": "2144254660",
                    "name": "Seungchan Kim"
                },
                {
                    "authorId": "144885169",
                    "name": "M. Littman"
                }
            ],
            "doi": null,
            "intent": [
                "background",
                "result"
            ],
            "isInfluential": false,
            "paperId": "069d18aefd5cc0eef1b3f0403ebcec188b1d2c1f",
            "title": "Combating the Compounding-Error Problem with a Multi-step Model",
            "url": "https://www.semanticscholar.org/paper/069d18aefd5cc0eef1b3f0403ebcec188b1d2c1f",
            "venue": "ArXiv",
            "year": 2019
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "95528042",
                    "name": "Bohan Wu"
                },
                {
                    "authorId": "38303675",
                    "name": "Jayesh K. Gupta"
                },
                {
                    "authorId": "79262652",
                    "name": "Mykel J. Kochenderfer"
                }
            ],
            "doi": "10.1007/s10458-020-09451-0",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "a7859b059cfe01d01f1bd795e86eb3f0771fb53b",
            "title": "Model primitives for hierarchical lifelong reinforcement learning",
            "url": "https://www.semanticscholar.org/paper/a7859b059cfe01d01f1bd795e86eb3f0771fb53b",
            "venue": "Autonomous Agents and Multi-Agent Systems",
            "year": 2019
        },
        {
            "arxivId": "1905.01718",
            "authors": [
                {
                    "authorId": "32606259",
                    "name": "Muhammad Burhan Hafez"
                },
                {
                    "authorId": "1798067",
                    "name": "C. Weber"
                },
                {
                    "authorId": "2991958",
                    "name": "Matthias Kerzel"
                },
                {
                    "authorId": "1736513",
                    "name": "Stefan Wermter"
                }
            ],
            "doi": "10.1109/IJCNN.2019.8852254",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "b91f6a10375e7064ca57400ad265114b8365f0ed",
            "title": "Curious Meta-Controller: Adaptive Alternation between Model-Based and Model-Free Control in Deep Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/b91f6a10375e7064ca57400ad265114b8365f0ed",
            "venue": "2019 International Joint Conference on Neural Networks (IJCNN)",
            "year": 2019
        },
        {
            "arxivId": "1905.01072",
            "authors": [
                {
                    "authorId": "2503523",
                    "name": "Shangtong Zhang"
                },
                {
                    "authorId": "144285271",
                    "name": "Wendelin B\u00f6hmer"
                },
                {
                    "authorId": "1766767",
                    "name": "Shimon Whiteson"
                }
            ],
            "doi": null,
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "a76db54e4b5130ee45c224a7518e8a159f0bd843",
            "title": "Deep Residual Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/a76db54e4b5130ee45c224a7518e8a159f0bd843",
            "venue": "AAMAS",
            "year": 2019
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "145991379",
                    "name": "K. Young"
                },
                {
                    "authorId": "2075299556",
                    "name": "Tian Tian"
                }
            ],
            "doi": null,
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "05d94cfe5768ebdcc1ecd8cb81de694e0d3e2f5d",
            "title": "MinAtar: An Atari-Inspired Testbed for Thorough and Reproducible Reinforcement Learning Experiments",
            "url": "https://www.semanticscholar.org/paper/05d94cfe5768ebdcc1ecd8cb81de694e0d3e2f5d",
            "venue": "",
            "year": 2019
        },
        {
            "arxivId": "1903.01567",
            "authors": [
                {
                    "authorId": "95528042",
                    "name": "Bohan Wu"
                },
                {
                    "authorId": "38303675",
                    "name": "Jayesh K. Gupta"
                },
                {
                    "authorId": "2275756",
                    "name": "Mykel J. Kochenderfer"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "4839f473193fccb5566ae6388ba6f40defdf10dc",
            "title": "Model Primitive Hierarchical Lifelong Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/4839f473193fccb5566ae6388ba6f40defdf10dc",
            "venue": "AAMAS",
            "year": 2019
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "39251318",
                    "name": "Lucas Lehnert"
                },
                {
                    "authorId": "144885169",
                    "name": "M. Littman"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": true,
            "paperId": "b35484a629152d8349046e81ac4671fc98d4d0b3",
            "title": "Successor Features Combine Elements of Model-Free and Model-based Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/b35484a629152d8349046e81ac4671fc98d4d0b3",
            "venue": "J. Mach. Learn. Res.",
            "year": 2019
        },
        {
            "arxivId": "1901.11437",
            "authors": [
                {
                    "authorId": "39251318",
                    "name": "Lucas Lehnert"
                },
                {
                    "authorId": "144885169",
                    "name": "M. Littman"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": true,
            "paperId": "84659d7cf5186a2640af6a4a26f9d8175fd87529",
            "title": "Successor Features Support Model-based and Model-free Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/84659d7cf5186a2640af6a4a26f9d8175fd87529",
            "venue": "ArXiv",
            "year": 2019
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "47612580",
                    "name": "S. Parbhoo"
                },
                {
                    "authorId": "34772064",
                    "name": "Omer Gottesman"
                },
                {
                    "authorId": "2068943123",
                    "name": "A. Ross"
                },
                {
                    "authorId": "6204450",
                    "name": "M. Komorowski"
                },
                {
                    "authorId": "35321363",
                    "name": "Aldo A. Faisal"
                },
                {
                    "authorId": "6739440",
                    "name": "I. Bon"
                },
                {
                    "authorId": "145677861",
                    "name": "Volker Roth"
                },
                {
                    "authorId": "1388372395",
                    "name": "F. Doshi-Velez"
                }
            ],
            "doi": "10.1371/journal.pone.0205839",
            "intent": [],
            "isInfluential": false,
            "paperId": "39045afc80a2ecc878ff73e209f699186bb4a179",
            "title": "Improving counterfactual reasoning with kernelised dynamic mixing models",
            "url": "https://www.semanticscholar.org/paper/39045afc80a2ecc878ff73e209f699186bb4a179",
            "venue": "PloS one",
            "year": 2018
        },
        {
            "arxivId": "1811.00128",
            "authors": [
                {
                    "authorId": "7981071",
                    "name": "Kavosh Asadi"
                },
                {
                    "authorId": "51000733",
                    "name": "Evan Cater"
                },
                {
                    "authorId": "31498163",
                    "name": "Dipendra Kumar Misra"
                },
                {
                    "authorId": "144885169",
                    "name": "M. Littman"
                }
            ],
            "doi": null,
            "intent": [
                "background",
                "result"
            ],
            "isInfluential": false,
            "paperId": "154c8a314b8387db2d75b7a6c319a040c8be5cfd",
            "title": "Towards a Simple Approach to Multi-step Model-based Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/154c8a314b8387db2d75b7a6c319a040c8be5cfd",
            "venue": "ArXiv",
            "year": 2018
        },
        {
            "arxivId": "1810.06339",
            "authors": [
                {
                    "authorId": "2276894",
                    "name": "Yuxi Li"
                }
            ],
            "doi": "10.1007/978-3-319-94463-0_9",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "f2ac2a3fd7b341f2b1be752b4dd46ed9abcf0751",
            "title": "Deep Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/f2ac2a3fd7b341f2b1be752b4dd46ed9abcf0751",
            "venue": "Reinforcement Learning for Cyber-Physical Systems",
            "year": 2018
        },
        {
            "arxivId": "1806.04624",
            "authors": [
                {
                    "authorId": "7303313",
                    "name": "Yangchen Pan"
                },
                {
                    "authorId": "145602215",
                    "name": "M. Zaheer"
                },
                {
                    "authorId": "145240145",
                    "name": "Adam White"
                },
                {
                    "authorId": "145690938",
                    "name": "Andrew Patterson"
                },
                {
                    "authorId": "144542337",
                    "name": "Martha White"
                }
            ],
            "doi": "10.24963/ijcai.2018/666",
            "intent": [
                "background",
                "methodology"
            ],
            "isInfluential": true,
            "paperId": "ba7a309fcc8dd361bddd27662fdfd68294e58b80",
            "title": "Organizing Experience: a Deeper Look at Replay Mechanisms for Sample-Based Planning in Continuous State Domains",
            "url": "https://www.semanticscholar.org/paper/ba7a309fcc8dd361bddd27662fdfd68294e58b80",
            "venue": "IJCAI",
            "year": 2018
        },
        {
            "arxivId": "1804.07193",
            "authors": [
                {
                    "authorId": "7981071",
                    "name": "Kavosh Asadi"
                },
                {
                    "authorId": "31498163",
                    "name": "Dipendra Kumar Misra"
                },
                {
                    "authorId": "144885169",
                    "name": "M. Littman"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "c4f529934b6f22aa38e014e295a9737daa6e7db5",
            "title": "Lipschitz Continuity in Model-based Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/c4f529934b6f22aa38e014e295a9737daa6e7db5",
            "venue": "ICML",
            "year": 2018
        },
        {
            "arxivId": "1801.09624",
            "authors": [
                {
                    "authorId": "1701322",
                    "name": "Erik Talvitie"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "900d3c8362686923e289c7ed6bc96c201e65d69c",
            "title": "Learning the Reward Function for a Misspecified Model",
            "url": "https://www.semanticscholar.org/paper/900d3c8362686923e289c7ed6bc96c201e65d69c",
            "venue": "ICML",
            "year": 2018
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "38698094",
                    "name": "Gregory Farquhar"
                },
                {
                    "authorId": "2620211",
                    "name": "Tim Rockt\u00e4schel"
                },
                {
                    "authorId": "27550002",
                    "name": "Maximilian Igl"
                },
                {
                    "authorId": "1766767",
                    "name": "Shimon Whiteson"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "11c421320be0e098ddb7e52257f3d132e99715d4",
            "title": "TreeQN and ATreeC: Differentiable Tree-Structured Models for Deep Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/11c421320be0e098ddb7e52257f3d132e99715d4",
            "venue": "ICLR",
            "year": 2017
        },
        {
            "arxivId": "1710.11417",
            "authors": [
                {
                    "authorId": "38698094",
                    "name": "Gregory Farquhar"
                },
                {
                    "authorId": "2620211",
                    "name": "Tim Rockt\u00e4schel"
                },
                {
                    "authorId": "27550002",
                    "name": "Maximilian Igl"
                },
                {
                    "authorId": "1766767",
                    "name": "Shimon Whiteson"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "da1d97dba0a34b1cc9171eb5b0e24d331eceb15c",
            "title": "TreeQN and ATreeC: Differentiable Tree Planning for Deep Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/da1d97dba0a34b1cc9171eb5b0e24d331eceb15c",
            "venue": "ICLR 2018",
            "year": 2017
        },
        {
            "arxivId": "1709.06009",
            "authors": [
                {
                    "authorId": "40066857",
                    "name": "Marlos C. Machado"
                },
                {
                    "authorId": "1792298",
                    "name": "Marc G. Bellemare"
                },
                {
                    "authorId": "1701322",
                    "name": "Erik Talvitie"
                },
                {
                    "authorId": "144056327",
                    "name": "J. Veness"
                },
                {
                    "authorId": "3308897",
                    "name": "Matthew J. Hausknecht"
                },
                {
                    "authorId": "143913104",
                    "name": "Michael H. Bowling"
                }
            ],
            "doi": "10.1613/jair.5699",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "3b290ffa1f4f8226e326f00984acecdfbe9e28bf",
            "title": "Revisiting the Arcade Learning Environment: Evaluation Protocols and Open Problems for General Agents",
            "url": "https://www.semanticscholar.org/paper/3b290ffa1f4f8226e326f00984acecdfbe9e28bf",
            "venue": "J. Artif. Intell. Res.",
            "year": 2017
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "143808691",
                    "name": "Jian Shen"
                },
                {
                    "authorId": "2054235888",
                    "name": "Hang Lai"
                },
                {
                    "authorId": "2232669157",
                    "name": "\u2020. MinghuanLiu"
                },
                {
                    "authorId": "2232668601",
                    "name": "\u2021. HanZhao"
                },
                {
                    "authorId": "2232746445",
                    "name": "Yong Yu"
                },
                {
                    "authorId": "2232668280",
                    "name": "\u2020. WeinanZhang"
                }
            ],
            "doi": null,
            "intent": [
                "background",
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "41e3b2b16ca00229b873328827cf69a707760e8a",
            "title": "Adaptation Augmented Model-based Policy Optimization",
            "url": "https://www.semanticscholar.org/paper/41e3b2b16ca00229b873328827cf69a707760e8a",
            "venue": "J. Mach. Learn. Res.",
            "year": 2023
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2044295861",
                    "name": "Kiarash Aghakasiri"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "4f7db3687405c2041ee422822568a4827c7d8f8a",
            "title": "Monte Carlo Tree Search in the Presence of Model Uncertainty",
            "url": "https://www.semanticscholar.org/paper/4f7db3687405c2041ee422822568a4827c7d8f8a",
            "venue": "",
            "year": 2022
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "34257663",
                    "name": "Clement Gehring"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "d7b57839eebb2b20738d0f2f35e46fbf1cfe0e95",
            "title": "Understanding End-to-End Model-Based Reinforcement Learning Methods as Implicit Parameterization",
            "url": "https://www.semanticscholar.org/paper/d7b57839eebb2b20738d0f2f35e46fbf1cfe0e95",
            "venue": "NeurIPS",
            "year": 2021
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2144191176",
                    "name": "Sean J. Wang"
                },
                {
                    "authorId": "2068071355",
                    "name": "S. Triest"
                },
                {
                    "authorId": "3174935",
                    "name": "Wenshan Wang"
                },
                {
                    "authorId": "32634992",
                    "name": "S. Scherer"
                },
                {
                    "authorId": "143837834",
                    "name": "Aaron M. Johnson"
                }
            ],
            "doi": null,
            "intent": [
                "background",
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "32e811ddb64eec516cc9bfa8ddd3e9572c6832d3",
            "title": "Rough Terrain Navigation Using Divergence Constrained Model-Based Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/32e811ddb64eec516cc9bfa8ddd3e9572c6832d3",
            "venue": "CoRL",
            "year": 2021
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "1419479157",
                    "name": "Taher Jafferjee"
                }
            ],
            "doi": "10.7939/R3-AYZF-PV64",
            "intent": [],
            "isInfluential": false,
            "paperId": "40b1b3b59e078c32a1c1fb1562906ad0b96c9c23",
            "title": "Chasing Hallucinated Value: A Pitfall of Dyna Style Algorithms with Imperfect Environment Models",
            "url": "https://www.semanticscholar.org/paper/40b1b3b59e078c32a1c1fb1562906ad0b96c9c23",
            "venue": "",
            "year": 2020
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2113291319",
                    "name": "Han Wang"
                }
            ],
            "doi": "10.7939/R3-1S8N-TM45",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "ea2995884db698f064c1bfb8a926f356cd984aa3",
            "title": "Emergent Representations in Reinforcement Learning and Their Properties",
            "url": "https://www.semanticscholar.org/paper/ea2995884db698f064c1bfb8a926f356cd984aa3",
            "venue": "",
            "year": 2020
        },
        {
            "arxivId": null,
            "authors": [],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "ad70dfb41b903ca4dbaa6532cfad779ac5a68fb0",
            "title": "Dynamics f \" Policy \u03c0 \" ( x ) Environment State Transitions RewardTrajectories Training : Maximum Likelihood Objective Mismatch Control Interacts Responses",
            "url": "https://www.semanticscholar.org/paper/ad70dfb41b903ca4dbaa6532cfad779ac5a68fb0",
            "venue": "",
            "year": 2019
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2294338354",
                    "name": "A. Deichler"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "872e068573cfa9b243cd092dfa72e160267e6ce1",
            "title": "Generalization and locality in the AlphaZero algorithm",
            "url": "https://www.semanticscholar.org/paper/872e068573cfa9b243cd092dfa72e160267e6ce1",
            "venue": "",
            "year": 2019
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "145289907",
                    "name": "Nhat M. Nguyen"
                }
            ],
            "doi": null,
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "cf40c34c1020819ffd7c4696904233a379f57b73",
            "title": "Improving model-based RL with Adaptive Rollout using Uncertainty Estimation",
            "url": "https://www.semanticscholar.org/paper/cf40c34c1020819ffd7c4696904233a379f57b73",
            "venue": "",
            "year": 2018
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2075389608",
                    "name": "Yi Wan"
                },
                {
                    "authorId": "145602215",
                    "name": "M. Zaheer"
                },
                {
                    "authorId": "144542337",
                    "name": "Martha White"
                },
                {
                    "authorId": "1699645",
                    "name": "R. Sutton"
                }
            ],
            "doi": null,
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "49c2b28f762ada831588bdf1bef3c3cba46022ed",
            "title": "Model-based Reinforcement Learning with Non-linear Expectation Models and Stochastic Environments",
            "url": "https://www.semanticscholar.org/paper/49c2b28f762ada831588bdf1bef3c3cba46022ed",
            "venue": "",
            "year": 2018
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "5689899",
                    "name": "Amir-massoud Farahmand"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "209a40022efbf895cd36387b9a3f3027066ae896",
            "title": "Iterative Value-Aware Model Learning",
            "url": "https://www.semanticscholar.org/paper/209a40022efbf895cd36387b9a3f3027066ae896",
            "venue": "NeurIPS",
            "year": 2018
        }
    ],
    "corpusId": 6349245,
    "doi": "10.1609/aaai.v31i1.10850",
    "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
    ],
    "influentialCitationCount": 5,
    "isOpenAccess": true,
    "isPublisherLicensed": true,
    "is_open_access": true,
    "is_publisher_licensed": true,
    "numCitedBy": 84,
    "numCiting": 16,
    "paperId": "ea22d6190b1ae38fefd391e3d6c48d8807d72626",
    "references": [
        {
            "arxivId": "1507.08750",
            "authors": [
                {
                    "authorId": "2894414",
                    "name": "Junhyuk Oh"
                },
                {
                    "authorId": "1955964",
                    "name": "Xiaoxiao Guo"
                },
                {
                    "authorId": "1697141",
                    "name": "Honglak Lee"
                },
                {
                    "authorId": "46328485",
                    "name": "Richard L. Lewis"
                },
                {
                    "authorId": "1699868",
                    "name": "Satinder Singh"
                }
            ],
            "doi": null,
            "intent": [
                "background",
                "methodology"
            ],
            "isInfluential": true,
            "paperId": "e4257bc131c36504a04382290cbc27ca8bb27813",
            "title": "Action-Conditional Video Prediction using Deep Networks in Atari Games",
            "url": "https://www.semanticscholar.org/paper/e4257bc131c36504a04382290cbc27ca8bb27813",
            "venue": "NIPS",
            "year": 2015
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "1701322",
                    "name": "Erik Talvitie"
                }
            ],
            "doi": "10.1609/aaai.v29i1.9616",
            "intent": [
                "background",
                "methodology"
            ],
            "isInfluential": true,
            "paperId": "817cd27958ee04a366909f9027003a95ddab4955",
            "title": "Agnostic System Identification for Monte Carlo Planning",
            "url": "https://www.semanticscholar.org/paper/817cd27958ee04a366909f9027003a95ddab4955",
            "venue": "AAAI",
            "year": 2015
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "1978198",
                    "name": "Arun Venkatraman"
                },
                {
                    "authorId": "145670946",
                    "name": "M. Hebert"
                },
                {
                    "authorId": "1756566",
                    "name": "J. Bagnell"
                }
            ],
            "doi": "10.1609/aaai.v29i1.9590",
            "intent": [
                "background",
                "methodology"
            ],
            "isInfluential": true,
            "paperId": "d5d46991c7e92352865dbf442be7c74d0d560dd8",
            "title": "Improving Multi-Step Prediction of Learned Time Series Models",
            "url": "https://www.semanticscholar.org/paper/d5d46991c7e92352865dbf442be7c74d0d560dd8",
            "venue": "AAAI",
            "year": 2015
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "1701322",
                    "name": "Erik Talvitie"
                }
            ],
            "doi": null,
            "intent": [
                "background",
                "methodology"
            ],
            "isInfluential": true,
            "paperId": "48aaaa1e59c58856315d814363f431b93f76e668",
            "title": "Model Regularization for Stable Sample Rollouts",
            "url": "https://www.semanticscholar.org/paper/48aaaa1e59c58856315d814363f431b93f76e668",
            "venue": "UAI",
            "year": 2014
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "1792298",
                    "name": "Marc G. Bellemare"
                },
                {
                    "authorId": "144056327",
                    "name": "J. Veness"
                },
                {
                    "authorId": "1701322",
                    "name": "Erik Talvitie"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "f6ca9c148417d4167ba8b72f185a35649dc4b446",
            "title": "Skip Context Tree Switching",
            "url": "https://www.semanticscholar.org/paper/f6ca9c148417d4167ba8b72f185a35649dc4b446",
            "venue": "ICML",
            "year": 2014
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "3308897",
                    "name": "Matthew J. Hausknecht"
                },
                {
                    "authorId": "39799304",
                    "name": "J. Lehman"
                },
                {
                    "authorId": "1686788",
                    "name": "R. Miikkulainen"
                },
                {
                    "authorId": "144848112",
                    "name": "P. Stone"
                }
            ],
            "doi": "10.1109/TCIAIG.2013.2294713",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "cf6c64b87459a3164ad54128fa085328c401c09f",
            "title": "A Neuroevolution Approach to General Atari Game Playing",
            "url": "https://www.semanticscholar.org/paper/cf6c64b87459a3164ad54128fa085328c401c09f",
            "venue": "IEEE Transactions on Computational Intelligence and AI in Games",
            "year": 2014
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2637940",
                    "name": "J. Joseph"
                },
                {
                    "authorId": "1979505",
                    "name": "A. Geramifard"
                },
                {
                    "authorId": "34763783",
                    "name": "John W. Roberts"
                },
                {
                    "authorId": "1713935",
                    "name": "J. How"
                },
                {
                    "authorId": "143724999",
                    "name": "N. Roy"
                }
            ],
            "doi": "10.1109/ICRA.2013.6630686",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "9025c315eac54b6eaea257e20b4cde9d114a40e2",
            "title": "Reinforcement learning with misspecified model classes",
            "url": "https://www.semanticscholar.org/paper/9025c315eac54b6eaea257e20b4cde9d114a40e2",
            "venue": "2013 IEEE International Conference on Robotics and Automation",
            "year": 2013
        },
        {
            "arxivId": "1203.1007",
            "authors": [
                {
                    "authorId": "1700433",
                    "name": "St\u00e9phane Ross"
                },
                {
                    "authorId": "72545155",
                    "name": "Drew Bagnell"
                }
            ],
            "doi": null,
            "intent": [
                "background",
                "methodology"
            ],
            "isInfluential": true,
            "paperId": "43be33ef48e66d1f293c73af73f2f6753c6c392c",
            "title": "Agnostic System Identification for Model-Based Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/43be33ef48e66d1f293c73af73f2f6753c6c392c",
            "venue": "ICML",
            "year": 2012
        },
        {
            "arxivId": "1111.3182",
            "authors": [
                {
                    "authorId": "144056327",
                    "name": "J. Veness"
                },
                {
                    "authorId": "34746380",
                    "name": "K. S. Ng"
                },
                {
                    "authorId": "144154444",
                    "name": "Marcus Hutter"
                },
                {
                    "authorId": "1687780",
                    "name": "Michael Bowling"
                }
            ],
            "doi": "10.1109/DCC.2012.39",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "be4318c4f7fbc821d9b80f569156b7ace81743c9",
            "title": "Context Tree Switching",
            "url": "https://www.semanticscholar.org/paper/be4318c4f7fbc821d9b80f569156b7ace81743c9",
            "venue": "2012 Data Compression Conference",
            "year": 2011
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "144123639",
                    "name": "Jonathan Sorg"
                },
                {
                    "authorId": "1699868",
                    "name": "Satinder Singh"
                },
                {
                    "authorId": "46328485",
                    "name": "Richard L. Lewis"
                }
            ],
            "doi": null,
            "intent": [
                "background",
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "8e767ae28510558344f90b0be08344d2b3769cd6",
            "title": "Reward Design via Online Gradient Ascent",
            "url": "https://www.semanticscholar.org/paper/8e767ae28510558344f90b0be08344d2b3769cd6",
            "venue": "NIPS",
            "year": 2010
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "1742557",
                    "name": "I. Szita"
                },
                {
                    "authorId": "40868287",
                    "name": "Csaba Szepesvari"
                }
            ],
            "doi": null,
            "intent": [
                "background",
                "methodology"
            ],
            "isInfluential": true,
            "paperId": "75c827ed14c8794b6babf05b944751877e7d2b77",
            "title": "Model-based reinforcement learning with nearly tight exploration complexity bounds",
            "url": "https://www.semanticscholar.org/paper/75c827ed14c8794b6babf05b944751877e7d2b77",
            "venue": "ICML",
            "year": 2010
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "144056327",
                    "name": "J. Veness"
                },
                {
                    "authorId": "34746380",
                    "name": "K. S. Ng"
                },
                {
                    "authorId": "144154444",
                    "name": "Marcus Hutter"
                },
                {
                    "authorId": "1742809",
                    "name": "William T. B. Uther"
                },
                {
                    "authorId": "145824029",
                    "name": "David Silver"
                }
            ],
            "doi": "10.1613/JAIR.3125",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "05f3b6736efa61909d871f8fe77bf2cea05e6917",
            "title": "A Monte-Carlo AIXI Approximation",
            "url": "https://www.semanticscholar.org/paper/05f3b6736efa61909d871f8fe77bf2cea05e6917",
            "venue": "J. Artif. Intell. Res.",
            "year": 2009
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "1689992",
                    "name": "P. Abbeel"
                },
                {
                    "authorId": "39100828",
                    "name": "M. Quigley"
                },
                {
                    "authorId": "34699434",
                    "name": "A. Ng"
                }
            ],
            "doi": "10.1145/1143844.1143845",
            "intent": [
                "background",
                "methodology"
            ],
            "isInfluential": true,
            "paperId": "30d8e493ae35a64b2bebbe6ec90dc190488f82fa",
            "title": "Using inaccurate models in reinforcement learning",
            "url": "https://www.semanticscholar.org/paper/30d8e493ae35a64b2bebbe6ec90dc190488f82fa",
            "venue": "ICML",
            "year": 2006
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "1687780",
                    "name": "Michael Bowling"
                },
                {
                    "authorId": "144781271",
                    "name": "Peter Mccracken"
                },
                {
                    "authorId": "71542506",
                    "name": "Michael R. James"
                },
                {
                    "authorId": "2094697289",
                    "name": "James Neufeld"
                },
                {
                    "authorId": "28124748",
                    "name": "Dana F. Wilkinson"
                }
            ],
            "doi": "10.1145/1143844.1143861",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "64c9ba448a4e62a3eaa0a1cf2998f1f9d0cf65a5",
            "title": "Learning predictive state representations using non-blind policies",
            "url": "https://www.semanticscholar.org/paper/64c9ba448a4e62a3eaa0a1cf2998f1f9d0cf65a5",
            "venue": "ICML",
            "year": 2006
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "1699108",
                    "name": "G. Tesauro"
                },
                {
                    "authorId": "2796200",
                    "name": "Gregory R. Galperin"
                }
            ],
            "doi": null,
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "3552fba431aa866bf9de293bebf7eff168e9e19c",
            "title": "On-line Policy Improvement using Monte-Carlo Search",
            "url": "https://www.semanticscholar.org/paper/3552fba431aa866bf9de293bebf7eff168e9e19c",
            "venue": "NIPS",
            "year": 1996
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "144695232",
                    "name": "S. Kakade"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": true,
            "paperId": "a9e5a40b0ff5c40d2db7b73490922e115576adb5",
            "title": "On the sample complexity of reinforcement learning.",
            "url": "https://www.semanticscholar.org/paper/a9e5a40b0ff5c40d2db7b73490922e115576adb5",
            "venue": "",
            "year": 2003
        }
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Mathematics",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "title": "Self-Correcting Models for Model-Based Reinforcement Learning",
    "topics": [],
    "url": "https://www.semanticscholar.org/paper/ea22d6190b1ae38fefd391e3d6c48d8807d72626",
    "venue": "AAAI Conference on Artificial Intelligence",
    "year": 2016
}
{
    "abstract": "We consider the problem of knowledge transfer when an agent is facing a series of Reinforcement Learning (RL) tasks. We introduce a novel metric between Markov Decision Processes and establish that close MDPs have close optimal value functions. Formally, the optimal value functions are Lipschitz continuous with respect to the tasks space. These theoretical results lead us to a value-transfer method for Lifelong RL, which we use to build a PAC-MDP algorithm with improved convergence rate. Further, we show the method to experience no negative transfer with high probability. We illustrate the benefits of the method in Lifelong RL experiments.",
    "arxivId": "2001.05411",
    "authors": [
        {
            "authorId": "34632439",
            "name": "Erwan Lecarpentier",
            "url": "https://www.semanticscholar.org/author/34632439"
        },
        {
            "authorId": "152422014",
            "name": "David Abel",
            "url": "https://www.semanticscholar.org/author/152422014"
        },
        {
            "authorId": "7981071",
            "name": "Kavosh Asadi",
            "url": "https://www.semanticscholar.org/author/7981071"
        },
        {
            "authorId": "3387240",
            "name": "Yuu Jinnai",
            "url": "https://www.semanticscholar.org/author/3387240"
        },
        {
            "authorId": "2558054",
            "name": "E. Rachelson",
            "url": "https://www.semanticscholar.org/author/2558054"
        },
        {
            "authorId": "144885169",
            "name": "M. Littman",
            "url": "https://www.semanticscholar.org/author/144885169"
        }
    ],
    "citationVelocity": 9,
    "citations": [
        {
            "arxivId": "2411.11372",
            "authors": [
                {
                    "authorId": "2092893913",
                    "name": "R. Arnau"
                },
                {
                    "authorId": "143602122",
                    "name": "J. Calabuig"
                },
                {
                    "authorId": "2205810560",
                    "name": "E. A. S'anchez-P'erez"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "fd20cf435a7729c3d801963fc3737a734deb8b79",
            "title": "Lattice Lipschitz operators on $C(K)-$space",
            "url": "https://www.semanticscholar.org/paper/fd20cf435a7729c3d801963fc3737a734deb8b79",
            "venue": "",
            "year": 2024
        },
        {
            "arxivId": "2411.00401",
            "authors": [
                {
                    "authorId": "2326248907",
                    "name": "Zhi Zhang"
                },
                {
                    "authorId": "2328978876",
                    "name": "Chris Chow"
                },
                {
                    "authorId": "2296023267",
                    "name": "Yasi Zhang"
                },
                {
                    "authorId": "120738683",
                    "name": "Yanchao Sun"
                },
                {
                    "authorId": "2329044674",
                    "name": "Haochen Zhang"
                },
                {
                    "authorId": "2270430482",
                    "name": "E. H. Jiang"
                },
                {
                    "authorId": "2329039164",
                    "name": "Han Liu"
                },
                {
                    "authorId": "2288331810",
                    "name": "Furong Huang"
                },
                {
                    "authorId": "2329141851",
                    "name": "Yuchen Cui"
                },
                {
                    "authorId": "2527891",
                    "name": "Oscar Hernan Madrid Padilla"
                }
            ],
            "doi": null,
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "89b7d22582b4ce7f4bcd70fda6caaf38dc283ff5",
            "title": "Statistical Guarantees for Lifelong Reinforcement Learning using PAC-Bayesian Theory",
            "url": "https://www.semanticscholar.org/paper/89b7d22582b4ce7f4bcd70fda6caaf38dc283ff5",
            "venue": "",
            "year": 2024
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2302812857",
                    "name": "Minghao Zhang"
                },
                {
                    "authorId": "2172390504",
                    "name": "Bifeng Song"
                },
                {
                    "authorId": "2268696971",
                    "name": "Changhao Chen"
                },
                {
                    "authorId": "1382552708",
                    "name": "Xinyu Lang"
                },
                {
                    "authorId": "2238164126",
                    "name": "Liang Wang"
                }
            ],
            "doi": "10.1007/s10489-024-05720-7",
            "intent": [],
            "isInfluential": false,
            "paperId": "8386e2ae69690b601b6c1f9551e5ed4d3c802d05",
            "title": "Concertorl: A reinforcement learning approach for finite-time single-life enhanced control and its application to direct-drive tandem-wing experiment platforms",
            "url": "https://www.semanticscholar.org/paper/8386e2ae69690b601b6c1f9551e5ed4d3c802d05",
            "venue": "Appl. Intell.",
            "year": 2024
        },
        {
            "arxivId": "2409.03577",
            "authors": [
                {
                    "authorId": "2319830693",
                    "name": "John Birkbeck"
                },
                {
                    "authorId": "2266134809",
                    "name": "A. Sobey"
                },
                {
                    "authorId": "2256980761",
                    "name": "Federico Cerutti"
                },
                {
                    "authorId": "2319836104",
                    "name": "Katherine Heseltine Hurley Flynn"
                },
                {
                    "authorId": "2256983585",
                    "name": "Timothy J. Norman"
                }
            ],
            "doi": "10.48550/arXiv.2409.03577",
            "intent": [],
            "isInfluential": false,
            "paperId": "4d05bd6ed1da22488ce95374e19fd4cf0443c1bc",
            "title": "CHIRPs: Change-Induced Regret Proxy metrics for Lifelong Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/4d05bd6ed1da22488ce95374e19fd4cf0443c1bc",
            "venue": "ArXiv",
            "year": 2024
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "1808903",
                    "name": "Shivam Goel"
                },
                {
                    "authorId": "49072236",
                    "name": "Panagiotis Lymperopoulos"
                },
                {
                    "authorId": "6258134",
                    "name": "Ravenna Thielstrom"
                },
                {
                    "authorId": "47721859",
                    "name": "Evan A. Krause"
                },
                {
                    "authorId": "47647336",
                    "name": "Patrick Feeney"
                },
                {
                    "authorId": "2221240969",
                    "name": "Pierrick Lorang"
                },
                {
                    "authorId": "2291609224",
                    "name": "Sarah Schneider"
                },
                {
                    "authorId": "2278588236",
                    "name": "Yichen Wei"
                },
                {
                    "authorId": "2291781151",
                    "name": "Eric Kildebeck"
                },
                {
                    "authorId": "2291781311",
                    "name": "Stephen Goss"
                },
                {
                    "authorId": "2291750400",
                    "name": "Michael C. Hughes"
                },
                {
                    "authorId": "2285934975",
                    "name": "Liping Liu"
                },
                {
                    "authorId": "1715858",
                    "name": "Jivko Sinapov"
                },
                {
                    "authorId": "121848090",
                    "name": "matthias. scheutz"
                }
            ],
            "doi": "10.1016/j.artint.2024.104111",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "e1d446dd8da96718e356f3ec8e7bf1f3769fad0f",
            "title": "A neurosymbolic cognitive architecture framework for handling novelties in open worlds",
            "url": "https://www.semanticscholar.org/paper/e1d446dd8da96718e356f3ec8e7bf1f3769fad0f",
            "venue": "Artif. Intell.",
            "year": 2024
        },
        {
            "arxivId": "2402.02701",
            "authors": [
                {
                    "authorId": "2008151131",
                    "name": "Jiafei Lyu"
                },
                {
                    "authorId": "2187301367",
                    "name": "Le Wan"
                },
                {
                    "authorId": "2180539270",
                    "name": "Xiu Li"
                },
                {
                    "authorId": "2282595865",
                    "name": "Zongqing Lu"
                }
            ],
            "doi": "10.1613/jair.1.16422",
            "intent": [],
            "isInfluential": false,
            "paperId": "7f260ddb35c5799495474cc619ac728ee541c162",
            "title": "Understanding What Affects the Generalization Gap in Visual Reinforcement Learning: Theory and Empirical Evidence",
            "url": "https://www.semanticscholar.org/paper/7f260ddb35c5799495474cc619ac728ee541c162",
            "venue": "J. Artif. Intell. Res.",
            "year": 2024
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2239512946",
                    "name": "Muhammad Abulaish"
                },
                {
                    "authorId": "2115013097",
                    "name": "Nesar Ahmad Wasi"
                },
                {
                    "authorId": "2280872296",
                    "name": "Shachi Sharma"
                }
            ],
            "doi": "10.1002/widm.1526",
            "intent": [],
            "isInfluential": false,
            "paperId": "c7009adca25d78b80c52f0428bcc59fcb3a4095b",
            "title": "The role of lifelong machine learning in bridging the gap between human and machine learning: A scientometric analysis",
            "url": "https://www.semanticscholar.org/paper/c7009adca25d78b80c52f0428bcc59fcb3a4095b",
            "venue": "WIREs Data. Mining. Knowl. Discov.",
            "year": 2024
        },
        {
            "arxivId": "2401.02349",
            "authors": [
                {
                    "authorId": "72639731",
                    "name": "Ezgi Korkmaz"
                }
            ],
            "doi": "10.48550/arXiv.2401.02349",
            "intent": [],
            "isInfluential": false,
            "paperId": "8929bb5e372fe36b85664fca0e6649a6f4dd2e49",
            "title": "A Survey Analyzing Generalization in Deep Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/8929bb5e372fe36b85664fca0e6649a6f4dd2e49",
            "venue": "ArXiv",
            "year": 2024
        },
        {
            "arxivId": "2312.03764",
            "authors": [
                {
                    "authorId": "144376484",
                    "name": "Sergio A. Serrano"
                },
                {
                    "authorId": "1390012055",
                    "name": "J. Mart\u00ednez-Carranza"
                },
                {
                    "authorId": "144763689",
                    "name": "L. Sucar"
                }
            ],
            "doi": "10.48550/arXiv.2312.03764",
            "intent": [
                "background",
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "92c0990657186f5bd593fa0581912a7e19669a7b",
            "title": "Similarity-based Knowledge Transfer for Cross-Domain Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/92c0990657186f5bd593fa0581912a7e19669a7b",
            "venue": "ArXiv",
            "year": 2023
        },
        {
            "arxivId": "2307.05834",
            "authors": [
                {
                    "authorId": "152560308",
                    "name": "Sanae Amani"
                },
                {
                    "authorId": "2220908633",
                    "name": "samani"
                }
            ],
            "doi": "10.48550/arXiv.2307.05834",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "5f66ae83d32157ed4b9b5d31c22a874c3a6e231e",
            "title": "Scaling Distributed Multi-task Reinforcement Learning with Experience Sharing",
            "url": "https://www.semanticscholar.org/paper/5f66ae83d32157ed4b9b5d31c22a874c3a6e231e",
            "venue": "ArXiv",
            "year": 2023
        },
        {
            "arxivId": "2306.17833",
            "authors": [
                {
                    "authorId": "7981071",
                    "name": "Kavosh Asadi"
                },
                {
                    "authorId": "2915023",
                    "name": "Rasool Fakoor"
                },
                {
                    "authorId": "3218963",
                    "name": "Shoham Sabach"
                }
            ],
            "doi": "10.48550/arXiv.2306.17833",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "d0eac1da5d54638fd3dc41cd1e477d804dc4d806",
            "title": "Resetting the Optimizer in Deep RL: An Empirical Study",
            "url": "https://www.semanticscholar.org/paper/d0eac1da5d54638fd3dc41cd1e477d804dc4d806",
            "venue": "NeurIPS",
            "year": 2023
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2196482524",
                    "name": "Zhechao Wang"
                },
                {
                    "authorId": "3176996",
                    "name": "Qiming Fu"
                },
                {
                    "authorId": "123878427",
                    "name": "Jianping Chen"
                },
                {
                    "authorId": "2115940311",
                    "name": "Yunzhe Wang"
                },
                {
                    "authorId": "48518056",
                    "name": "You Lu"
                },
                {
                    "authorId": "2120431143",
                    "name": "Hongjie Wu"
                }
            ],
            "doi": "10.1007/s10723-023-09663-0",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "023e7a6cd3ad6bc8deb1a4cc38d96d692a31feb6",
            "title": "Reinforcement Learning in Few-Shot Scenarios: A Survey",
            "url": "https://www.semanticscholar.org/paper/023e7a6cd3ad6bc8deb1a4cc38d96d692a31feb6",
            "venue": "Journal of Grid Computing",
            "year": 2023
        },
        {
            "arxivId": "2305.13804",
            "authors": [
                {
                    "authorId": "153068698",
                    "name": "Sibo Gai"
                },
                {
                    "authorId": "2111224425",
                    "name": "Donglin Wang"
                },
                {
                    "authorId": "47648453",
                    "name": "Li He"
                }
            ],
            "doi": "10.3233/FAIA230343",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "9ced2505d3c720a05b490c1a887af9f0e9110c07",
            "title": "Offline Experience Replay for Continual Offline Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/9ced2505d3c720a05b490c1a887af9f0e9110c07",
            "venue": "ECAI",
            "year": 2023
        },
        {
            "arxivId": "2305.13937",
            "authors": [
                {
                    "authorId": "49785134",
                    "name": "Lei Yuan"
                },
                {
                    "authorId": "2216719801",
                    "name": "Lihe Li"
                },
                {
                    "authorId": "2188107173",
                    "name": "Ziqian Zhang"
                },
                {
                    "authorId": "2166590799",
                    "name": "Fuxiang Zhang"
                },
                {
                    "authorId": "2174870366",
                    "name": "Cong Guan"
                },
                {
                    "authorId": "2152850415",
                    "name": "Yang Yu"
                }
            ],
            "doi": "10.48550/arXiv.2305.13937",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "00e730f1a001c200cd93883e1cbeb0337c11faee",
            "title": "Multi-agent Continual Coordination via Progressive Task Contextualization",
            "url": "https://www.semanticscholar.org/paper/00e730f1a001c200cd93883e1cbeb0337c11faee",
            "venue": "IEEE transactions on neural networks and learning systems",
            "year": 2023
        },
        {
            "arxivId": "2303.08115",
            "authors": [
                {
                    "authorId": "116261591",
                    "name": "Ali Beikmohammadi"
                },
                {
                    "authorId": "31783616",
                    "name": "S. Magn\u00fasson"
                }
            ],
            "doi": "10.48550/arXiv.2303.08115",
            "intent": [
                "background",
                "methodology"
            ],
            "isInfluential": true,
            "paperId": "66fb5b32220041ab54c39afa38ea199b2cfb1c66",
            "title": "Human-Inspired Framework to Accelerate Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/66fb5b32220041ab54c39afa38ea199b2cfb1c66",
            "venue": "ArXiv",
            "year": 2023
        },
        {
            "arxivId": "2301.04268",
            "authors": [
                {
                    "authorId": "152749916",
                    "name": "Quan Nguyen"
                },
                {
                    "authorId": "144447714",
                    "name": "Nishant A. Mehta"
                }
            ],
            "doi": "10.48550/arXiv.2301.04268",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "1542e0e17aa09a0d8979cfde11c4130307c17736",
            "title": "Adversarial Online Multi-Task Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/1542e0e17aa09a0d8979cfde11c4130307c17736",
            "venue": "ALT",
            "year": 2023
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "3176996",
                    "name": "Qiming Fu"
                },
                {
                    "authorId": "2196482524",
                    "name": "Zhechao Wang"
                },
                {
                    "authorId": "2150506091",
                    "name": "Nengwei Fang"
                },
                {
                    "authorId": "2174759759",
                    "name": "Bin Xing"
                },
                {
                    "authorId": "2115479122",
                    "name": "Xiao Zhang"
                },
                {
                    "authorId": "123878427",
                    "name": "Jianping Chen"
                }
            ],
            "doi": "10.1007/s11704-022-2037-1",
            "intent": [],
            "isInfluential": false,
            "paperId": "1647c41b322e6aba9323793c49699438d2251e3a",
            "title": "MAML2: meta reinforcement learning via meta-learning for task categories",
            "url": "https://www.semanticscholar.org/paper/1647c41b322e6aba9323793c49699438d2251e3a",
            "venue": "Frontiers Comput. Sci.",
            "year": 2022
        },
        {
            "arxivId": "2210.10469",
            "authors": [
                {
                    "authorId": "2152644271",
                    "name": "Chengqian Gao"
                },
                {
                    "authorId": "36303818",
                    "name": "Kelvin Xu"
                },
                {
                    "authorId": "2149366820",
                    "name": "Liu Liu"
                },
                {
                    "authorId": "2055648566",
                    "name": "Deheng Ye"
                },
                {
                    "authorId": "144259957",
                    "name": "P. Zhao"
                },
                {
                    "authorId": "2181566947",
                    "name": "Zhiqiang Xu"
                }
            ],
            "doi": "10.48550/arXiv.2210.10469",
            "intent": [],
            "isInfluential": false,
            "paperId": "168a5a913352dc1376401cfb758f99637256470f",
            "title": "Robust Offline Reinforcement Learning with Gradient Penalty and Constraint Relaxation",
            "url": "https://www.semanticscholar.org/paper/168a5a913352dc1376401cfb758f99637256470f",
            "venue": "ArXiv",
            "year": 2022
        },
        {
            "arxivId": "2206.12493",
            "authors": [
                {
                    "authorId": "1808903",
                    "name": "Shivam Goel"
                },
                {
                    "authorId": "66483933",
                    "name": "Yash Shukla"
                },
                {
                    "authorId": "3379438",
                    "name": "Vasanth Sarathy"
                },
                {
                    "authorId": "121848090",
                    "name": "matthias. scheutz"
                },
                {
                    "authorId": "1715858",
                    "name": "Jivko Sinapov"
                }
            ],
            "doi": "10.1109/ICDL53763.2022.9962230",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "09273f03215a2d6405f17deec1983748502c56fc",
            "title": "RAPid-Learn: A Framework for Learning to Recover for Handling Novelties in Open-World Environments.",
            "url": "https://www.semanticscholar.org/paper/09273f03215a2d6405f17deec1983748502c56fc",
            "venue": "2022 IEEE International Conference on Development and Learning (ICDL)",
            "year": 2022
        },
        {
            "arxivId": "2206.00270",
            "authors": [
                {
                    "authorId": "152560308",
                    "name": "Sanae Amani"
                },
                {
                    "authorId": "2155556894",
                    "name": "Lin F. Yang"
                },
                {
                    "authorId": "2109943279",
                    "name": "Ching-An Cheng"
                }
            ],
            "doi": "10.48550/arXiv.2206.00270",
            "intent": [],
            "isInfluential": false,
            "paperId": "054f555d1a414172dfbd60e8bfe71129c2ddf860",
            "title": "Provably Efficient Lifelong Reinforcement Learning with Linear Function Approximation",
            "url": "https://www.semanticscholar.org/paper/054f555d1a414172dfbd60e8bfe71129c2ddf860",
            "venue": "ArXiv",
            "year": 2022
        },
        {
            "arxivId": "2205.14571",
            "authors": [
                {
                    "authorId": "40333747",
                    "name": "Alekh Agarwal"
                },
                {
                    "authorId": "2152602077",
                    "name": "Yuda Song"
                },
                {
                    "authorId": "144426657",
                    "name": "Wen Sun"
                },
                {
                    "authorId": "2148352172",
                    "name": "Kaiwen Wang"
                },
                {
                    "authorId": "50468734",
                    "name": "Mengdi Wang"
                },
                {
                    "authorId": "2108039040",
                    "name": "Xuezhou Zhang"
                }
            ],
            "doi": "10.48550/arXiv.2205.14571",
            "intent": [],
            "isInfluential": false,
            "paperId": "195aa06297b26bf695ff168facd2fc1314136950",
            "title": "Provable Benefits of Representational Transfer in Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/195aa06297b26bf695ff168facd2fc1314136950",
            "venue": "COLT",
            "year": 2022
        },
        {
            "arxivId": "2203.15955",
            "authors": [
                {
                    "authorId": "2113291319",
                    "name": "Han Wang"
                },
                {
                    "authorId": "1388010628",
                    "name": "Erfan Miahi"
                },
                {
                    "authorId": "144542337",
                    "name": "Martha White"
                },
                {
                    "authorId": "40066857",
                    "name": "Marlos C. Machado"
                },
                {
                    "authorId": "2160722469",
                    "name": "Zaheer Abbas"
                },
                {
                    "authorId": "2188358",
                    "name": "Raksha Kumaraswamy"
                },
                {
                    "authorId": "2059936479",
                    "name": "Vincent Liu"
                },
                {
                    "authorId": "145240145",
                    "name": "Adam White"
                }
            ],
            "doi": "10.48550/arXiv.2203.15955",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "5460282826b62e267aa496cc9c578b489b4f55f9",
            "title": "Investigating the Properties of Neural Network Representations in Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/5460282826b62e267aa496cc9c578b489b4f55f9",
            "venue": "Artif. Intell.",
            "year": 2022
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "34970419",
                    "name": "E. Morales"
                },
                {
                    "authorId": "1399074465",
                    "name": "Rafael Murrieta-Cid"
                },
                {
                    "authorId": "145830385",
                    "name": "Israel Becerra"
                },
                {
                    "authorId": "2141098817",
                    "name": "Marco A. Esquivel-Basaldua"
                }
            ],
            "doi": "10.1007/s11370-021-00398-z",
            "intent": [
                "background"
            ],
            "isInfluential": true,
            "paperId": "7d541b023e6feb8aee059744b87e78c1d23cd160",
            "title": "A survey on deep learning and deep reinforcement learning in robotics with a tutorial on deep reinforcement learning",
            "url": "https://www.semanticscholar.org/paper/7d541b023e6feb8aee059744b87e78c1d23cd160",
            "venue": "Intelligent Service Robotics",
            "year": 2021
        },
        {
            "arxivId": "2110.12276",
            "authors": [
                {
                    "authorId": "34772064",
                    "name": "Omer Gottesman"
                },
                {
                    "authorId": "7981071",
                    "name": "Kavosh Asadi"
                },
                {
                    "authorId": "46781095",
                    "name": "Cameron S. Allen"
                },
                {
                    "authorId": "148084317",
                    "name": "Sam Lobel"
                },
                {
                    "authorId": "1765407",
                    "name": "G. Konidaris"
                },
                {
                    "authorId": "2056611060",
                    "name": "Michael S. Littman"
                }
            ],
            "doi": null,
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "c3966ade2d5345b4503a9acd17cf28efe34cdb09",
            "title": "Coarse-Grained Smoothness for RL in Metric Spaces",
            "url": "https://www.semanticscholar.org/paper/c3966ade2d5345b4503a9acd17cf28efe34cdb09",
            "venue": "ArXiv",
            "year": 2021
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "1762522",
                    "name": "Xianchao Zhu"
                },
                {
                    "authorId": "2109025908",
                    "name": "Tianyi Huang"
                },
                {
                    "authorId": "2328020117",
                    "name": "Ruiyuan Zhang"
                },
                {
                    "authorId": "145517018",
                    "name": "William Zhu"
                }
            ],
            "doi": "10.1007/s10489-021-02787-4",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "a6961a96ada0f00aae3f48f446f708c035c3a8c2",
            "title": "WDIBS: Wasserstein deterministic information bottleneck for state abstraction to balance state-compression and performance",
            "url": "https://www.semanticscholar.org/paper/a6961a96ada0f00aae3f48f446f708c035c3a8c2",
            "venue": "Applied Intelligence",
            "year": 2021
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "144376484",
                    "name": "Sergio A. Serrano"
                }
            ],
            "doi": "10.24963/ijcai.2021/689",
            "intent": [
                "background",
                "methodology"
            ],
            "isInfluential": true,
            "paperId": "fff0c08a5269842be55b614a5593237ff1812be8",
            "title": "Inter-Task Similarity for Lifelong Reinforcement Learning in Heterogeneous Tasks",
            "url": "https://www.semanticscholar.org/paper/fff0c08a5269842be55b614a5593237ff1812be8",
            "venue": "IJCAI",
            "year": 2021
        },
        {
            "arxivId": "2103.06257",
            "authors": [
                {
                    "authorId": "8140754",
                    "name": "Benjamin Eysenbach"
                },
                {
                    "authorId": "1736651",
                    "name": "S. Levine"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": true,
            "paperId": "b284afe9a7363b898661c9b3cfb7f015b158cc63",
            "title": "Maximum Entropy RL (Provably) Solves Some Robust RL Problems",
            "url": "https://www.semanticscholar.org/paper/b284afe9a7363b898661c9b3cfb7f015b158cc63",
            "venue": "ICLR",
            "year": 2021
        },
        {
            "arxivId": "2010.12645",
            "authors": [
                {
                    "authorId": "2232505",
                    "name": "Yash Chandak"
                },
                {
                    "authorId": "143900003",
                    "name": "Scott M. Jordan"
                },
                {
                    "authorId": "1709005",
                    "name": "Georgios Theocharous"
                },
                {
                    "authorId": "144542337",
                    "name": "Martha White"
                },
                {
                    "authorId": "143640165",
                    "name": "P. Thomas"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "919bb7e60833cc845e236f575f9b4c82ce569c81",
            "title": "Towards Safe Policy Improvement for Non-Stationary MDPs",
            "url": "https://www.semanticscholar.org/paper/919bb7e60833cc845e236f575f9b4c82ce569c81",
            "venue": "NeurIPS",
            "year": 2020
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "3468413",
                    "name": "Kangru Wang"
                },
                {
                    "authorId": "2152513042",
                    "name": "Lei Wang"
                },
                {
                    "authorId": "2118044519",
                    "name": "Xiaolin Zhang"
                },
                {
                    "authorId": "23637713",
                    "name": "Jiamao Li"
                }
            ],
            "doi": "10.1109/LSP.2024.3409213",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "638ea093f9883cc4fd581eab055bbacbc904ad91",
            "title": "Continual Multiview Spectral Clustering via Multilevel Knowledge",
            "url": "https://www.semanticscholar.org/paper/638ea093f9883cc4fd581eab055bbacbc904ad91",
            "venue": "IEEE Signal Processing Letters",
            "year": 2024
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "34772064",
                    "name": "Omer Gottesman"
                },
                {
                    "authorId": "7981071",
                    "name": "Kavosh Asadi"
                },
                {
                    "authorId": "46781095",
                    "name": "Cameron S. Allen"
                },
                {
                    "authorId": "148084317",
                    "name": "Sam Lobel"
                },
                {
                    "authorId": "1765407",
                    "name": "G. Konidaris"
                },
                {
                    "authorId": "2056611060",
                    "name": "Michael S. Littman"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "dff6c3efd37f02096041b55691bfce6ee411e4df",
            "title": "Coarse-Grained Smoothness for Reinforcement Learning in Metric Spaces",
            "url": "https://www.semanticscholar.org/paper/dff6c3efd37f02096041b55691bfce6ee411e4df",
            "venue": "AISTATS",
            "year": 2023
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "116261591",
                    "name": "Ali Beikmohammadi"
                },
                {
                    "authorId": "31783616",
                    "name": "S. Magn\u00fasson"
                }
            ],
            "doi": "10.5555/3545946.3598951",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "9c9a527ad885e664a31f0b70ec5f838d0c6ebfa6",
            "title": "TA-Explore: Teacher-Assisted Exploration for Facilitating Fast Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/9c9a527ad885e664a31f0b70ec5f838d0c6ebfa6",
            "venue": "AAMAS",
            "year": 2023
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2221240969",
                    "name": "Pierrick Lorang"
                },
                {
                    "authorId": "1808903",
                    "name": "Shivam Goel"
                },
                {
                    "authorId": "2296020466",
                    "name": "Patrik Zips"
                },
                {
                    "authorId": "1715858",
                    "name": "Jivko Sinapov"
                },
                {
                    "authorId": "121848090",
                    "name": "matthias. scheutz"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "b59d4d86b432f8c91327f3246042420fe312e0c9",
            "title": "Speeding-up Continual Learning through Information Gains in Novel Experiences",
            "url": "https://www.semanticscholar.org/paper/b59d4d86b432f8c91327f3246042420fe312e0c9",
            "venue": "",
            "year": 2022
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "1391377556",
                    "name": "Mark W. Nemecek"
                },
                {
                    "authorId": "40191597",
                    "name": "R. Parr"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "bf882d67f4a2900b16faf9d6802e25d4620effae",
            "title": "Policy Caches with Successor Features",
            "url": "https://www.semanticscholar.org/paper/bf882d67f4a2900b16faf9d6802e25d4620effae",
            "venue": "ICML",
            "year": 2021
        }
    ],
    "corpusId": 210700598,
    "doi": "10.1609/aaai.v35i9.17006",
    "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
    ],
    "influentialCitationCount": 4,
    "isOpenAccess": true,
    "isPublisherLicensed": true,
    "is_open_access": true,
    "is_publisher_licensed": true,
    "numCitedBy": 33,
    "numCiting": 32,
    "paperId": "207c7b8ea8f94463383a089e4f7f24b64503f9c0",
    "references": [
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2325898125",
                    "name": "Kevin J. Hastings"
                }
            ],
            "doi": "10.1201/9781315275987-6",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "281074804c8c01d1eef495182a977a1066b4c8f8",
            "title": "Dynamic Programming",
            "url": "https://www.semanticscholar.org/paper/281074804c8c01d1eef495182a977a1066b4c8f8",
            "venue": "Introduction to the Mathematics of Operations Research with Mathematica\u00ae",
            "year": 2018
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "152422014",
                    "name": "David Abel"
                },
                {
                    "authorId": "3387240",
                    "name": "Yuu Jinnai"
                },
                {
                    "authorId": "1390575736",
                    "name": "Yue (Sophie) Guo"
                },
                {
                    "authorId": "1765407",
                    "name": "G. Konidaris"
                },
                {
                    "authorId": "144885169",
                    "name": "M. Littman"
                }
            ],
            "doi": null,
            "intent": [
                "background",
                "methodology"
            ],
            "isInfluential": true,
            "paperId": "12fcadd19ca4652934997ac537b071a4b6b221d2",
            "title": "Policy and Value Transfer in Lifelong Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/12fcadd19ca4652934997ac537b071a4b6b221d2",
            "venue": "ICML",
            "year": 2018
        },
        {
            "arxivId": "1804.07193",
            "authors": [
                {
                    "authorId": "7981071",
                    "name": "Kavosh Asadi"
                },
                {
                    "authorId": "31498163",
                    "name": "Dipendra Kumar Misra"
                },
                {
                    "authorId": "144885169",
                    "name": "M. Littman"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "c4f529934b6f22aa38e014e295a9737daa6e7db5",
            "title": "Lipschitz Continuity in Model-based Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/c4f529934b6f22aa38e014e295a9737daa6e7db5",
            "venue": "ICML",
            "year": 2018
        },
        {
            "arxivId": "1703.07710",
            "authors": [
                {
                    "authorId": "2160071",
                    "name": "Christoph Dann"
                },
                {
                    "authorId": "2989692",
                    "name": "Tor Lattimore"
                },
                {
                    "authorId": "2563117",
                    "name": "E. Brunskill"
                }
            ],
            "doi": null,
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "5dcc07acb63cc909c5be701c1c88fef3718ba326",
            "title": "Unifying PAC and Regret: Uniform PAC Bounds for Episodic Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/5dcc07acb63cc909c5be701c1c88fef3718ba326",
            "venue": "NIPS",
            "year": 2017
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2112622925",
                    "name": "Jinhua Song"
                },
                {
                    "authorId": "145644819",
                    "name": "Yang Gao"
                },
                {
                    "authorId": "46506174",
                    "name": "Hao Wang"
                },
                {
                    "authorId": "143706345",
                    "name": "Bo An"
                }
            ],
            "doi": null,
            "intent": [
                "background",
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "84d9cf32975989a48931e651df13af6d1b7857ca",
            "title": "Measuring the Distance Between Finite Markov Decision Processes",
            "url": "https://www.semanticscholar.org/paper/84d9cf32975989a48931e651df13af6d1b7857ca",
            "venue": "AAMAS",
            "year": 2016
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "6234609",
                    "name": "Matteo Pirotta"
                },
                {
                    "authorId": "1792167",
                    "name": "Marcello Restelli"
                },
                {
                    "authorId": "1944485",
                    "name": "L. Bascetta"
                }
            ],
            "doi": "10.1007/s10994-015-5484-1",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "372e760481b2c02b025c9fce151fb1c565ccb36f",
            "title": "Policy gradient in Lipschitz Markov Decision Processes",
            "url": "https://www.semanticscholar.org/paper/372e760481b2c02b025c9fce151fb1c565ccb36f",
            "venue": "Machine Learning",
            "year": 2015
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2563117",
                    "name": "E. Brunskill"
                },
                {
                    "authorId": "47681372",
                    "name": "Lihong Li"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "d163ae2ae7ee2b7991ab017113f13f54fc5c8c5f",
            "title": "PAC-inspired Option Discovery in Lifelong Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/d163ae2ae7ee2b7991ab017113f13f54fc5c8c5f",
            "venue": "ICML",
            "year": 2014
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "46257744",
                    "name": "H. Ammar"
                },
                {
                    "authorId": "144020269",
                    "name": "Eric Eaton"
                },
                {
                    "authorId": "39286677",
                    "name": "Matthew E. Taylor"
                },
                {
                    "authorId": "2571038",
                    "name": "D. Mocanu"
                },
                {
                    "authorId": "1695114",
                    "name": "K. Driessens"
                },
                {
                    "authorId": "144799183",
                    "name": "Gerhard Weiss"
                },
                {
                    "authorId": "2274623",
                    "name": "K. Tuyls"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "fa56ea61131a42afd1b2413c3d39576092b678db",
            "title": "An automated measure of MDP similarity for transfer in reinforcement learning",
            "url": "https://www.semanticscholar.org/paper/fa56ea61131a42afd1b2413c3d39576092b678db",
            "venue": "AAAI 2014",
            "year": 2014
        },
        {
            "arxivId": "1311.3959",
            "authors": [
                {
                    "authorId": "144774720",
                    "name": "M. H. Mahmud"
                },
                {
                    "authorId": "2762811",
                    "name": "Majd Hawasly"
                },
                {
                    "authorId": "2831294",
                    "name": "Benjamin Rosman"
                },
                {
                    "authorId": "144826759",
                    "name": "S. Ramamoorthy"
                }
            ],
            "doi": null,
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "0f85103cece38d1085f58ec5d20ab7583459a5d4",
            "title": "Clustering Markov Decision Processes For Continual Transfer",
            "url": "https://www.semanticscholar.org/paper/0f85103cece38d1085f58ec5d20ab7583459a5d4",
            "venue": "ArXiv",
            "year": 2013
        },
        {
            "arxivId": "1309.6821",
            "authors": [
                {
                    "authorId": "2563117",
                    "name": "E. Brunskill"
                },
                {
                    "authorId": "47681372",
                    "name": "Lihong Li"
                }
            ],
            "doi": null,
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "a05da3a9fee38d2c81216bf5b24ba50c84f7d9bc",
            "title": "Sample Complexity of Multi-task Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/a05da3a9fee38d2c81216bf5b24ba50c84f7d9bc",
            "venue": "UAI",
            "year": 2013
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "49601276",
                    "name": "D. Silver"
                },
                {
                    "authorId": "152290618",
                    "name": "Qiang Yang"
                },
                {
                    "authorId": "2048948347",
                    "name": "Lianghao Li"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "5776d0fea69d826519ee3649f620e8755a490efe",
            "title": "Lifelong Machine Learning Systems: Beyond Learning Algorithms",
            "url": "https://www.semanticscholar.org/paper/5776d0fea69d826519ee3649f620e8755a490efe",
            "venue": "AAAI Spring Symposium: Lifelong Machine Learning",
            "year": 2013
        },
        {
            "arxivId": "1207.4708",
            "authors": [
                {
                    "authorId": "1792298",
                    "name": "Marc G. Bellemare"
                },
                {
                    "authorId": "2294249",
                    "name": "Yavar Naddaf"
                },
                {
                    "authorId": "144056327",
                    "name": "J. Veness"
                },
                {
                    "authorId": "1687780",
                    "name": "Michael Bowling"
                }
            ],
            "doi": "10.1613/jair.3912",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "f82e4ff4f003581330338aaae71f60316e58dd26",
            "title": "The Arcade Learning Environment: An Evaluation Platform for General Agents",
            "url": "https://www.semanticscholar.org/paper/f82e4ff4f003581330338aaae71f60316e58dd26",
            "venue": "J. Artif. Intell. Res.",
            "year": 2012
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "144439416",
                    "name": "Karun K. Rao"
                },
                {
                    "authorId": "1766767",
                    "name": "Shimon Whiteson"
                }
            ],
            "doi": null,
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "dad5393b1d68d6ec793383757b580bb6cc8d4ac0",
            "title": "V-MAX: tempered optimism for better PAC reinforcement learning",
            "url": "https://www.semanticscholar.org/paper/dad5393b1d68d6ec793383757b580bb6cc8d4ac0",
            "venue": "AAMAS",
            "year": 2012
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "1742557",
                    "name": "I. Szita"
                },
                {
                    "authorId": "40868287",
                    "name": "Csaba Szepesvari"
                }
            ],
            "doi": null,
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "75c827ed14c8794b6babf05b944751877e7d2b77",
            "title": "Model-based reinforcement learning with nearly tight exploration complexity bounds",
            "url": "https://www.semanticscholar.org/paper/75c827ed14c8794b6babf05b944751877e7d2b77",
            "venue": "ICML",
            "year": 2010
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "1990806",
                    "name": "Alexander L. Strehl"
                },
                {
                    "authorId": "47681372",
                    "name": "Lihong Li"
                },
                {
                    "authorId": "144885169",
                    "name": "M. Littman"
                }
            ],
            "doi": "10.5555/1577069.1755867",
            "intent": [
                "background",
                "methodology"
            ],
            "isInfluential": true,
            "paperId": "5d8e1eeeb0e4b0e0846a355532d0f9452249e68a",
            "title": "Reinforcement Learning in Finite MDPs: PAC Analysis",
            "url": "https://www.semanticscholar.org/paper/5d8e1eeeb0e4b0e0846a355532d0f9452249e68a",
            "venue": "J. Mach. Learn. Res.",
            "year": 2009
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "39286677",
                    "name": "Matthew E. Taylor"
                },
                {
                    "authorId": "144848112",
                    "name": "P. Stone"
                }
            ],
            "doi": "10.5555/1577069.1755839",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "467568f1777bc51a15a5100516cd4fe8de62b9ab",
            "title": "Transfer Learning for Reinforcement Learning Domains: A Survey",
            "url": "https://www.semanticscholar.org/paper/467568f1777bc51a15a5100516cd4fe8de62b9ab",
            "venue": "J. Mach. Learn. Res.",
            "year": 2009
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "144123639",
                    "name": "Jonathan Sorg"
                },
                {
                    "authorId": "1699868",
                    "name": "Satinder Singh"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "33c86d187209cf39fc4a2233523b1b84d86ffa26",
            "title": "Transfer via soft homomorphisms",
            "url": "https://www.semanticscholar.org/paper/33c86d187209cf39fc4a2233523b1b84d86ffa26",
            "venue": "AAMAS",
            "year": 2009
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "16614521",
                    "name": "C. Villani"
                }
            ],
            "doi": "10.1007/978-3-540-71050-9",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "7f05b312f2de7e59c7869558507fa4a9fa0d0971",
            "title": "Optimal Transport: Old and New",
            "url": "https://www.semanticscholar.org/paper/7f05b312f2de7e59c7869558507fa4a9fa0d0971",
            "venue": "",
            "year": 2008
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "3254390",
                    "name": "A. Lazaric"
                },
                {
                    "authorId": "1792167",
                    "name": "Marcello Restelli"
                },
                {
                    "authorId": "1729320",
                    "name": "Andrea Bonarini"
                }
            ],
            "doi": "10.1145/1390156.1390225",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "117d0903a0dc0d78aacc8cbc84e6cd86f4530ef2",
            "title": "Transfer of samples in batch reinforcement learning",
            "url": "https://www.semanticscholar.org/paper/117d0903a0dc0d78aacc8cbc84e6cd86f4530ef2",
            "venue": "ICML '08",
            "year": 2008
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "144056302",
                    "name": "Aaron Wilson"
                },
                {
                    "authorId": "145841336",
                    "name": "Alan Fern"
                },
                {
                    "authorId": "145527877",
                    "name": "Soumya Ray"
                },
                {
                    "authorId": "1729906",
                    "name": "Prasad Tadepalli"
                }
            ],
            "doi": "10.1145/1273496.1273624",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "638ab3eb4723add266e484f8f792cd6e14ce5e3e",
            "title": "Multi-task reinforcement learning: a hierarchical Bayesian approach",
            "url": "https://www.semanticscholar.org/paper/638ab3eb4723add266e484f8f792cd6e14ce5e3e",
            "venue": "ICML '07",
            "year": 2007
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "1783425",
                    "name": "J. Carroll"
                },
                {
                    "authorId": "31819161",
                    "name": "Kevin Seppi"
                }
            ],
            "doi": "10.1109/IJCNN.2005.1555955",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "b44a5e11ea81a3aeca01ebbc5919b51074997b88",
            "title": "Task similarity measures for transfer in reinforcement learning task libraries",
            "url": "https://www.semanticscholar.org/paper/b44a5e11ea81a3aeca01ebbc5919b51074997b88",
            "venue": "Proceedings. 2005 IEEE International Joint Conference on Neural Networks, 2005.",
            "year": 2005
        },
        {
            "arxivId": "1207.4114",
            "authors": [
                {
                    "authorId": "1757489",
                    "name": "N. Ferns"
                },
                {
                    "authorId": "1784317",
                    "name": "P. Panangaden"
                },
                {
                    "authorId": "144368601",
                    "name": "Doina Precup"
                }
            ],
            "doi": null,
            "intent": [
                "background",
                "methodology"
            ],
            "isInfluential": true,
            "paperId": "2c85356cd182c16e0a2e5c4a97112efbc1132cdf",
            "title": "Metrics for Finite Markov Decision Processes",
            "url": "https://www.semanticscholar.org/paper/2c85356cd182c16e0a2e5c4a97112efbc1132cdf",
            "venue": "AAAI",
            "year": 2004
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "37814588",
                    "name": "M. Puterman"
                }
            ],
            "doi": "10.2307/2291177",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "a9cd8efe9184dddb1bedbbec3a356c4dfb22fe63",
            "title": "Markov Decision Processes: Discrete Stochastic Dynamic Programming",
            "url": "https://www.semanticscholar.org/paper/a9cd8efe9184dddb1bedbbec3a356c4dfb22fe63",
            "venue": "",
            "year": 1994
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "145290695",
                    "name": "C. Watkins"
                },
                {
                    "authorId": "1790646",
                    "name": "P. Dayan"
                }
            ],
            "doi": "10.1007/BF00992698",
            "intent": [],
            "isInfluential": false,
            "paperId": "03b7e51c52084ac1db5118342a00b5fbcfc587aa",
            "title": "Q-learning",
            "url": "https://www.semanticscholar.org/paper/03b7e51c52084ac1db5118342a00b5fbcfc587aa",
            "venue": "Machine Learning",
            "year": 1992
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "47106318",
                    "name": "J. Neyman"
                }
            ],
            "doi": "10.1098/RSTA.1937.0005",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "b0a843ee1cd0d15086b1b6ec45e2f38d73e63b36",
            "title": "Outline of a Theory of Statistical Estimation Based on the Classical Theory of Probability",
            "url": "https://www.semanticscholar.org/paper/b0a843ee1cd0d15086b1b6ec45e2f38d73e63b36",
            "venue": "",
            "year": 1937
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "3140253",
                    "name": "Jason Pazis"
                },
                {
                    "authorId": "145726861",
                    "name": "Ronald E. Parr"
                },
                {
                    "authorId": "1713935",
                    "name": "J. How"
                }
            ],
            "doi": null,
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "38c96f8e8432b4ad029b078d27d315313f75d5f0",
            "title": "Improving PAC Exploration Using the Median Of Means",
            "url": "https://www.semanticscholar.org/paper/38c96f8e8432b4ad029b078d27d315313f75d5f0",
            "venue": "NIPS",
            "year": 2016
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "3254390",
                    "name": "A. Lazaric"
                }
            ],
            "doi": "10.1007/978-3-642-27645-3_5",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "16c97a8a29b0d63fdb119daefabc47df92ff6c24",
            "title": "Transfer in Reinforcement Learning: A Framework and a Survey",
            "url": "https://www.semanticscholar.org/paper/16c97a8a29b0d63fdb119daefabc47df92ff6c24",
            "venue": "Reinforcement Learning",
            "year": 2012
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2558054",
                    "name": "E. Rachelson"
                },
                {
                    "authorId": "1784072",
                    "name": "M. Lagoudakis"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "9ec3e62212a0b9037e0a3d0f4702582a39f43575",
            "title": "On the locality of action domination in sequential decision making",
            "url": "https://www.semanticscholar.org/paper/9ec3e62212a0b9037e0a3d0f4702582a39f43575",
            "venue": "ISAIM",
            "year": 2010
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "1680506",
                    "name": "R. Brafman"
                },
                {
                    "authorId": "1708847",
                    "name": "Moshe Tennenholtz"
                }
            ],
            "doi": null,
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "c7dbf5ed7e9b63e104adb4e18bfbc98f5d6afdae",
            "title": "R-MAX - A General Polynomial Time Algorithm for Near-Optimal Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/c7dbf5ed7e9b63e104adb4e18bfbc98f5d6afdae",
            "venue": "J. Mach. Learn. Res.",
            "year": 2001
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2238176724",
                    "name": "R. S. Sutton"
                },
                {
                    "authorId": "1730590",
                    "name": "A. Barto"
                }
            ],
            "doi": "10.1109/TNN.1998.712192",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "97efafdb4a3942ab3efba53ded7413199f79c054",
            "title": "Reinforcement Learning: An Introduction",
            "url": "https://www.semanticscholar.org/paper/97efafdb4a3942ab3efba53ded7413199f79c054",
            "venue": "IEEE Trans. Neural Networks",
            "year": 1998
        }
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Mathematics",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "title": "Lipschitz Lifelong Reinforcement Learning",
    "topics": [],
    "url": "https://www.semanticscholar.org/paper/207c7b8ea8f94463383a089e4f7f24b64503f9c0",
    "venue": "AAAI Conference on Artificial Intelligence",
    "year": 2020
}
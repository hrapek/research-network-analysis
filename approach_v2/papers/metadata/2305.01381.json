{
    "abstract": "Linear Temporal Logic (LTL) is widely used to specify high-level objectives for system policies, and it is highly desirable for autonomous systems to learn the optimal policy with respect to such specifications. However, learning the optimal policy from LTL specifications is not trivial. We present a model-free Reinforcement Learning (RL) approach that efficiently learns an optimal policy for an unknown stochastic system, modelled using Markov Decision Processes (MDPs). We propose a novel and more general product MDP, reward structure and discounting mechanism that, when applied in conjunction with off-the-shelf model-free RL algorithms, efficiently learn the optimal policy that maximizes the probability of satisfying a given LTL specification with optimality guarantees. We also provide improved theoretical results on choosing the key parameters in RL to ensure optimality. To directly evaluate the learned policy, we adopt probabilistic model checker PRISM to compute the probability of the policy satisfying such specifications. Several experiments on various tabular MDP environments across different LTL tasks demonstrate the improved sample efficiency and optimal policy convergence.",
    "arxivId": "2305.01381",
    "authors": [
        {
            "authorId": "2215864601",
            "name": "Daqian Shao",
            "url": "https://www.semanticscholar.org/author/2215864601"
        },
        {
            "authorId": "1701316",
            "name": "M. Kwiatkowska",
            "url": "https://www.semanticscholar.org/author/1701316"
        }
    ],
    "citationVelocity": 0,
    "citations": [
        {
            "arxivId": "2408.09495",
            "authors": [
                {
                    "authorId": "2131957731",
                    "name": "Marco Bagatella"
                },
                {
                    "authorId": "2286302105",
                    "name": "Andreas Krause"
                },
                {
                    "authorId": "144247521",
                    "name": "G. Martius"
                }
            ],
            "doi": "10.48550/arXiv.2408.09495",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "46b6a615baf77306611f77ecf6dfe35d611eab59",
            "title": "Directed Exploration in Reinforcement Learning from Linear Temporal Logic",
            "url": "https://www.semanticscholar.org/paper/46b6a615baf77306611f77ecf6dfe35d611eab59",
            "venue": "ArXiv",
            "year": 2024
        },
        {
            "arxivId": "2408.05438",
            "authors": [
                {
                    "authorId": "2295670811",
                    "name": "Zetong Xuan"
                },
                {
                    "authorId": "2296049944",
                    "name": "Yu Wang"
                }
            ],
            "doi": null,
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "6f2edc771bbc9fb0dba93af3b9d18fedee902495",
            "title": "Convergence Guarantee of Dynamic Programming for LTL Surrogate Reward",
            "url": "https://www.semanticscholar.org/paper/6f2edc771bbc9fb0dba93af3b9d18fedee902495",
            "venue": "",
            "year": 2024
        },
        {
            "arxivId": "2408.01923",
            "authors": [
                {
                    "authorId": "2314903772",
                    "name": "Yiting He"
                },
                {
                    "authorId": "2314968936",
                    "name": "Peiran Liu"
                },
                {
                    "authorId": "2315071849",
                    "name": "Yiding Ji"
                }
            ],
            "doi": "10.48550/arXiv.2408.01923",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "6374becbbad65580ddb12c29ecfd6a512ce8d8d9",
            "title": "Scalable Signal Temporal Logic Guided Reinforcement Learning via Value Function Space Optimization",
            "url": "https://www.semanticscholar.org/paper/6374becbbad65580ddb12c29ecfd6a512ce8d8d9",
            "venue": "ArXiv",
            "year": 2024
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "49444240",
                    "name": "M. Kwiatkowska"
                }
            ],
            "doi": null,
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "11cca3968b569ef58bcf8ec4b5716e681e140e90",
            "title": "Robust Decision Pipelines: Opportunities and Challenges for AI in Business Process Modelling \u22c6",
            "url": "https://www.semanticscholar.org/paper/11cca3968b569ef58bcf8ec4b5716e681e140e90",
            "venue": "",
            "year": 2023
        }
    ],
    "corpusId": 258436969,
    "doi": "10.48550/arXiv.2305.01381",
    "fieldsOfStudy": [
        "Computer Science"
    ],
    "influentialCitationCount": 0,
    "isOpenAccess": true,
    "isPublisherLicensed": true,
    "is_open_access": true,
    "is_publisher_licensed": true,
    "numCitedBy": 4,
    "numCiting": 46,
    "paperId": "b3747f920d5bbca7bcb6ae41bfe90cb3c03fd7b3",
    "references": [
        {
            "arxivId": "2111.00272",
            "authors": [
                {
                    "authorId": "1710176",
                    "name": "R. Alur"
                },
                {
                    "authorId": "40917740",
                    "name": "Suguman Bansal"
                },
                {
                    "authorId": "1697444",
                    "name": "O. Bastani"
                },
                {
                    "authorId": "2075278726",
                    "name": "Kishor Jothimurugan"
                }
            ],
            "doi": "10.1007/978-3-031-22337-2_29",
            "intent": [
                "background",
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "c7d6e5351bfa6a2dc94f0bb6e98972509616c17f",
            "title": "A Framework for Transforming Specifications in Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/c7d6e5351bfa6a2dc94f0bb6e98972509616c17f",
            "venue": "Principles of Systems Design",
            "year": 2021
        },
        {
            "arxivId": "2106.13906",
            "authors": [
                {
                    "authorId": "2075278726",
                    "name": "Kishor Jothimurugan"
                },
                {
                    "authorId": "40917740",
                    "name": "Suguman Bansal"
                },
                {
                    "authorId": "1697444",
                    "name": "O. Bastani"
                },
                {
                    "authorId": "1710176",
                    "name": "R. Alur"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "ce7e0c1e5f22fa80fbeba7792c1323180a99359f",
            "title": "Compositional Reinforcement Learning from Logical Specifications",
            "url": "https://www.semanticscholar.org/paper/ce7e0c1e5f22fa80fbeba7792c1323180a99359f",
            "venue": "NeurIPS",
            "year": 2021
        },
        {
            "arxivId": "2102.12855",
            "authors": [
                {
                    "authorId": "1825246897",
                    "name": "Mingyu Cai"
                },
                {
                    "authorId": "35302287",
                    "name": "Mohammadhosein Hasanbeig"
                },
                {
                    "authorId": "152897566",
                    "name": "Shaoping Xiao"
                },
                {
                    "authorId": "144938187",
                    "name": "A. Abate"
                },
                {
                    "authorId": "2025727",
                    "name": "Z. Kan"
                }
            ],
            "doi": "10.1109/LRA.2021.3101544",
            "intent": [],
            "isInfluential": false,
            "paperId": "c7fb785b402b20072d0f7a09bab8014409fefbe7",
            "title": "Modular Deep Reinforcement Learning for Continuous Motion Planning With Temporal Logic",
            "url": "https://www.semanticscholar.org/paper/c7fb785b402b20072d0f7a09bab8014409fefbe7",
            "venue": "IEEE Robotics and Automation Letters",
            "year": 2021
        },
        {
            "arxivId": "2010.03950",
            "authors": [
                {
                    "authorId": "15316342",
                    "name": "Rodrigo Toro Icarte"
                },
                {
                    "authorId": "1758085",
                    "name": "Toryn Q. Klassen"
                },
                {
                    "authorId": "2682734",
                    "name": "R. Valenzano"
                },
                {
                    "authorId": "1683896",
                    "name": "Sheila A. McIlraith"
                }
            ],
            "doi": "10.1613/jair.1.12440",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "6778d6a0f959cdcc42718ee9fc279fd1f00f3d88",
            "title": "Reward Machines: Exploiting Reward Function Structure in Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/6778d6a0f959cdcc42718ee9fc279fd1f00f3d88",
            "venue": "J. Artif. Intell. Res.",
            "year": 2020
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "35302287",
                    "name": "Mohammadhosein Hasanbeig"
                },
                {
                    "authorId": "145763733",
                    "name": "D. Kroening"
                },
                {
                    "authorId": "144938187",
                    "name": "A. Abate"
                }
            ],
            "doi": "10.1007/978-3-030-57628-8_1",
            "intent": [],
            "isInfluential": false,
            "paperId": "e3450150135b97ad379cc35fe44afde021c37d44",
            "title": "Deep Reinforcement Learning with Temporal Logics",
            "url": "https://www.semanticscholar.org/paper/e3450150135b97ad379cc35fe44afde021c37d44",
            "venue": "FORMATS",
            "year": 2020
        },
        {
            "arxivId": "2008.09293",
            "authors": [
                {
                    "authorId": "1387888844",
                    "name": "Kishor Jothimurugan"
                },
                {
                    "authorId": "1710176",
                    "name": "R. Alur"
                },
                {
                    "authorId": "1697444",
                    "name": "O. Bastani"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "8770280ae538dffe083e87a7093195b1c42d6b73",
            "title": "A Composable Specification Language for Reinforcement Learning Tasks",
            "url": "https://www.semanticscholar.org/paper/8770280ae538dffe083e87a7093195b1c42d6b73",
            "venue": "NeurIPS",
            "year": 2020
        },
        {
            "arxivId": "2007.01498",
            "authors": [
                {
                    "authorId": "48751979",
                    "name": "Yuqian Jiang"
                },
                {
                    "authorId": "22697629",
                    "name": "Suda Bharadwaj"
                },
                {
                    "authorId": "152365289",
                    "name": "Bo Wu"
                },
                {
                    "authorId": "9578995",
                    "name": "Rishi Shah"
                },
                {
                    "authorId": "3199888",
                    "name": "U. Topcu"
                },
                {
                    "authorId": "144848112",
                    "name": "P. Stone"
                }
            ],
            "doi": "10.1609/aaai.v35i9.16975",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "9402e3ebf9f34407144414aea4fc4a753932d4f5",
            "title": "Temporal-Logic-Based Reward Shaping for Continuing Reinforcement Learning Tasks",
            "url": "https://www.semanticscholar.org/paper/9402e3ebf9f34407144414aea4fc4a753932d4f5",
            "venue": "AAAI",
            "year": 2020
        },
        {
            "arxivId": "1909.07299",
            "authors": [
                {
                    "authorId": "144229259",
                    "name": "A. Bozkurt"
                },
                {
                    "authorId": "2153603617",
                    "name": "Yu Wang"
                },
                {
                    "authorId": "1764546",
                    "name": "M. Zavlanos"
                },
                {
                    "authorId": "144628431",
                    "name": "Miroslav Pajic"
                }
            ],
            "doi": "10.1109/ICRA40945.2020.9196796",
            "intent": [],
            "isInfluential": false,
            "paperId": "7c7c36b83556b71221c898aa4e7ea2edabd80314",
            "title": "Control Synthesis from Linear Temporal Logic Specifications using Model-Free Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/7c7c36b83556b71221c898aa4e7ea2edabd80314",
            "venue": "2020 IEEE International Conference on Robotics and Automation (ICRA)",
            "year": 2019
        },
        {
            "arxivId": "1909.05304",
            "authors": [
                {
                    "authorId": "35302287",
                    "name": "Mohammadhosein Hasanbeig"
                },
                {
                    "authorId": "3092871",
                    "name": "Y. Kantaros"
                },
                {
                    "authorId": "144938187",
                    "name": "A. Abate"
                },
                {
                    "authorId": "145763733",
                    "name": "D. Kroening"
                },
                {
                    "authorId": "143770945",
                    "name": "George Pappas"
                },
                {
                    "authorId": "144637634",
                    "name": "Insup Lee"
                }
            ],
            "doi": "10.1109/CDC40024.2019.9028919",
            "intent": [],
            "isInfluential": false,
            "paperId": "3ee06b4f0ed488bbffc84e441cd66372ee5de0e8",
            "title": "Reinforcement Learning for Temporal Logic Control Synthesis with Probabilistic Satisfaction Guarantees",
            "url": "https://www.semanticscholar.org/paper/3ee06b4f0ed488bbffc84e441cd66372ee5de0e8",
            "venue": "2019 IEEE 58th Conference on Decision and Control (CDC)",
            "year": 2019
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "47505744",
                    "name": "Alberto Camacho"
                },
                {
                    "authorId": "15316342",
                    "name": "Rodrigo Toro Icarte"
                },
                {
                    "authorId": "1758085",
                    "name": "Toryn Q. Klassen"
                },
                {
                    "authorId": "2682734",
                    "name": "R. Valenzano"
                },
                {
                    "authorId": "1683896",
                    "name": "Sheila A. McIlraith"
                }
            ],
            "doi": "10.24963/ijcai.2019/840",
            "intent": [],
            "isInfluential": false,
            "paperId": "c3d0e3c5ca9fa56cf2ff7303a2f67bf44694e6d4",
            "title": "LTL and Beyond: Formal Languages for Reward Function Specification in Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/c3d0e3c5ca9fa56cf2ff7303a2f67bf44694e6d4",
            "venue": "IJCAI",
            "year": 2019
        },
        {
            "arxivId": "1909.04256",
            "authors": [
                {
                    "authorId": "50070268",
                    "name": "Zhe Xu"
                },
                {
                    "authorId": "3199888",
                    "name": "U. Topcu"
                }
            ],
            "doi": "10.24963/IJCAI.2019/557",
            "intent": [
                "background",
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "a5c0645162f4b74895b86a98db86df8af680de77",
            "title": "Transfer of Temporal Logic Formulas in Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/a5c0645162f4b74895b86a98db86df8af680de77",
            "venue": "IJCAI",
            "year": 2019
        },
        {
            "arxivId": "1810.00950",
            "authors": [
                {
                    "authorId": "1727062",
                    "name": "E. M. Hahn"
                },
                {
                    "authorId": "145304742",
                    "name": "Mateo Perez"
                },
                {
                    "authorId": "2701127",
                    "name": "S. Schewe"
                },
                {
                    "authorId": "1693050",
                    "name": "F. Somenzi"
                },
                {
                    "authorId": "1781100",
                    "name": "Ashutosh Trivedi"
                },
                {
                    "authorId": "3038359",
                    "name": "D. Wojtczak"
                }
            ],
            "doi": "10.1007/978-3-030-17462-0_27",
            "intent": [],
            "isInfluential": false,
            "paperId": "7dbfb295615534834ab2d7706a7e481afe9be186",
            "title": "Omega-Regular Objectives in Model-Free Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/7dbfb295615534834ab2d7706a7e481afe9be186",
            "venue": "TACAS",
            "year": 2018
        },
        {
            "arxivId": "1807.06333",
            "authors": [
                {
                    "authorId": "1719219",
                    "name": "Giuseppe De Giacomo"
                },
                {
                    "authorId": "1712013",
                    "name": "L. Iocchi"
                },
                {
                    "authorId": "51113841",
                    "name": "Marco Favorito"
                },
                {
                    "authorId": "1698994",
                    "name": "F. Patrizi"
                }
            ],
            "doi": "10.1609/icaps.v29i1.3549",
            "intent": [],
            "isInfluential": false,
            "paperId": "1b6924a5ba6c6efa88ec432b49f2a931afc92871",
            "title": "Foundations for Restraining Bolts: Reinforcement Learning with LTLf/LDLf Restraining Specifications",
            "url": "https://www.semanticscholar.org/paper/1b6924a5ba6c6efa88ec432b49f2a931afc92871",
            "venue": "ICAPS",
            "year": 2018
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2502692",
                    "name": "Jan K\u0159et\u00ednsk\u00fd"
                },
                {
                    "authorId": "8812899",
                    "name": "Tobias Meggendorfer"
                },
                {
                    "authorId": "2657655",
                    "name": "Salomon Sickert"
                },
                {
                    "authorId": "145150347",
                    "name": "Christopher Ziegler"
                }
            ],
            "doi": "10.1007/978-3-319-96145-3_30",
            "intent": [],
            "isInfluential": false,
            "paperId": "914d71c8598df8b911934d44783a4141cf8393b3",
            "title": "Rabinizer 4: From LTL to Your Favourite Deterministic Automaton",
            "url": "https://www.semanticscholar.org/paper/914d71c8598df8b911934d44783a4141cf8393b3",
            "venue": "CAV",
            "year": 2018
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "15316342",
                    "name": "Rodrigo Toro Icarte"
                },
                {
                    "authorId": "1758085",
                    "name": "Toryn Q. Klassen"
                },
                {
                    "authorId": "2682734",
                    "name": "R. Valenzano"
                },
                {
                    "authorId": "1683896",
                    "name": "Sheila A. McIlraith"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "00ec8123dd2ba03afab7c1fa02f774062f769181",
            "title": "Using Reward Machines for High-Level Task Specification and Decomposition in Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/00ec8123dd2ba03afab7c1fa02f774062f769181",
            "venue": "ICML",
            "year": 2018
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "51056119",
                    "name": "Sultan Javed Majeed"
                },
                {
                    "authorId": "144154444",
                    "name": "Marcus Hutter"
                }
            ],
            "doi": "10.24963/ijcai.2018/353",
            "intent": [],
            "isInfluential": false,
            "paperId": "66d76444255be0ac378a0a93ee0379fc721a386f",
            "title": "On Q-learning Convergence for Non-Markov Decision Processes",
            "url": "https://www.semanticscholar.org/paper/66d76444255be0ac378a0a93ee0379fc721a386f",
            "venue": "IJCAI",
            "year": 2018
        },
        {
            "arxivId": "1704.04341",
            "authors": [
                {
                    "authorId": "144885169",
                    "name": "M. Littman"
                },
                {
                    "authorId": "3199888",
                    "name": "U. Topcu"
                },
                {
                    "authorId": "2119313209",
                    "name": "Jie Fu"
                },
                {
                    "authorId": "1787816",
                    "name": "C. Isbell"
                },
                {
                    "authorId": "2055605825",
                    "name": "Min Wen"
                },
                {
                    "authorId": "2700008",
                    "name": "J. MacGlashan"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "e77bb3a20de767338ce0e5d733e54461221419b3",
            "title": "Environment-Independent Task Specifications via GLTL",
            "url": "https://www.semanticscholar.org/paper/e77bb3a20de767338ce0e5d733e54461221419b3",
            "venue": "ArXiv",
            "year": 2017
        },
        {
            "arxivId": "1612.03471",
            "authors": [
                {
                    "authorId": "2108786992",
                    "name": "Xiao Li"
                },
                {
                    "authorId": "1935392",
                    "name": "C. Vasile"
                },
                {
                    "authorId": "1730719",
                    "name": "C. Belta"
                }
            ],
            "doi": "10.1109/IROS.2017.8206234",
            "intent": [],
            "isInfluential": false,
            "paperId": "abb7670d0770d67e74e34b8622ad62a18cbdbdc1",
            "title": "Reinforcement learning with temporal logic rewards",
            "url": "https://www.semanticscholar.org/paper/abb7670d0770d67e74e34b8622ad62a18cbdbdc1",
            "venue": "2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)",
            "year": 2016
        },
        {
            "arxivId": "1611.01796",
            "authors": [
                {
                    "authorId": "2112400",
                    "name": "Jacob Andreas"
                },
                {
                    "authorId": "38666915",
                    "name": "D. Klein"
                },
                {
                    "authorId": "1736651",
                    "name": "S. Levine"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "3a13f7c43b767b1fb72ef107ef62a4ddd48dd2a7",
            "title": "Modular Multitask Reinforcement Learning with Policy Sketches",
            "url": "https://www.semanticscholar.org/paper/3a13f7c43b767b1fb72ef107ef62a4ddd48dd2a7",
            "venue": "ICML",
            "year": 2016
        },
        {
            "arxivId": "1609.07409",
            "authors": [
                {
                    "authorId": "2761699",
                    "name": "Derya Aksaray"
                },
                {
                    "authorId": "120250753",
                    "name": "Austin M. Jones"
                },
                {
                    "authorId": "2817767",
                    "name": "Z. Kong"
                },
                {
                    "authorId": "3179069",
                    "name": "M. Schwager"
                },
                {
                    "authorId": "1730719",
                    "name": "C. Belta"
                }
            ],
            "doi": "10.1109/CDC.2016.7799279",
            "intent": [],
            "isInfluential": false,
            "paperId": "abd75723e8e208b54a7d3d3644555d61124dad26",
            "title": "Q-Learning for robust satisfaction of signal temporal logic specifications",
            "url": "https://www.semanticscholar.org/paper/abd75723e8e208b54a7d3d3644555d61124dad26",
            "venue": "2016 IEEE 55th Conference on Decision and Control (CDC)",
            "year": 2016
        },
        {
            "arxivId": "1606.01540",
            "authors": [
                {
                    "authorId": "2065151121",
                    "name": "Greg Brockman"
                },
                {
                    "authorId": "34415167",
                    "name": "Vicki Cheung"
                },
                {
                    "authorId": "152877508",
                    "name": "Ludwig Pettersson"
                },
                {
                    "authorId": "2113526509",
                    "name": "Jonas Schneider"
                },
                {
                    "authorId": "47971768",
                    "name": "John Schulman"
                },
                {
                    "authorId": "2109541439",
                    "name": "Jie Tang"
                },
                {
                    "authorId": "2563432",
                    "name": "Wojciech Zaremba"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "2b10281297ee001a9f3f4ea1aa9bea6b638c27df",
            "title": "OpenAI Gym",
            "url": "https://www.semanticscholar.org/paper/2b10281297ee001a9f3f4ea1aa9bea6b638c27df",
            "venue": "ArXiv",
            "year": 2016
        },
        {
            "arxivId": "1409.5486",
            "authors": [
                {
                    "authorId": "1779671",
                    "name": "Dorsa Sadigh"
                },
                {
                    "authorId": "2266031206",
                    "name": "Eric S Kim"
                },
                {
                    "authorId": "143962489",
                    "name": "S. Coogan"
                },
                {
                    "authorId": "2265970408",
                    "name": "S. Shankar"
                },
                {
                    "authorId": "2265969326",
                    "name": "Sastry Sanjit"
                },
                {
                    "authorId": "2265972013",
                    "name": "A. Seshia"
                },
                {
                    "authorId": "2266031206",
                    "name": "Eric S Kim"
                },
                {
                    "authorId": "2237581603",
                    "name": "S. S. Sastry"
                },
                {
                    "authorId": "1775517",
                    "name": "S. Seshia"
                }
            ],
            "doi": "10.1109/CDC.2014.7039527",
            "intent": [],
            "isInfluential": false,
            "paperId": "2759004ac7b9e0f4c0ca7e36bd0f2cb5c2b1b1e6",
            "title": "A learning based approach to control synthesis of Markov decision processes for linear temporal logic specifications",
            "url": "https://www.semanticscholar.org/paper/2759004ac7b9e0f4c0ca7e36bd0f2cb5c2b1b1e6",
            "venue": "53rd IEEE Conference on Decision and Control",
            "year": 2014
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "1693696",
                    "name": "Sam Devlin"
                },
                {
                    "authorId": "2380005",
                    "name": "D. Kudenko"
                }
            ],
            "doi": null,
            "intent": [
                "background",
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "400342b108446f260538420ab754613c7336af63",
            "title": "Dynamic potential-based reward shaping",
            "url": "https://www.semanticscholar.org/paper/400342b108446f260538420ab754613c7336af63",
            "venue": "AAMAS",
            "year": 2012
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "1701316",
                    "name": "M. Kwiatkowska"
                },
                {
                    "authorId": "145766447",
                    "name": "G. Norman"
                },
                {
                    "authorId": "144381875",
                    "name": "D. Parker"
                }
            ],
            "doi": "10.1007/978-3-642-22110-1_47",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "be3fae30a804e260255d738c324eed60115f48dc",
            "title": "PRISM 4.0: Verification of Probabilistic Real-Time Systems",
            "url": "https://www.semanticscholar.org/paper/be3fae30a804e260255d738c324eed60115f48dc",
            "venue": "CAV",
            "year": 2011
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "1707613",
                    "name": "F. Cassez"
                },
                {
                    "authorId": "1748754",
                    "name": "C. Jard"
                }
            ],
            "doi": null,
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "8d3876f6e1311d5a2854cbc1e44676e9a7a95a27",
            "title": "Proceedings of the 6th international conference on Formal Modeling and Analysis of Timed Systems",
            "url": "https://www.semanticscholar.org/paper/8d3876f6e1311d5a2854cbc1e44676e9a7a95a27",
            "venue": "",
            "year": 2008
        },
        {
            "arxivId": "0711.2185",
            "authors": [
                {
                    "authorId": "3037476",
                    "name": "A. Leizarowitz"
                },
                {
                    "authorId": "2329399883",
                    "name": "Adam Shwartz"
                }
            ],
            "doi": "10.1016/j.automatica.2007.09.013",
            "intent": [],
            "isInfluential": false,
            "paperId": "812fd36846ffd57b063690e791abd1e686ca3c8d",
            "title": "Exact finite approximations of average-cost countable Markov decision processes",
            "url": "https://www.semanticscholar.org/paper/812fd36846ffd57b063690e791abd1e686ca3c8d",
            "venue": "Autom.",
            "year": 2007
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "34699434",
                    "name": "A. Ng"
                },
                {
                    "authorId": "1868677",
                    "name": "Daishi Harada"
                },
                {
                    "authorId": "145107462",
                    "name": "Stuart J. Russell"
                }
            ],
            "doi": null,
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "94066dc12fe31e96af7557838159bde598cb4f10",
            "title": "Policy Invariance Under Reward Transformations: Theory and Application to Reward Shaping",
            "url": "https://www.semanticscholar.org/paper/94066dc12fe31e96af7557838159bde598cb4f10",
            "venue": "ICML",
            "year": 1999
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "145290695",
                    "name": "C. Watkins"
                },
                {
                    "authorId": "1790646",
                    "name": "P. Dayan"
                }
            ],
            "doi": "10.1007/BF00992698",
            "intent": [],
            "isInfluential": false,
            "paperId": "03b7e51c52084ac1db5118342a00b5fbcfc587aa",
            "title": "Q-learning",
            "url": "https://www.semanticscholar.org/paper/03b7e51c52084ac1db5118342a00b5fbcfc587aa",
            "venue": "Machine Learning",
            "year": 1992
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "1727062",
                    "name": "E. M. Hahn"
                },
                {
                    "authorId": "145304742",
                    "name": "Mateo Perez"
                },
                {
                    "authorId": "2701127",
                    "name": "S. Schewe"
                },
                {
                    "authorId": "1693050",
                    "name": "F. Somenzi"
                },
                {
                    "authorId": "1781100",
                    "name": "Ashutosh Trivedi"
                },
                {
                    "authorId": "3038359",
                    "name": "D. Wojtczak"
                }
            ],
            "doi": "10.1007/978-3-030-59152-6_6",
            "intent": [],
            "isInfluential": false,
            "paperId": "f757058c0042facca65ba1a1e0d137f392d75181",
            "title": "Faithful and Effective Reward Schemes for Model-Free Reinforcement Learning of Omega-Regular Objectives",
            "url": "https://www.semanticscholar.org/paper/f757058c0042facca65ba1a1e0d137f392d75181",
            "venue": "ATVA",
            "year": 2020
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2180533",
                    "name": "A. Mueller"
                }
            ],
            "doi": "10.1007/978-3-319-44878-7",
            "intent": [],
            "isInfluential": false,
            "paperId": "49e116c29c7d9f24ebbcbbb4e49c6f379f10184a",
            "title": "Formal Modeling and Analysis of Timed Systems",
            "url": "https://www.semanticscholar.org/paper/49e116c29c7d9f24ebbcbbb4e49c6f379f10184a",
            "venue": "Lecture Notes in Computer Science",
            "year": 2016
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "1944069",
                    "name": "Josef Bajada"
                },
                {
                    "authorId": "145130479",
                    "name": "M. Fox"
                },
                {
                    "authorId": "144954846",
                    "name": "D. Long"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "9f65fb097ddc0f80d420b1656b905de3b46ec9ea",
            "title": "IJCAI International Joint Conference on Artificial Intelligence",
            "url": "https://www.semanticscholar.org/paper/9f65fb097ddc0f80d420b1656b905de3b46ec9ea",
            "venue": "IJCAI 2015",
            "year": 2015
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2238176724",
                    "name": "R. S. Sutton"
                },
                {
                    "authorId": "1730590",
                    "name": "A. Barto"
                }
            ],
            "doi": "10.1109/TNN.1998.712192",
            "intent": [
                "background",
                "methodology"
            ],
            "isInfluential": true,
            "paperId": "97efafdb4a3942ab3efba53ded7413199f79c054",
            "title": "Reinforcement Learning: An Introduction",
            "url": "https://www.semanticscholar.org/paper/97efafdb4a3942ab3efba53ded7413199f79c054",
            "venue": "IEEE Trans. Neural Networks",
            "year": 1998
        },
        {
            "arxivId": null,
            "authors": [],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "ab7466983afe852ab7b13e0e2eea2e741088b40d",
            "title": "Proceedings of the Twenty-Third International Joint Conference on Artificial Intelligence Linear Temporal Logic and Linear Dynamic Logic on Finite Traces",
            "url": "https://www.semanticscholar.org/paper/ab7466983afe852ab7b13e0e2eea2e741088b40d",
            "venue": "",
            "year": null
        }
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "title": "Sample Efficient Model-free Reinforcement Learning from LTL Specifications with Optimality Guarantees",
    "topics": [],
    "url": "https://www.semanticscholar.org/paper/b3747f920d5bbca7bcb6ae41bfe90cb3c03fd7b3",
    "venue": "International Joint Conference on Artificial Intelligence",
    "year": 2023
}
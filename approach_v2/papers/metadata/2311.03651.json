{
    "abstract": "Robotic agents trained using reinforcement learning have the problem of taking unreliable actions in an out-of-distribution (OOD) state. Agents can easily become OOD in real-world environments because it is almost impossible for them to visit and learn the entire state space during training. Unfortunately, unreliable actions do not ensure that agents perform their original tasks successfully. Therefore, agents should be able to recognize whether they are in OOD states and learn how to return to the learned state distribution rather than continue to take unreliable actions. In this study, we propose a novel method for retraining agents to recover from OOD situations in a self-supervised manner when they fall into OOD states. Our in-depth experimental results demonstrate that our method substantially improves the agent\u2019s ability to recover from OOD situations in terms of sample efficiency and restoration of the performance for the original tasks. Moreover, we show that our method can retrain the agent to recover from OOD situations even when in-distribution states are difficult to visit through exploration. Code and supplementary materials are available at https://github.com/SNUChanKim/SeRO.",
    "arxivId": "2311.03651",
    "authors": [
        {
            "authorId": "2149054775",
            "name": "Chan Kim",
            "url": "https://www.semanticscholar.org/author/2149054775"
        },
        {
            "authorId": "2162206100",
            "name": "JaeKyung Cho",
            "url": "https://www.semanticscholar.org/author/2162206100"
        },
        {
            "authorId": "1707152",
            "name": "C. Bobda",
            "url": "https://www.semanticscholar.org/author/1707152"
        },
        {
            "authorId": "2072585957",
            "name": "Seung-Woo Seo",
            "url": "https://www.semanticscholar.org/author/2072585957"
        },
        {
            "authorId": "2135954604",
            "name": "Seong-Woo Kim",
            "url": "https://www.semanticscholar.org/author/2135954604"
        }
    ],
    "citationVelocity": 0,
    "citations": [
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2315892134",
                    "name": "Ju-Hyeok Ryu"
                },
                {
                    "authorId": "2149054775",
                    "name": "Chan Kim"
                },
                {
                    "authorId": "2135954604",
                    "name": "Seong-Woo Kim"
                }
            ],
            "doi": "10.1109/ICRA57147.2024.10611683",
            "intent": [],
            "isInfluential": false,
            "paperId": "246448d4e1ba2ded6b5c1912e79b1463f784d324",
            "title": "Active Automotive Augmented Reality Displays using Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/246448d4e1ba2ded6b5c1912e79b1463f784d324",
            "venue": "2024 IEEE International Conference on Robotics and Automation (ICRA)",
            "year": 2024
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2292990994",
                    "name": "Yufeng Xie"
                },
                {
                    "authorId": "2292665956",
                    "name": "Yinan Wang"
                },
                {
                    "authorId": "2293128974",
                    "name": "Han Wang"
                },
                {
                    "authorId": "2292433030",
                    "name": "Qingshan Li"
                }
            ],
            "doi": "10.1109/ICASSP48485.2024.10447216",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "40dee39711d16a364d354b43e283c37399cb0f5c",
            "title": "Self-Supervised Reinforcement Learning for Out-of-Distribution Recovery via Auxiliary Reward",
            "url": "https://www.semanticscholar.org/paper/40dee39711d16a364d354b43e283c37399cb0f5c",
            "venue": "ICASSP 2024 - 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)",
            "year": 2024
        }
    ],
    "corpusId": 260846694,
    "doi": "10.24963/ijcai.2023/432",
    "fieldsOfStudy": [
        "Computer Science"
    ],
    "influentialCitationCount": 0,
    "isOpenAccess": true,
    "isPublisherLicensed": true,
    "is_open_access": true,
    "is_publisher_licensed": true,
    "numCitedBy": 2,
    "numCiting": 34,
    "paperId": "31d481a2d4b1a13aee09b592ccdfeb4a4f6e3a01",
    "references": [
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": null,
                    "name": "Sahil Sharma"
                },
                {
                    "authorId": "41207614",
                    "name": "A. Srinivas"
                },
                {
                    "authorId": "1723632",
                    "name": "Balaraman Ravindran"
                }
            ],
            "doi": "10.1109/ICCCNT56998.2023.10306453",
            "intent": [],
            "isInfluential": false,
            "paperId": "f8ad22941c633b62573aaee9cee651a9bc895fe5",
            "title": "Deep Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/f8ad22941c633b62573aaee9cee651a9bc895fe5",
            "venue": "2023 14th International Conference on Computing Communication and Networking Technologies (ICCCNT)",
            "year": 2023
        },
        {
            "arxivId": "2206.10524",
            "authors": [
                {
                    "authorId": "2114072662",
                    "name": "Katie Kang"
                },
                {
                    "authorId": "1802492129",
                    "name": "Paula Gradu"
                },
                {
                    "authorId": "2149218929",
                    "name": "Jason J. Choi"
                },
                {
                    "authorId": "35163402",
                    "name": "Michael Janner"
                },
                {
                    "authorId": "1693894",
                    "name": "C. Tomlin"
                },
                {
                    "authorId": "1736651",
                    "name": "S. Levine"
                }
            ],
            "doi": "10.48550/arXiv.2206.10524",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "8cf45c7e1d9d02ccf2a764fdedacc63906af546a",
            "title": "Lyapunov Density Models: Constraining Distribution Shift in Learning-Based Control",
            "url": "https://www.semanticscholar.org/paper/8cf45c7e1d9d02ccf2a764fdedacc63906af546a",
            "venue": "ICML",
            "year": 2022
        },
        {
            "arxivId": "2205.05212",
            "authors": [
                {
                    "authorId": "50465276",
                    "name": "Archit Sharma"
                },
                {
                    "authorId": "2054232649",
                    "name": "Rehaan Ahmad"
                },
                {
                    "authorId": "46881670",
                    "name": "Chelsea Finn"
                }
            ],
            "doi": "10.48550/arXiv.2205.05212",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "14903cf4df35936b8a5c1dfa638c59727be6112d",
            "title": "A State-Distribution Matching Approach to Non-Episodic Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/14903cf4df35936b8a5c1dfa638c59727be6112d",
            "venue": "ICML",
            "year": 2022
        },
        {
            "arxivId": "2112.09605",
            "authors": [
                {
                    "authorId": "50465276",
                    "name": "Archit Sharma"
                },
                {
                    "authorId": "36303818",
                    "name": "Kelvin Xu"
                },
                {
                    "authorId": "2076413731",
                    "name": "Nikhil Sardana"
                },
                {
                    "authorId": "144150274",
                    "name": "Abhishek Gupta"
                },
                {
                    "authorId": "1944801",
                    "name": "Karol Hausman"
                },
                {
                    "authorId": "1736651",
                    "name": "S. Levine"
                },
                {
                    "authorId": "46881670",
                    "name": "Chelsea Finn"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "5dd82eee3efefb96aeaaae8b817b6be2e204dc2f",
            "title": "Autonomous Reinforcement Learning: Formalism and Benchmarking",
            "url": "https://www.semanticscholar.org/paper/5dd82eee3efefb96aeaaae8b817b6be2e204dc2f",
            "venue": "ICLR",
            "year": 2021
        },
        {
            "arxivId": "2111.05440",
            "authors": [
                {
                    "authorId": "2109377974",
                    "name": "Jinning Li"
                },
                {
                    "authorId": "1491105028",
                    "name": "Chen Tang"
                },
                {
                    "authorId": "1680165",
                    "name": "M. Tomizuka"
                },
                {
                    "authorId": "144267500",
                    "name": "Wei Zhan"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "798da6871400a119e70a46dba963e0bcdf2986d5",
            "title": "Dealing with the Unknown: Pessimistic Offline Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/798da6871400a119e70a46dba963e0bcdf2986d5",
            "venue": "CoRL",
            "year": 2021
        },
        {
            "arxivId": "2107.12931",
            "authors": [
                {
                    "authorId": "50465276",
                    "name": "Archit Sharma"
                },
                {
                    "authorId": "2129458064",
                    "name": "Abhishek Gupta"
                },
                {
                    "authorId": "1736651",
                    "name": "S. Levine"
                },
                {
                    "authorId": "1944801",
                    "name": "Karol Hausman"
                },
                {
                    "authorId": "46881670",
                    "name": "Chelsea Finn"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "95e078afe47c574da17c14d52614b0ccfceb1eb4",
            "title": "Autonomous Reinforcement Learning via Subgoal Curricula",
            "url": "https://www.semanticscholar.org/paper/95e078afe47c574da17c14d52614b0ccfceb1eb4",
            "venue": "NeurIPS",
            "year": 2021
        },
        {
            "arxivId": "2105.08140",
            "authors": [
                {
                    "authorId": "2109036744",
                    "name": "Yue Wu"
                },
                {
                    "authorId": "2443456",
                    "name": "Shuangfei Zhai"
                },
                {
                    "authorId": "2897313",
                    "name": "Nitish Srivastava"
                },
                {
                    "authorId": "49158771",
                    "name": "J. Susskind"
                },
                {
                    "authorId": "2155127104",
                    "name": "Jian Zhang"
                },
                {
                    "authorId": "145124475",
                    "name": "R. Salakhutdinov"
                },
                {
                    "authorId": "39538991",
                    "name": "Hanlin Goh"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "2c23085488337c4c1b5673b8d0f4ac95bda73529",
            "title": "Uncertainty Weighted Actor-Critic for Offline Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/2c23085488337c4c1b5673b8d0f4ac95bda73529",
            "venue": "ICML",
            "year": 2021
        },
        {
            "arxivId": "2011.06225",
            "authors": [
                {
                    "authorId": "7412048",
                    "name": "Moloud Abdar"
                },
                {
                    "authorId": "1866603",
                    "name": "Farhad Pourpanah"
                },
                {
                    "authorId": "1833049320",
                    "name": "Sadiq Hussain"
                },
                {
                    "authorId": "1404229235",
                    "name": "Dana Rezazadegan"
                },
                {
                    "authorId": "2150977916",
                    "name": "Li Liu"
                },
                {
                    "authorId": "1678622",
                    "name": "M. Ghavamzadeh"
                },
                {
                    "authorId": "1731709",
                    "name": "P. Fieguth"
                },
                {
                    "authorId": "1719250",
                    "name": "Xiaochun Cao"
                },
                {
                    "authorId": "145434108",
                    "name": "A. Khosravi"
                },
                {
                    "authorId": "2238592603",
                    "name": "U. R. Acharya"
                },
                {
                    "authorId": "144531494",
                    "name": "V. Makarenkov"
                },
                {
                    "authorId": "1743136",
                    "name": "S. Nahavandi"
                }
            ],
            "doi": "10.1016/j.inffus.2021.05.008",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "f14fc9e399d44463a17cc47a9b339b58f6ef7502",
            "title": "A Review of Uncertainty Quantification in Deep Learning: Techniques, Applications and Challenges",
            "url": "https://www.semanticscholar.org/paper/f14fc9e399d44463a17cc47a9b339b58f6ef7502",
            "venue": "Inf. Fusion",
            "year": 2020
        },
        {
            "arxivId": "2010.15920",
            "authors": [
                {
                    "authorId": "20474099",
                    "name": "Brijen Thananjeyan"
                },
                {
                    "authorId": "3117588",
                    "name": "A. Balakrishna"
                },
                {
                    "authorId": "4734949",
                    "name": "Suraj Nair"
                },
                {
                    "authorId": "1491203133",
                    "name": "Michael Luo"
                },
                {
                    "authorId": "2093939303",
                    "name": "K. Srinivasan"
                },
                {
                    "authorId": "7845778",
                    "name": "M. Hwang"
                },
                {
                    "authorId": "49988044",
                    "name": "Joseph E. Gonzalez"
                },
                {
                    "authorId": "46920727",
                    "name": "Julian Ibarz"
                },
                {
                    "authorId": "46881670",
                    "name": "Chelsea Finn"
                },
                {
                    "authorId": "144344283",
                    "name": "Ken Goldberg"
                }
            ],
            "doi": "10.1109/LRA.2021.3070252",
            "intent": [],
            "isInfluential": false,
            "paperId": "431dc05ac25510de6264084434254cca877f9ab3",
            "title": "Recovery RL: Safe Reinforcement Learning With Learned Recovery Zones",
            "url": "https://www.semanticscholar.org/paper/431dc05ac25510de6264084434254cca877f9ab3",
            "venue": "IEEE Robotics and Automation Letters",
            "year": 2020
        },
        {
            "arxivId": "2006.04779",
            "authors": [
                {
                    "authorId": "1488785534",
                    "name": "Aviral Kumar"
                },
                {
                    "authorId": "35499972",
                    "name": "Aurick Zhou"
                },
                {
                    "authorId": "145499435",
                    "name": "G. Tucker"
                },
                {
                    "authorId": "1736651",
                    "name": "S. Levine"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "28db20a81eec74a50204686c3cf796c42a020d2e",
            "title": "Conservative Q-Learning for Offline Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/28db20a81eec74a50204686c3cf796c42a020d2e",
            "venue": "NeurIPS",
            "year": 2020
        },
        {
            "arxivId": "2006.12024",
            "authors": [
                {
                    "authorId": "3451409",
                    "name": "Ethan Goan"
                },
                {
                    "authorId": "3140440",
                    "name": "C. Fookes"
                }
            ],
            "doi": "10.1007/978-3-030-42553-1_3",
            "intent": [],
            "isInfluential": false,
            "paperId": "5aa40518f2a3df8d628bbc5c02ff1bb9b72740cc",
            "title": "Bayesian Neural Networks: An Introduction and Survey",
            "url": "https://www.semanticscholar.org/paper/5aa40518f2a3df8d628bbc5c02ff1bb9b72740cc",
            "venue": "Case Studies in Applied Bayesian Data Science",
            "year": 2020
        },
        {
            "arxivId": "2005.01643",
            "authors": [
                {
                    "authorId": "1736651",
                    "name": "S. Levine"
                },
                {
                    "authorId": "1488785534",
                    "name": "Aviral Kumar"
                },
                {
                    "authorId": "145499435",
                    "name": "G. Tucker"
                },
                {
                    "authorId": "2550764",
                    "name": "Justin Fu"
                }
            ],
            "doi": null,
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "5e7bc93622416f14e6948a500278bfbe58cd3890",
            "title": "Offline Reinforcement Learning: Tutorial, Review, and Perspectives on Open Problems",
            "url": "https://www.semanticscholar.org/paper/5e7bc93622416f14e6948a500278bfbe58cd3890",
            "venue": "ArXiv",
            "year": 2020
        },
        {
            "arxivId": "1910.07113",
            "authors": [
                {
                    "authorId": "51139888",
                    "name": "OpenAI"
                },
                {
                    "authorId": "2258629",
                    "name": "Ilge Akkaya"
                },
                {
                    "authorId": "2206490",
                    "name": "Marcin Andrychowicz"
                },
                {
                    "authorId": "36045639",
                    "name": "Maciek Chociej"
                },
                {
                    "authorId": "1380985420",
                    "name": "Ma-teusz Litwin"
                },
                {
                    "authorId": "39593364",
                    "name": "Bob McGrew"
                },
                {
                    "authorId": "6817951",
                    "name": "Arthur Petron"
                },
                {
                    "authorId": "34800652",
                    "name": "Alex Paino"
                },
                {
                    "authorId": "3407285",
                    "name": "Matthias Plappert"
                },
                {
                    "authorId": "2059171221",
                    "name": "Glenn Powell"
                },
                {
                    "authorId": "1380603785",
                    "name": "Raphael Ribas"
                },
                {
                    "authorId": "2113526509",
                    "name": "Jonas Schneider"
                },
                {
                    "authorId": "145950540",
                    "name": "N. Tezak"
                },
                {
                    "authorId": "2065005836",
                    "name": "Jerry Tworek"
                },
                {
                    "authorId": "2930640",
                    "name": "P. Welinder"
                },
                {
                    "authorId": "2065741038",
                    "name": "Lilian Weng"
                },
                {
                    "authorId": "153930486",
                    "name": "Qiming Yuan"
                },
                {
                    "authorId": "2563432",
                    "name": "Wojciech Zaremba"
                },
                {
                    "authorId": "2152836492",
                    "name": "Lei M. Zhang"
                }
            ],
            "doi": null,
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "320b227027030fc291de2896fc3c6da49d7614be",
            "title": "Solving Rubik's Cube with a Robot Hand",
            "url": "https://www.semanticscholar.org/paper/320b227027030fc291de2896fc3c6da49d7614be",
            "venue": "ArXiv",
            "year": 2019
        },
        {
            "arxivId": "1911.11361",
            "authors": [
                {
                    "authorId": "2013680445",
                    "name": "Yifan Wu"
                },
                {
                    "authorId": "145499435",
                    "name": "G. Tucker"
                },
                {
                    "authorId": "7624658",
                    "name": "Ofir Nachum"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "9be492858863c8c7c24be1ecb75724de5086bd8e",
            "title": "Behavior Regularized Offline Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/9be492858863c8c7c24be1ecb75724de5086bd8e",
            "venue": "ArXiv",
            "year": 2019
        },
        {
            "arxivId": "1906.00949",
            "authors": [
                {
                    "authorId": "1488785534",
                    "name": "Aviral Kumar"
                },
                {
                    "authorId": "2550764",
                    "name": "Justin Fu"
                },
                {
                    "authorId": "145499435",
                    "name": "G. Tucker"
                },
                {
                    "authorId": "1736651",
                    "name": "S. Levine"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "82b4b03a4659d6e04bd7cbf51d6e08fde1348dbd",
            "title": "Stabilizing Off-Policy Q-Learning via Bootstrapping Error Reduction",
            "url": "https://www.semanticscholar.org/paper/82b4b03a4659d6e04bd7cbf51d6e08fde1348dbd",
            "venue": "NeurIPS",
            "year": 2019
        },
        {
            "arxivId": null,
            "authors": [],
            "doi": "10.1109/icra39644.2019",
            "intent": [],
            "isInfluential": false,
            "paperId": "babd88f02ff8d131f1907785fc6fd0ff2da4a1e0",
            "title": "2019 International Conference on Robotics and Automation (ICRA)",
            "url": "https://www.semanticscholar.org/paper/babd88f02ff8d131f1907785fc6fd0ff2da4a1e0",
            "venue": "",
            "year": 2019
        },
        {
            "arxivId": "1901.02705",
            "authors": [
                {
                    "authorId": "39713408",
                    "name": "Mikael Henaff"
                },
                {
                    "authorId": "2067767",
                    "name": "A. Canziani"
                },
                {
                    "authorId": "1688882",
                    "name": "Yann LeCun"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "2eeace98cf3c105a8d37884dc8d33c50ae4b7ddb",
            "title": "Model-Predictive Policy Learning with Uncertainty Regularization for Driving in Dense Traffic",
            "url": "https://www.semanticscholar.org/paper/2eeace98cf3c105a8d37884dc8d33c50ae4b7ddb",
            "venue": "ICLR",
            "year": 2019
        },
        {
            "arxivId": "1812.02900",
            "authors": [
                {
                    "authorId": "14637819",
                    "name": "Scott Fujimoto"
                },
                {
                    "authorId": "2462512",
                    "name": "D. Meger"
                },
                {
                    "authorId": "144368601",
                    "name": "Doina Precup"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "5285cb8faada5de8a92a47622950f6cfd476ac1d",
            "title": "Off-Policy Deep Reinforcement Learning without Exploration",
            "url": "https://www.semanticscholar.org/paper/5285cb8faada5de8a92a47622950f6cfd476ac1d",
            "venue": "ICML",
            "year": 2018
        },
        {
            "arxivId": "1810.08700",
            "authors": [
                {
                    "authorId": "81551971",
                    "name": "Bj\u00f6rn L\u00fctjens"
                },
                {
                    "authorId": "144019526",
                    "name": "Michael Everett"
                },
                {
                    "authorId": "1713935",
                    "name": "J. How"
                }
            ],
            "doi": "10.1109/ICRA.2019.8793611",
            "intent": [],
            "isInfluential": false,
            "paperId": "dd54595a62a57b23f1f5ba25066618dcd044153b",
            "title": "Safe Reinforcement Learning With Model Uncertainty Estimates",
            "url": "https://www.semanticscholar.org/paper/dd54595a62a57b23f1f5ba25066618dcd044153b",
            "venue": "2019 International Conference on Robotics and Automation (ICRA)",
            "year": 2018
        },
        {
            "arxivId": "1801.01290",
            "authors": [
                {
                    "authorId": "2587648",
                    "name": "Tuomas Haarnoja"
                },
                {
                    "authorId": "35499972",
                    "name": "Aurick Zhou"
                },
                {
                    "authorId": "1689992",
                    "name": "P. Abbeel"
                },
                {
                    "authorId": "1736651",
                    "name": "S. Levine"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "811df72e210e20de99719539505da54762a11c6d",
            "title": "Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor",
            "url": "https://www.semanticscholar.org/paper/811df72e210e20de99719539505da54762a11c6d",
            "venue": "ICML",
            "year": 2018
        },
        {
            "arxivId": "1711.06782",
            "authors": [
                {
                    "authorId": "8140754",
                    "name": "Benjamin Eysenbach"
                },
                {
                    "authorId": "2046135",
                    "name": "S. Gu"
                },
                {
                    "authorId": "46920727",
                    "name": "Julian Ibarz"
                },
                {
                    "authorId": "1736651",
                    "name": "S. Levine"
                }
            ],
            "doi": null,
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "ec4df801c640169e18d8da1bdc65a0b6fc2d3d94",
            "title": "Leave no Trace: Learning to Reset for Safe and Autonomous Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/ec4df801c640169e18d8da1bdc65a0b6fc2d3d94",
            "venue": "ICLR",
            "year": 2017
        },
        {
            "arxivId": "1707.02286",
            "authors": [
                {
                    "authorId": "2801204",
                    "name": "N. Heess"
                },
                {
                    "authorId": "22216833",
                    "name": "TB Dhruva"
                },
                {
                    "authorId": "2054369418",
                    "name": "S. Sriram"
                },
                {
                    "authorId": "144083287",
                    "name": "Jay Lemmon"
                },
                {
                    "authorId": "1879232",
                    "name": "J. Merel"
                },
                {
                    "authorId": "89504302",
                    "name": "Greg Wayne"
                },
                {
                    "authorId": "2109481",
                    "name": "Yuval Tassa"
                },
                {
                    "authorId": "1968210",
                    "name": "Tom Erez"
                },
                {
                    "authorId": "2117966548",
                    "name": "Ziyun Wang"
                },
                {
                    "authorId": "143648071",
                    "name": "S. Eslami"
                },
                {
                    "authorId": "3137672",
                    "name": "Martin A. Riedmiller"
                },
                {
                    "authorId": "145824029",
                    "name": "David Silver"
                }
            ],
            "doi": null,
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "a762ae907b7dd71a59bd8bd98aba69dfe2de13a2",
            "title": "Emergence of Locomotion Behaviours in Rich Environments",
            "url": "https://www.semanticscholar.org/paper/a762ae907b7dd71a59bd8bd98aba69dfe2de13a2",
            "venue": "ArXiv",
            "year": 2017
        },
        {
            "arxivId": "1702.01182",
            "authors": [
                {
                    "authorId": "46292812",
                    "name": "G. Kahn"
                },
                {
                    "authorId": "9542787",
                    "name": "A. Villaflor"
                },
                {
                    "authorId": "144401061",
                    "name": "Vitchyr H. Pong"
                },
                {
                    "authorId": "1689992",
                    "name": "P. Abbeel"
                },
                {
                    "authorId": "1736651",
                    "name": "S. Levine"
                }
            ],
            "doi": null,
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "f2c20cb6ebd2ad704c5bcae4eb8b942d3c62f8e0",
            "title": "Uncertainty-Aware Reinforcement Learning for Collision Avoidance",
            "url": "https://www.semanticscholar.org/paper/f2c20cb6ebd2ad704c5bcae4eb8b942d3c62f8e0",
            "venue": "ArXiv",
            "year": 2017
        },
        {
            "arxivId": "1610.00633",
            "authors": [
                {
                    "authorId": "2046135",
                    "name": "S. Gu"
                },
                {
                    "authorId": "29891985",
                    "name": "E. Holly"
                },
                {
                    "authorId": "2542999",
                    "name": "T. Lillicrap"
                },
                {
                    "authorId": "1736651",
                    "name": "S. Levine"
                }
            ],
            "doi": "10.1109/ICRA.2017.7989385",
            "intent": [],
            "isInfluential": false,
            "paperId": "e37b999f0c96d7136db07b0185b837d5decd599a",
            "title": "Deep reinforcement learning for robotic manipulation with asynchronous off-policy updates",
            "url": "https://www.semanticscholar.org/paper/e37b999f0c96d7136db07b0185b837d5decd599a",
            "venue": "2017 IEEE International Conference on Robotics and Automation (ICRA)",
            "year": 2016
        },
        {
            "arxivId": "1606.06565",
            "authors": [
                {
                    "authorId": "2698777",
                    "name": "Dario Amodei"
                },
                {
                    "authorId": "37232298",
                    "name": "C. Olah"
                },
                {
                    "authorId": "5164568",
                    "name": "J. Steinhardt"
                },
                {
                    "authorId": "145791315",
                    "name": "P. Christiano"
                },
                {
                    "authorId": "47971768",
                    "name": "John Schulman"
                },
                {
                    "authorId": "30415265",
                    "name": "Dandelion Man\u00e9"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "e86f71ca2948d17b003a5f068db1ecb2b77827f7",
            "title": "Concrete Problems in AI Safety",
            "url": "https://www.semanticscholar.org/paper/e86f71ca2948d17b003a5f068db1ecb2b77827f7",
            "venue": "ArXiv",
            "year": 2016
        },
        {
            "arxivId": "1506.02438",
            "authors": [
                {
                    "authorId": "47971768",
                    "name": "John Schulman"
                },
                {
                    "authorId": "29912342",
                    "name": "Philipp Moritz"
                },
                {
                    "authorId": "1736651",
                    "name": "S. Levine"
                },
                {
                    "authorId": "1694621",
                    "name": "Michael I. Jordan"
                },
                {
                    "authorId": "1689992",
                    "name": "P. Abbeel"
                }
            ],
            "doi": null,
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "d316c82c12cf4c45f9e85211ef3d1fa62497bff8",
            "title": "High-Dimensional Continuous Control Using Generalized Advantage Estimation",
            "url": "https://www.semanticscholar.org/paper/d316c82c12cf4c45f9e85211ef3d1fa62497bff8",
            "venue": "ICLR",
            "year": 2015
        },
        {
            "arxivId": "1506.02142",
            "authors": [
                {
                    "authorId": "2681954",
                    "name": "Y. Gal"
                },
                {
                    "authorId": "1744700",
                    "name": "Zoubin Ghahramani"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "f35de4f9b1a7c4d3fa96a0d2ab1bf8937671f6b6",
            "title": "Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning",
            "url": "https://www.semanticscholar.org/paper/f35de4f9b1a7c4d3fa96a0d2ab1bf8937671f6b6",
            "venue": "ICML",
            "year": 2015
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2059358552",
                    "name": "P. Cochat"
                },
                {
                    "authorId": "13267685",
                    "name": "L. Vaucoret"
                },
                {
                    "authorId": "2097644863",
                    "name": "J. Sarles"
                }
            ],
            "doi": "10.1136/ebmh.11.4.102",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "bc6dff14a130c57a91d5a21339c23471faf1d46f",
            "title": "Et al",
            "url": "https://www.semanticscholar.org/paper/bc6dff14a130c57a91d5a21339c23471faf1d46f",
            "venue": "Archives de pediatrie : organe officiel de la Societe francaise de pediatrie",
            "year": 2008
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2248834664",
                    "name": "Christopher K. I. Williams"
                },
                {
                    "authorId": "2247411478",
                    "name": "Carl E. Rasmussen"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "4d98ce60f4f8ed822503b8d13b0605f8c5d74ca7",
            "title": "Gaussian Processes for Regression",
            "url": "https://www.semanticscholar.org/paper/4d98ce60f4f8ed822503b8d13b0605f8c5d74ca7",
            "venue": "NIPS",
            "year": 1995
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2120932",
                    "name": "A. Clark"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "a7b489df9fc391334b34204b90d101bb37ddee06",
            "title": "Proceedings of The 28th International Conference on Machine Learning",
            "url": "https://www.semanticscholar.org/paper/a7b489df9fc391334b34204b90d101bb37ddee06",
            "venue": "",
            "year": 2011
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "1796280",
                    "name": "T. Yoshikawa"
                }
            ],
            "doi": "10.1007/bfb0004373",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "a2d498e4361b44418998e1c06af09505103e3563",
            "title": "Lyapunov Stability Theory",
            "url": "https://www.semanticscholar.org/paper/a2d498e4361b44418998e1c06af09505103e3563",
            "venue": "",
            "year": 2003
        }
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "title": "SeRO: Self-Supervised Reinforcement Learning for Recovery from Out-of-Distribution Situations",
    "topics": [],
    "url": "https://www.semanticscholar.org/paper/31d481a2d4b1a13aee09b592ccdfeb4a4f6e3a01",
    "venue": "International Joint Conference on Artificial Intelligence",
    "year": 2023
}
{
    "abstract": "We show how an action-dependent baseline can be used by the policy gradient theorem using function approximation, originally presented with action-independent baselines by (Sutton et al. 2000).",
    "arxivId": "1706.06643",
    "authors": [
        {
            "authorId": "143640165",
            "name": "P. Thomas",
            "url": "https://www.semanticscholar.org/author/143640165"
        },
        {
            "authorId": "2563117",
            "name": "E. Brunskill",
            "url": "https://www.semanticscholar.org/author/2563117"
        }
    ],
    "citationVelocity": 6,
    "citations": [
        {
            "arxivId": "2410.02226",
            "authors": [
                {
                    "authorId": "2135194248",
                    "name": "Shuze Liu"
                },
                {
                    "authorId": "2324074342",
                    "name": "Claire Chen"
                },
                {
                    "authorId": "2279599626",
                    "name": "Shangtong Zhang"
                }
            ],
            "doi": "10.48550/arXiv.2410.02226",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "a04ff3cf506d02691816a67e7944d480d4799caa",
            "title": "Doubly Optimal Policy Evaluation for Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/a04ff3cf506d02691816a67e7944d480d4799caa",
            "venue": "ArXiv",
            "year": 2024
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2276488518",
                    "name": "Yanan Xiao"
                },
                {
                    "authorId": "2112546695",
                    "name": "Lu Jiang"
                },
                {
                    "authorId": "2313359482",
                    "name": "Kunpeng Liu"
                },
                {
                    "authorId": "2313357461",
                    "name": "Yuanbo Xu"
                },
                {
                    "authorId": "2266377754",
                    "name": "Pengyang Wang"
                },
                {
                    "authorId": "2276427578",
                    "name": "Minghao Yin"
                }
            ],
            "doi": "10.24963/ijcai.2024/272",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "e07079def5d026c49977c04109c4b6e4d8c23dbd",
            "title": "Hierarchical Reinforcement Learning for Point of Interest Recommendation",
            "url": "https://www.semanticscholar.org/paper/e07079def5d026c49977c04109c4b6e4d8c23dbd",
            "venue": "IJCAI",
            "year": 2024
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2243360296",
                    "name": "Qin Zhang"
                },
                {
                    "authorId": "2242966016",
                    "name": "Bo Tan"
                },
                {
                    "authorId": "2243363166",
                    "name": "Xiong Hu"
                }
            ],
            "doi": "10.23919/CCC58697.2023.10240793",
            "intent": [],
            "isInfluential": false,
            "paperId": "d3474204544629c9fa2a697a1aab4ac456776ad7",
            "title": "Ship Heave Compensation Based on PID-DDPG Hybrid Control",
            "url": "https://www.semanticscholar.org/paper/d3474204544629c9fa2a697a1aab4ac456776ad7",
            "venue": "2023 42nd Chinese Control Conference (CCC)",
            "year": 2023
        },
        {
            "arxivId": "2306.16803",
            "authors": [
                {
                    "authorId": "1753618449",
                    "name": "Alexander Meulemans"
                },
                {
                    "authorId": "1620691564",
                    "name": "Simon Schug"
                },
                {
                    "authorId": "51194506",
                    "name": "Seijin Kobayashi"
                },
                {
                    "authorId": "1784997",
                    "name": "N. Daw"
                },
                {
                    "authorId": "2220827796",
                    "name": "Gregory Wayne"
                }
            ],
            "doi": "10.48550/arXiv.2306.16803",
            "intent": [],
            "isInfluential": false,
            "paperId": "bd120c6c642022683b7148bb83113f734ba140bb",
            "title": "Would I have gotten that reward? Long-term credit assignment by counterfactual contribution analysis",
            "url": "https://www.semanticscholar.org/paper/bd120c6c642022683b7148bb83113f734ba140bb",
            "venue": "NeurIPS",
            "year": 2023
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2267074808",
                    "name": "Ke Jiang"
                },
                {
                    "authorId": "2267203010",
                    "name": "Jialu Hu"
                },
                {
                    "authorId": "2267222878",
                    "name": "Chuxing Fang"
                },
                {
                    "authorId": "2261684728",
                    "name": "Hongjing Li"
                }
            ],
            "doi": "10.1145/3606043.3606087",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "8d5f0ccf465788aefea62277b13b4dc98f6a4798",
            "title": "Adaptive Anti-jitter Optimization for Immersive Streaming in Metaverse Scenarios",
            "url": "https://www.semanticscholar.org/paper/8d5f0ccf465788aefea62277b13b4dc98f6a4798",
            "venue": "HP3C",
            "year": 2023
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2156060815",
                    "name": "Li Li"
                },
                {
                    "authorId": "2618744",
                    "name": "Lun Tang"
                },
                {
                    "authorId": "2182019588",
                    "name": "Qinghai Liu"
                },
                {
                    "authorId": "2136911057",
                    "name": "Yaqing Wang"
                },
                {
                    "authorId": "7792215",
                    "name": "Xiaoqiang He"
                },
                {
                    "authorId": "8559810",
                    "name": "Qianbin Chen"
                }
            ],
            "doi": "10.1109/JIOT.2023.3241925",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "f714ccaeb9cad1b6f754f179050c2b6604c68da2",
            "title": "DTN-Assisted Dynamic Cooperative Slicing for Delay-Sensitive Service in MEC-Enabled IoT via Deep Deterministic Policy Gradient With Variable Action",
            "url": "https://www.semanticscholar.org/paper/f714ccaeb9cad1b6f754f179050c2b6604c68da2",
            "venue": "IEEE Internet of Things Journal",
            "year": 2023
        },
        {
            "arxivId": "2301.13236",
            "authors": [
                {
                    "authorId": "2801905",
                    "name": "Gal Dalal"
                },
                {
                    "authorId": "21062872",
                    "name": "Assaf Hallak"
                },
                {
                    "authorId": "3305080",
                    "name": "Gugan Thoppe"
                },
                {
                    "authorId": "1712535",
                    "name": "Shie Mannor"
                },
                {
                    "authorId": "1732280",
                    "name": "Gal Chechik"
                }
            ],
            "doi": "10.48550/arXiv.2301.13236",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "d0b93a2fcfe277edd1d9f59360df1deca5c98f56",
            "title": "SoftTreeMax: Exponential Variance Reduction in Policy Gradient via Tree Search",
            "url": "https://www.semanticscholar.org/paper/d0b93a2fcfe277edd1d9f59360df1deca5c98f56",
            "venue": "ArXiv",
            "year": 2023
        },
        {
            "arxivId": "2212.09010",
            "authors": [
                {
                    "authorId": "1598440076",
                    "name": "Erfaun Noorani"
                },
                {
                    "authorId": "50691785",
                    "name": "Christos N. Mavridis"
                },
                {
                    "authorId": "1737891",
                    "name": "J. Baras"
                }
            ],
            "doi": "10.48550/arXiv.2212.09010",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "f114e0d03a5fda080b1a04e31f8873464a2ed872",
            "title": "Risk-Sensitive Reinforcement Learning with Exponential Criteria",
            "url": "https://www.semanticscholar.org/paper/f114e0d03a5fda080b1a04e31f8873464a2ed872",
            "venue": "ArXiv",
            "year": 2022
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2095917",
                    "name": "Giorgio Manganini"
                },
                {
                    "authorId": "2073420264",
                    "name": "Simone Fioravanti"
                },
                {
                    "authorId": "144763838",
                    "name": "Giorgia Ramponi"
                }
            ],
            "doi": "10.1109/CDC51059.2022.9993035",
            "intent": [],
            "isInfluential": false,
            "paperId": "934192ad9f22316b3bbd8242199479a976da4b3d",
            "title": "Newton-based Policy Search for Networked Multi-agent Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/934192ad9f22316b3bbd8242199479a976da4b3d",
            "venue": "2022 IEEE 61st Conference on Decision and Control (CDC)",
            "year": 2022
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2193559109",
                    "name": "Zhenghongyuan Ni"
                },
                {
                    "authorId": "2110438935",
                    "name": "Ye Jin"
                },
                {
                    "authorId": "39336958",
                    "name": "Peng Liu"
                },
                {
                    "authorId": "144122124",
                    "name": "Wei Zhao"
                }
            ],
            "doi": "10.1007/s10846-022-01771-5",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "031265825d67730c56e40b2020726bfeb2895222",
            "title": "Spatial Consciousness Model of Intrinsic Reward in Partially Observable Environments",
            "url": "https://www.semanticscholar.org/paper/031265825d67730c56e40b2020726bfeb2895222",
            "venue": "Journal of Intelligent & Robotic Systems",
            "year": 2022
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "145494532",
                    "name": "C. Bao"
                },
                {
                    "authorId": "49830623",
                    "name": "Peng Wang"
                },
                {
                    "authorId": "47339842",
                    "name": "R. He"
                },
                {
                    "authorId": "2914033",
                    "name": "G. Tang"
                }
            ],
            "doi": "10.1177/09544100221138911",
            "intent": [],
            "isInfluential": false,
            "paperId": "2538975a18a7704236b1e31b5f9ff84fc6a59ab3",
            "title": "Autonomous trajectory planning method for hypersonic vehicles in glide phase based on DDPG algorithm",
            "url": "https://www.semanticscholar.org/paper/2538975a18a7704236b1e31b5f9ff84fc6a59ab3",
            "venue": "Proceedings of the Institution of Mechanical Engineers, Part G: Journal of Aerospace Engineering",
            "year": 2022
        },
        {
            "arxivId": "2209.13966",
            "authors": [
                {
                    "authorId": "2801905",
                    "name": "Gal Dalal"
                },
                {
                    "authorId": "21062872",
                    "name": "Assaf Hallak"
                },
                {
                    "authorId": "1712535",
                    "name": "Shie Mannor"
                },
                {
                    "authorId": "1732280",
                    "name": "Gal Chechik"
                }
            ],
            "doi": "10.48550/arXiv.2209.13966",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "08b409a3c3d72c1ce1fe2f6db0928c0bdec58693",
            "title": "SoftTreeMax: Policy Gradient with Tree Search",
            "url": "https://www.semanticscholar.org/paper/08b409a3c3d72c1ce1fe2f6db0928c0bdec58693",
            "venue": "ArXiv",
            "year": 2022
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "1422863917",
                    "name": "Omar al-Ani"
                },
                {
                    "authorId": "2155897283",
                    "name": "Sanjoy Das"
                }
            ],
            "doi": "10.3390/en15176392",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "ac5504439f700b099efdf4a943a6a96b8f543431",
            "title": "Reinforcement Learning: Theory and Applications in HEMS",
            "url": "https://www.semanticscholar.org/paper/ac5504439f700b099efdf4a943a6a96b8f543431",
            "venue": "Energies",
            "year": 2022
        },
        {
            "arxivId": "2111.00185",
            "authors": [
                {
                    "authorId": "6303990",
                    "name": "Matthew Shunshi Zhang"
                },
                {
                    "authorId": "2090630",
                    "name": "Murat A. Erdogdu"
                },
                {
                    "authorId": "1873736",
                    "name": "Animesh Garg"
                }
            ],
            "doi": "10.1609/aaai.v36i8.20891",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "1378b2b507fbbc6d475835eeb740f1c7426d7be5",
            "title": "Convergence and Optimality of Policy Gradient Methods in Weakly Smooth Settings",
            "url": "https://www.semanticscholar.org/paper/1378b2b507fbbc6d475835eeb740f1c7426d7be5",
            "venue": "AAAI",
            "year": 2021
        },
        {
            "arxivId": "2109.07054",
            "authors": [
                {
                    "authorId": "2053190916",
                    "name": "Ishaan Shah"
                },
                {
                    "authorId": "144251911",
                    "name": "D. Halpern"
                },
                {
                    "authorId": "7981071",
                    "name": "Kavosh Asadi"
                },
                {
                    "authorId": "144885169",
                    "name": "M. Littman"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "737da08b32cf9b7a448c29c8d192bb47480ad48c",
            "title": "Convergence of a Human-in-the-Loop Policy-Gradient Algorithm With Eligibility Trace Under Reward, Policy, and Advantage Feedback",
            "url": "https://www.semanticscholar.org/paper/737da08b32cf9b7a448c29c8d192bb47480ad48c",
            "venue": "ArXiv",
            "year": 2021
        },
        {
            "arxivId": "2109.05866",
            "authors": [
                {
                    "authorId": "98593830",
                    "name": "Mohamed Baioumy"
                },
                {
                    "authorId": "145350537",
                    "name": "Bruno Lacerda"
                },
                {
                    "authorId": "48201226",
                    "name": "Paul Duckworth"
                },
                {
                    "authorId": "2072387078",
                    "name": "Nick Hawes"
                }
            ],
            "doi": "10.1007/978-3-030-93736-2_58",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "b8ba67c204105ed835274e5388332d15cffe5d1b",
            "title": "On Solving a Stochastic Shortest-Path Markov Decision Process as Probabilistic Inference",
            "url": "https://www.semanticscholar.org/paper/b8ba67c204105ed835274e5388332d15cffe5d1b",
            "venue": "PKDD/ECML Workshops",
            "year": 2021
        },
        {
            "arxivId": "2108.02551",
            "authors": [
                {
                    "authorId": "3106003",
                    "name": "Shagufta Henna"
                },
                {
                    "authorId": "2273890",
                    "name": "Abid Ali Minhas"
                },
                {
                    "authorId": "2115773935",
                    "name": "Muhammad Saeed Khan"
                },
                {
                    "authorId": "2069559752",
                    "name": "M. S. Iqbal"
                }
            ],
            "doi": "10.1016/j.optcom.2022.129186",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "2d0c8300566a0bee97f2b1a092a18cc1847189f2",
            "title": "Ensemble consensus representation deep reinforcement learning for hybrid FSO/RF communication systems",
            "url": "https://www.semanticscholar.org/paper/2d0c8300566a0bee97f2b1a092a18cc1847189f2",
            "venue": "Optics Communications",
            "year": 2021
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "144944455",
                    "name": "Hamid Ali"
                },
                {
                    "authorId": "2899772",
                    "name": "Hammad Majeed"
                },
                {
                    "authorId": "46923248",
                    "name": "I. Usman"
                },
                {
                    "authorId": "97117896",
                    "name": "Khalid A. Almejalli"
                }
            ],
            "doi": "10.1155/2021/9920591",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "c61d977df423f127cb2a92eb37910da4e49200ff",
            "title": "Reducing Entropy Overestimation in Soft Actor Critic Using Dual Policy Network",
            "url": "https://www.semanticscholar.org/paper/c61d977df423f127cb2a92eb37910da4e49200ff",
            "venue": "Wirel. Commun. Mob. Comput.",
            "year": 2021
        },
        {
            "arxivId": "2104.10415",
            "authors": [
                {
                    "authorId": "8800430",
                    "name": "Yuqiong Qi"
                },
                {
                    "authorId": "2113665991",
                    "name": "Yang Hu"
                },
                {
                    "authorId": "1430766392",
                    "name": "Haibin Wu"
                },
                {
                    "authorId": "2153698839",
                    "name": "Shen Li"
                },
                {
                    "authorId": "3064097",
                    "name": "Haiyu Mao"
                },
                {
                    "authorId": "144530359",
                    "name": "Xiaochun Ye"
                },
                {
                    "authorId": "3276641",
                    "name": "Dongrui Fan"
                },
                {
                    "authorId": "145550877",
                    "name": "Ninghui Sun"
                }
            ],
            "doi": null,
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "3adc4783538dc729a32fdae43fd46a3b2212fd68",
            "title": "Tackling Variabilities in Autonomous Driving",
            "url": "https://www.semanticscholar.org/paper/3adc4783538dc729a32fdae43fd46a3b2212fd68",
            "venue": "ArXiv",
            "year": 2021
        },
        {
            "arxivId": "2103.01009",
            "authors": [
                {
                    "authorId": "115851875",
                    "name": "Charlie Blake"
                },
                {
                    "authorId": "30525721",
                    "name": "Vitaly Kurin"
                },
                {
                    "authorId": "27550002",
                    "name": "Maximilian Igl"
                },
                {
                    "authorId": "1766767",
                    "name": "Shimon Whiteson"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "dd35486225229c95acfbbaf50be0ec9a28e074cf",
            "title": "Snowflake: Scaling GNNs to High-Dimensional Continuous Control via Parameter Freezing",
            "url": "https://www.semanticscholar.org/paper/dd35486225229c95acfbbaf50be0ec9a28e074cf",
            "venue": "NeurIPS",
            "year": 2021
        },
        {
            "arxivId": "2102.10362",
            "authors": [
                {
                    "authorId": "49306150",
                    "name": "Thomas Spooner"
                },
                {
                    "authorId": "38921168",
                    "name": "N. Vadori"
                },
                {
                    "authorId": "27411264",
                    "name": "Sumitra Ganesh"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "f8b4cb8c4d014c8502745e72027e7862270825d6",
            "title": "Factored Policy Gradients: Leveraging Structure for Efficient Learning in MOMDPs",
            "url": "https://www.semanticscholar.org/paper/f8b4cb8c4d014c8502745e72027e7862270825d6",
            "venue": "NeurIPS",
            "year": 2021
        },
        {
            "arxivId": "2102.02125",
            "authors": [
                {
                    "authorId": "123959763",
                    "name": "Lovis Anderson"
                },
                {
                    "authorId": "2093407075",
                    "name": "Mark Turner"
                },
                {
                    "authorId": "32565945",
                    "name": "T. Koch"
                }
            ],
            "doi": "10.1007/s00186-022-00777-x",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "6eab7ca8f0a637a1a9cbf80a07fc8d43292e9d94",
            "title": "Generative deep learning for decision making in gas networks",
            "url": "https://www.semanticscholar.org/paper/6eab7ca8f0a637a1a9cbf80a07fc8d43292e9d94",
            "venue": "Mathematical Methods of Operations Research",
            "year": 2021
        },
        {
            "arxivId": "2102.12277",
            "authors": [
                {
                    "authorId": "2143376015",
                    "name": "Yining Wang"
                },
                {
                    "authorId": "2107942948",
                    "name": "Mingzhe Chen"
                },
                {
                    "authorId": "2155029411",
                    "name": "Zhaohui Yang"
                },
                {
                    "authorId": "145412074",
                    "name": "W. Saad"
                },
                {
                    "authorId": "145406704",
                    "name": "T. Luo"
                },
                {
                    "authorId": "144404242",
                    "name": "Shuguang Cui"
                },
                {
                    "authorId": "145967056",
                    "name": "H. Poor"
                }
            ],
            "doi": "10.1109/TWC.2022.3161970",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "cc336144cc6f37e02744a479f80f2f3db3a0462a",
            "title": "Meta-Reinforcement Learning for Reliable Communication in THz/VLC Wireless VR Networks",
            "url": "https://www.semanticscholar.org/paper/cc336144cc6f37e02744a479f80f2f3db3a0462a",
            "venue": "IEEE Transactions on Wireless Communications",
            "year": 2021
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "145401371",
                    "name": "R. Song"
                },
                {
                    "authorId": "120204054",
                    "name": "Fengming Li"
                },
                {
                    "authorId": "2105503057",
                    "name": "Wei Quan"
                },
                {
                    "authorId": "2128655398",
                    "name": "Xuting Yang"
                },
                {
                    "authorId": "32524009",
                    "name": "Jie Zhao"
                }
            ],
            "doi": "10.1016/J.ROBOT.2020.103651",
            "intent": [],
            "isInfluential": false,
            "paperId": "ae8b6635898f438ec7e965817749241300c767cd",
            "title": "Skill learning for robotic assembly based on visual perspectives and force sensing",
            "url": "https://www.semanticscholar.org/paper/ae8b6635898f438ec7e965817749241300c767cd",
            "venue": "Robotics Auton. Syst.",
            "year": 2021
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2087017995",
                    "name": "Hongzhi Xiao"
                },
                {
                    "authorId": "2057590702",
                    "name": "Chen Qiu"
                },
                {
                    "authorId": "2029694981",
                    "name": "Qinglin Yang"
                },
                {
                    "authorId": "2146052866",
                    "name": "Huakun Huang"
                },
                {
                    "authorId": "2115932018",
                    "name": "Junbo Wang"
                },
                {
                    "authorId": "34651006",
                    "name": "Chunhua Su"
                }
            ],
            "doi": "10.1109/MSN50589.2020.00036",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "a3b3f134f0234104bc2b43c0052df2881503ee24",
            "title": "Deep Reinforcement Learning for Optimal Resource Allocation in Blockchain-based IoV Secure Systems",
            "url": "https://www.semanticscholar.org/paper/a3b3f134f0234104bc2b43c0052df2881503ee24",
            "venue": "2020 16th International Conference on Mobility, Sensing and Networking (MSN)",
            "year": 2020
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2108994958",
                    "name": "Mingchao Wang"
                },
                {
                    "authorId": "36175554",
                    "name": "X. Ruan"
                },
                {
                    "authorId": "48386589",
                    "name": "Xiao-qing Zhu"
                }
            ],
            "doi": "10.1109/CAC51589.2020.9326973",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "56da250e01ac3055c66ac28769f047ac29c90045",
            "title": "Heuristic Gait Learning of Quadruped Robot Based on Deep Deterministic Policy Gradient Algorithm",
            "url": "https://www.semanticscholar.org/paper/56da250e01ac3055c66ac28769f047ac29c90045",
            "venue": "2020 Chinese Automation Congress (CAC)",
            "year": 2020
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2288611802",
                    "name": "Menglin Li"
                },
                {
                    "authorId": "2052503739",
                    "name": "Chen Jing"
                },
                {
                    "authorId": "2241097454",
                    "name": "Shaofei Chen"
                },
                {
                    "authorId": "2113825587",
                    "name": "Gao Wei"
                }
            ],
            "doi": "10.23919/CCC50068.2020.9189606",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "3c259fc386985b683630024802fabde8d627102d",
            "title": "A New Reinforcement Learning Algorithm Based on Counterfactual Experience Replay",
            "url": "https://www.semanticscholar.org/paper/3c259fc386985b683630024802fabde8d627102d",
            "venue": "2020 39th Chinese Control Conference (CCC)",
            "year": 2020
        },
        {
            "arxivId": "1907.10097",
            "authors": [
                {
                    "authorId": "3433875",
                    "name": "Sixiong You"
                },
                {
                    "authorId": "1878564",
                    "name": "R. Dai"
                },
                {
                    "authorId": "145240182",
                    "name": "P. Lu"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "cf3df400d1860c5f42452608d34845c2fff16ce2",
            "title": "Learning-based Hamilton-Jacobi-Bellman Methods for Optimal Control.",
            "url": "https://www.semanticscholar.org/paper/cf3df400d1860c5f42452608d34845c2fff16ce2",
            "venue": "",
            "year": 2019
        },
        {
            "arxivId": "1906.01772",
            "authors": [
                {
                    "authorId": "2232505",
                    "name": "Yash Chandak"
                },
                {
                    "authorId": "1709005",
                    "name": "Georgios Theocharous"
                },
                {
                    "authorId": "66908272",
                    "name": "Blossom Metevier"
                },
                {
                    "authorId": "143640165",
                    "name": "P. Thomas"
                }
            ],
            "doi": "10.1609/AAAI.V34I04.5740",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "2c02fb1fb0753db1c4012158f01341c1118c6b09",
            "title": "Reinforcement Learning When All Actions are Not Always Available",
            "url": "https://www.semanticscholar.org/paper/2c02fb1fb0753db1c4012158f01341c1118c6b09",
            "venue": "AAAI",
            "year": 2019
        },
        {
            "arxivId": "1901.07159",
            "authors": [
                {
                    "authorId": "2086783951",
                    "name": "Fan-Xu Meng"
                },
                {
                    "authorId": "2149069496",
                    "name": "Peng Chen"
                },
                {
                    "authorId": "2858143",
                    "name": "Lenan Wu"
                },
                {
                    "authorId": "145511976",
                    "name": "Julian Cheng"
                }
            ],
            "doi": "10.1109/TWC.2020.3001736",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "96811236da814c5a5fdc327f65c91efcf5bd2044",
            "title": "Power Allocation in Multi-User Cellular Networks: Deep Reinforcement Learning Approaches",
            "url": "https://www.semanticscholar.org/paper/96811236da814c5a5fdc327f65c91efcf5bd2044",
            "venue": "IEEE Transactions on Wireless Communications",
            "year": 2019
        },
        {
            "arxivId": "1812.01488",
            "authors": [
                {
                    "authorId": "143946241",
                    "name": "Saket Tiwari"
                },
                {
                    "authorId": "143640165",
                    "name": "P. Thomas"
                }
            ],
            "doi": "10.1609/aaai.v33i01.33015175",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "b83a550a85a6852517a36029fe7f64c554383504",
            "title": "Natural Option Critic",
            "url": "https://www.semanticscholar.org/paper/b83a550a85a6852517a36029fe7f64c554383504",
            "venue": "AAAI",
            "year": 2018
        },
        {
            "arxivId": "1806.05618",
            "authors": [
                {
                    "authorId": "145388375",
                    "name": "M. Papini"
                },
                {
                    "authorId": "51035180",
                    "name": "Damiano Binaghi"
                },
                {
                    "authorId": "51032963",
                    "name": "Giuseppe Canonaco"
                },
                {
                    "authorId": "6234609",
                    "name": "Matteo Pirotta"
                },
                {
                    "authorId": "1792167",
                    "name": "Marcello Restelli"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "108b2ea6100d71fd25e3f71743c1e5c4674d6d8c",
            "title": "Stochastic Variance-Reduced Policy Gradient",
            "url": "https://www.semanticscholar.org/paper/108b2ea6100d71fd25e3f71743c1e5c4674d6d8c",
            "venue": "ICML",
            "year": 2018
        },
        {
            "arxivId": "1802.10031",
            "authors": [
                {
                    "authorId": "145499435",
                    "name": "G. Tucker"
                },
                {
                    "authorId": "9692128",
                    "name": "Surya Bhupatiraju"
                },
                {
                    "authorId": "2046135",
                    "name": "S. Gu"
                },
                {
                    "authorId": "145369890",
                    "name": "Richard E. Turner"
                },
                {
                    "authorId": "1744700",
                    "name": "Zoubin Ghahramani"
                },
                {
                    "authorId": "1736651",
                    "name": "S. Levine"
                }
            ],
            "doi": "10.17863/CAM.23539",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "8a05d72b6f54479c5ab3ceaccd221b2119f0ea7d",
            "title": "The Mirage of Action-Dependent Baselines in Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/8a05d72b6f54479c5ab3ceaccd221b2119f0ea7d",
            "venue": "ICML",
            "year": 2018
        },
        {
            "arxivId": "1801.03326",
            "authors": [
                {
                    "authorId": "2474449",
                    "name": "K. Ciosek"
                },
                {
                    "authorId": "1766767",
                    "name": "Shimon Whiteson"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "cf9d6a148462a66964d891c5d32f92d38a75d1db",
            "title": "Expected Policy Gradients for Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/cf9d6a148462a66964d891c5d32f92d38a75d1db",
            "venue": "J. Mach. Learn. Res.",
            "year": 2018
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2143855835",
                    "name": "Hao Liu"
                },
                {
                    "authorId": "22758695",
                    "name": "Yihao Feng"
                },
                {
                    "authorId": "2117695125",
                    "name": "Yi Mao"
                },
                {
                    "authorId": "24982365",
                    "name": "Dengyong Zhou"
                },
                {
                    "authorId": "143718676",
                    "name": "Jian Peng"
                },
                {
                    "authorId": "47362268",
                    "name": "Qiang Liu"
                }
            ],
            "doi": null,
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "4d93459b5be1e0cba5612c001a000aad9eff985a",
            "title": "Action-depedent Control Variates for Policy Optimization via Stein's Identity",
            "url": "https://www.semanticscholar.org/paper/4d93459b5be1e0cba5612c001a000aad9eff985a",
            "venue": "",
            "year": 2017
        },
        {
            "arxivId": "1710.11198",
            "authors": [
                {
                    "authorId": "2143855921",
                    "name": "Hao Liu"
                },
                {
                    "authorId": "22758695",
                    "name": "Yihao Feng"
                },
                {
                    "authorId": "2117695125",
                    "name": "Yi Mao"
                },
                {
                    "authorId": "24982365",
                    "name": "Dengyong Zhou"
                },
                {
                    "authorId": "143718676",
                    "name": "Jian Peng"
                },
                {
                    "authorId": "47362268",
                    "name": "Qiang Liu"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "3d58ab2b6cc503012496d16aac8155550aac6afa",
            "title": "Sample-efficient Policy Optimization with Stein Control Variate",
            "url": "https://www.semanticscholar.org/paper/3d58ab2b6cc503012496d16aac8155550aac6afa",
            "venue": "ArXiv",
            "year": 2017
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "33802689",
                    "name": "V. Singh"
                },
                {
                    "authorId": "143606925",
                    "name": "K. Willcox"
                }
            ],
            "doi": "10.12783/SHM2017/13943",
            "intent": [],
            "isInfluential": false,
            "paperId": "792c48d6b90262678600e0e18a85d82127e6585e",
            "title": "Engineering Design with Digital Thread",
            "url": "https://www.semanticscholar.org/paper/792c48d6b90262678600e0e18a85d82127e6585e",
            "venue": "AIAA Journal",
            "year": 2017
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2240250960",
                    "name": "Qingyu Liu"
                },
                {
                    "authorId": "2240093998",
                    "name": "Duo Xu"
                },
                {
                    "authorId": "2240082275",
                    "name": "Bing Yuan"
                },
                {
                    "authorId": "2240076656",
                    "name": "Zian Mou"
                },
                {
                    "authorId": "2145298104",
                    "name": "Min Wang"
                }
            ],
            "doi": "10.1109/ACCESS.2023.3313637",
            "intent": [],
            "isInfluential": false,
            "paperId": "14287da068c730f11c33c8b2f9b2090a20be7223",
            "title": "Distance-Controllable Long Jump of Quadruped Robot Based on Parameter Optimization Using Deep Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/14287da068c730f11c33c8b2f9b2090a20be7223",
            "venue": "IEEE Access",
            "year": 2023
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "49306150",
                    "name": "Thomas Spooner"
                },
                {
                    "authorId": "38921168",
                    "name": "N. Vadori"
                },
                {
                    "authorId": "27411264",
                    "name": "Sumitra Ganesh"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "7640f093b007b95029ef33bd3e8744d07f644cec",
            "title": "Causal Policy Gradients",
            "url": "https://www.semanticscholar.org/paper/7640f093b007b95029ef33bd3e8744d07f644cec",
            "venue": "ArXiv",
            "year": 2021
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "123959763",
                    "name": "Lovis Anderson"
                },
                {
                    "authorId": "2093407075",
                    "name": "Mark Turner"
                },
                {
                    "authorId": "2054952642",
                    "name": "Thorsten Koch"
                },
                {
                    "authorId": "13979888",
                    "name": "January"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "43b6bb142349ba6d49ed3ebc78ac4d3409014b79",
            "title": "A generative deep learning approach towards decisions in transient gas networks",
            "url": "https://www.semanticscholar.org/paper/43b6bb142349ba6d49ed3ebc78ac4d3409014b79",
            "venue": "",
            "year": 2021
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "49306150",
                    "name": "Thomas Spooner"
                },
                {
                    "authorId": "38921168",
                    "name": "N. Vadori"
                },
                {
                    "authorId": "27411264",
                    "name": "Sumitra Ganesh"
                }
            ],
            "doi": null,
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "6e50409be614e8fcf0acda8377193522fbbb71ad",
            "title": "Causal Policy Gradients: Leveraging Structure for Ef\ufb01cient Learning in (Factored) MOMDPs",
            "url": "https://www.semanticscholar.org/paper/6e50409be614e8fcf0acda8377193522fbbb71ad",
            "venue": "",
            "year": 2021
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "71309987",
                    "name": "Chris Nota"
                },
                {
                    "authorId": "143640165",
                    "name": "P. Thomas"
                },
                {
                    "authorId": "145471664",
                    "name": "Bruno C. da Silva"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "9696cf55d042ad0d158308b1a2c33a89cc040b63",
            "title": "Posterior Value Functions: Hindsight Baselines for Policy Gradient Methods",
            "url": "https://www.semanticscholar.org/paper/9696cf55d042ad0d158308b1a2c33a89cc040b63",
            "venue": "ICML",
            "year": 2021
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2146565949",
                    "name": "Guixuan Wen"
                },
                {
                    "authorId": "1804764",
                    "name": "Kaigui Wu"
                }
            ],
            "doi": null,
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "778050b4bb4e63d43864981de9a155ceb560fc0e",
            "title": "Building Decision Tree for Imbalanced Classification via Deep Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/778050b4bb4e63d43864981de9a155ceb560fc0e",
            "venue": "ACML",
            "year": 2021
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "33843425",
                    "name": "Hootan Rashtian"
                },
                {
                    "authorId": "1755223",
                    "name": "S. Gopalakrishnan"
                }
            ],
            "doi": "10.1109/ACCESS.2020.2994600",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "b680572ff7cff2f0dea0ad1585166d4fd56d16b5",
            "title": "Using Deep Reinforcement Learning to Improve Sensor Selection in the Internet of Things",
            "url": "https://www.semanticscholar.org/paper/b680572ff7cff2f0dea0ad1585166d4fd56d16b5",
            "venue": "IEEE Access",
            "year": 2020
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "33843425",
                    "name": "Hootan Rashtian"
                }
            ],
            "doi": "10.14288/1.0394147",
            "intent": [],
            "isInfluential": false,
            "paperId": "47a0d26aceeacb71b7f04ecfecd8b96c796255aa",
            "title": "Reinforcement learning for data scheduling in internet of things (IoT) networks",
            "url": "https://www.semanticscholar.org/paper/47a0d26aceeacb71b7f04ecfecd8b96c796255aa",
            "venue": "",
            "year": 2020
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2140068196",
                    "name": "Yu Chang"
                },
                {
                    "authorId": "1878461",
                    "name": "Hang Lei"
                },
                {
                    "authorId": "1597361648",
                    "name": "Xiaoyu Li"
                },
                {
                    "authorId": "2108573927",
                    "name": "Yiming Huang"
                }
            ],
            "doi": null,
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "6fbf313b7fd9f193225861db4c2e4f4475cce17b",
            "title": "A Reinforced Improved Attention Model for Abstractive Text Summarization",
            "url": "https://www.semanticscholar.org/paper/6fbf313b7fd9f193225861db4c2e4f4475cce17b",
            "venue": "",
            "year": 2019
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "118055456",
                    "name": "Anneli Engstr\u00f6m"
                },
                {
                    "authorId": "151054421",
                    "name": "Joel Lidin"
                },
                {
                    "authorId": "97635648",
                    "name": "Gustav Molander"
                },
                {
                    "authorId": "151153185",
                    "name": "Noa Onoszko"
                },
                {
                    "authorId": "151161151",
                    "name": "O. M\u00e5nsson"
                },
                {
                    "authorId": "151026741",
                    "name": "Hugo \u00d6lund"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "32c946ae39b3539a23a5a3e20ea2cd015969c529",
            "title": "Pathfinding med reinforcement learning i delvis observerbara milj\u00f6er",
            "url": "https://www.semanticscholar.org/paper/32c946ae39b3539a23a5a3e20ea2cd015969c529",
            "venue": "",
            "year": 2019
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2143855893",
                    "name": "Hao Liu"
                }
            ],
            "doi": null,
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "e70f515be612a8da557c75bd5de1afc9f2bebb7f",
            "title": "A CTION-DEPENDENT C ONTROL V ARIATES FOR P OL-ICY O PTIMIZATION VIA S TEIN \u2019 S I DENTITY",
            "url": "https://www.semanticscholar.org/paper/e70f515be612a8da557c75bd5de1afc9f2bebb7f",
            "venue": "",
            "year": 2018
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2143855893",
                    "name": "Hao Liu"
                }
            ],
            "doi": null,
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "ef8c1d0a8450d11dc984a2a33b6c0a3efa6728a6",
            "title": "A CTION-DEPENDENT C ONTROL V ARIATES FOR P OL-ICY O PTIMIZATION VIA S TEIN \u2019 S I DENTITY",
            "url": "https://www.semanticscholar.org/paper/ef8c1d0a8450d11dc984a2a33b6c0a3efa6728a6",
            "venue": "",
            "year": 2018
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "66144778",
                    "name": "Arjun Neervannan"
                }
            ],
            "doi": "10.22364/bjmc.2018.6.4.02",
            "intent": [],
            "isInfluential": false,
            "paperId": "244d427585df221c34e8c2c657fa0c6daf4a94bc",
            "title": "Evaluating the Effectiveness of Deep Reinforcement Learning Algorithms in a Walking Environment",
            "url": "https://www.semanticscholar.org/paper/244d427585df221c34e8c2c657fa0c6daf4a94bc",
            "venue": "Balt. J. Mod. Comput.",
            "year": 2018
        }
    ],
    "corpusId": 12355382,
    "doi": null,
    "fieldsOfStudy": [
        "Computer Science"
    ],
    "influentialCitationCount": 0,
    "isOpenAccess": false,
    "isPublisherLicensed": true,
    "is_open_access": false,
    "is_publisher_licensed": true,
    "numCitedBy": 50,
    "numCiting": 3,
    "paperId": "5dc5782ff93cf641463bcfffa14e791317fb2a3b",
    "references": [
        {
            "arxivId": "1512.09075",
            "authors": [
                {
                    "authorId": "143640165",
                    "name": "P. Thomas"
                }
            ],
            "doi": null,
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "9d610a65203c189045982e656f22ff20204aded4",
            "title": "A Notation for Markov Decision Processes",
            "url": "https://www.semanticscholar.org/paper/9d610a65203c189045982e656f22ff20204aded4",
            "venue": "ArXiv",
            "year": 2015
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "1699645",
                    "name": "R. Sutton"
                },
                {
                    "authorId": "145689002",
                    "name": "David A. McAllester"
                },
                {
                    "authorId": "1699868",
                    "name": "Satinder Singh"
                },
                {
                    "authorId": "144830983",
                    "name": "Y. Mansour"
                }
            ],
            "doi": null,
            "intent": [
                "background",
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "a20f0ce0616def7cc9a87446c228906cd5da093b",
            "title": "Policy Gradient Methods for Reinforcement Learning with Function Approximation",
            "url": "https://www.semanticscholar.org/paper/a20f0ce0616def7cc9a87446c228906cd5da093b",
            "venue": "NIPS",
            "year": 1999
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "47392513",
                    "name": "Jonathan Baxter"
                },
                {
                    "authorId": "1745169",
                    "name": "P. Bartlett"
                }
            ],
            "doi": null,
            "intent": [
                "background",
                "methodology"
            ],
            "isInfluential": true,
            "paperId": "d2a1fd4998a9d690cf9e91012e37407b9c65fb3f",
            "title": "Direct Gradient-Based Reinforcement Learning: I. Gradient Estimation Algorithms",
            "url": "https://www.semanticscholar.org/paper/d2a1fd4998a9d690cf9e91012e37407b9c65fb3f",
            "venue": "",
            "year": 1999
        }
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        },
        {
            "category": "Mathematics",
            "source": "s2-fos-model"
        }
    ],
    "title": "Policy Gradient Methods for Reinforcement Learning with Function Approximation and Action-Dependent Baselines",
    "topics": [],
    "url": "https://www.semanticscholar.org/paper/5dc5782ff93cf641463bcfffa14e791317fb2a3b",
    "venue": "arXiv.org",
    "year": 2017
}
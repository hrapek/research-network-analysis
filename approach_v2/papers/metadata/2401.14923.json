{
    "abstract": "Many important behavior changes are frictionful; they require individuals to expend effort over a long period with little immediate gratification. Here, an artificial intelligence (AI) agent can provide personalized interventions to help individuals stick to their goals. In these settings, the AI agent must personalize rapidly (before the individual disengages) and interpretably, to help us understand the behavioral interventions. In this paper, we introduce Behavior Model Reinforcement Learning (BMRL), a framework in which an AI agent intervenes on the parameters of a Markov Decision Process (MDP) belonging to a boundedly rational human agent. Our formulation of the human decision-maker as a planning agent allows us to attribute undesirable human policies (ones that do not lead to the goal) to their maladapted MDP parameters, such as an extremely low discount factor. Furthermore, we propose a class of tractable human models that captures fundamental behaviors in frictionful tasks. Introducing a notion of MDP equivalence specific to BMRL, we theoretically and empirically show that AI planning with our human models can lead to helpful policies on a wide range of more complex, ground-truth humans.",
    "arxivId": "2401.14923",
    "authors": [
        {
            "authorId": "2281639518",
            "name": "Eura Nofshin",
            "url": "https://www.semanticscholar.org/author/2281639518"
        },
        {
            "authorId": "15187083",
            "name": "S. Swaroop",
            "url": "https://www.semanticscholar.org/author/15187083"
        },
        {
            "authorId": "3291783",
            "name": "Weiwei Pan",
            "url": "https://www.semanticscholar.org/author/3291783"
        },
        {
            "authorId": "2271930263",
            "name": "Susan A. Murphy",
            "url": "https://www.semanticscholar.org/author/2271930263"
        },
        {
            "authorId": "1388372395",
            "name": "F. Doshi-Velez",
            "url": "https://www.semanticscholar.org/author/1388372395"
        }
    ],
    "citationVelocity": 0,
    "citations": [
        {
            "arxivId": "2402.05605",
            "authors": [
                {
                    "authorId": "2054439565",
                    "name": "Andrew Fuchs"
                },
                {
                    "authorId": "2174176466",
                    "name": "A. Passarella"
                },
                {
                    "authorId": "2060071082",
                    "name": "M. Conti"
                }
            ],
            "doi": "10.1145/3687130",
            "intent": [],
            "isInfluential": false,
            "paperId": "1fef6bf6db93c130587c00bc3c5759de26087302",
            "title": "Optimizing Delegation in Collaborative Human-AI Hybrid Teams",
            "url": "https://www.semanticscholar.org/paper/1fef6bf6db93c130587c00bc3c5759de26087302",
            "venue": "ACM Transactions on Autonomous and Adaptive Systems",
            "year": 2024
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2281639518",
                    "name": "Eura Nofshin"
                }
            ],
            "doi": "10.5555/3635637.3663279",
            "intent": [
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "5ff892e06ea21db166067a0eaf3c8d2c11de052a",
            "title": "Leveraging Interpretable Human Models to Personalize AI Interventions for Behavior Change",
            "url": "https://www.semanticscholar.org/paper/5ff892e06ea21db166067a0eaf3c8d2c11de052a",
            "venue": "AAMAS",
            "year": 2024
        }
    ],
    "corpusId": 267301096,
    "doi": "10.48550/arXiv.2401.14923",
    "fieldsOfStudy": [
        "Computer Science",
        "Medicine"
    ],
    "influentialCitationCount": 0,
    "isOpenAccess": false,
    "isPublisherLicensed": true,
    "is_open_access": false,
    "is_publisher_licensed": true,
    "numCitedBy": 2,
    "numCiting": 50,
    "paperId": "880d3d952f95bc46cd447efaeb45a17d3cf05dd8",
    "references": [
        {
            "arxivId": "2310.18591",
            "authors": [
                {
                    "authorId": "123723354",
                    "name": "Daniel Jarrett"
                },
                {
                    "authorId": "83246796",
                    "name": "Alihan H\u00fcy\u00fck"
                },
                {
                    "authorId": "1729969",
                    "name": "M. Schaar"
                }
            ],
            "doi": "10.48550/arXiv.2310.18591",
            "intent": [],
            "isInfluential": false,
            "paperId": "4d7032df86929584bb7a82e7bdb3a138f12f0719",
            "title": "Inverse Decision Modeling: Learning Interpretable Representations of Behavior",
            "url": "https://www.semanticscholar.org/paper/4d7032df86929584bb7a82e7bdb3a138f12f0719",
            "venue": "ICML",
            "year": 2023
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2116649329",
                    "name": "Joonyoung Park"
                },
                {
                    "authorId": "143924171",
                    "name": "Uichin Lee"
                }
            ],
            "doi": "10.1145/3596240",
            "intent": [],
            "isInfluential": false,
            "paperId": "27da5d688140ff06488b12f8644f615199a13580",
            "title": "Understanding Disengagement in Just-in-Time Mobile Health Interventions",
            "url": "https://www.semanticscholar.org/paper/27da5d688140ff06488b12f8644f615199a13580",
            "venue": "Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.",
            "year": 2023
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2051613108",
                    "name": "Jeremiah M. Brown"
                },
                {
                    "authorId": "31290640",
                    "name": "Jeffrey S. Stein"
                }
            ],
            "doi": "10.3389/fpubh.2022.1020171",
            "intent": [],
            "isInfluential": false,
            "paperId": "f14f3bcd23196f67cd011eafcaa9e4bebc377e72",
            "title": "Putting prospection into practice: Methodological considerations in the use of episodic future thinking to reduce delay discounting and maladaptive health behaviors",
            "url": "https://www.semanticscholar.org/paper/f14f3bcd23196f67cd011eafcaa9e4bebc377e72",
            "venue": "Frontiers in Public Health",
            "year": 2022
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "9551276",
                    "name": "Xuhai Xu"
                }
            ],
            "doi": "10.1145/3526114.3558524",
            "intent": [],
            "isInfluential": false,
            "paperId": "8b14b3470369f8d8a2ef67feb7fa609c08fda8bc",
            "title": "Towards Future Health and Well-being: Bridging Behavior Modeling and Intervention",
            "url": "https://www.semanticscholar.org/paper/8b14b3470369f8d8a2ef67feb7fa609c08fda8bc",
            "venue": "UIST",
            "year": 2022
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2116615581",
                    "name": "Guanghui Yu"
                },
                {
                    "authorId": "40029912",
                    "name": "Chien-Ju Ho"
                }
            ],
            "doi": "10.24963/ijcai.2022/84",
            "intent": [],
            "isInfluential": false,
            "paperId": "ad118464028fe3d3a239401539e5af5b1249ecde",
            "title": "Environment Design for Biased Decision Makers",
            "url": "https://www.semanticscholar.org/paper/ad118464028fe3d3a239401539e5af5b1249ecde",
            "venue": "IJCAI",
            "year": 2022
        },
        {
            "arxivId": "2206.03944",
            "authors": [
                {
                    "authorId": "2113964440",
                    "name": "Anna L. Trella"
                },
                {
                    "authorId": "2119059281",
                    "name": "Kelly W. Zhang"
                },
                {
                    "authorId": "1397927581",
                    "name": "I. Nahum-Shani"
                },
                {
                    "authorId": "144644109",
                    "name": "V. Shetty"
                },
                {
                    "authorId": "1388372395",
                    "name": "F. Doshi-Velez"
                },
                {
                    "authorId": "144180010",
                    "name": "S. Murphy"
                }
            ],
            "doi": "10.3390/a15080255",
            "intent": [],
            "isInfluential": false,
            "paperId": "4f39aa0047396a55c85d1d98b2c43353e649abec",
            "title": "Designing Reinforcement Learning Algorithms for Digital Interventions: Pre-Implementation Guidelines",
            "url": "https://www.semanticscholar.org/paper/4f39aa0047396a55c85d1d98b2c43353e649abec",
            "venue": "Algorithms",
            "year": 2022
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2152736487",
                    "name": "Chao Zhang"
                },
                {
                    "authorId": "1717534",
                    "name": "J. Vanschoren"
                },
                {
                    "authorId": "2171579599",
                    "name": "Arlette van Wissen"
                },
                {
                    "authorId": "87792747",
                    "name": "D. Lakens"
                },
                {
                    "authorId": "117843365",
                    "name": "Boris De Ruyter"
                },
                {
                    "authorId": "1679478",
                    "name": "W. Ijsselsteijn"
                }
            ],
            "doi": "10.1007/s11257-022-09326-x",
            "intent": [],
            "isInfluential": false,
            "paperId": "f16d5f9365f80147b2642c5b786d12791f9220e3",
            "title": "Theory-based habit modeling for enhancing behavior prediction in behavior change support systems",
            "url": "https://www.semanticscholar.org/paper/f16d5f9365f80147b2642c5b786d12791f9220e3",
            "venue": "User Modeling and User-Adapted Interaction",
            "year": 2022
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2109511123",
                    "name": "Shihan Wang"
                },
                {
                    "authorId": "2152737012",
                    "name": "Chao Zhang"
                },
                {
                    "authorId": "1804676",
                    "name": "B. Kr\u00f6se"
                },
                {
                    "authorId": "47662867",
                    "name": "H. V. Hoof"
                }
            ],
            "doi": "10.1007/s10916-021-01773-0",
            "intent": [],
            "isInfluential": false,
            "paperId": "f481fd4d3c175ce3e75264f5c14384f0771270e1",
            "title": "Optimizing Adaptive Notifications in Mobile Health Interventions Systems: Reinforcement Learning from a Data-driven Behavioral Simulator",
            "url": "https://www.semanticscholar.org/paper/f481fd4d3c175ce3e75264f5c14384f0771270e1",
            "venue": "Journal of Medical Systems",
            "year": 2021
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2455130",
                    "name": "V. Taylor"
                },
                {
                    "authorId": "1573830065",
                    "name": "I. Moseley"
                },
                {
                    "authorId": "2218687967",
                    "name": "S. Sun"
                },
                {
                    "authorId": "2109281073",
                    "name": "R. Smith"
                },
                {
                    "authorId": "51173468",
                    "name": "A. Roy"
                },
                {
                    "authorId": "2120198",
                    "name": "V. U. Ludwig"
                },
                {
                    "authorId": "10686504",
                    "name": "J. Brewer"
                }
            ],
            "doi": "10.1556/2006.2021.00020",
            "intent": [],
            "isInfluential": false,
            "paperId": "d519409889d8266df57e12754b0b343ec2fef586",
            "title": "Awareness drives changes in reward value which predict eating behavior change: Probing reinforcement learning using experience sampling from mobile mindfulness training for maladaptive eating",
            "url": "https://www.semanticscholar.org/paper/d519409889d8266df57e12754b0b343ec2fef586",
            "venue": "Journal of behavioral addictions",
            "year": 2021
        },
        {
            "arxivId": "2103.06160",
            "authors": [
                {
                    "authorId": "2152737012",
                    "name": "Chao Zhang"
                },
                {
                    "authorId": "2109511123",
                    "name": "Shihan Wang"
                },
                {
                    "authorId": "3206457",
                    "name": "H. Aarts"
                },
                {
                    "authorId": "1707738",
                    "name": "M. Dastani"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "84b1baf0f667e1286714b50c9b5fcddfa89387d0",
            "title": "Using Cognitive Models to Train Warm Start Reinforcement Learning Agents for Human-Computer Interactions",
            "url": "https://www.semanticscholar.org/paper/84b1baf0f667e1286714b50c9b5fcddfa89387d0",
            "venue": "ArXiv",
            "year": 2021
        },
        {
            "arxivId": "2011.03275",
            "authors": [
                {
                    "authorId": "72446930",
                    "name": "Jonas Tebbe"
                },
                {
                    "authorId": "2007716504",
                    "name": "Lukas Krauch"
                },
                {
                    "authorId": "2329796",
                    "name": "Yapeng Gao"
                },
                {
                    "authorId": "144625394",
                    "name": "A. Zell"
                }
            ],
            "doi": "10.1109/ICRA48506.2021.9560764",
            "intent": [],
            "isInfluential": false,
            "paperId": "d0b69a1885781e38de0f2cb81651fb852799ba3a",
            "title": "Sample-efficient Reinforcement Learning in Robotic Table Tennis",
            "url": "https://www.semanticscholar.org/paper/d0b69a1885781e38de0f2cb81651fb852799ba3a",
            "venue": "2021 IEEE International Conference on Robotics and Automation (ICRA)",
            "year": 2020
        },
        {
            "arxivId": "2008.02840",
            "authors": [
                {
                    "authorId": "37372079",
                    "name": "S. Reddy"
                },
                {
                    "authorId": "1736651",
                    "name": "S. Levine"
                },
                {
                    "authorId": "2745001",
                    "name": "A. Dragan"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "a7a8e68befc76e80d8cfa0b033ffc4387b78d6e0",
            "title": "Assisted Perception: Optimizing Observations to Communicate State",
            "url": "https://www.semanticscholar.org/paper/a7a8e68befc76e80d8cfa0b033ffc4387b78d6e0",
            "venue": "CoRL",
            "year": 2020
        },
        {
            "arxivId": "2006.07532",
            "authors": [
                {
                    "authorId": "120636597",
                    "name": "Tan Zhi-Xuan"
                },
                {
                    "authorId": "1750402174",
                    "name": "Jordyn L. Mann"
                },
                {
                    "authorId": "39047272",
                    "name": "Tom Silver"
                },
                {
                    "authorId": "1763295",
                    "name": "J. Tenenbaum"
                },
                {
                    "authorId": "1735083",
                    "name": "Vikash K. Mansinghka"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "82a8b7164f377c139e848986a2980a6678aa6cd3",
            "title": "Online Bayesian Goal Inference for Boundedly-Rational Planning Agents",
            "url": "https://www.semanticscholar.org/paper/82a8b7164f377c139e848986a2980a6678aa6cd3",
            "venue": "NeurIPS",
            "year": 2020
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "23066716",
                    "name": "C\u00e9sar A. Mart\u00edn"
                },
                {
                    "authorId": "145546431",
                    "name": "D. Rivera"
                },
                {
                    "authorId": "3062685",
                    "name": "E. Hekler"
                },
                {
                    "authorId": "34955047",
                    "name": "W. Riley"
                },
                {
                    "authorId": "2862455",
                    "name": "M. Buman"
                },
                {
                    "authorId": "144010876",
                    "name": "M. Adams"
                },
                {
                    "authorId": "19231969",
                    "name": "Alicia B. Magann"
                }
            ],
            "doi": "10.1109/TCST.2018.2873538",
            "intent": [],
            "isInfluential": false,
            "paperId": "7208557dac4e314cf275959fae16421bc21ab9f0",
            "title": "Development of a Control-Oriented Model of Social Cognitive Theory for Optimized mHealth Behavioral Interventions",
            "url": "https://www.semanticscholar.org/paper/7208557dac4e314cf275959fae16421bc21ab9f0",
            "venue": "IEEE Transactions on Control Systems Technology",
            "year": 2020
        },
        {
            "arxivId": "2002.11963",
            "authors": [
                {
                    "authorId": "3468383",
                    "name": "Elise van der Pol"
                },
                {
                    "authorId": "41016725",
                    "name": "Thomas Kipf"
                },
                {
                    "authorId": "1799949",
                    "name": "F. Oliehoek"
                },
                {
                    "authorId": "1678311",
                    "name": "M. Welling"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "7d2c7517a59669108588b98de1876f54ca23f6b2",
            "title": "Plannable Approximations to MDP Homomorphisms: Equivariance under Actions",
            "url": "https://www.semanticscholar.org/paper/7d2c7517a59669108588b98de1876f54ca23f6b2",
            "venue": "AAMAS",
            "year": 2020
        },
        {
            "arxivId": "1907.03613",
            "authors": [
                {
                    "authorId": "2108795581",
                    "name": "Yuxiang Yang"
                },
                {
                    "authorId": "2758571",
                    "name": "Ken Caluwaerts"
                },
                {
                    "authorId": "2106754",
                    "name": "Atil Iscen"
                },
                {
                    "authorId": "28292148",
                    "name": "Tingnan Zhang"
                },
                {
                    "authorId": "1739176520",
                    "name": "Jie Tan"
                },
                {
                    "authorId": "1808676",
                    "name": "Vikas Sindhwani"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "d078f720a7fb0e1961a17ea967332599e6d2b692",
            "title": "Data Efficient Reinforcement Learning for Legged Robots",
            "url": "https://www.semanticscholar.org/paper/d078f720a7fb0e1961a17ea967332599e6d2b692",
            "venue": "CoRL",
            "year": 2019
        },
        {
            "arxivId": "1908.05546",
            "authors": [
                {
                    "authorId": "34184496",
                    "name": "M. Thabet"
                },
                {
                    "authorId": "3366919",
                    "name": "Massimiliano Patacchiola"
                },
                {
                    "authorId": "1692929",
                    "name": "A. Cangelosi"
                }
            ],
            "doi": "10.1109/IROS40897.2019.8967834",
            "intent": [],
            "isInfluential": false,
            "paperId": "0def8f1b4893f87289b33d776fda9b96a4cb3eb3",
            "title": "Sample-efficient Deep Reinforcement Learning with Imaginary Rollouts for Human-Robot Interaction",
            "url": "https://www.semanticscholar.org/paper/0def8f1b4893f87289b33d776fda9b96a4cb3eb3",
            "venue": "2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)",
            "year": 2019
        },
        {
            "arxivId": "1906.05803",
            "authors": [
                {
                    "authorId": "1909685",
                    "name": "Quanying Liu"
                },
                {
                    "authorId": "2119019973",
                    "name": "Haiyan Wu"
                },
                {
                    "authorId": "38696911",
                    "name": "Anqi Liu"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "7c798a70cd4a2ef23434ebd6ada743c9cc3c5e6d",
            "title": "Modeling and Interpreting Real-world Human Risk Decision Making with Inverse Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/7c798a70cd4a2ef23434ebd6ada743c9cc3c5e6d",
            "venue": "ArXiv",
            "year": 2019
        },
        {
            "arxivId": "1906.09624",
            "authors": [
                {
                    "authorId": "40947489",
                    "name": "Rohin Shah"
                },
                {
                    "authorId": "104391473",
                    "name": "Noah Gundotra"
                },
                {
                    "authorId": "1689992",
                    "name": "P. Abbeel"
                },
                {
                    "authorId": "2745001",
                    "name": "A. Dragan"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "3771ee5dff0beb52e13428b9f617b7f59a3968da",
            "title": "On the Feasibility of Learning, Rather than Assuming, Human Biases for Reward Inference",
            "url": "https://www.semanticscholar.org/paper/3771ee5dff0beb52e13428b9f617b7f59a3968da",
            "venue": "ICML",
            "year": 2019
        },
        {
            "arxivId": "1904.06387",
            "authors": [
                {
                    "authorId": "47627548",
                    "name": "Daniel S. Brown"
                },
                {
                    "authorId": "3461969",
                    "name": "Wonjoon Goo"
                },
                {
                    "authorId": "40608791",
                    "name": "P. Nagarajan"
                },
                {
                    "authorId": "2791038",
                    "name": "S. Niekum"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "2fc328f3702d6f8730235b1b3ddf7cc5fc096c0d",
            "title": "Extrapolating Beyond Suboptimal Demonstrations via Inverse Reinforcement Learning from Observations",
            "url": "https://www.semanticscholar.org/paper/2fc328f3702d6f8730235b1b3ddf7cc5fc096c0d",
            "venue": "ICML",
            "year": 2019
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "88728681",
                    "name": "Aaquib Tabrez"
                },
                {
                    "authorId": "145518539",
                    "name": "Shivendra Agrawal"
                },
                {
                    "authorId": "30325272",
                    "name": "Bradley Hayes"
                }
            ],
            "doi": "10.1109/HRI.2019.8673104",
            "intent": [],
            "isInfluential": false,
            "paperId": "8ac79fb5282c1536a6b14fa62a90db660e50fc04",
            "title": "Explanation-Based Reward Coaching to Improve Human Performance via Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/8ac79fb5282c1536a6b14fa62a90db660e50fc04",
            "venue": "2019 14th ACM/IEEE International Conference on Human-Robot Interaction (HRI)",
            "year": 2019
        },
        {
            "arxivId": "1902.06865",
            "authors": [
                {
                    "authorId": "26958176",
                    "name": "W. Fedus"
                },
                {
                    "authorId": "52382152",
                    "name": "Carles Gelada"
                },
                {
                    "authorId": "1751762",
                    "name": "Yoshua Bengio"
                },
                {
                    "authorId": "1792298",
                    "name": "Marc G. Bellemare"
                },
                {
                    "authorId": "1777528",
                    "name": "H. Larochelle"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "c3f13bcbd19ed1082f95cb042f8f4dd593b12764",
            "title": "Hyperbolic Discounting and Learning over Multiple Horizons",
            "url": "https://www.semanticscholar.org/paper/c3f13bcbd19ed1082f95cb042f8f4dd593b12764",
            "venue": "ArXiv",
            "year": 2019
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "3145149",
                    "name": "S. A. Tabatabaei"
                },
                {
                    "authorId": "144074133",
                    "name": "M. Hoogendoorn"
                },
                {
                    "authorId": "145635423",
                    "name": "A. V. Halteren"
                }
            ],
            "doi": "10.1007/978-3-030-03098-8_19",
            "intent": [],
            "isInfluential": false,
            "paperId": "5566f538540b28e0692da6400f0674091b119dc0",
            "title": "Narrowing Reinforcement Learning: Overcoming the Cold Start Problem for Personalized Health Interventions",
            "url": "https://www.semanticscholar.org/paper/5566f538540b28e0692da6400f0674091b119dc0",
            "venue": "PRIMA",
            "year": 2018
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "143925889",
                    "name": "Mo Zhou"
                },
                {
                    "authorId": "40613216",
                    "name": "Yonatan Dov Mintz"
                },
                {
                    "authorId": "36040454",
                    "name": "Yoshimi Fukuoka"
                },
                {
                    "authorId": "144344283",
                    "name": "Ken Goldberg"
                },
                {
                    "authorId": "145522620",
                    "name": "E. Flowers"
                },
                {
                    "authorId": "46272135",
                    "name": "Philip M. Kaminsky"
                },
                {
                    "authorId": "2078418892",
                    "name": "Alejandro Castillejo"
                },
                {
                    "authorId": "144775461",
                    "name": "A. Aswani"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "782405c860bf3812d9c78bd6bcef17adaf48c033",
            "title": "Personalizing Mobile Fitness Apps using Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/782405c860bf3812d9c78bd6bcef17adaf48c033",
            "venue": "IUI Workshops",
            "year": 2018
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2171455",
                    "name": "N. Mogles"
                },
                {
                    "authorId": "1706904",
                    "name": "J. Padget"
                },
                {
                    "authorId": "1404294410",
                    "name": "Elizabeth Gabe-Thomas"
                },
                {
                    "authorId": "144556654",
                    "name": "I. Walker"
                },
                {
                    "authorId": "2108569467",
                    "name": "Jeehang Lee"
                }
            ],
            "doi": "10.1007/s11257-017-9199-9",
            "intent": [],
            "isInfluential": false,
            "paperId": "2761e8b60091b9ee0c79389262fa59ae2d6b43c3",
            "title": "A computational model for designing energy behaviour change interventions",
            "url": "https://www.semanticscholar.org/paper/2761e8b60091b9ee0c79389262fa59ae2d6b43c3",
            "venue": "User Modeling and User-Adapted Interaction",
            "year": 2017
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "144775461",
                    "name": "A. Aswani"
                },
                {
                    "authorId": "46272135",
                    "name": "Philip M. Kaminsky"
                },
                {
                    "authorId": "40613216",
                    "name": "Yonatan Dov Mintz"
                },
                {
                    "authorId": "145522620",
                    "name": "E. Flowers"
                },
                {
                    "authorId": "36040454",
                    "name": "Yoshimi Fukuoka"
                }
            ],
            "doi": "10.2139/ssrn.2838443",
            "intent": [],
            "isInfluential": false,
            "paperId": "15719c90bed598504511aff1e002118941290f58",
            "title": "Behavioral Modeling in Weight Loss Interventions",
            "url": "https://www.semanticscholar.org/paper/15719c90bed598504511aff1e002118941290f58",
            "venue": "Eur. J. Oper. Res.",
            "year": 2016
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "144980333",
                    "name": "P. Pirolli"
                }
            ],
            "doi": "10.1007/s13142-016-0391-y",
            "intent": [],
            "isInfluential": false,
            "paperId": "767348d1c9b648ea3c38dce543ea0c918f8e1d0d",
            "title": "A computational cognitive model of self-efficacy and daily adherence in mHealth",
            "url": "https://www.semanticscholar.org/paper/767348d1c9b648ea3c38dce543ea0c918f8e1d0d",
            "venue": "Translational behavioral medicine",
            "year": 2016
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2237206",
                    "name": "Joseph R. Fanfarelli"
                },
                {
                    "authorId": "1856774",
                    "name": "Stephanie Vie"
                },
                {
                    "authorId": "3122390",
                    "name": "R. McDaniel"
                }
            ],
            "doi": "10.1145/2792989.2792998",
            "intent": [],
            "isInfluential": false,
            "paperId": "5eeb399b7a2de9ea6939be0ec11fd09f1920a090",
            "title": "Understanding digital badges through feedback, reward, and narrative: a multidisciplinary approach to building better badges in social environments",
            "url": "https://www.semanticscholar.org/paper/5eeb399b7a2de9ea6939be0ec11fd09f1920a090",
            "venue": "CDQR",
            "year": 2015
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2875272",
                    "name": "H. Shteingart"
                },
                {
                    "authorId": "2934154",
                    "name": "Y. Loewenstein"
                }
            ],
            "doi": "10.1016/j.conb.2013.12.004",
            "intent": [],
            "isInfluential": false,
            "paperId": "1cd252b91e8f1fdaf14ca0cb7d8590ce444111c8",
            "title": "Reinforcement learning and human behavior",
            "url": "https://www.semanticscholar.org/paper/1cd252b91e8f1fdaf14ca0cb7d8590ce444111c8",
            "venue": "Current Opinion in Neurobiology",
            "year": 2014
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2407747",
                    "name": "Giles W. Story"
                },
                {
                    "authorId": "2612995",
                    "name": "I. Vlaev"
                },
                {
                    "authorId": "145324953",
                    "name": "B. Seymour"
                },
                {
                    "authorId": "11388466",
                    "name": "A. Darzi"
                },
                {
                    "authorId": "2231343",
                    "name": "R. Dolan"
                }
            ],
            "doi": "10.3389/fnbeh.2014.00076",
            "intent": [],
            "isInfluential": false,
            "paperId": "d464014d8c52305d0689dbbb922d97dfdd0d3bb6",
            "title": "Does temporal discounting explain unhealthy behavior? A systematic review and reinforcement learning perspective",
            "url": "https://www.semanticscholar.org/paper/d464014d8c52305d0689dbbb922d97dfdd0d3bb6",
            "venue": "Front. Behav. Neurosci.",
            "year": 2014
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2196679672",
                    "name": "Irena Moroshko"
                },
                {
                    "authorId": "144175247",
                    "name": "L. Brennan"
                },
                {
                    "authorId": "52009157",
                    "name": "P. O\u2019Brien"
                }
            ],
            "doi": "10.1111/j.1467-789X.2011.00915.x",
            "intent": [],
            "isInfluential": false,
            "paperId": "4a6d885c83883dd75d69cd8cfca21ec0e275cd79",
            "title": "Predictors of dropout in weight loss interventions: a systematic review of the literature",
            "url": "https://www.semanticscholar.org/paper/4a6d885c83883dd75d69cd8cfca21ec0e275cd79",
            "venue": "Obesity reviews : an official journal of the International Association for the Study of Obesity",
            "year": 2011
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "9796712",
                    "name": "Y. Niv"
                }
            ],
            "doi": "10.1016/J.JMP.2008.12.005",
            "intent": [],
            "isInfluential": false,
            "paperId": "59bf2a4efdd6fce10f9d0e37ffc8ef689e35f315",
            "title": "Reinforcement learning in the brain",
            "url": "https://www.semanticscholar.org/paper/59bf2a4efdd6fce10f9d0e37ffc8ef689e35f315",
            "venue": "",
            "year": 2009
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "1718146",
                    "name": "R. Givan"
                },
                {
                    "authorId": "1680510",
                    "name": "T. Dean"
                },
                {
                    "authorId": "47158391",
                    "name": "M. Greig"
                }
            ],
            "doi": "10.1016/S0004-3702(02)00376-4",
            "intent": [],
            "isInfluential": false,
            "paperId": "2020aca3838a0e8a723761e74899b183d6b56f30",
            "title": "Equivalence notions and model minimization in Markov decision processes",
            "url": "https://www.semanticscholar.org/paper/2020aca3838a0e8a723761e74899b183d6b56f30",
            "venue": "Artif. Intell.",
            "year": 2003
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "1723632",
                    "name": "Balaraman Ravindran"
                },
                {
                    "authorId": "1730590",
                    "name": "A. Barto"
                }
            ],
            "doi": "10.1007/3-540-45622-8_15",
            "intent": [],
            "isInfluential": false,
            "paperId": "a6ed036a5523d8356085316116a805a2664d1e2b",
            "title": "Model Minimization in Hierarchical Reinforcement Learning",
            "url": "https://www.semanticscholar.org/paper/a6ed036a5523d8356085316116a805a2664d1e2b",
            "venue": "SARA",
            "year": 2002
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "107940205",
                    "name": "A. Bandura"
                }
            ],
            "doi": "10.1111/1467-839X.00024",
            "intent": [],
            "isInfluential": false,
            "paperId": "bb8c9fed9429ad2417b9caea8ff3c5407c58f876",
            "title": "Social cognitive theory: an agentic perspective.",
            "url": "https://www.semanticscholar.org/paper/bb8c9fed9429ad2417b9caea8ff3c5407c58f876",
            "venue": "Annual review of psychology",
            "year": 1999
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "2146199479",
                    "name": "Babatunde H. Giwa"
                },
                {
                    "authorId": "2143724945",
                    "name": "Chi-Guhn Lee"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "10a512bd46809b5ca9e3e174ec06c713b6a2da76",
            "title": "Estimation of Discount Factor in a Model-Based Inverse Reinforcement Learning Framework",
            "url": "https://www.semanticscholar.org/paper/10a512bd46809b5ca9e3e174ec06c713b6a2da76",
            "venue": "",
            "year": 2021
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "39187982",
                    "name": "Tobias Mutter"
                },
                {
                    "authorId": "3121115",
                    "name": "Dennis Kundisch"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "91e8dd20214e8ea8d261ee66bf5377e89bfdcd8f",
            "title": "Behavioral Mechanisms Prompted by Badges: The Goal-Gradient Hypothesis",
            "url": "https://www.semanticscholar.org/paper/91e8dd20214e8ea8d261ee66bf5377e89bfdcd8f",
            "venue": "ICIS",
            "year": 2014
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "47681372",
                    "name": "Lihong Li"
                },
                {
                    "authorId": "144926179",
                    "name": "Thomas J. Walsh"
                },
                {
                    "authorId": "144885169",
                    "name": "M. Littman"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "ca9a2d326b9de48c095a6cb5912e1990d2c5ab46",
            "title": "Towards a Unified Theory of State Abstraction for MDPs",
            "url": "https://www.semanticscholar.org/paper/ca9a2d326b9de48c095a6cb5912e1990d2c5ab46",
            "venue": "AI&M",
            "year": 2006
        },
        {
            "arxivId": null,
            "authors": [
                {
                    "authorId": "1723632",
                    "name": "Balaraman Ravindran"
                }
            ],
            "doi": null,
            "intent": [],
            "isInfluential": false,
            "paperId": "133583b9c4634702ab2579205ee3eb78714b7feb",
            "title": "Approximate Homomorphisms : A framework for non-exact minimization in Markov Decision Processes",
            "url": "https://www.semanticscholar.org/paper/133583b9c4634702ab2579205ee3eb78714b7feb",
            "venue": "",
            "year": null
        }
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Medicine",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "title": "Reinforcement Learning Interventions on Boundedly Rational Human Agents in Frictionful Tasks",
    "topics": [],
    "url": "https://www.semanticscholar.org/paper/880d3d952f95bc46cd447efaeb45a17d3cf05dd8",
    "venue": "Adaptive Agents and Multi-Agent Systems",
    "year": 2024
}
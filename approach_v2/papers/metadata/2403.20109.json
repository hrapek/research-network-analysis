{
    "abstract": "Optimizing techniques for discovering molecular structures with desired properties is crucial in artificial intelligence(AI)-based drug discovery. Combining deep generative models with reinforcement learning has emerged as an effective strategy for generating molecules with specific properties. Despite its potential, this approach is ineffective in exploring the vast chemical space and optimizing particular chemical properties. To overcome these limitations, we present Mol-AIR, a reinforcement learning-based framework using adaptive intrinsic rewards for effective goal-directed molecular generation. Mol-AIR leverages the strengths of both history-based and learning-based intrinsic rewards by exploiting random distillation network and counting-based strategies. In benchmark tests, Mol-AIR demonstrates superior performance over existing approaches in generating molecules with desired properties without any prior knowledge, including penalized LogP, QED, and celecoxib similarity. We believe that Mol-AIR represents a significant advancement in drug discovery, offering a more efficient path to discovering novel therapeutics.",
    "arxivId": "2403.20109",
    "authors": [
        {
            "authorId": "2294225468",
            "name": "Jinyeong Park",
            "url": "https://www.semanticscholar.org/author/2294225468"
        },
        {
            "authorId": "2294315662",
            "name": "Jaegyoon Ahn",
            "url": "https://www.semanticscholar.org/author/2294315662"
        },
        {
            "authorId": "29877537",
            "name": "Jonghwan Choi",
            "url": "https://www.semanticscholar.org/author/29877537"
        },
        {
            "authorId": "2294304119",
            "name": "Jibum Kim",
            "url": "https://www.semanticscholar.org/author/2294304119"
        }
    ],
    "citationVelocity": 0,
    "citations": [
        {
            "arxivId": "2410.10431",
            "authors": [
                {
                    "authorId": "2174737145",
                    "name": "Hampus Gummesson Svensson"
                },
                {
                    "authorId": "2231021",
                    "name": "C. Tyrchan"
                },
                {
                    "authorId": "2268590953",
                    "name": "Ola Engkvist"
                },
                {
                    "authorId": "31527457",
                    "name": "M. Chehreghani"
                }
            ],
            "doi": "10.48550/arXiv.2410.10431",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "5c5c38e842a823601f6c139ed34e05a4b726dbe8",
            "title": "Diversity-Aware Reinforcement Learning for de novo Drug Design",
            "url": "https://www.semanticscholar.org/paper/5c5c38e842a823601f6c139ed34e05a4b726dbe8",
            "venue": "ArXiv",
            "year": 2024
        }
    ],
    "corpusId": 268793684,
    "doi": "10.48550/arXiv.2403.20109",
    "fieldsOfStudy": [
        "Computer Science",
        "Biology"
    ],
    "influentialCitationCount": 0,
    "isOpenAccess": false,
    "isPublisherLicensed": true,
    "is_open_access": false,
    "is_publisher_licensed": true,
    "numCitedBy": 1,
    "numCiting": 10,
    "paperId": "34a1b39ded76621764814fe339cfbc69d9d7158b",
    "references": [
        {
            "arxivId": "2401.06771",
            "authors": [
                {
                    "authorId": "104856634",
                    "name": "M. Chadi"
                },
                {
                    "authorId": "2431019",
                    "name": "H. Mousannif"
                },
                {
                    "authorId": "2242943445",
                    "name": "Ahmed Aamouche"
                }
            ],
            "doi": "10.1109/ICITRI59340.2023.10249596",
            "intent": [
                "background"
            ],
            "isInfluential": false,
            "paperId": "d9247b9eeedc5ef03efd31c0def31980d9a6a681",
            "title": "Curiosity as a Self-Supervised Method to Improve Exploration in De Novo Drug Design",
            "url": "https://www.semanticscholar.org/paper/d9247b9eeedc5ef03efd31c0def31980d9a6a681",
            "venue": "2023 International Conference on Information Technology Research and Innovation (ICITRI)",
            "year": 2023
        },
        {
            "arxivId": "1705.05363",
            "authors": [
                {
                    "authorId": "38236002",
                    "name": "Deepak Pathak"
                },
                {
                    "authorId": "33932184",
                    "name": "Pulkit Agrawal"
                },
                {
                    "authorId": "1763086",
                    "name": "Alexei A. Efros"
                },
                {
                    "authorId": "1753210",
                    "name": "Trevor Darrell"
                }
            ],
            "doi": "10.1109/CVPRW.2017.70",
            "intent": [
                "background",
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "225ab689f41cef1dc18237ef5dab059a49950abf",
            "title": "Curiosity-Driven Exploration by Self-Supervised Prediction",
            "url": "https://www.semanticscholar.org/paper/225ab689f41cef1dc18237ef5dab059a49950abf",
            "venue": "2017 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)",
            "year": 2017
        },
        {
            "arxivId": "1703.01310",
            "authors": [
                {
                    "authorId": "2273072",
                    "name": "Georg Ostrovski"
                },
                {
                    "authorId": "1792298",
                    "name": "Marc G. Bellemare"
                },
                {
                    "authorId": "3422336",
                    "name": "A\u00e4ron van den Oord"
                },
                {
                    "authorId": "1708654",
                    "name": "R. Munos"
                }
            ],
            "doi": null,
            "intent": [
                "background",
                "methodology"
            ],
            "isInfluential": false,
            "paperId": "12f67fb182bc934fc95ce97acff553d83e2ca72e",
            "title": "Count-Based Exploration with Neural Density Models",
            "url": "https://www.semanticscholar.org/paper/12f67fb182bc934fc95ce97acff553d83e2ca72e",
            "venue": "ICML",
            "year": 2017
        }
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Biology",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        },
        {
            "category": "Chemistry",
            "source": "s2-fos-model"
        }
    ],
    "title": "Mol-AIR: Molecular Reinforcement Learning with Adaptive Intrinsic Rewards for Goal-directed Molecular Generation",
    "topics": [],
    "url": "https://www.semanticscholar.org/paper/34a1b39ded76621764814fe339cfbc69d9d7158b",
    "venue": "arXiv.org",
    "year": 2024
}